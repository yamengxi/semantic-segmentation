Torch version: 1.5, 1.5.0
dataset = cityscapes
ignore_label = 255
num_classes = 19
cv split val 2 ['train/monchengladbach', 'train/strasbourg', 'train/stuttgart']
mode val found 655 images
cn num_classes 19
cv split train 2 ['val/munster', 'val/lindau', 'val/frankfurt', 'train/aachen', 'train/bochum', 'train/bremen', 'train/cologne', 'train/darmstadt', 'train/dusseldorf', 'train/erfurt', 'train/hamburg', 'train/hanover', 'train/jena', 'train/krefeld', 'train/tubingen', 'train/ulm', 'train/weimar', 'train/zurich']
mode train found 2820 images
cn num_classes 19
Loading centroid file /var/tmp/fastseg-training/assets/uniform_centroids/cityscapes_cv2_tile1024.json
Found 19 centroids
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
Using Cross Entropy Loss
Trunk: mobilenetv3_small
Model params = 1.1M
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 0], [iter 1 / 176], [train main loss 6.299214], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 2 / 176], [train main loss 5.822591], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 3 / 176], [train main loss 5.049192], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 4 / 176], [train main loss 4.094681], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 5 / 176], [train main loss 3.960597], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 6 / 176], [train main loss 3.632369], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 7 / 176], [train main loss 3.796702], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 8 / 176], [train main loss 3.673273], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 9 / 176], [train main loss 3.539451], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 10 / 176], [train main loss 2.914237], [lr 0.010000] [batchtime 0]
[epoch 0], [iter 11 / 176], [train main loss 2.477383], [lr 0.010000] [batchtime 0.375]
[epoch 0], [iter 12 / 176], [train main loss 2.349707], [lr 0.010000] [batchtime 0.4]
[epoch 0], [iter 13 / 176], [train main loss 2.202244], [lr 0.010000] [batchtime 0.398]
[epoch 0], [iter 14 / 176], [train main loss 2.017304], [lr 0.010000] [batchtime 0.398]
[epoch 0], [iter 15 / 176], [train main loss 1.884004], [lr 0.010000] [batchtime 0.399]
[epoch 0], [iter 16 / 176], [train main loss 1.862458], [lr 0.010000] [batchtime 0.398]
[epoch 0], [iter 17 / 176], [train main loss 1.577562], [lr 0.010000] [batchtime 0.404]
[epoch 0], [iter 18 / 176], [train main loss 1.499263], [lr 0.010000] [batchtime 0.412]
[epoch 0], [iter 19 / 176], [train main loss 1.499737], [lr 0.010000] [batchtime 0.409]
[epoch 0], [iter 20 / 176], [train main loss 1.398202], [lr 0.010000] [batchtime 0.408]
[epoch 0], [iter 21 / 176], [train main loss 1.223272], [lr 0.010000] [batchtime 0.406]
[epoch 0], [iter 22 / 176], [train main loss 1.104127], [lr 0.010000] [batchtime 0.405]
[epoch 0], [iter 23 / 176], [train main loss 1.058382], [lr 0.010000] [batchtime 0.405]
[epoch 0], [iter 24 / 176], [train main loss 1.109160], [lr 0.010000] [batchtime 0.404]
[epoch 0], [iter 25 / 176], [train main loss 1.037685], [lr 0.010000] [batchtime 0.403]
[epoch 0], [iter 26 / 176], [train main loss 0.943785], [lr 0.010000] [batchtime 0.403]
[epoch 0], [iter 27 / 176], [train main loss 0.999954], [lr 0.010000] [batchtime 0.403]
[epoch 0], [iter 28 / 176], [train main loss 1.002356], [lr 0.010000] [batchtime 0.403]
[epoch 0], [iter 29 / 176], [train main loss 0.884816], [lr 0.010000] [batchtime 0.402]
[epoch 0], [iter 30 / 176], [train main loss 0.884878], [lr 0.010000] [batchtime 0.402]
[epoch 0], [iter 31 / 176], [train main loss 0.798169], [lr 0.010000] [batchtime 0.402]
[epoch 0], [iter 32 / 176], [train main loss 0.723242], [lr 0.010000] [batchtime 0.401]
[epoch 0], [iter 33 / 176], [train main loss 0.637272], [lr 0.010000] [batchtime 0.401]
[epoch 0], [iter 34 / 176], [train main loss 0.489168], [lr 0.010000] [batchtime 0.407]
[epoch 0], [iter 35 / 176], [train main loss 0.393964], [lr 0.010000] [batchtime 0.406]
[epoch 0], [iter 36 / 176], [train main loss 0.352245], [lr 0.010000] [batchtime 0.406]
[epoch 0], [iter 37 / 176], [train main loss 0.368317], [lr 0.010000] [batchtime 0.405]
[epoch 0], [iter 38 / 176], [train main loss 0.390942], [lr 0.010000] [batchtime 0.404]
[epoch 0], [iter 39 / 176], [train main loss 0.390437], [lr 0.010000] [batchtime 0.404]
[epoch 0], [iter 40 / 176], [train main loss 0.374120], [lr 0.010000] [batchtime 0.404]
[epoch 0], [iter 41 / 176], [train main loss 0.324801], [lr 0.010000] [batchtime 0.407]
[epoch 0], [iter 42 / 176], [train main loss 0.251067], [lr 0.010000] [batchtime 0.435]
[epoch 0], [iter 43 / 176], [train main loss 0.175771], [lr 0.010000] [batchtime 0.434]
[epoch 0], [iter 44 / 176], [train main loss 0.135724], [lr 0.010000] [batchtime 0.432]
[epoch 0], [iter 45 / 176], [train main loss 0.120184], [lr 0.010000] [batchtime 0.431]
[epoch 0], [iter 46 / 176], [train main loss 0.094872], [lr 0.010000] [batchtime 0.43]
[epoch 0], [iter 47 / 176], [train main loss 0.104249], [lr 0.010000] [batchtime 0.429]
[epoch 0], [iter 48 / 176], [train main loss 0.046237], [lr 0.010000] [batchtime 0.428]
[epoch 0], [iter 49 / 176], [train main loss 0.048735], [lr 0.010000] [batchtime 0.427]
[epoch 0], [iter 50 / 176], [train main loss -0.021960], [lr 0.010000] [batchtime 0.427]
[epoch 0], [iter 51 / 176], [train main loss 0.041866], [lr 0.010000] [batchtime 0.426]
[epoch 0], [iter 52 / 176], [train main loss 0.060355], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 53 / 176], [train main loss 0.031788], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 54 / 176], [train main loss 0.011968], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 55 / 176], [train main loss -0.014338], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 56 / 176], [train main loss -0.035562], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 57 / 176], [train main loss -0.046014], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 58 / 176], [train main loss -0.088033], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 59 / 176], [train main loss -0.109772], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 60 / 176], [train main loss -0.074426], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 61 / 176], [train main loss -0.029388], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 62 / 176], [train main loss -0.055785], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 63 / 176], [train main loss -0.080848], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 64 / 176], [train main loss -0.082496], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 65 / 176], [train main loss -0.052265], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 66 / 176], [train main loss -0.044410], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 67 / 176], [train main loss -0.055631], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 68 / 176], [train main loss -0.054103], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 69 / 176], [train main loss -0.047941], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 70 / 176], [train main loss -0.062153], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 71 / 176], [train main loss -0.058738], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 72 / 176], [train main loss -0.071337], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 73 / 176], [train main loss -0.082467], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 74 / 176], [train main loss -0.072918], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 75 / 176], [train main loss -0.070834], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 76 / 176], [train main loss -0.088015], [lr 0.010000] [batchtime 0.415]
[epoch 0], [iter 77 / 176], [train main loss -0.113464], [lr 0.010000] [batchtime 0.415]
[epoch 0], [iter 78 / 176], [train main loss -0.102185], [lr 0.010000] [batchtime 0.415]
[epoch 0], [iter 79 / 176], [train main loss -0.117183], [lr 0.010000] [batchtime 0.414]
[epoch 0], [iter 80 / 176], [train main loss -0.095013], [lr 0.010000] [batchtime 0.414]
[epoch 0], [iter 81 / 176], [train main loss -0.102405], [lr 0.010000] [batchtime 0.414]
[epoch 0], [iter 82 / 176], [train main loss -0.128941], [lr 0.010000] [batchtime 0.413]
[epoch 0], [iter 83 / 176], [train main loss -0.150232], [lr 0.010000] [batchtime 0.413]
[epoch 0], [iter 84 / 176], [train main loss -0.132352], [lr 0.010000] [batchtime 0.413]
[epoch 0], [iter 85 / 176], [train main loss -0.104967], [lr 0.010000] [batchtime 0.413]
[epoch 0], [iter 86 / 176], [train main loss -0.121414], [lr 0.010000] [batchtime 0.413]
[epoch 0], [iter 87 / 176], [train main loss -0.106752], [lr 0.010000] [batchtime 0.412]
[epoch 0], [iter 88 / 176], [train main loss -0.114326], [lr 0.010000] [batchtime 0.412]
[epoch 0], [iter 89 / 176], [train main loss -0.120290], [lr 0.010000] [batchtime 0.414]
[epoch 0], [iter 90 / 176], [train main loss -0.120540], [lr 0.010000] [batchtime 0.429]
[epoch 0], [iter 91 / 176], [train main loss -0.116595], [lr 0.010000] [batchtime 0.428]
[epoch 0], [iter 92 / 176], [train main loss -0.108087], [lr 0.010000] [batchtime 0.428]
[epoch 0], [iter 93 / 176], [train main loss -0.123597], [lr 0.010000] [batchtime 0.427]
[epoch 0], [iter 94 / 176], [train main loss -0.127280], [lr 0.010000] [batchtime 0.427]
[epoch 0], [iter 95 / 176], [train main loss -0.139990], [lr 0.010000] [batchtime 0.426]
[epoch 0], [iter 96 / 176], [train main loss -0.133321], [lr 0.010000] [batchtime 0.426]
[epoch 0], [iter 97 / 176], [train main loss -0.128862], [lr 0.010000] [batchtime 0.426]
[epoch 0], [iter 98 / 176], [train main loss -0.087736], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 99 / 176], [train main loss -0.083436], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 100 / 176], [train main loss -0.104832], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 101 / 176], [train main loss -0.103657], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 102 / 176], [train main loss -0.086026], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 103 / 176], [train main loss -0.104766], [lr 0.010000] [batchtime 0.427]
[epoch 0], [iter 104 / 176], [train main loss -0.103997], [lr 0.010000] [batchtime 0.426]
[epoch 0], [iter 105 / 176], [train main loss -0.090584], [lr 0.010000] [batchtime 0.426]
[epoch 0], [iter 106 / 176], [train main loss -0.108509], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 107 / 176], [train main loss -0.133490], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 108 / 176], [train main loss -0.127850], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 109 / 176], [train main loss -0.133497], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 110 / 176], [train main loss -0.137592], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 111 / 176], [train main loss -0.107745], [lr 0.010000] [batchtime 0.425]
[epoch 0], [iter 112 / 176], [train main loss -0.114181], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 113 / 176], [train main loss -0.112709], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 114 / 176], [train main loss -0.113599], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 115 / 176], [train main loss -0.148084], [lr 0.010000] [batchtime 0.424]
[epoch 0], [iter 116 / 176], [train main loss -0.133737], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 117 / 176], [train main loss -0.125019], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 118 / 176], [train main loss -0.148354], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 119 / 176], [train main loss -0.175638], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 120 / 176], [train main loss -0.179126], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 121 / 176], [train main loss -0.188909], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 122 / 176], [train main loss -0.197232], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 123 / 176], [train main loss -0.209516], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 124 / 176], [train main loss -0.225159], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 125 / 176], [train main loss -0.232611], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 126 / 176], [train main loss -0.224109], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 127 / 176], [train main loss -0.222285], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 128 / 176], [train main loss -0.223397], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 129 / 176], [train main loss -0.217042], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 130 / 176], [train main loss -0.200638], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 131 / 176], [train main loss -0.207742], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 132 / 176], [train main loss -0.204744], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 133 / 176], [train main loss -0.206718], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 134 / 176], [train main loss -0.200209], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 135 / 176], [train main loss -0.192841], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 136 / 176], [train main loss -0.188845], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 137 / 176], [train main loss -0.198599], [lr 0.010000] [batchtime 0.423]
[epoch 0], [iter 138 / 176], [train main loss -0.209161], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 139 / 176], [train main loss -0.213244], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 140 / 176], [train main loss -0.205538], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 141 / 176], [train main loss -0.210538], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 142 / 176], [train main loss -0.224459], [lr 0.010000] [batchtime 0.422]
[epoch 0], [iter 143 / 176], [train main loss -0.215844], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 144 / 176], [train main loss -0.218150], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 145 / 176], [train main loss -0.209876], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 146 / 176], [train main loss -0.203628], [lr 0.010000] [batchtime 0.421]
[epoch 0], [iter 147 / 176], [train main loss -0.186351], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 148 / 176], [train main loss -0.189825], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 149 / 176], [train main loss -0.183632], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 150 / 176], [train main loss -0.190040], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 151 / 176], [train main loss -0.178089], [lr 0.010000] [batchtime 0.42]
[epoch 0], [iter 152 / 176], [train main loss -0.193294], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 153 / 176], [train main loss -0.193136], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 154 / 176], [train main loss -0.202908], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 155 / 176], [train main loss -0.194136], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 156 / 176], [train main loss -0.197085], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 157 / 176], [train main loss -0.206387], [lr 0.010000] [batchtime 0.419]
[epoch 0], [iter 158 / 176], [train main loss -0.207687], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 159 / 176], [train main loss -0.222850], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 160 / 176], [train main loss -0.215263], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 161 / 176], [train main loss -0.213138], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 162 / 176], [train main loss -0.212737], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 163 / 176], [train main loss -0.218462], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 164 / 176], [train main loss -0.211604], [lr 0.010000] [batchtime 0.418]
[epoch 0], [iter 165 / 176], [train main loss -0.214854], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 166 / 176], [train main loss -0.210989], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 167 / 176], [train main loss -0.203281], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 168 / 176], [train main loss -0.192662], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 169 / 176], [train main loss -0.186220], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 170 / 176], [train main loss -0.181908], [lr 0.010000] [batchtime 0.417]
[epoch 0], [iter 171 / 176], [train main loss -0.186068], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 172 / 176], [train main loss -0.177977], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 173 / 176], [train main loss -0.170305], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 174 / 176], [train main loss -0.180776], [lr 0.010000] [batchtime 0.416]
[epoch 0], [iter 175 / 176], [train main loss -0.177770], [lr 0.010000] [batchtime 0.415]
[epoch 0], [iter 176 / 176], [train main loss -0.180935], [lr 0.010000] [batchtime 0.415]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP           FP      FN    Precision    Recall
----  -------------  --------  -----  -----------  ------  -----------  --------
   0  road              69.25  35.24         0.03    0.41         0.97      0.71
   1  sidewalk           0.00   0.00  25883118.00   32.67         0.00      0.03
   2  building          34.83  11.82         1.25    0.62         0.44      0.62
   3  wall               0.00   0.00       inf     nan            0.00    nan
   4  fence              0.00   0.00       inf     nan            0.00    nan
   5  pole               0.00   0.00       inf     nan            0.00    nan
   6  traffic light      0.00   0.00       inf     nan            0.00    nan
   7  traffic sign       0.00   0.00       inf     nan            0.00    nan
   8  vegetation        37.86   9.91         0.25    1.39         0.80      0.42
   9  terrain            0.00   0.00       inf     nan            0.00    nan
  10  sky               57.57   3.32         0.17    0.57         0.86      0.64
  11  person             0.00   0.00       inf     nan            0.00    nan
  12  rider              0.00   0.00       inf     nan            0.00    nan
  13  car                9.67   0.81         7.73    1.61         0.11      0.38
  14  truck              0.00   0.00       inf     nan            0.00    nan
  15  bus                0.00   0.00       inf     nan            0.00    nan
  16  train              0.00   0.00       inf     nan            0.00    nan
  17  motorcycle         0.00   0.00       inf     nan            0.00    nan
  18  bicycle            0.00   0.00       inf     nan            0.00    nan
Mean: 11.01
-----------------------------------------------------------------------------------------------------------
this : [epoch 0], [val loss 1.29325], [acc 0.61100], [acc_cls 0.16777], [mean_iu 0.11009], [fwavacc 0.42030]
best : [epoch 0], [val loss 1.29325], [acc 0.61100], [acc_cls 0.16777], [mean_iu 0.11009], [fwavacc 0.42030]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 1], [iter 1 / 176], [train main loss -0.711205], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 2 / 176], [train main loss -2.893027], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 3 / 176], [train main loss -2.195601], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 4 / 176], [train main loss -2.329842], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 5 / 176], [train main loss -2.164031], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 6 / 176], [train main loss -2.039798], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 7 / 176], [train main loss -1.589975], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 8 / 176], [train main loss -1.843117], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 9 / 176], [train main loss -1.894553], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 10 / 176], [train main loss -1.407607], [lr 0.009943] [batchtime 0]
[epoch 1], [iter 11 / 176], [train main loss -1.428148], [lr 0.009943] [batchtime 0.362]
[epoch 1], [iter 12 / 176], [train main loss -1.336291], [lr 0.009943] [batchtime 0.377]
[epoch 1], [iter 13 / 176], [train main loss -1.424612], [lr 0.009943] [batchtime 0.384]
[epoch 1], [iter 14 / 176], [train main loss -1.615884], [lr 0.009943] [batchtime 0.39]
[epoch 1], [iter 15 / 176], [train main loss -1.502464], [lr 0.009943] [batchtime 0.393]
[epoch 1], [iter 16 / 176], [train main loss -1.629484], [lr 0.009943] [batchtime 0.394]
[epoch 1], [iter 17 / 176], [train main loss -1.535009], [lr 0.009943] [batchtime 0.395]
[epoch 1], [iter 18 / 176], [train main loss -1.356877], [lr 0.009943] [batchtime 0.397]
[epoch 1], [iter 19 / 176], [train main loss -1.430740], [lr 0.009943] [batchtime 0.4]
[epoch 1], [iter 20 / 176], [train main loss -1.457045], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 21 / 176], [train main loss -1.427378], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 22 / 176], [train main loss -1.337787], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 23 / 176], [train main loss -1.509461], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 24 / 176], [train main loss -1.471415], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 25 / 176], [train main loss -1.457578], [lr 0.009943] [batchtime 0.402]
[epoch 1], [iter 26 / 176], [train main loss -1.413693], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 27 / 176], [train main loss -1.332072], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 28 / 176], [train main loss -1.273134], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 29 / 176], [train main loss -1.211757], [lr 0.009943] [batchtime 0.401]
[epoch 1], [iter 30 / 176], [train main loss -1.192157], [lr 0.009943] [batchtime 0.478]
[epoch 1], [iter 31 / 176], [train main loss -1.048317], [lr 0.009943] [batchtime 0.481]
[epoch 1], [iter 32 / 176], [train main loss -1.023698], [lr 0.009943] [batchtime 0.478]
[epoch 1], [iter 33 / 176], [train main loss -0.976140], [lr 0.009943] [batchtime 0.475]
[epoch 1], [iter 34 / 176], [train main loss -0.986013], [lr 0.009943] [batchtime 0.471]
[epoch 1], [iter 35 / 176], [train main loss -0.899220], [lr 0.009943] [batchtime 0.469]
[epoch 1], [iter 36 / 176], [train main loss -0.875266], [lr 0.009943] [batchtime 0.465]
[epoch 1], [iter 37 / 176], [train main loss -0.929145], [lr 0.009943] [batchtime 0.463]
[epoch 1], [iter 38 / 176], [train main loss -0.878720], [lr 0.009943] [batchtime 0.461]
[epoch 1], [iter 39 / 176], [train main loss -0.929537], [lr 0.009943] [batchtime 0.459]
[epoch 1], [iter 40 / 176], [train main loss -0.928793], [lr 0.009943] [batchtime 0.457]
[epoch 1], [iter 41 / 176], [train main loss -0.936120], [lr 0.009943] [batchtime 0.455]
[epoch 1], [iter 42 / 176], [train main loss -0.918981], [lr 0.009943] [batchtime 0.454]
[epoch 1], [iter 43 / 176], [train main loss -0.899457], [lr 0.009943] [batchtime 0.452]
[epoch 1], [iter 44 / 176], [train main loss -0.904059], [lr 0.009943] [batchtime 0.45]
[epoch 1], [iter 45 / 176], [train main loss -0.878342], [lr 0.009943] [batchtime 0.449]
[epoch 1], [iter 46 / 176], [train main loss -0.901901], [lr 0.009943] [batchtime 0.448]
[epoch 1], [iter 47 / 176], [train main loss -0.941587], [lr 0.009943] [batchtime 0.446]
[epoch 1], [iter 48 / 176], [train main loss -0.917413], [lr 0.009943] [batchtime 0.445]
[epoch 1], [iter 49 / 176], [train main loss -0.970819], [lr 0.009943] [batchtime 0.444]
[epoch 1], [iter 50 / 176], [train main loss -0.917543], [lr 0.009943] [batchtime 0.443]
[epoch 1], [iter 51 / 176], [train main loss -0.864774], [lr 0.009943] [batchtime 0.442]
[epoch 1], [iter 52 / 176], [train main loss -0.906450], [lr 0.009943] [batchtime 0.441]
[epoch 1], [iter 53 / 176], [train main loss -0.920769], [lr 0.009943] [batchtime 0.439]
[epoch 1], [iter 54 / 176], [train main loss -0.897931], [lr 0.009943] [batchtime 0.439]
[epoch 1], [iter 55 / 176], [train main loss -0.894627], [lr 0.009943] [batchtime 0.438]
[epoch 1], [iter 56 / 176], [train main loss -0.831081], [lr 0.009943] [batchtime 0.437]
[epoch 1], [iter 57 / 176], [train main loss -0.862454], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 58 / 176], [train main loss -0.882931], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 59 / 176], [train main loss -0.900271], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 60 / 176], [train main loss -0.878580], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 61 / 176], [train main loss -0.887304], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 62 / 176], [train main loss -0.861063], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 63 / 176], [train main loss -0.792196], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 64 / 176], [train main loss -0.779273], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 65 / 176], [train main loss -0.759485], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 66 / 176], [train main loss -0.750719], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 67 / 176], [train main loss -0.740627], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 68 / 176], [train main loss -0.730147], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 69 / 176], [train main loss -0.700890], [lr 0.009943] [batchtime 0.428]
[epoch 1], [iter 70 / 176], [train main loss -0.644151], [lr 0.009943] [batchtime 0.428]
[epoch 1], [iter 71 / 176], [train main loss -0.656580], [lr 0.009943] [batchtime 0.428]
[epoch 1], [iter 72 / 176], [train main loss -0.641741], [lr 0.009943] [batchtime 0.427]
[epoch 1], [iter 73 / 176], [train main loss -0.711954], [lr 0.009943] [batchtime 0.427]
[epoch 1], [iter 74 / 176], [train main loss -0.705335], [lr 0.009943] [batchtime 0.426]
[epoch 1], [iter 75 / 176], [train main loss -0.681658], [lr 0.009943] [batchtime 0.426]
[epoch 1], [iter 76 / 176], [train main loss -0.687016], [lr 0.009943] [batchtime 0.446]
[epoch 1], [iter 77 / 176], [train main loss -0.711820], [lr 0.009943] [batchtime 0.447]
[epoch 1], [iter 78 / 176], [train main loss -0.716331], [lr 0.009943] [batchtime 0.446]
[epoch 1], [iter 79 / 176], [train main loss -0.692438], [lr 0.009943] [batchtime 0.445]
[epoch 1], [iter 80 / 176], [train main loss -0.716012], [lr 0.009943] [batchtime 0.444]
[epoch 1], [iter 81 / 176], [train main loss -0.678590], [lr 0.009943] [batchtime 0.444]
[epoch 1], [iter 82 / 176], [train main loss -0.672898], [lr 0.009943] [batchtime 0.443]
[epoch 1], [iter 83 / 176], [train main loss -0.688641], [lr 0.009943] [batchtime 0.443]
[epoch 1], [iter 84 / 176], [train main loss -0.679976], [lr 0.009943] [batchtime 0.442]
[epoch 1], [iter 85 / 176], [train main loss -0.693083], [lr 0.009943] [batchtime 0.441]
[epoch 1], [iter 86 / 176], [train main loss -0.713841], [lr 0.009943] [batchtime 0.441]
[epoch 1], [iter 87 / 176], [train main loss -0.719341], [lr 0.009943] [batchtime 0.441]
[epoch 1], [iter 88 / 176], [train main loss -0.739178], [lr 0.009943] [batchtime 0.44]
[epoch 1], [iter 89 / 176], [train main loss -0.720394], [lr 0.009943] [batchtime 0.44]
[epoch 1], [iter 90 / 176], [train main loss -0.728377], [lr 0.009943] [batchtime 0.439]
[epoch 1], [iter 91 / 176], [train main loss -0.720239], [lr 0.009943] [batchtime 0.439]
[epoch 1], [iter 92 / 176], [train main loss -0.723781], [lr 0.009943] [batchtime 0.438]
[epoch 1], [iter 93 / 176], [train main loss -0.739077], [lr 0.009943] [batchtime 0.438]
[epoch 1], [iter 94 / 176], [train main loss -0.732069], [lr 0.009943] [batchtime 0.437]
[epoch 1], [iter 95 / 176], [train main loss -0.735854], [lr 0.009943] [batchtime 0.437]
[epoch 1], [iter 96 / 176], [train main loss -0.759338], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 97 / 176], [train main loss -0.772407], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 98 / 176], [train main loss -0.783151], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 99 / 176], [train main loss -0.770688], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 100 / 176], [train main loss -0.772792], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 101 / 176], [train main loss -0.763224], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 102 / 176], [train main loss -0.766743], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 103 / 176], [train main loss -0.756460], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 104 / 176], [train main loss -0.751751], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 105 / 176], [train main loss -0.741457], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 106 / 176], [train main loss -0.744720], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 107 / 176], [train main loss -0.725006], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 108 / 176], [train main loss -0.734059], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 109 / 176], [train main loss -0.721600], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 110 / 176], [train main loss -0.703457], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 111 / 176], [train main loss -0.709664], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 112 / 176], [train main loss -0.715202], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 113 / 176], [train main loss -0.715703], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 114 / 176], [train main loss -0.737477], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 115 / 176], [train main loss -0.741564], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 116 / 176], [train main loss -0.726469], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 117 / 176], [train main loss -0.740869], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 118 / 176], [train main loss -0.748561], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 119 / 176], [train main loss -0.761195], [lr 0.009943] [batchtime 0.428]
[epoch 1], [iter 120 / 176], [train main loss -0.773611], [lr 0.009943] [batchtime 0.428]
[epoch 1], [iter 121 / 176], [train main loss -0.799533], [lr 0.009943] [batchtime 0.428]
[epoch 1], [iter 122 / 176], [train main loss -0.809463], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 123 / 176], [train main loss -0.781566], [lr 0.009943] [batchtime 0.441]
[epoch 1], [iter 124 / 176], [train main loss -0.789030], [lr 0.009943] [batchtime 0.441]
[epoch 1], [iter 125 / 176], [train main loss -0.802301], [lr 0.009943] [batchtime 0.44]
[epoch 1], [iter 126 / 176], [train main loss -0.799054], [lr 0.009943] [batchtime 0.44]
[epoch 1], [iter 127 / 176], [train main loss -0.807217], [lr 0.009943] [batchtime 0.44]
[epoch 1], [iter 128 / 176], [train main loss -0.783445], [lr 0.009943] [batchtime 0.439]
[epoch 1], [iter 129 / 176], [train main loss -0.788251], [lr 0.009943] [batchtime 0.439]
[epoch 1], [iter 130 / 176], [train main loss -0.815016], [lr 0.009943] [batchtime 0.438]
[epoch 1], [iter 131 / 176], [train main loss -0.804842], [lr 0.009943] [batchtime 0.438]
[epoch 1], [iter 132 / 176], [train main loss -0.823338], [lr 0.009943] [batchtime 0.438]
[epoch 1], [iter 133 / 176], [train main loss -0.817999], [lr 0.009943] [batchtime 0.437]
[epoch 1], [iter 134 / 176], [train main loss -0.824051], [lr 0.009943] [batchtime 0.437]
[epoch 1], [iter 135 / 176], [train main loss -0.809721], [lr 0.009943] [batchtime 0.437]
[epoch 1], [iter 136 / 176], [train main loss -0.794548], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 137 / 176], [train main loss -0.788325], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 138 / 176], [train main loss -0.786280], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 139 / 176], [train main loss -0.771141], [lr 0.009943] [batchtime 0.436]
[epoch 1], [iter 140 / 176], [train main loss -0.754179], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 141 / 176], [train main loss -0.749427], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 142 / 176], [train main loss -0.757829], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 143 / 176], [train main loss -0.745923], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 144 / 176], [train main loss -0.750375], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 145 / 176], [train main loss -0.768282], [lr 0.009943] [batchtime 0.435]
[epoch 1], [iter 146 / 176], [train main loss -0.769913], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 147 / 176], [train main loss -0.747877], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 148 / 176], [train main loss -0.732767], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 149 / 176], [train main loss -0.730249], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 150 / 176], [train main loss -0.732347], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 151 / 176], [train main loss -0.728417], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 152 / 176], [train main loss -0.732215], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 153 / 176], [train main loss -0.714953], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 154 / 176], [train main loss -0.723309], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 155 / 176], [train main loss -0.728471], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 156 / 176], [train main loss -0.717885], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 157 / 176], [train main loss -0.708604], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 158 / 176], [train main loss -0.729073], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 159 / 176], [train main loss -0.743475], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 160 / 176], [train main loss -0.740219], [lr 0.009943] [batchtime 0.431]
[epoch 1], [iter 161 / 176], [train main loss -0.728024], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 162 / 176], [train main loss -0.728179], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 163 / 176], [train main loss -0.736307], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 164 / 176], [train main loss -0.736998], [lr 0.009943] [batchtime 0.43]
[epoch 1], [iter 165 / 176], [train main loss -0.750398], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 166 / 176], [train main loss -0.758161], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 167 / 176], [train main loss -0.770390], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 168 / 176], [train main loss -0.758737], [lr 0.009943] [batchtime 0.429]
[epoch 1], [iter 169 / 176], [train main loss -0.755781], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 170 / 176], [train main loss -0.771934], [lr 0.009943] [batchtime 0.434]
[epoch 1], [iter 171 / 176], [train main loss -0.767332], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 172 / 176], [train main loss -0.762944], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 173 / 176], [train main loss -0.755430], [lr 0.009943] [batchtime 0.433]
[epoch 1], [iter 174 / 176], [train main loss -0.756141], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 175 / 176], [train main loss -0.764894], [lr 0.009943] [batchtime 0.432]
[epoch 1], [iter 176 / 176], [train main loss -0.769019], [lr 0.009943] [batchtime 0.432]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              73.71  35.50    0.02    0.33         0.98      0.75
   1  sidewalk           0.38   0.03  258.42    6.10         0.00      0.14
   2  building          40.30  13.33    0.99    0.49         0.50      0.67
   3  wall               0.00   0.00  inf     nan            0.00    nan
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               0.00   0.00  inf     nan            0.00    nan
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       0.15   0.00  663.89    0.06         0.00      0.94
   8  vegetation        40.14  10.09    0.23    1.27         0.82      0.44
   9  terrain            1.46   0.01   64.59    2.72         0.02      0.27
  10  sky               65.69   3.47    0.12    0.41         0.90      0.71
  11  person             0.00   0.00  inf     nan            0.00    nan
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               21.62   2.13    2.32    1.31         0.30      0.43
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            0.00   0.00  inf     nan            0.00    nan
Mean: 12.81
-----------------------------------------------------------------------------------------------------------
this : [epoch 1], [val loss 1.05094], [acc 0.64552], [acc_cls 0.18480], [mean_iu 0.12813], [fwavacc 0.46583]
best : [epoch 1], [val loss 1.05094], [acc 0.64552], [acc_cls 0.18480], [mean_iu 0.12813], [fwavacc 0.46583]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 2], [iter 1 / 176], [train main loss -1.129473], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 2 / 176], [train main loss -0.516523], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 3 / 176], [train main loss -0.574617], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 4 / 176], [train main loss -0.499802], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 5 / 176], [train main loss -0.476173], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 6 / 176], [train main loss -0.466887], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 7 / 176], [train main loss -0.340707], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 8 / 176], [train main loss -0.584397], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 9 / 176], [train main loss -0.559859], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 10 / 176], [train main loss -0.380817], [lr 0.009886] [batchtime 0]
[epoch 2], [iter 11 / 176], [train main loss -0.301198], [lr 0.009886] [batchtime 0.373]
[epoch 2], [iter 12 / 176], [train main loss -0.370484], [lr 0.009886] [batchtime 0.398]
[epoch 2], [iter 13 / 176], [train main loss -0.568328], [lr 0.009886] [batchtime 0.398]
[epoch 2], [iter 14 / 176], [train main loss -0.821590], [lr 0.009886] [batchtime 0.406]
[epoch 2], [iter 15 / 176], [train main loss -0.758830], [lr 0.009886] [batchtime 0.443]
[epoch 2], [iter 16 / 176], [train main loss -0.795564], [lr 0.009886] [batchtime 0.436]
[epoch 2], [iter 17 / 176], [train main loss -0.772965], [lr 0.009886] [batchtime 0.431]
[epoch 2], [iter 18 / 176], [train main loss -0.936966], [lr 0.009886] [batchtime 0.427]
[epoch 2], [iter 19 / 176], [train main loss -0.947378], [lr 0.009886] [batchtime 0.425]
[epoch 2], [iter 20 / 176], [train main loss -1.148342], [lr 0.009886] [batchtime 0.421]
[epoch 2], [iter 21 / 176], [train main loss -1.018483], [lr 0.009886] [batchtime 0.42]
[epoch 2], [iter 22 / 176], [train main loss -1.004834], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 23 / 176], [train main loss -0.994521], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 24 / 176], [train main loss -0.954281], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 25 / 176], [train main loss -0.884082], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 26 / 176], [train main loss -0.772797], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 27 / 176], [train main loss -0.807080], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 28 / 176], [train main loss -0.948250], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 29 / 176], [train main loss -1.017058], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 30 / 176], [train main loss -0.953491], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 31 / 176], [train main loss -0.895111], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 32 / 176], [train main loss -0.860855], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 33 / 176], [train main loss -0.794161], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 34 / 176], [train main loss -0.801935], [lr 0.009886] [batchtime 0.409]
[epoch 2], [iter 35 / 176], [train main loss -0.805495], [lr 0.009886] [batchtime 0.409]
[epoch 2], [iter 36 / 176], [train main loss -0.815478], [lr 0.009886] [batchtime 0.408]
[epoch 2], [iter 37 / 176], [train main loss -0.786924], [lr 0.009886] [batchtime 0.408]
[epoch 2], [iter 38 / 176], [train main loss -0.830980], [lr 0.009886] [batchtime 0.407]
[epoch 2], [iter 39 / 176], [train main loss -0.858624], [lr 0.009886] [batchtime 0.427]
[epoch 2], [iter 40 / 176], [train main loss -0.911725], [lr 0.009886] [batchtime 0.426]
[epoch 2], [iter 41 / 176], [train main loss -0.896128], [lr 0.009886] [batchtime 0.425]
[epoch 2], [iter 42 / 176], [train main loss -0.893275], [lr 0.009886] [batchtime 0.424]
[epoch 2], [iter 43 / 176], [train main loss -0.889706], [lr 0.009886] [batchtime 0.424]
[epoch 2], [iter 44 / 176], [train main loss -0.870081], [lr 0.009886] [batchtime 0.423]
[epoch 2], [iter 45 / 176], [train main loss -0.827256], [lr 0.009886] [batchtime 0.422]
[epoch 2], [iter 46 / 176], [train main loss -0.823909], [lr 0.009886] [batchtime 0.422]
[epoch 2], [iter 47 / 176], [train main loss -0.802514], [lr 0.009886] [batchtime 0.421]
[epoch 2], [iter 48 / 176], [train main loss -0.804022], [lr 0.009886] [batchtime 0.42]
[epoch 2], [iter 49 / 176], [train main loss -0.791155], [lr 0.009886] [batchtime 0.42]
[epoch 2], [iter 50 / 176], [train main loss -0.746328], [lr 0.009886] [batchtime 0.419]
[epoch 2], [iter 51 / 176], [train main loss -0.759273], [lr 0.009886] [batchtime 0.419]
[epoch 2], [iter 52 / 176], [train main loss -0.726964], [lr 0.009886] [batchtime 0.419]
[epoch 2], [iter 53 / 176], [train main loss -0.754675], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 54 / 176], [train main loss -0.803850], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 55 / 176], [train main loss -0.759527], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 56 / 176], [train main loss -0.735714], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 57 / 176], [train main loss -0.738412], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 58 / 176], [train main loss -0.747077], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 59 / 176], [train main loss -0.786312], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 60 / 176], [train main loss -0.776391], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 61 / 176], [train main loss -0.754216], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 62 / 176], [train main loss -0.770755], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 63 / 176], [train main loss -0.768901], [lr 0.009886] [batchtime 0.419]
[epoch 2], [iter 64 / 176], [train main loss -0.771399], [lr 0.009886] [batchtime 0.419]
[epoch 2], [iter 65 / 176], [train main loss -0.794876], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 66 / 176], [train main loss -0.832674], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 67 / 176], [train main loss -0.798192], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 68 / 176], [train main loss -0.799977], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 69 / 176], [train main loss -0.761730], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 70 / 176], [train main loss -0.757654], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 71 / 176], [train main loss -0.776101], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 72 / 176], [train main loss -0.838376], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 73 / 176], [train main loss -0.826768], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 74 / 176], [train main loss -0.811312], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 75 / 176], [train main loss -0.808542], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 76 / 176], [train main loss -0.807125], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 77 / 176], [train main loss -0.776201], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 78 / 176], [train main loss -0.767071], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 79 / 176], [train main loss -0.786219], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 80 / 176], [train main loss -0.792858], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 81 / 176], [train main loss -0.789431], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 82 / 176], [train main loss -0.784557], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 83 / 176], [train main loss -0.806189], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 84 / 176], [train main loss -0.777707], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 85 / 176], [train main loss -0.778741], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 86 / 176], [train main loss -0.749655], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 87 / 176], [train main loss -0.757576], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 88 / 176], [train main loss -0.729989], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 89 / 176], [train main loss -0.746927], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 90 / 176], [train main loss -0.751723], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 91 / 176], [train main loss -0.750163], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 92 / 176], [train main loss -0.766567], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 93 / 176], [train main loss -0.752356], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 94 / 176], [train main loss -0.759024], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 95 / 176], [train main loss -0.776291], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 96 / 176], [train main loss -0.785350], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 97 / 176], [train main loss -0.783357], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 98 / 176], [train main loss -0.774956], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 99 / 176], [train main loss -0.767104], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 100 / 176], [train main loss -0.780369], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 101 / 176], [train main loss -0.792673], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 102 / 176], [train main loss -0.758101], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 103 / 176], [train main loss -0.769822], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 104 / 176], [train main loss -0.755730], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 105 / 176], [train main loss -0.756851], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 106 / 176], [train main loss -0.756335], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 107 / 176], [train main loss -0.763402], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 108 / 176], [train main loss -0.730464], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 109 / 176], [train main loss -0.759298], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 110 / 176], [train main loss -0.724563], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 111 / 176], [train main loss -0.732526], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 112 / 176], [train main loss -0.709221], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 113 / 176], [train main loss -0.739448], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 114 / 176], [train main loss -0.747467], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 115 / 176], [train main loss -0.757471], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 116 / 176], [train main loss -0.736452], [lr 0.009886] [batchtime 0.413]
[epoch 2], [iter 117 / 176], [train main loss -0.742325], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 118 / 176], [train main loss -0.738366], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 119 / 176], [train main loss -0.777008], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 120 / 176], [train main loss -0.782197], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 121 / 176], [train main loss -0.789140], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 122 / 176], [train main loss -0.788266], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 123 / 176], [train main loss -0.779020], [lr 0.009886] [batchtime 0.412]
[epoch 2], [iter 124 / 176], [train main loss -0.769967], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 125 / 176], [train main loss -0.782135], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 126 / 176], [train main loss -0.788095], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 127 / 176], [train main loss -0.800395], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 128 / 176], [train main loss -0.813874], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 129 / 176], [train main loss -0.825751], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 130 / 176], [train main loss -0.818424], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 131 / 176], [train main loss -0.818324], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 132 / 176], [train main loss -0.807117], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 133 / 176], [train main loss -0.782630], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 134 / 176], [train main loss -0.779883], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 135 / 176], [train main loss -0.783125], [lr 0.009886] [batchtime 0.41]
[epoch 2], [iter 136 / 176], [train main loss -0.782204], [lr 0.009886] [batchtime 0.411]
[epoch 2], [iter 137 / 176], [train main loss -0.780248], [lr 0.009886] [batchtime 0.418]
[epoch 2], [iter 138 / 176], [train main loss -0.779388], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 139 / 176], [train main loss -0.772698], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 140 / 176], [train main loss -0.765075], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 141 / 176], [train main loss -0.765057], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 142 / 176], [train main loss -0.749008], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 143 / 176], [train main loss -0.750323], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 144 / 176], [train main loss -0.746050], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 145 / 176], [train main loss -0.740954], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 146 / 176], [train main loss -0.742974], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 147 / 176], [train main loss -0.748132], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 148 / 176], [train main loss -0.740358], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 149 / 176], [train main loss -0.734510], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 150 / 176], [train main loss -0.722851], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 151 / 176], [train main loss -0.709237], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 152 / 176], [train main loss -0.689013], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 153 / 176], [train main loss -0.693044], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 154 / 176], [train main loss -0.691166], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 155 / 176], [train main loss -0.696405], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 156 / 176], [train main loss -0.701075], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 157 / 176], [train main loss -0.709378], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 158 / 176], [train main loss -0.714812], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 159 / 176], [train main loss -0.706799], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 160 / 176], [train main loss -0.710032], [lr 0.009886] [batchtime 0.417]
[epoch 2], [iter 161 / 176], [train main loss -0.702634], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 162 / 176], [train main loss -0.696941], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 163 / 176], [train main loss -0.695277], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 164 / 176], [train main loss -0.698993], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 165 / 176], [train main loss -0.698396], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 166 / 176], [train main loss -0.696717], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 167 / 176], [train main loss -0.700165], [lr 0.009886] [batchtime 0.416]
[epoch 2], [iter 168 / 176], [train main loss -0.713926], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 169 / 176], [train main loss -0.715872], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 170 / 176], [train main loss -0.743365], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 171 / 176], [train main loss -0.742214], [lr 0.009886] [batchtime 0.415]
[epoch 2], [iter 172 / 176], [train main loss -0.727993], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 173 / 176], [train main loss -0.722602], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 174 / 176], [train main loss -0.726246], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 175 / 176], [train main loss -0.718786], [lr 0.009886] [batchtime 0.414]
[epoch 2], [iter 176 / 176], [train main loss -0.709964], [lr 0.009886] [batchtime 0.413]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              78.13  34.58    0.05    0.23         0.95      0.81
   1  sidewalk           5.11   0.40   15.37    3.20         0.06      0.24
   2  building          51.46  19.83    0.34    0.60         0.75      0.62
   3  wall               0.00   0.00  inf     nan            0.00    nan
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               0.00   0.00  inf     nan            0.00    nan
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       1.51   0.01   65.28    0.10         0.02      0.91
   8  vegetation        45.26   7.62    0.62    0.59         0.62      0.63
   9  terrain            8.73   0.08    8.34    2.11         0.11      0.32
  10  sky               68.08   3.71    0.04    0.42         0.96      0.70
  11  person             0.00   0.00  inf     nan            0.00    nan
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               24.60   2.66    1.66    1.41         0.38      0.42
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            0.00   0.00  inf     nan            0.00    nan
Mean: 14.89
-----------------------------------------------------------------------------------------------------------
this : [epoch 2], [val loss 0.96173], [acc 0.68893], [acc_cls 0.20163], [mean_iu 0.14889], [fwavacc 0.52469]
best : [epoch 2], [val loss 0.96173], [acc 0.68893], [acc_cls 0.20163], [mean_iu 0.14889], [fwavacc 0.52469]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 3], [iter 1 / 176], [train main loss 0.309488], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 2 / 176], [train main loss 0.609341], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 3 / 176], [train main loss 0.502976], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 4 / 176], [train main loss 0.405841], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 5 / 176], [train main loss 0.035185], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 6 / 176], [train main loss -0.237914], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 7 / 176], [train main loss -0.082027], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 8 / 176], [train main loss 0.013389], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 9 / 176], [train main loss -0.011813], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 10 / 176], [train main loss 0.080075], [lr 0.009829] [batchtime 0]
[epoch 3], [iter 11 / 176], [train main loss 0.206671], [lr 0.009829] [batchtime 0.373]
[epoch 3], [iter 12 / 176], [train main loss 0.439875], [lr 0.009829] [batchtime 0.398]
[epoch 3], [iter 13 / 176], [train main loss 0.302232], [lr 0.009829] [batchtime 0.418]
[epoch 3], [iter 14 / 176], [train main loss 0.366012], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 15 / 176], [train main loss 0.367427], [lr 0.009829] [batchtime 0.409]
[epoch 3], [iter 16 / 176], [train main loss 0.338733], [lr 0.009829] [batchtime 0.408]
[epoch 3], [iter 17 / 176], [train main loss 0.254838], [lr 0.009829] [batchtime 0.406]
[epoch 3], [iter 18 / 176], [train main loss 0.135631], [lr 0.009829] [batchtime 0.405]
[epoch 3], [iter 19 / 176], [train main loss 0.084266], [lr 0.009829] [batchtime 0.404]
[epoch 3], [iter 20 / 176], [train main loss 0.140822], [lr 0.009829] [batchtime 0.403]
[epoch 3], [iter 21 / 176], [train main loss 0.240256], [lr 0.009829] [batchtime 0.402]
[epoch 3], [iter 22 / 176], [train main loss 0.195496], [lr 0.009829] [batchtime 0.402]
[epoch 3], [iter 23 / 176], [train main loss 0.095171], [lr 0.009829] [batchtime 0.402]
[epoch 3], [iter 24 / 176], [train main loss 0.082525], [lr 0.009829] [batchtime 0.401]
[epoch 3], [iter 25 / 176], [train main loss 0.025724], [lr 0.009829] [batchtime 0.402]
[epoch 3], [iter 26 / 176], [train main loss -0.072263], [lr 0.009829] [batchtime 0.4]
[epoch 3], [iter 27 / 176], [train main loss -0.043236], [lr 0.009829] [batchtime 0.4]
[epoch 3], [iter 28 / 176], [train main loss -0.017592], [lr 0.009829] [batchtime 0.4]
[epoch 3], [iter 29 / 176], [train main loss -0.112007], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 30 / 176], [train main loss -0.100299], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 31 / 176], [train main loss -0.151185], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 32 / 176], [train main loss -0.211415], [lr 0.009829] [batchtime 0.398]
[epoch 3], [iter 33 / 176], [train main loss -0.176609], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 34 / 176], [train main loss -0.189122], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 35 / 176], [train main loss -0.181689], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 36 / 176], [train main loss -0.254097], [lr 0.009829] [batchtime 0.399]
[epoch 3], [iter 37 / 176], [train main loss -0.329320], [lr 0.009829] [batchtime 0.421]
[epoch 3], [iter 38 / 176], [train main loss -0.375622], [lr 0.009829] [batchtime 0.424]
[epoch 3], [iter 39 / 176], [train main loss -0.524069], [lr 0.009829] [batchtime 0.423]
[epoch 3], [iter 40 / 176], [train main loss -0.523932], [lr 0.009829] [batchtime 0.422]
[epoch 3], [iter 41 / 176], [train main loss -0.551574], [lr 0.009829] [batchtime 0.421]
[epoch 3], [iter 42 / 176], [train main loss -0.545238], [lr 0.009829] [batchtime 0.42]
[epoch 3], [iter 43 / 176], [train main loss -0.610014], [lr 0.009829] [batchtime 0.42]
[epoch 3], [iter 44 / 176], [train main loss -0.581584], [lr 0.009829] [batchtime 0.419]
[epoch 3], [iter 45 / 176], [train main loss -0.551656], [lr 0.009829] [batchtime 0.418]
[epoch 3], [iter 46 / 176], [train main loss -0.553384], [lr 0.009829] [batchtime 0.417]
[epoch 3], [iter 47 / 176], [train main loss -0.543330], [lr 0.009829] [batchtime 0.417]
[epoch 3], [iter 48 / 176], [train main loss -0.540160], [lr 0.009829] [batchtime 0.416]
[epoch 3], [iter 49 / 176], [train main loss -0.534683], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 50 / 176], [train main loss -0.531373], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 51 / 176], [train main loss -0.506380], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 52 / 176], [train main loss -0.497095], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 53 / 176], [train main loss -0.531144], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 54 / 176], [train main loss -0.512288], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 55 / 176], [train main loss -0.521881], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 56 / 176], [train main loss -0.539812], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 57 / 176], [train main loss -0.545733], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 58 / 176], [train main loss -0.552719], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 59 / 176], [train main loss -0.533522], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 60 / 176], [train main loss -0.491783], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 61 / 176], [train main loss -0.561300], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 62 / 176], [train main loss -0.558758], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 63 / 176], [train main loss -0.601285], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 64 / 176], [train main loss -0.610314], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 65 / 176], [train main loss -0.631214], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 66 / 176], [train main loss -0.630438], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 67 / 176], [train main loss -0.672093], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 68 / 176], [train main loss -0.666048], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 69 / 176], [train main loss -0.651403], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 70 / 176], [train main loss -0.689737], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 71 / 176], [train main loss -0.681169], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 72 / 176], [train main loss -0.679106], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 73 / 176], [train main loss -0.670996], [lr 0.009829] [batchtime 0.41]
[epoch 3], [iter 74 / 176], [train main loss -0.647531], [lr 0.009829] [batchtime 0.41]
[epoch 3], [iter 75 / 176], [train main loss -0.686211], [lr 0.009829] [batchtime 0.41]
[epoch 3], [iter 76 / 176], [train main loss -0.700116], [lr 0.009829] [batchtime 0.409]
[epoch 3], [iter 77 / 176], [train main loss -0.691703], [lr 0.009829] [batchtime 0.409]
[epoch 3], [iter 78 / 176], [train main loss -0.668725], [lr 0.009829] [batchtime 0.409]
[epoch 3], [iter 79 / 176], [train main loss -0.696011], [lr 0.009829] [batchtime 0.409]
[epoch 3], [iter 80 / 176], [train main loss -0.726935], [lr 0.009829] [batchtime 0.409]
[epoch 3], [iter 81 / 176], [train main loss -0.709044], [lr 0.009829] [batchtime 0.408]
[epoch 3], [iter 82 / 176], [train main loss -0.721750], [lr 0.009829] [batchtime 0.408]
[epoch 3], [iter 83 / 176], [train main loss -0.752355], [lr 0.009829] [batchtime 0.408]
[epoch 3], [iter 84 / 176], [train main loss -0.757109], [lr 0.009829] [batchtime 0.408]
[epoch 3], [iter 85 / 176], [train main loss -0.754883], [lr 0.009829] [batchtime 0.41]
[epoch 3], [iter 86 / 176], [train main loss -0.739668], [lr 0.009829] [batchtime 0.422]
[epoch 3], [iter 87 / 176], [train main loss -0.701287], [lr 0.009829] [batchtime 0.421]
[epoch 3], [iter 88 / 176], [train main loss -0.719712], [lr 0.009829] [batchtime 0.421]
[epoch 3], [iter 89 / 176], [train main loss -0.701781], [lr 0.009829] [batchtime 0.42]
[epoch 3], [iter 90 / 176], [train main loss -0.691506], [lr 0.009829] [batchtime 0.42]
[epoch 3], [iter 91 / 176], [train main loss -0.703521], [lr 0.009829] [batchtime 0.419]
[epoch 3], [iter 92 / 176], [train main loss -0.690885], [lr 0.009829] [batchtime 0.419]
[epoch 3], [iter 93 / 176], [train main loss -0.714645], [lr 0.009829] [batchtime 0.419]
[epoch 3], [iter 94 / 176], [train main loss -0.730184], [lr 0.009829] [batchtime 0.418]
[epoch 3], [iter 95 / 176], [train main loss -0.719385], [lr 0.009829] [batchtime 0.418]
[epoch 3], [iter 96 / 176], [train main loss -0.720712], [lr 0.009829] [batchtime 0.418]
[epoch 3], [iter 97 / 176], [train main loss -0.726278], [lr 0.009829] [batchtime 0.417]
[epoch 3], [iter 98 / 176], [train main loss -0.747570], [lr 0.009829] [batchtime 0.417]
[epoch 3], [iter 99 / 176], [train main loss -0.759657], [lr 0.009829] [batchtime 0.417]
[epoch 3], [iter 100 / 176], [train main loss -0.761894], [lr 0.009829] [batchtime 0.417]
[epoch 3], [iter 101 / 176], [train main loss -0.730129], [lr 0.009829] [batchtime 0.416]
[epoch 3], [iter 102 / 176], [train main loss -0.728145], [lr 0.009829] [batchtime 0.416]
[epoch 3], [iter 103 / 176], [train main loss -0.729786], [lr 0.009829] [batchtime 0.416]
[epoch 3], [iter 104 / 176], [train main loss -0.710365], [lr 0.009829] [batchtime 0.416]
[epoch 3], [iter 105 / 176], [train main loss -0.708872], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 106 / 176], [train main loss -0.691745], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 107 / 176], [train main loss -0.690426], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 108 / 176], [train main loss -0.671928], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 109 / 176], [train main loss -0.665660], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 110 / 176], [train main loss -0.650283], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 111 / 176], [train main loss -0.664586], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 112 / 176], [train main loss -0.677710], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 113 / 176], [train main loss -0.718109], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 114 / 176], [train main loss -0.723514], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 115 / 176], [train main loss -0.722636], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 116 / 176], [train main loss -0.718861], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 117 / 176], [train main loss -0.721126], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 118 / 176], [train main loss -0.721415], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 119 / 176], [train main loss -0.719792], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 120 / 176], [train main loss -0.704816], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 121 / 176], [train main loss -0.718953], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 122 / 176], [train main loss -0.719483], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 123 / 176], [train main loss -0.738182], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 124 / 176], [train main loss -0.733843], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 125 / 176], [train main loss -0.766063], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 126 / 176], [train main loss -0.761374], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 127 / 176], [train main loss -0.754672], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 128 / 176], [train main loss -0.751729], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 129 / 176], [train main loss -0.749479], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 130 / 176], [train main loss -0.752112], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 131 / 176], [train main loss -0.740269], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 132 / 176], [train main loss -0.740842], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 133 / 176], [train main loss -0.736340], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 134 / 176], [train main loss -0.756059], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 135 / 176], [train main loss -0.780165], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 136 / 176], [train main loss -0.767999], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 137 / 176], [train main loss -0.735433], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 138 / 176], [train main loss -0.731757], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 139 / 176], [train main loss -0.709277], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 140 / 176], [train main loss -0.695492], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 141 / 176], [train main loss -0.704450], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 142 / 176], [train main loss -0.694015], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 143 / 176], [train main loss -0.692170], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 144 / 176], [train main loss -0.687652], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 145 / 176], [train main loss -0.688962], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 146 / 176], [train main loss -0.695072], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 147 / 176], [train main loss -0.716209], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 148 / 176], [train main loss -0.721368], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 149 / 176], [train main loss -0.751969], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 150 / 176], [train main loss -0.756005], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 151 / 176], [train main loss -0.726839], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 152 / 176], [train main loss -0.737944], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 153 / 176], [train main loss -0.747115], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 154 / 176], [train main loss -0.753532], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 155 / 176], [train main loss -0.752043], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 156 / 176], [train main loss -0.765551], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 157 / 176], [train main loss -0.748561], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 158 / 176], [train main loss -0.746256], [lr 0.009829] [batchtime 0.415]
[epoch 3], [iter 159 / 176], [train main loss -0.763848], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 160 / 176], [train main loss -0.762845], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 161 / 176], [train main loss -0.764461], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 162 / 176], [train main loss -0.770786], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 163 / 176], [train main loss -0.776841], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 164 / 176], [train main loss -0.772559], [lr 0.009829] [batchtime 0.414]
[epoch 3], [iter 165 / 176], [train main loss -0.771085], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 166 / 176], [train main loss -0.775421], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 167 / 176], [train main loss -0.795116], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 168 / 176], [train main loss -0.795955], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 169 / 176], [train main loss -0.798324], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 170 / 176], [train main loss -0.790614], [lr 0.009829] [batchtime 0.413]
[epoch 3], [iter 171 / 176], [train main loss -0.790668], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 172 / 176], [train main loss -0.787391], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 173 / 176], [train main loss -0.790848], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 174 / 176], [train main loss -0.791358], [lr 0.009829] [batchtime 0.412]
[epoch 3], [iter 175 / 176], [train main loss -0.781089], [lr 0.009829] [batchtime 0.411]
[epoch 3], [iter 176 / 176], [train main loss -0.775002], [lr 0.009829] [batchtime 0.411]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              77.89  35.54    0.02    0.26         0.98      0.79
   1  sidewalk           5.27   0.41   14.98    2.98         0.06      0.25
   2  building          47.43  13.85    0.92    0.19         0.52      0.84
   3  wall               0.00   0.00  inf     nan            0.00    nan
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               0.00   0.00  inf     nan            0.00    nan
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       0.35   0.00  281.55    0.02         0.00      0.98
   8  vegetation        46.74  10.61    0.17    0.97         0.86      0.51
   9  terrain            6.95   0.10    6.48    6.91         0.13      0.13
  10  sky               77.33   3.69    0.05    0.24         0.95      0.80
  11  person             0.00   0.00  inf     nan            0.00    nan
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               33.05   4.43    0.60    1.43         0.63      0.41
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            0.00   0.00  inf     nan            0.00    nan
Mean: 15.53
-----------------------------------------------------------------------------------------------------------
this : [epoch 3], [val loss 1.00170], [acc 0.68635], [acc_cls 0.21766], [mean_iu 0.15527], [fwavacc 0.52441]
best : [epoch 3], [val loss 1.00170], [acc 0.68635], [acc_cls 0.21766], [mean_iu 0.15527], [fwavacc 0.52441]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 4], [iter 1 / 176], [train main loss -1.385012], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 2 / 176], [train main loss -1.386243], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 3 / 176], [train main loss -0.936703], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 4 / 176], [train main loss -1.042887], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 5 / 176], [train main loss -1.408878], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 6 / 176], [train main loss -0.873376], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 7 / 176], [train main loss -0.853442], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 8 / 176], [train main loss -1.102359], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 9 / 176], [train main loss -1.123846], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 10 / 176], [train main loss -1.291962], [lr 0.009771] [batchtime 0]
[epoch 4], [iter 11 / 176], [train main loss -1.547003], [lr 0.009771] [batchtime 0.44]
[epoch 4], [iter 12 / 176], [train main loss -1.500335], [lr 0.009771] [batchtime 0.445]
[epoch 4], [iter 13 / 176], [train main loss -1.399134], [lr 0.009771] [batchtime 0.426]
[epoch 4], [iter 14 / 176], [train main loss -1.314790], [lr 0.009771] [batchtime 0.418]
[epoch 4], [iter 15 / 176], [train main loss -1.146304], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 16 / 176], [train main loss -1.250341], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 17 / 176], [train main loss -1.300257], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 18 / 176], [train main loss -1.331888], [lr 0.009771] [batchtime 0.409]
[epoch 4], [iter 19 / 176], [train main loss -1.399857], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 20 / 176], [train main loss -1.485082], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 21 / 176], [train main loss -1.443657], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 22 / 176], [train main loss -1.480240], [lr 0.009771] [batchtime 0.404]
[epoch 4], [iter 23 / 176], [train main loss -1.513848], [lr 0.009771] [batchtime 0.404]
[epoch 4], [iter 24 / 176], [train main loss -1.617461], [lr 0.009771] [batchtime 0.404]
[epoch 4], [iter 25 / 176], [train main loss -1.485976], [lr 0.009771] [batchtime 0.404]
[epoch 4], [iter 26 / 176], [train main loss -1.401921], [lr 0.009771] [batchtime 0.403]
[epoch 4], [iter 27 / 176], [train main loss -1.369643], [lr 0.009771] [batchtime 0.403]
[epoch 4], [iter 28 / 176], [train main loss -1.368596], [lr 0.009771] [batchtime 0.403]
[epoch 4], [iter 29 / 176], [train main loss -1.406214], [lr 0.009771] [batchtime 0.403]
[epoch 4], [iter 30 / 176], [train main loss -1.421444], [lr 0.009771] [batchtime 0.403]
[epoch 4], [iter 31 / 176], [train main loss -1.405481], [lr 0.009771] [batchtime 0.403]
[epoch 4], [iter 32 / 176], [train main loss -1.357708], [lr 0.009771] [batchtime 0.402]
[epoch 4], [iter 33 / 176], [train main loss -1.341681], [lr 0.009771] [batchtime 0.402]
[epoch 4], [iter 34 / 176], [train main loss -1.257449], [lr 0.009771] [batchtime 0.402]
[epoch 4], [iter 35 / 176], [train main loss -1.212018], [lr 0.009771] [batchtime 0.402]
[epoch 4], [iter 36 / 176], [train main loss -1.266778], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 37 / 176], [train main loss -1.243721], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 38 / 176], [train main loss -1.231188], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 39 / 176], [train main loss -1.253788], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 40 / 176], [train main loss -1.287629], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 41 / 176], [train main loss -1.321396], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 42 / 176], [train main loss -1.369279], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 43 / 176], [train main loss -1.386749], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 44 / 176], [train main loss -1.407054], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 45 / 176], [train main loss -1.458202], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 46 / 176], [train main loss -1.446628], [lr 0.009771] [batchtime 0.41]
[epoch 4], [iter 47 / 176], [train main loss -1.377890], [lr 0.009771] [batchtime 0.41]
[epoch 4], [iter 48 / 176], [train main loss -1.336932], [lr 0.009771] [batchtime 0.41]
[epoch 4], [iter 49 / 176], [train main loss -1.307267], [lr 0.009771] [batchtime 0.409]
[epoch 4], [iter 50 / 176], [train main loss -1.349593], [lr 0.009771] [batchtime 0.409]
[epoch 4], [iter 51 / 176], [train main loss -1.369605], [lr 0.009771] [batchtime 0.409]
[epoch 4], [iter 52 / 176], [train main loss -1.303009], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 53 / 176], [train main loss -1.268602], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 54 / 176], [train main loss -1.275796], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 55 / 176], [train main loss -1.293636], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 56 / 176], [train main loss -1.316193], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 57 / 176], [train main loss -1.340859], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 58 / 176], [train main loss -1.298269], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 59 / 176], [train main loss -1.339618], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 60 / 176], [train main loss -1.375013], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 61 / 176], [train main loss -1.414543], [lr 0.009771] [batchtime 0.409]
[epoch 4], [iter 62 / 176], [train main loss -1.409660], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 63 / 176], [train main loss -1.387971], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 64 / 176], [train main loss -1.320132], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 65 / 176], [train main loss -1.345832], [lr 0.009771] [batchtime 0.408]
[epoch 4], [iter 66 / 176], [train main loss -1.342172], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 67 / 176], [train main loss -1.303743], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 68 / 176], [train main loss -1.284091], [lr 0.009771] [batchtime 0.407]
[epoch 4], [iter 69 / 176], [train main loss -1.269712], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 70 / 176], [train main loss -1.259469], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 71 / 176], [train main loss -1.216341], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 72 / 176], [train main loss -1.173761], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 73 / 176], [train main loss -1.171858], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 74 / 176], [train main loss -1.199271], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 75 / 176], [train main loss -1.183893], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 76 / 176], [train main loss -1.165598], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 77 / 176], [train main loss -1.125748], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 78 / 176], [train main loss -1.120147], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 79 / 176], [train main loss -1.111138], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 80 / 176], [train main loss -1.108347], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 81 / 176], [train main loss -1.115869], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 82 / 176], [train main loss -1.111433], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 83 / 176], [train main loss -1.143773], [lr 0.009771] [batchtime 0.405]
[epoch 4], [iter 84 / 176], [train main loss -1.126754], [lr 0.009771] [batchtime 0.404]
[epoch 4], [iter 85 / 176], [train main loss -1.108807], [lr 0.009771] [batchtime 0.406]
[epoch 4], [iter 86 / 176], [train main loss -1.095145], [lr 0.009771] [batchtime 0.42]
[epoch 4], [iter 87 / 176], [train main loss -1.120171], [lr 0.009771] [batchtime 0.419]
[epoch 4], [iter 88 / 176], [train main loss -1.103282], [lr 0.009771] [batchtime 0.419]
[epoch 4], [iter 89 / 176], [train main loss -1.105208], [lr 0.009771] [batchtime 0.419]
[epoch 4], [iter 90 / 176], [train main loss -1.092554], [lr 0.009771] [batchtime 0.418]
[epoch 4], [iter 91 / 176], [train main loss -1.088598], [lr 0.009771] [batchtime 0.418]
[epoch 4], [iter 92 / 176], [train main loss -1.096771], [lr 0.009771] [batchtime 0.418]
[epoch 4], [iter 93 / 176], [train main loss -1.089111], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 94 / 176], [train main loss -1.069398], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 95 / 176], [train main loss -1.101634], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 96 / 176], [train main loss -1.127490], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 97 / 176], [train main loss -1.153436], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 98 / 176], [train main loss -1.158367], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 99 / 176], [train main loss -1.161731], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 100 / 176], [train main loss -1.154901], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 101 / 176], [train main loss -1.136472], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 102 / 176], [train main loss -1.149116], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 103 / 176], [train main loss -1.129377], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 104 / 176], [train main loss -1.125746], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 105 / 176], [train main loss -1.122912], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 106 / 176], [train main loss -1.121316], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 107 / 176], [train main loss -1.107320], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 108 / 176], [train main loss -1.111842], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 109 / 176], [train main loss -1.092921], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 110 / 176], [train main loss -1.072261], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 111 / 176], [train main loss -1.077960], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 112 / 176], [train main loss -1.101041], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 113 / 176], [train main loss -1.105523], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 114 / 176], [train main loss -1.102245], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 115 / 176], [train main loss -1.100511], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 116 / 176], [train main loss -1.104213], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 117 / 176], [train main loss -1.085654], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 118 / 176], [train main loss -1.071408], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 119 / 176], [train main loss -1.088216], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 120 / 176], [train main loss -1.090630], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 121 / 176], [train main loss -1.089104], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 122 / 176], [train main loss -1.085411], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 123 / 176], [train main loss -1.114252], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 124 / 176], [train main loss -1.103892], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 125 / 176], [train main loss -1.129791], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 126 / 176], [train main loss -1.126778], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 127 / 176], [train main loss -1.114092], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 128 / 176], [train main loss -1.104008], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 129 / 176], [train main loss -1.113210], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 130 / 176], [train main loss -1.121769], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 131 / 176], [train main loss -1.098146], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 132 / 176], [train main loss -1.066170], [lr 0.009771] [batchtime 0.411]
[epoch 4], [iter 133 / 176], [train main loss -1.087535], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 134 / 176], [train main loss -1.117449], [lr 0.009771] [batchtime 0.418]
[epoch 4], [iter 135 / 176], [train main loss -1.126235], [lr 0.009771] [batchtime 0.418]
[epoch 4], [iter 136 / 176], [train main loss -1.134321], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 137 / 176], [train main loss -1.117369], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 138 / 176], [train main loss -1.101782], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 139 / 176], [train main loss -1.096565], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 140 / 176], [train main loss -1.092482], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 141 / 176], [train main loss -1.081250], [lr 0.009771] [batchtime 0.417]
[epoch 4], [iter 142 / 176], [train main loss -1.083334], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 143 / 176], [train main loss -1.081484], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 144 / 176], [train main loss -1.086397], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 145 / 176], [train main loss -1.069489], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 146 / 176], [train main loss -1.068339], [lr 0.009771] [batchtime 0.416]
[epoch 4], [iter 147 / 176], [train main loss -1.062511], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 148 / 176], [train main loss -1.086567], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 149 / 176], [train main loss -1.101934], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 150 / 176], [train main loss -1.078611], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 151 / 176], [train main loss -1.077635], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 152 / 176], [train main loss -1.087801], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 153 / 176], [train main loss -1.087241], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 154 / 176], [train main loss -1.079515], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 155 / 176], [train main loss -1.073457], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 156 / 176], [train main loss -1.079160], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 157 / 176], [train main loss -1.074225], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 158 / 176], [train main loss -1.075032], [lr 0.009771] [batchtime 0.415]
[epoch 4], [iter 159 / 176], [train main loss -1.075103], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 160 / 176], [train main loss -1.069591], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 161 / 176], [train main loss -1.069567], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 162 / 176], [train main loss -1.075401], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 163 / 176], [train main loss -1.082269], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 164 / 176], [train main loss -1.089267], [lr 0.009771] [batchtime 0.414]
[epoch 4], [iter 165 / 176], [train main loss -1.075665], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 166 / 176], [train main loss -1.068856], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 167 / 176], [train main loss -1.066958], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 168 / 176], [train main loss -1.064203], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 169 / 176], [train main loss -1.062114], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 170 / 176], [train main loss -1.060899], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 171 / 176], [train main loss -1.058925], [lr 0.009771] [batchtime 0.413]
[epoch 4], [iter 172 / 176], [train main loss -1.054412], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 173 / 176], [train main loss -1.050338], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 174 / 176], [train main loss -1.062062], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 175 / 176], [train main loss -1.049589], [lr 0.009771] [batchtime 0.412]
[epoch 4], [iter 176 / 176], [train main loss -1.057023], [lr 0.009771] [batchtime 0.412]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              81.83  35.01    0.04    0.18         0.96      0.84
   1  sidewalk          14.52   1.24    4.33    1.56         0.19      0.39
   2  building          63.50  20.34    0.31    0.27         0.77      0.79
   3  wall               0.00   0.00  inf     nan            0.00    nan
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               0.00   0.00  inf     nan            0.00    nan
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       0.37   0.00  270.15    0.10         0.00      0.91
   8  vegetation        56.81  10.80    0.15    0.62         0.87      0.62
   9  terrain            3.73   0.03   23.40    2.44         0.04      0.29
  10  sky               79.79   3.74    0.04    0.22         0.96      0.82
  11  person             0.00   0.00  inf     inf            0.00      0.00
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               42.80   4.37    0.62    0.72         0.62      0.58
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            0.00   0.00  inf     nan            0.00    nan
Mean: 18.07
-----------------------------------------------------------------------------------------------------------
this : [epoch 4], [val loss 0.81125], [acc 0.75528], [acc_cls 0.23244], [mean_iu 0.18071], [fwavacc 0.60760]
best : [epoch 4], [val loss 0.81125], [acc 0.75528], [acc_cls 0.23244], [mean_iu 0.18071], [fwavacc 0.60760]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 5], [iter 1 / 176], [train main loss -2.536974], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 2 / 176], [train main loss -2.851050], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 3 / 176], [train main loss -2.709894], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 4 / 176], [train main loss -2.265951], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 5 / 176], [train main loss -2.041496], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 6 / 176], [train main loss -1.710679], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 7 / 176], [train main loss -1.626839], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 8 / 176], [train main loss -1.631642], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 9 / 176], [train main loss -1.305735], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 10 / 176], [train main loss -1.028950], [lr 0.009714] [batchtime 0]
[epoch 5], [iter 11 / 176], [train main loss -1.091008], [lr 0.009714] [batchtime 0.361]
[epoch 5], [iter 12 / 176], [train main loss -1.240505], [lr 0.009714] [batchtime 0.376]
[epoch 5], [iter 13 / 176], [train main loss -1.297936], [lr 0.009714] [batchtime 0.382]
[epoch 5], [iter 14 / 176], [train main loss -1.292795], [lr 0.009714] [batchtime 0.387]
[epoch 5], [iter 15 / 176], [train main loss -1.299250], [lr 0.009714] [batchtime 0.389]
[epoch 5], [iter 16 / 176], [train main loss -1.086301], [lr 0.009714] [batchtime 0.39]
[epoch 5], [iter 17 / 176], [train main loss -1.037781], [lr 0.009714] [batchtime 0.392]
[epoch 5], [iter 18 / 176], [train main loss -1.157727], [lr 0.009714] [batchtime 0.393]
[epoch 5], [iter 19 / 176], [train main loss -1.001777], [lr 0.009714] [batchtime 0.394]
[epoch 5], [iter 20 / 176], [train main loss -0.957217], [lr 0.009714] [batchtime 0.394]
[epoch 5], [iter 21 / 176], [train main loss -0.997628], [lr 0.009714] [batchtime 0.395]
[epoch 5], [iter 22 / 176], [train main loss -0.973229], [lr 0.009714] [batchtime 0.395]
[epoch 5], [iter 23 / 176], [train main loss -0.900088], [lr 0.009714] [batchtime 0.395]
[epoch 5], [iter 24 / 176], [train main loss -0.917275], [lr 0.009714] [batchtime 0.395]
[epoch 5], [iter 25 / 176], [train main loss -0.944588], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 26 / 176], [train main loss -0.948617], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 27 / 176], [train main loss -0.811732], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 28 / 176], [train main loss -0.845681], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 29 / 176], [train main loss -0.934054], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 30 / 176], [train main loss -0.896118], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 31 / 176], [train main loss -0.930949], [lr 0.009714] [batchtime 0.396]
[epoch 5], [iter 32 / 176], [train main loss -0.898418], [lr 0.009714] [batchtime 0.404]
[epoch 5], [iter 33 / 176], [train main loss -0.857717], [lr 0.009714] [batchtime 0.464]
[epoch 5], [iter 34 / 176], [train main loss -0.829467], [lr 0.009714] [batchtime 0.461]
[epoch 5], [iter 35 / 176], [train main loss -0.861012], [lr 0.009714] [batchtime 0.458]
[epoch 5], [iter 36 / 176], [train main loss -0.833831], [lr 0.009714] [batchtime 0.455]
[epoch 5], [iter 37 / 176], [train main loss -0.859476], [lr 0.009714] [batchtime 0.453]
[epoch 5], [iter 38 / 176], [train main loss -0.833260], [lr 0.009714] [batchtime 0.45]
[epoch 5], [iter 39 / 176], [train main loss -0.833009], [lr 0.009714] [batchtime 0.448]
[epoch 5], [iter 40 / 176], [train main loss -0.863602], [lr 0.009714] [batchtime 0.446]
[epoch 5], [iter 41 / 176], [train main loss -0.864049], [lr 0.009714] [batchtime 0.445]
[epoch 5], [iter 42 / 176], [train main loss -0.867087], [lr 0.009714] [batchtime 0.443]
[epoch 5], [iter 43 / 176], [train main loss -0.835272], [lr 0.009714] [batchtime 0.448]
[epoch 5], [iter 44 / 176], [train main loss -0.794508], [lr 0.009714] [batchtime 0.446]
[epoch 5], [iter 45 / 176], [train main loss -0.808072], [lr 0.009714] [batchtime 0.445]
[epoch 5], [iter 46 / 176], [train main loss -0.778586], [lr 0.009714] [batchtime 0.443]
[epoch 5], [iter 47 / 176], [train main loss -0.797159], [lr 0.009714] [batchtime 0.442]
[epoch 5], [iter 48 / 176], [train main loss -0.774184], [lr 0.009714] [batchtime 0.441]
[epoch 5], [iter 49 / 176], [train main loss -0.798908], [lr 0.009714] [batchtime 0.44]
[epoch 5], [iter 50 / 176], [train main loss -0.817430], [lr 0.009714] [batchtime 0.439]
[epoch 5], [iter 51 / 176], [train main loss -0.820055], [lr 0.009714] [batchtime 0.438]
[epoch 5], [iter 52 / 176], [train main loss -0.843561], [lr 0.009714] [batchtime 0.437]
[epoch 5], [iter 53 / 176], [train main loss -0.811388], [lr 0.009714] [batchtime 0.436]
[epoch 5], [iter 54 / 176], [train main loss -0.799627], [lr 0.009714] [batchtime 0.435]
[epoch 5], [iter 55 / 176], [train main loss -0.812467], [lr 0.009714] [batchtime 0.434]
[epoch 5], [iter 56 / 176], [train main loss -0.880340], [lr 0.009714] [batchtime 0.433]
[epoch 5], [iter 57 / 176], [train main loss -0.854301], [lr 0.009714] [batchtime 0.432]
[epoch 5], [iter 58 / 176], [train main loss -0.873786], [lr 0.009714] [batchtime 0.432]
[epoch 5], [iter 59 / 176], [train main loss -0.834075], [lr 0.009714] [batchtime 0.431]
[epoch 5], [iter 60 / 176], [train main loss -0.814197], [lr 0.009714] [batchtime 0.43]
[epoch 5], [iter 61 / 176], [train main loss -0.766920], [lr 0.009714] [batchtime 0.43]
[epoch 5], [iter 62 / 176], [train main loss -0.780388], [lr 0.009714] [batchtime 0.429]
[epoch 5], [iter 63 / 176], [train main loss -0.792945], [lr 0.009714] [batchtime 0.428]
[epoch 5], [iter 64 / 176], [train main loss -0.762633], [lr 0.009714] [batchtime 0.428]
[epoch 5], [iter 65 / 176], [train main loss -0.753155], [lr 0.009714] [batchtime 0.427]
[epoch 5], [iter 66 / 176], [train main loss -0.753673], [lr 0.009714] [batchtime 0.427]
[epoch 5], [iter 67 / 176], [train main loss -0.767250], [lr 0.009714] [batchtime 0.426]
[epoch 5], [iter 68 / 176], [train main loss -0.726674], [lr 0.009714] [batchtime 0.426]
[epoch 5], [iter 69 / 176], [train main loss -0.710432], [lr 0.009714] [batchtime 0.425]
[epoch 5], [iter 70 / 176], [train main loss -0.708342], [lr 0.009714] [batchtime 0.425]
[epoch 5], [iter 71 / 176], [train main loss -0.728771], [lr 0.009714] [batchtime 0.424]
[epoch 5], [iter 72 / 176], [train main loss -0.740285], [lr 0.009714] [batchtime 0.424]
[epoch 5], [iter 73 / 176], [train main loss -0.759096], [lr 0.009714] [batchtime 0.424]
[epoch 5], [iter 74 / 176], [train main loss -0.753378], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 75 / 176], [train main loss -0.754056], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 76 / 176], [train main loss -0.752122], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 77 / 176], [train main loss -0.751452], [lr 0.009714] [batchtime 0.422]
[epoch 5], [iter 78 / 176], [train main loss -0.738587], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 79 / 176], [train main loss -0.741717], [lr 0.009714] [batchtime 0.428]
[epoch 5], [iter 80 / 176], [train main loss -0.744401], [lr 0.009714] [batchtime 0.428]
[epoch 5], [iter 81 / 176], [train main loss -0.770866], [lr 0.009714] [batchtime 0.427]
[epoch 5], [iter 82 / 176], [train main loss -0.786937], [lr 0.009714] [batchtime 0.427]
[epoch 5], [iter 83 / 176], [train main loss -0.757054], [lr 0.009714] [batchtime 0.426]
[epoch 5], [iter 84 / 176], [train main loss -0.729963], [lr 0.009714] [batchtime 0.426]
[epoch 5], [iter 85 / 176], [train main loss -0.706819], [lr 0.009714] [batchtime 0.425]
[epoch 5], [iter 86 / 176], [train main loss -0.720886], [lr 0.009714] [batchtime 0.425]
[epoch 5], [iter 87 / 176], [train main loss -0.727058], [lr 0.009714] [batchtime 0.425]
[epoch 5], [iter 88 / 176], [train main loss -0.719276], [lr 0.009714] [batchtime 0.424]
[epoch 5], [iter 89 / 176], [train main loss -0.700741], [lr 0.009714] [batchtime 0.424]
[epoch 5], [iter 90 / 176], [train main loss -0.710525], [lr 0.009714] [batchtime 0.424]
[epoch 5], [iter 91 / 176], [train main loss -0.738533], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 92 / 176], [train main loss -0.740710], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 93 / 176], [train main loss -0.706996], [lr 0.009714] [batchtime 0.423]
[epoch 5], [iter 94 / 176], [train main loss -0.757424], [lr 0.009714] [batchtime 0.422]
[epoch 5], [iter 95 / 176], [train main loss -0.768525], [lr 0.009714] [batchtime 0.422]
[epoch 5], [iter 96 / 176], [train main loss -0.761398], [lr 0.009714] [batchtime 0.422]
[epoch 5], [iter 97 / 176], [train main loss -0.785137], [lr 0.009714] [batchtime 0.421]
[epoch 5], [iter 98 / 176], [train main loss -0.766503], [lr 0.009714] [batchtime 0.421]
[epoch 5], [iter 99 / 176], [train main loss -0.797897], [lr 0.009714] [batchtime 0.421]
[epoch 5], [iter 100 / 176], [train main loss -0.804168], [lr 0.009714] [batchtime 0.421]
[epoch 5], [iter 101 / 176], [train main loss -0.818078], [lr 0.009714] [batchtime 0.421]
[epoch 5], [iter 102 / 176], [train main loss -0.842113], [lr 0.009714] [batchtime 0.42]
[epoch 5], [iter 103 / 176], [train main loss -0.867155], [lr 0.009714] [batchtime 0.42]
[epoch 5], [iter 104 / 176], [train main loss -0.864321], [lr 0.009714] [batchtime 0.42]
[epoch 5], [iter 105 / 176], [train main loss -0.852232], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 106 / 176], [train main loss -0.875881], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 107 / 176], [train main loss -0.881514], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 108 / 176], [train main loss -0.864527], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 109 / 176], [train main loss -0.901557], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 110 / 176], [train main loss -0.878865], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 111 / 176], [train main loss -0.904603], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 112 / 176], [train main loss -0.945427], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 113 / 176], [train main loss -0.951641], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 114 / 176], [train main loss -0.955567], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 115 / 176], [train main loss -0.964377], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 116 / 176], [train main loss -0.959047], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 117 / 176], [train main loss -0.964934], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 118 / 176], [train main loss -0.963462], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 119 / 176], [train main loss -0.981497], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 120 / 176], [train main loss -0.975055], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 121 / 176], [train main loss -0.986470], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 122 / 176], [train main loss -0.975666], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 123 / 176], [train main loss -0.978260], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 124 / 176], [train main loss -0.966147], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 125 / 176], [train main loss -0.964092], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 126 / 176], [train main loss -0.971053], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 127 / 176], [train main loss -0.959024], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 128 / 176], [train main loss -0.969710], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 129 / 176], [train main loss -0.968892], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 130 / 176], [train main loss -0.977593], [lr 0.009714] [batchtime 0.419]
[epoch 5], [iter 131 / 176], [train main loss -0.959199], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 132 / 176], [train main loss -0.962833], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 133 / 176], [train main loss -0.973079], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 134 / 176], [train main loss -0.970530], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 135 / 176], [train main loss -0.984965], [lr 0.009714] [batchtime 0.418]
[epoch 5], [iter 136 / 176], [train main loss -0.991335], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 137 / 176], [train main loss -0.979636], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 138 / 176], [train main loss -0.961121], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 139 / 176], [train main loss -0.946864], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 140 / 176], [train main loss -0.952605], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 141 / 176], [train main loss -0.962887], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 142 / 176], [train main loss -0.945998], [lr 0.009714] [batchtime 0.417]
[epoch 5], [iter 143 / 176], [train main loss -0.947708], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 144 / 176], [train main loss -0.948763], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 145 / 176], [train main loss -0.947939], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 146 / 176], [train main loss -0.957384], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 147 / 176], [train main loss -0.975574], [lr 0.009714] [batchtime 0.416]
[epoch 5], [iter 148 / 176], [train main loss -0.992384], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 149 / 176], [train main loss -0.989824], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 150 / 176], [train main loss -0.998404], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 151 / 176], [train main loss -1.018771], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 152 / 176], [train main loss -0.999641], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 153 / 176], [train main loss -0.991276], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 154 / 176], [train main loss -0.986714], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 155 / 176], [train main loss -0.994454], [lr 0.009714] [batchtime 0.415]
[epoch 5], [iter 156 / 176], [train main loss -0.996323], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 157 / 176], [train main loss -0.990734], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 158 / 176], [train main loss -1.010592], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 159 / 176], [train main loss -1.004585], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 160 / 176], [train main loss -1.017830], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 161 / 176], [train main loss -1.024246], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 162 / 176], [train main loss -1.029212], [lr 0.009714] [batchtime 0.414]
[epoch 5], [iter 163 / 176], [train main loss -1.036646], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 164 / 176], [train main loss -1.041433], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 165 / 176], [train main loss -1.044440], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 166 / 176], [train main loss -1.042153], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 167 / 176], [train main loss -1.044820], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 168 / 176], [train main loss -1.049020], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 169 / 176], [train main loss -1.056020], [lr 0.009714] [batchtime 0.413]
[epoch 5], [iter 170 / 176], [train main loss -1.052039], [lr 0.009714] [batchtime 0.412]
[epoch 5], [iter 171 / 176], [train main loss -1.044817], [lr 0.009714] [batchtime 0.412]
[epoch 5], [iter 172 / 176], [train main loss -1.067648], [lr 0.009714] [batchtime 0.412]
[epoch 5], [iter 173 / 176], [train main loss -1.054821], [lr 0.009714] [batchtime 0.412]
[epoch 5], [iter 174 / 176], [train main loss -1.061541], [lr 0.009714] [batchtime 0.411]
[epoch 5], [iter 175 / 176], [train main loss -1.063288], [lr 0.009714] [batchtime 0.411]
[epoch 5], [iter 176 / 176], [train main loss -1.072301], [lr 0.009714] [batchtime 0.411]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              82.55  35.21      0.03    0.18         0.97      0.85
   1  sidewalk          20.90   1.85      2.56    1.22         0.28      0.45
   2  building          68.84  21.95      0.21    0.24         0.83      0.81
   3  wall               0.00   0.00    inf     nan            0.00    nan
   4  fence              0.00   0.00    inf     nan            0.00    nan
   5  pole               0.00   0.00    inf     inf            0.00      0.00
   6  traffic light      0.00   0.00    inf     nan            0.00    nan
   7  traffic sign       0.28   0.00    360.34    0.13         0.00      0.88
   8  vegetation        62.99  10.81      0.14    0.44         0.87      0.69
   9  terrain            7.80   0.07      9.55    2.26         0.09      0.31
  10  sky               84.52   3.64      0.06    0.12         0.94      0.89
  11  person             0.00   0.00  26036.51    2.90         0.00      0.26
  12  rider              0.00   0.00    inf     nan            0.00    nan
  13  car               46.84   4.57      0.55    0.59         0.65      0.63
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.00   0.00    inf     nan            0.00    nan
  16  train              0.00   0.00    inf     nan            0.00    nan
  17  motorcycle         0.00   0.00    inf     nan            0.00    nan
  18  bicycle            0.00   0.00    inf     nan            0.00    nan
Mean: 19.72
-----------------------------------------------------------------------------------------------------------
this : [epoch 5], [val loss 0.69961], [acc 0.78090], [acc_cls 0.24375], [mean_iu 0.19723], [fwavacc 0.64125]
best : [epoch 5], [val loss 0.69961], [acc 0.78090], [acc_cls 0.24375], [mean_iu 0.19723], [fwavacc 0.64125]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 6], [iter 1 / 176], [train main loss -1.661287], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 2 / 176], [train main loss -1.514394], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 3 / 176], [train main loss -2.190133], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 4 / 176], [train main loss -2.138543], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 5 / 176], [train main loss -1.876657], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 6 / 176], [train main loss -1.766440], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 7 / 176], [train main loss -1.782413], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 8 / 176], [train main loss -1.575726], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 9 / 176], [train main loss -1.798183], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 10 / 176], [train main loss -1.488617], [lr 0.009657] [batchtime 0]
[epoch 6], [iter 11 / 176], [train main loss -1.558968], [lr 0.009657] [batchtime 0.382]
[epoch 6], [iter 12 / 176], [train main loss -1.368974], [lr 0.009657] [batchtime 0.388]
[epoch 6], [iter 13 / 176], [train main loss -1.420604], [lr 0.009657] [batchtime 0.389]
[epoch 6], [iter 14 / 176], [train main loss -1.378329], [lr 0.009657] [batchtime 0.392]
[epoch 6], [iter 15 / 176], [train main loss -1.338980], [lr 0.009657] [batchtime 0.39]
[epoch 6], [iter 16 / 176], [train main loss -1.232458], [lr 0.009657] [batchtime 0.393]
[epoch 6], [iter 17 / 176], [train main loss -1.290646], [lr 0.009657] [batchtime 0.393]
[epoch 6], [iter 18 / 176], [train main loss -1.215418], [lr 0.009657] [batchtime 0.394]
[epoch 6], [iter 19 / 176], [train main loss -1.376558], [lr 0.009657] [batchtime 0.393]
[epoch 6], [iter 20 / 176], [train main loss -1.502201], [lr 0.009657] [batchtime 0.393]
[epoch 6], [iter 21 / 176], [train main loss -1.494350], [lr 0.009657] [batchtime 0.394]
[epoch 6], [iter 22 / 176], [train main loss -1.481779], [lr 0.009657] [batchtime 0.395]
[epoch 6], [iter 23 / 176], [train main loss -1.420804], [lr 0.009657] [batchtime 0.395]
[epoch 6], [iter 24 / 176], [train main loss -1.390866], [lr 0.009657] [batchtime 0.397]
[epoch 6], [iter 25 / 176], [train main loss -1.417972], [lr 0.009657] [batchtime 0.397]
[epoch 6], [iter 26 / 176], [train main loss -1.392479], [lr 0.009657] [batchtime 0.397]
[epoch 6], [iter 27 / 176], [train main loss -1.460893], [lr 0.009657] [batchtime 0.396]
[epoch 6], [iter 28 / 176], [train main loss -1.443048], [lr 0.009657] [batchtime 0.396]
[epoch 6], [iter 29 / 176], [train main loss -1.489377], [lr 0.009657] [batchtime 0.406]
[epoch 6], [iter 30 / 176], [train main loss -1.451202], [lr 0.009657] [batchtime 0.473]
[epoch 6], [iter 31 / 176], [train main loss -1.396517], [lr 0.009657] [batchtime 0.468]
[epoch 6], [iter 32 / 176], [train main loss -1.326761], [lr 0.009657] [batchtime 0.464]
[epoch 6], [iter 33 / 176], [train main loss -1.452186], [lr 0.009657] [batchtime 0.461]
[epoch 6], [iter 34 / 176], [train main loss -1.418954], [lr 0.009657] [batchtime 0.459]
[epoch 6], [iter 35 / 176], [train main loss -1.421879], [lr 0.009657] [batchtime 0.456]
[epoch 6], [iter 36 / 176], [train main loss -1.490303], [lr 0.009657] [batchtime 0.454]
[epoch 6], [iter 37 / 176], [train main loss -1.558142], [lr 0.009657] [batchtime 0.452]
[epoch 6], [iter 38 / 176], [train main loss -1.460459], [lr 0.009657] [batchtime 0.45]
[epoch 6], [iter 39 / 176], [train main loss -1.437700], [lr 0.009657] [batchtime 0.448]
[epoch 6], [iter 40 / 176], [train main loss -1.469883], [lr 0.009657] [batchtime 0.446]
[epoch 6], [iter 41 / 176], [train main loss -1.559142], [lr 0.009657] [batchtime 0.445]
[epoch 6], [iter 42 / 176], [train main loss -1.586814], [lr 0.009657] [batchtime 0.443]
[epoch 6], [iter 43 / 176], [train main loss -1.518406], [lr 0.009657] [batchtime 0.442]
[epoch 6], [iter 44 / 176], [train main loss -1.509228], [lr 0.009657] [batchtime 0.441]
[epoch 6], [iter 45 / 176], [train main loss -1.485681], [lr 0.009657] [batchtime 0.439]
[epoch 6], [iter 46 / 176], [train main loss -1.485245], [lr 0.009657] [batchtime 0.438]
[epoch 6], [iter 47 / 176], [train main loss -1.449586], [lr 0.009657] [batchtime 0.437]
[epoch 6], [iter 48 / 176], [train main loss -1.496524], [lr 0.009657] [batchtime 0.436]
[epoch 6], [iter 49 / 176], [train main loss -1.480923], [lr 0.009657] [batchtime 0.435]
[epoch 6], [iter 50 / 176], [train main loss -1.565904], [lr 0.009657] [batchtime 0.434]
[epoch 6], [iter 51 / 176], [train main loss -1.568719], [lr 0.009657] [batchtime 0.433]
[epoch 6], [iter 52 / 176], [train main loss -1.578661], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 53 / 176], [train main loss -1.563930], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 54 / 176], [train main loss -1.556144], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 55 / 176], [train main loss -1.535598], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 56 / 176], [train main loss -1.544530], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 57 / 176], [train main loss -1.489533], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 58 / 176], [train main loss -1.428611], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 59 / 176], [train main loss -1.431213], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 60 / 176], [train main loss -1.473361], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 61 / 176], [train main loss -1.489517], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 62 / 176], [train main loss -1.471055], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 63 / 176], [train main loss -1.484844], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 64 / 176], [train main loss -1.502143], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 65 / 176], [train main loss -1.495467], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 66 / 176], [train main loss -1.451375], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 67 / 176], [train main loss -1.466633], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 68 / 176], [train main loss -1.465751], [lr 0.009657] [batchtime 0.422]
[epoch 6], [iter 69 / 176], [train main loss -1.436626], [lr 0.009657] [batchtime 0.422]
[epoch 6], [iter 70 / 176], [train main loss -1.391407], [lr 0.009657] [batchtime 0.421]
[epoch 6], [iter 71 / 176], [train main loss -1.418610], [lr 0.009657] [batchtime 0.421]
[epoch 6], [iter 72 / 176], [train main loss -1.457056], [lr 0.009657] [batchtime 0.42]
[epoch 6], [iter 73 / 176], [train main loss -1.442723], [lr 0.009657] [batchtime 0.42]
[epoch 6], [iter 74 / 176], [train main loss -1.429138], [lr 0.009657] [batchtime 0.42]
[epoch 6], [iter 75 / 176], [train main loss -1.412671], [lr 0.009657] [batchtime 0.42]
[epoch 6], [iter 76 / 176], [train main loss -1.418501], [lr 0.009657] [batchtime 0.421]
[epoch 6], [iter 77 / 176], [train main loss -1.430716], [lr 0.009657] [batchtime 0.442]
[epoch 6], [iter 78 / 176], [train main loss -1.450990], [lr 0.009657] [batchtime 0.441]
[epoch 6], [iter 79 / 176], [train main loss -1.479171], [lr 0.009657] [batchtime 0.44]
[epoch 6], [iter 80 / 176], [train main loss -1.464056], [lr 0.009657] [batchtime 0.439]
[epoch 6], [iter 81 / 176], [train main loss -1.464876], [lr 0.009657] [batchtime 0.438]
[epoch 6], [iter 82 / 176], [train main loss -1.453258], [lr 0.009657] [batchtime 0.438]
[epoch 6], [iter 83 / 176], [train main loss -1.459766], [lr 0.009657] [batchtime 0.437]
[epoch 6], [iter 84 / 176], [train main loss -1.414331], [lr 0.009657] [batchtime 0.436]
[epoch 6], [iter 85 / 176], [train main loss -1.451614], [lr 0.009657] [batchtime 0.436]
[epoch 6], [iter 86 / 176], [train main loss -1.421690], [lr 0.009657] [batchtime 0.435]
[epoch 6], [iter 87 / 176], [train main loss -1.433313], [lr 0.009657] [batchtime 0.435]
[epoch 6], [iter 88 / 176], [train main loss -1.426115], [lr 0.009657] [batchtime 0.434]
[epoch 6], [iter 89 / 176], [train main loss -1.412001], [lr 0.009657] [batchtime 0.434]
[epoch 6], [iter 90 / 176], [train main loss -1.389114], [lr 0.009657] [batchtime 0.434]
[epoch 6], [iter 91 / 176], [train main loss -1.348856], [lr 0.009657] [batchtime 0.433]
[epoch 6], [iter 92 / 176], [train main loss -1.338352], [lr 0.009657] [batchtime 0.433]
[epoch 6], [iter 93 / 176], [train main loss -1.332790], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 94 / 176], [train main loss -1.303449], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 95 / 176], [train main loss -1.302263], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 96 / 176], [train main loss -1.283634], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 97 / 176], [train main loss -1.259840], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 98 / 176], [train main loss -1.273851], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 99 / 176], [train main loss -1.260511], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 100 / 176], [train main loss -1.268219], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 101 / 176], [train main loss -1.276384], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 102 / 176], [train main loss -1.246523], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 103 / 176], [train main loss -1.232465], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 104 / 176], [train main loss -1.200535], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 105 / 176], [train main loss -1.185248], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 106 / 176], [train main loss -1.196023], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 107 / 176], [train main loss -1.197289], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 108 / 176], [train main loss -1.206515], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 109 / 176], [train main loss -1.213629], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 110 / 176], [train main loss -1.225756], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 111 / 176], [train main loss -1.233917], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 112 / 176], [train main loss -1.256559], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 113 / 176], [train main loss -1.263010], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 114 / 176], [train main loss -1.259772], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 115 / 176], [train main loss -1.261553], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 116 / 176], [train main loss -1.271729], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 117 / 176], [train main loss -1.270591], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 118 / 176], [train main loss -1.260171], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 119 / 176], [train main loss -1.263634], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 120 / 176], [train main loss -1.253717], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 121 / 176], [train main loss -1.243228], [lr 0.009657] [batchtime 0.422]
[epoch 6], [iter 122 / 176], [train main loss -1.237957], [lr 0.009657] [batchtime 0.422]
[epoch 6], [iter 123 / 176], [train main loss -1.231562], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 124 / 176], [train main loss -1.236614], [lr 0.009657] [batchtime 0.435]
[epoch 6], [iter 125 / 176], [train main loss -1.240291], [lr 0.009657] [batchtime 0.434]
[epoch 6], [iter 126 / 176], [train main loss -1.244618], [lr 0.009657] [batchtime 0.434]
[epoch 6], [iter 127 / 176], [train main loss -1.229262], [lr 0.009657] [batchtime 0.433]
[epoch 6], [iter 128 / 176], [train main loss -1.238592], [lr 0.009657] [batchtime 0.433]
[epoch 6], [iter 129 / 176], [train main loss -1.238375], [lr 0.009657] [batchtime 0.433]
[epoch 6], [iter 130 / 176], [train main loss -1.244895], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 131 / 176], [train main loss -1.249716], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 132 / 176], [train main loss -1.248050], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 133 / 176], [train main loss -1.271999], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 134 / 176], [train main loss -1.251979], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 135 / 176], [train main loss -1.256329], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 136 / 176], [train main loss -1.252630], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 137 / 176], [train main loss -1.239205], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 138 / 176], [train main loss -1.241133], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 139 / 176], [train main loss -1.231404], [lr 0.009657] [batchtime 0.43]
[epoch 6], [iter 140 / 176], [train main loss -1.230674], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 141 / 176], [train main loss -1.222959], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 142 / 176], [train main loss -1.210664], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 143 / 176], [train main loss -1.209517], [lr 0.009657] [batchtime 0.429]
[epoch 6], [iter 144 / 176], [train main loss -1.219697], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 145 / 176], [train main loss -1.242717], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 146 / 176], [train main loss -1.231373], [lr 0.009657] [batchtime 0.428]
[epoch 6], [iter 147 / 176], [train main loss -1.240547], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 148 / 176], [train main loss -1.242376], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 149 / 176], [train main loss -1.236313], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 150 / 176], [train main loss -1.239760], [lr 0.009657] [batchtime 0.427]
[epoch 6], [iter 151 / 176], [train main loss -1.231924], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 152 / 176], [train main loss -1.242833], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 153 / 176], [train main loss -1.231589], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 154 / 176], [train main loss -1.229066], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 155 / 176], [train main loss -1.229883], [lr 0.009657] [batchtime 0.426]
[epoch 6], [iter 156 / 176], [train main loss -1.228745], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 157 / 176], [train main loss -1.220684], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 158 / 176], [train main loss -1.209591], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 159 / 176], [train main loss -1.208657], [lr 0.009657] [batchtime 0.425]
[epoch 6], [iter 160 / 176], [train main loss -1.204601], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 161 / 176], [train main loss -1.196849], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 162 / 176], [train main loss -1.221996], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 163 / 176], [train main loss -1.228169], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 164 / 176], [train main loss -1.226093], [lr 0.009657] [batchtime 0.424]
[epoch 6], [iter 165 / 176], [train main loss -1.224223], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 166 / 176], [train main loss -1.225933], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 167 / 176], [train main loss -1.222908], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 168 / 176], [train main loss -1.219878], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 169 / 176], [train main loss -1.213499], [lr 0.009657] [batchtime 0.423]
[epoch 6], [iter 170 / 176], [train main loss -1.192312], [lr 0.009657] [batchtime 0.422]
[epoch 6], [iter 171 / 176], [train main loss -1.190217], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 172 / 176], [train main loss -1.192187], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 173 / 176], [train main loss -1.192395], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 174 / 176], [train main loss -1.200664], [lr 0.009657] [batchtime 0.432]
[epoch 6], [iter 175 / 176], [train main loss -1.200917], [lr 0.009657] [batchtime 0.431]
[epoch 6], [iter 176 / 176], [train main loss -1.196430], [lr 0.009657] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              84.37  34.38       0.06    0.13         0.95      0.89
   1  sidewalk          25.13   2.37       1.78    1.20         0.36      0.46
   2  building          71.03  23.97       0.11    0.30         0.90      0.77
   3  wall               0.00   0.00     inf     nan            0.00    nan
   4  fence              0.00   0.00     inf     nan            0.00    nan
   5  pole               0.00   0.00  291058.03    2.11         0.00      0.32
   6  traffic light      0.00   0.00     inf     nan            0.00    nan
   7  traffic sign       0.22   0.00     451.08    0.20         0.00      0.83
   8  vegetation        68.44  10.01       0.23    0.23         0.81      0.82
   9  terrain            3.76   0.03      23.18    2.45         0.04      0.29
  10  sky               85.87   3.67       0.06    0.11         0.95      0.90
  11  person             0.01   0.00    6759.21    1.31         0.00      0.43
  12  rider              0.00   0.00     inf     nan            0.00    nan
  13  car               51.04   5.24       0.35    0.61         0.74      0.62
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00     inf     nan            0.00    nan
  16  train              0.00   0.00     inf     nan            0.00    nan
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle            0.00   0.00     inf     nan            0.00    nan
Mean: 20.52
-----------------------------------------------------------------------------------------------------------
this : [epoch 6], [val loss 0.66998], [acc 0.79675], [acc_cls 0.24993], [mean_iu 0.20520], [fwavacc 0.66641]
best : [epoch 6], [val loss 0.66998], [acc 0.79675], [acc_cls 0.24993], [mean_iu 0.20520], [fwavacc 0.66641]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 7], [iter 1 / 176], [train main loss -2.156288], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 2 / 176], [train main loss -0.725566], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 3 / 176], [train main loss -1.387841], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 4 / 176], [train main loss -1.380663], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 5 / 176], [train main loss -1.986030], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 6 / 176], [train main loss -1.759277], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 7 / 176], [train main loss -1.466045], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 8 / 176], [train main loss -1.551580], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 9 / 176], [train main loss -1.490060], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 10 / 176], [train main loss -1.576350], [lr 0.009600] [batchtime 0]
[epoch 7], [iter 11 / 176], [train main loss -1.444625], [lr 0.009600] [batchtime 0.374]
[epoch 7], [iter 12 / 176], [train main loss -1.226582], [lr 0.009600] [batchtime 0.384]
[epoch 7], [iter 13 / 176], [train main loss -1.440647], [lr 0.009600] [batchtime 0.388]
[epoch 7], [iter 14 / 176], [train main loss -1.528841], [lr 0.009600] [batchtime 0.388]
[epoch 7], [iter 15 / 176], [train main loss -1.551526], [lr 0.009600] [batchtime 0.393]
[epoch 7], [iter 16 / 176], [train main loss -1.570672], [lr 0.009600] [batchtime 0.395]
[epoch 7], [iter 17 / 176], [train main loss -1.504392], [lr 0.009600] [batchtime 0.394]
[epoch 7], [iter 18 / 176], [train main loss -1.582661], [lr 0.009600] [batchtime 0.401]
[epoch 7], [iter 19 / 176], [train main loss -1.591719], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 20 / 176], [train main loss -1.480121], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 21 / 176], [train main loss -1.670680], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 22 / 176], [train main loss -1.592144], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 23 / 176], [train main loss -1.632910], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 24 / 176], [train main loss -1.583049], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 25 / 176], [train main loss -1.624180], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 26 / 176], [train main loss -1.635442], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 27 / 176], [train main loss -1.583803], [lr 0.009600] [batchtime 0.41]
[epoch 7], [iter 28 / 176], [train main loss -1.497976], [lr 0.009600] [batchtime 0.409]
[epoch 7], [iter 29 / 176], [train main loss -1.469260], [lr 0.009600] [batchtime 0.408]
[epoch 7], [iter 30 / 176], [train main loss -1.451802], [lr 0.009600] [batchtime 0.407]
[epoch 7], [iter 31 / 176], [train main loss -1.394006], [lr 0.009600] [batchtime 0.407]
[epoch 7], [iter 32 / 176], [train main loss -1.422177], [lr 0.009600] [batchtime 0.406]
[epoch 7], [iter 33 / 176], [train main loss -1.382044], [lr 0.009600] [batchtime 0.405]
[epoch 7], [iter 34 / 176], [train main loss -1.398233], [lr 0.009600] [batchtime 0.405]
[epoch 7], [iter 35 / 176], [train main loss -1.401884], [lr 0.009600] [batchtime 0.405]
[epoch 7], [iter 36 / 176], [train main loss -1.387980], [lr 0.009600] [batchtime 0.405]
[epoch 7], [iter 37 / 176], [train main loss -1.295961], [lr 0.009600] [batchtime 0.405]
[epoch 7], [iter 38 / 176], [train main loss -1.272680], [lr 0.009600] [batchtime 0.404]
[epoch 7], [iter 39 / 176], [train main loss -1.256271], [lr 0.009600] [batchtime 0.404]
[epoch 7], [iter 40 / 176], [train main loss -1.288831], [lr 0.009600] [batchtime 0.404]
[epoch 7], [iter 41 / 176], [train main loss -1.272119], [lr 0.009600] [batchtime 0.404]
[epoch 7], [iter 42 / 176], [train main loss -1.296163], [lr 0.009600] [batchtime 0.403]
[epoch 7], [iter 43 / 176], [train main loss -1.267979], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 44 / 176], [train main loss -1.225057], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 45 / 176], [train main loss -1.190312], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 46 / 176], [train main loss -1.125716], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 47 / 176], [train main loss -1.147733], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 48 / 176], [train main loss -1.196290], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 49 / 176], [train main loss -1.230476], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 50 / 176], [train main loss -1.260287], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 51 / 176], [train main loss -1.189721], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 52 / 176], [train main loss -1.149035], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 53 / 176], [train main loss -1.201259], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 54 / 176], [train main loss -1.177640], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 55 / 176], [train main loss -1.196287], [lr 0.009600] [batchtime 0.415]
[epoch 7], [iter 56 / 176], [train main loss -1.186238], [lr 0.009600] [batchtime 0.415]
[epoch 7], [iter 57 / 176], [train main loss -1.175667], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 58 / 176], [train main loss -1.175489], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 59 / 176], [train main loss -1.210453], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 60 / 176], [train main loss -1.188611], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 61 / 176], [train main loss -1.180016], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 62 / 176], [train main loss -1.226239], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 63 / 176], [train main loss -1.237732], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 64 / 176], [train main loss -1.235789], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 65 / 176], [train main loss -1.242488], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 66 / 176], [train main loss -1.214567], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 67 / 176], [train main loss -1.232928], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 68 / 176], [train main loss -1.243626], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 69 / 176], [train main loss -1.212910], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 70 / 176], [train main loss -1.245719], [lr 0.009600] [batchtime 0.415]
[epoch 7], [iter 71 / 176], [train main loss -1.233636], [lr 0.009600] [batchtime 0.415]
[epoch 7], [iter 72 / 176], [train main loss -1.260847], [lr 0.009600] [batchtime 0.415]
[epoch 7], [iter 73 / 176], [train main loss -1.246146], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 74 / 176], [train main loss -1.238294], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 75 / 176], [train main loss -1.248588], [lr 0.009600] [batchtime 0.414]
[epoch 7], [iter 76 / 176], [train main loss -1.208848], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 77 / 176], [train main loss -1.209646], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 78 / 176], [train main loss -1.217285], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 79 / 176], [train main loss -1.258252], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 80 / 176], [train main loss -1.245244], [lr 0.009600] [batchtime 0.413]
[epoch 7], [iter 81 / 176], [train main loss -1.254317], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 82 / 176], [train main loss -1.214268], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 83 / 176], [train main loss -1.224884], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 84 / 176], [train main loss -1.229421], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 85 / 176], [train main loss -1.194238], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 86 / 176], [train main loss -1.180143], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 87 / 176], [train main loss -1.164450], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 88 / 176], [train main loss -1.179134], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 89 / 176], [train main loss -1.181481], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 90 / 176], [train main loss -1.187689], [lr 0.009600] [batchtime 0.411]
[epoch 7], [iter 91 / 176], [train main loss -1.202131], [lr 0.009600] [batchtime 0.412]
[epoch 7], [iter 92 / 176], [train main loss -1.182269], [lr 0.009600] [batchtime 0.426]
[epoch 7], [iter 93 / 176], [train main loss -1.162793], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 94 / 176], [train main loss -1.185180], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 95 / 176], [train main loss -1.196389], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 96 / 176], [train main loss -1.194247], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 97 / 176], [train main loss -1.203850], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 98 / 176], [train main loss -1.192756], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 99 / 176], [train main loss -1.177066], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 100 / 176], [train main loss -1.153538], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 101 / 176], [train main loss -1.155083], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 102 / 176], [train main loss -1.159204], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 103 / 176], [train main loss -1.153770], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 104 / 176], [train main loss -1.160963], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 105 / 176], [train main loss -1.169688], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 106 / 176], [train main loss -1.157465], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 107 / 176], [train main loss -1.144561], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 108 / 176], [train main loss -1.152318], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 109 / 176], [train main loss -1.167153], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 110 / 176], [train main loss -1.169875], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 111 / 176], [train main loss -1.147625], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 112 / 176], [train main loss -1.150507], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 113 / 176], [train main loss -1.134756], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 114 / 176], [train main loss -1.122654], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 115 / 176], [train main loss -1.106111], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 116 / 176], [train main loss -1.101313], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 117 / 176], [train main loss -1.119868], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 118 / 176], [train main loss -1.108860], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 119 / 176], [train main loss -1.120863], [lr 0.009600] [batchtime 0.42]
[epoch 7], [iter 120 / 176], [train main loss -1.123260], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 121 / 176], [train main loss -1.126275], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 122 / 176], [train main loss -1.127329], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 123 / 176], [train main loss -1.117853], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 124 / 176], [train main loss -1.105159], [lr 0.009600] [batchtime 0.419]
[epoch 7], [iter 125 / 176], [train main loss -1.113127], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 126 / 176], [train main loss -1.086870], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 127 / 176], [train main loss -1.074576], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 128 / 176], [train main loss -1.089105], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 129 / 176], [train main loss -1.105670], [lr 0.009600] [batchtime 0.418]
[epoch 7], [iter 130 / 176], [train main loss -1.106348], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 131 / 176], [train main loss -1.095619], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 132 / 176], [train main loss -1.092311], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 133 / 176], [train main loss -1.084820], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 134 / 176], [train main loss -1.082685], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 135 / 176], [train main loss -1.086601], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 136 / 176], [train main loss -1.087509], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 137 / 176], [train main loss -1.087362], [lr 0.009600] [batchtime 0.416]
[epoch 7], [iter 138 / 176], [train main loss -1.105091], [lr 0.009600] [batchtime 0.417]
[epoch 7], [iter 139 / 176], [train main loss -1.108668], [lr 0.009600] [batchtime 0.427]
[epoch 7], [iter 140 / 176], [train main loss -1.111137], [lr 0.009600] [batchtime 0.427]
[epoch 7], [iter 141 / 176], [train main loss -1.100567], [lr 0.009600] [batchtime 0.427]
[epoch 7], [iter 142 / 176], [train main loss -1.085962], [lr 0.009600] [batchtime 0.426]
[epoch 7], [iter 143 / 176], [train main loss -1.069885], [lr 0.009600] [batchtime 0.426]
[epoch 7], [iter 144 / 176], [train main loss -1.060830], [lr 0.009600] [batchtime 0.426]
[epoch 7], [iter 145 / 176], [train main loss -1.061478], [lr 0.009600] [batchtime 0.426]
[epoch 7], [iter 146 / 176], [train main loss -1.052344], [lr 0.009600] [batchtime 0.426]
[epoch 7], [iter 147 / 176], [train main loss -1.053980], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 148 / 176], [train main loss -1.051703], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 149 / 176], [train main loss -1.057739], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 150 / 176], [train main loss -1.054494], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 151 / 176], [train main loss -1.040855], [lr 0.009600] [batchtime 0.425]
[epoch 7], [iter 152 / 176], [train main loss -1.068919], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 153 / 176], [train main loss -1.059535], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 154 / 176], [train main loss -1.055345], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 155 / 176], [train main loss -1.073339], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 156 / 176], [train main loss -1.086859], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 157 / 176], [train main loss -1.092054], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 158 / 176], [train main loss -1.084874], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 159 / 176], [train main loss -1.099804], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 160 / 176], [train main loss -1.110497], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 161 / 176], [train main loss -1.123003], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 162 / 176], [train main loss -1.131171], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 163 / 176], [train main loss -1.121947], [lr 0.009600] [batchtime 0.424]
[epoch 7], [iter 164 / 176], [train main loss -1.126467], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 165 / 176], [train main loss -1.116284], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 166 / 176], [train main loss -1.116814], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 167 / 176], [train main loss -1.109697], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 168 / 176], [train main loss -1.106556], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 169 / 176], [train main loss -1.100348], [lr 0.009600] [batchtime 0.423]
[epoch 7], [iter 170 / 176], [train main loss -1.095287], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 171 / 176], [train main loss -1.077005], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 172 / 176], [train main loss -1.066382], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 173 / 176], [train main loss -1.090174], [lr 0.009600] [batchtime 0.422]
[epoch 7], [iter 174 / 176], [train main loss -1.109017], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 175 / 176], [train main loss -1.116013], [lr 0.009600] [batchtime 0.421]
[epoch 7], [iter 176 / 176], [train main loss -1.124076], [lr 0.009600] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              84.41  35.31        0.03    0.16         0.97      0.87
   1  sidewalk          23.29   2.03        2.25    1.04         0.31      0.49
   2  building          71.50  22.34        0.19    0.21         0.84      0.83
   3  wall               0.00   0.00      inf     nan            0.00    nan
   4  fence              0.00   0.00      inf     nan            0.00    nan
   5  pole               0.05   0.00     2061.34    1.45         0.00      0.41
   6  traffic light      0.00   0.00      inf     nan            0.00    nan
   7  traffic sign       1.06   0.01       91.85    1.17         0.01      0.46
   8  vegetation        65.52  11.14        0.11    0.42         0.90      0.71
   9  terrain           10.90   0.11        5.85    2.33         0.15      0.30
  10  sky               86.18   3.72        0.04    0.12         0.96      0.89
  11  person             0.28   0.00      356.69    1.69         0.00      0.37
  12  rider              0.00   0.00      inf     nan            0.00    nan
  13  car               53.44   5.17        0.37    0.50         0.73      0.67
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00      inf     nan            0.00    nan
  16  train              0.00   0.00      inf     nan            0.00    nan
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle            0.00   0.00  1530243.00    0.67         0.00      0.60
Mean: 20.88
-----------------------------------------------------------------------------------------------------------
this : [epoch 7], [val loss 0.69964], [acc 0.79819], [acc_cls 0.25636], [mean_iu 0.20876], [fwavacc 0.66544]
best : [epoch 7], [val loss 0.69964], [acc 0.79819], [acc_cls 0.25636], [mean_iu 0.20876], [fwavacc 0.66544]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 8], [iter 1 / 176], [train main loss -0.118739], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 2 / 176], [train main loss -0.187023], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 3 / 176], [train main loss -0.176851], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 4 / 176], [train main loss -0.345733], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 5 / 176], [train main loss -0.404112], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 6 / 176], [train main loss -0.431041], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 7 / 176], [train main loss -0.588586], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 8 / 176], [train main loss -0.722951], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 9 / 176], [train main loss -0.614562], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 10 / 176], [train main loss -0.938492], [lr 0.009543] [batchtime 0]
[epoch 8], [iter 11 / 176], [train main loss -0.963046], [lr 0.009543] [batchtime 0.37]
[epoch 8], [iter 12 / 176], [train main loss -0.823209], [lr 0.009543] [batchtime 0.38]
[epoch 8], [iter 13 / 176], [train main loss -1.037837], [lr 0.009543] [batchtime 0.4]
[epoch 8], [iter 14 / 176], [train main loss -1.038067], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 15 / 176], [train main loss -1.013035], [lr 0.009543] [batchtime 0.396]
[epoch 8], [iter 16 / 176], [train main loss -0.989777], [lr 0.009543] [batchtime 0.398]
[epoch 8], [iter 17 / 176], [train main loss -1.064513], [lr 0.009543] [batchtime 0.399]
[epoch 8], [iter 18 / 176], [train main loss -1.070845], [lr 0.009543] [batchtime 0.4]
[epoch 8], [iter 19 / 176], [train main loss -1.044501], [lr 0.009543] [batchtime 0.399]
[epoch 8], [iter 20 / 176], [train main loss -1.060309], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 21 / 176], [train main loss -1.075120], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 22 / 176], [train main loss -1.140423], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 23 / 176], [train main loss -1.010522], [lr 0.009543] [batchtime 0.396]
[epoch 8], [iter 24 / 176], [train main loss -0.993573], [lr 0.009543] [batchtime 0.396]
[epoch 8], [iter 25 / 176], [train main loss -0.912972], [lr 0.009543] [batchtime 0.402]
[epoch 8], [iter 26 / 176], [train main loss -0.911759], [lr 0.009543] [batchtime 0.401]
[epoch 8], [iter 27 / 176], [train main loss -0.928574], [lr 0.009543] [batchtime 0.401]
[epoch 8], [iter 28 / 176], [train main loss -0.940117], [lr 0.009543] [batchtime 0.4]
[epoch 8], [iter 29 / 176], [train main loss -0.963600], [lr 0.009543] [batchtime 0.4]
[epoch 8], [iter 30 / 176], [train main loss -0.965929], [lr 0.009543] [batchtime 0.399]
[epoch 8], [iter 31 / 176], [train main loss -0.982097], [lr 0.009543] [batchtime 0.398]
[epoch 8], [iter 32 / 176], [train main loss -0.999493], [lr 0.009543] [batchtime 0.398]
[epoch 8], [iter 33 / 176], [train main loss -1.117859], [lr 0.009543] [batchtime 0.398]
[epoch 8], [iter 34 / 176], [train main loss -1.091348], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 35 / 176], [train main loss -1.041005], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 36 / 176], [train main loss -1.062516], [lr 0.009543] [batchtime 0.397]
[epoch 8], [iter 37 / 176], [train main loss -0.969607], [lr 0.009543] [batchtime 0.398]
[epoch 8], [iter 38 / 176], [train main loss -1.001646], [lr 0.009543] [batchtime 0.423]
[epoch 8], [iter 39 / 176], [train main loss -1.043002], [lr 0.009543] [batchtime 0.423]
[epoch 8], [iter 40 / 176], [train main loss -1.013750], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 41 / 176], [train main loss -1.047443], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 42 / 176], [train main loss -1.065428], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 43 / 176], [train main loss -1.039884], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 44 / 176], [train main loss -0.989787], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 45 / 176], [train main loss -0.974237], [lr 0.009543] [batchtime 0.416]
[epoch 8], [iter 46 / 176], [train main loss -0.979304], [lr 0.009543] [batchtime 0.416]
[epoch 8], [iter 47 / 176], [train main loss -0.981607], [lr 0.009543] [batchtime 0.415]
[epoch 8], [iter 48 / 176], [train main loss -1.008897], [lr 0.009543] [batchtime 0.414]
[epoch 8], [iter 49 / 176], [train main loss -0.953568], [lr 0.009543] [batchtime 0.414]
[epoch 8], [iter 50 / 176], [train main loss -0.944851], [lr 0.009543] [batchtime 0.413]
[epoch 8], [iter 51 / 176], [train main loss -0.900895], [lr 0.009543] [batchtime 0.412]
[epoch 8], [iter 52 / 176], [train main loss -0.897702], [lr 0.009543] [batchtime 0.412]
[epoch 8], [iter 53 / 176], [train main loss -0.899964], [lr 0.009543] [batchtime 0.412]
[epoch 8], [iter 54 / 176], [train main loss -0.866756], [lr 0.009543] [batchtime 0.411]
[epoch 8], [iter 55 / 176], [train main loss -0.912612], [lr 0.009543] [batchtime 0.411]
[epoch 8], [iter 56 / 176], [train main loss -0.938935], [lr 0.009543] [batchtime 0.41]
[epoch 8], [iter 57 / 176], [train main loss -0.960374], [lr 0.009543] [batchtime 0.41]
[epoch 8], [iter 58 / 176], [train main loss -0.968969], [lr 0.009543] [batchtime 0.41]
[epoch 8], [iter 59 / 176], [train main loss -0.971347], [lr 0.009543] [batchtime 0.409]
[epoch 8], [iter 60 / 176], [train main loss -0.960134], [lr 0.009543] [batchtime 0.409]
[epoch 8], [iter 61 / 176], [train main loss -0.972516], [lr 0.009543] [batchtime 0.409]
[epoch 8], [iter 62 / 176], [train main loss -0.953572], [lr 0.009543] [batchtime 0.409]
[epoch 8], [iter 63 / 176], [train main loss -0.989956], [lr 0.009543] [batchtime 0.409]
[epoch 8], [iter 64 / 176], [train main loss -0.993815], [lr 0.009543] [batchtime 0.409]
[epoch 8], [iter 65 / 176], [train main loss -1.018560], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 66 / 176], [train main loss -1.006990], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 67 / 176], [train main loss -0.985686], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 68 / 176], [train main loss -1.008213], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 69 / 176], [train main loss -1.042834], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 70 / 176], [train main loss -1.077191], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 71 / 176], [train main loss -1.108786], [lr 0.009543] [batchtime 0.408]
[epoch 8], [iter 72 / 176], [train main loss -1.113756], [lr 0.009543] [batchtime 0.407]
[epoch 8], [iter 73 / 176], [train main loss -1.172396], [lr 0.009543] [batchtime 0.407]
[epoch 8], [iter 74 / 176], [train main loss -1.144322], [lr 0.009543] [batchtime 0.407]
[epoch 8], [iter 75 / 176], [train main loss -1.138530], [lr 0.009543] [batchtime 0.407]
[epoch 8], [iter 76 / 176], [train main loss -1.118971], [lr 0.009543] [batchtime 0.406]
[epoch 8], [iter 77 / 176], [train main loss -1.102317], [lr 0.009543] [batchtime 0.406]
[epoch 8], [iter 78 / 176], [train main loss -1.141876], [lr 0.009543] [batchtime 0.406]
[epoch 8], [iter 79 / 176], [train main loss -1.137047], [lr 0.009543] [batchtime 0.406]
[epoch 8], [iter 80 / 176], [train main loss -1.144842], [lr 0.009543] [batchtime 0.406]
[epoch 8], [iter 81 / 176], [train main loss -1.140114], [lr 0.009543] [batchtime 0.405]
[epoch 8], [iter 82 / 176], [train main loss -1.157225], [lr 0.009543] [batchtime 0.405]
[epoch 8], [iter 83 / 176], [train main loss -1.188406], [lr 0.009543] [batchtime 0.405]
[epoch 8], [iter 84 / 176], [train main loss -1.201614], [lr 0.009543] [batchtime 0.405]
[epoch 8], [iter 85 / 176], [train main loss -1.200415], [lr 0.009543] [batchtime 0.405]
[epoch 8], [iter 86 / 176], [train main loss -1.190749], [lr 0.009543] [batchtime 0.407]
[epoch 8], [iter 87 / 176], [train main loss -1.179511], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 88 / 176], [train main loss -1.155254], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 89 / 176], [train main loss -1.147038], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 90 / 176], [train main loss -1.115253], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 91 / 176], [train main loss -1.118742], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 92 / 176], [train main loss -1.129195], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 93 / 176], [train main loss -1.122555], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 94 / 176], [train main loss -1.133952], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 95 / 176], [train main loss -1.155942], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 96 / 176], [train main loss -1.154435], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 97 / 176], [train main loss -1.137865], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 98 / 176], [train main loss -1.144105], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 99 / 176], [train main loss -1.163571], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 100 / 176], [train main loss -1.159134], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 101 / 176], [train main loss -1.153067], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 102 / 176], [train main loss -1.157808], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 103 / 176], [train main loss -1.166075], [lr 0.009543] [batchtime 0.416]
[epoch 8], [iter 104 / 176], [train main loss -1.180421], [lr 0.009543] [batchtime 0.416]
[epoch 8], [iter 105 / 176], [train main loss -1.197439], [lr 0.009543] [batchtime 0.416]
[epoch 8], [iter 106 / 176], [train main loss -1.167960], [lr 0.009543] [batchtime 0.416]
[epoch 8], [iter 107 / 176], [train main loss -1.145260], [lr 0.009543] [batchtime 0.415]
[epoch 8], [iter 108 / 176], [train main loss -1.153903], [lr 0.009543] [batchtime 0.415]
[epoch 8], [iter 109 / 176], [train main loss -1.141664], [lr 0.009543] [batchtime 0.415]
[epoch 8], [iter 110 / 176], [train main loss -1.138716], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 111 / 176], [train main loss -1.167289], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 112 / 176], [train main loss -1.183382], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 113 / 176], [train main loss -1.183621], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 114 / 176], [train main loss -1.188389], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 115 / 176], [train main loss -1.188255], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 116 / 176], [train main loss -1.190958], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 117 / 176], [train main loss -1.192860], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 118 / 176], [train main loss -1.186986], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 119 / 176], [train main loss -1.213172], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 120 / 176], [train main loss -1.201540], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 121 / 176], [train main loss -1.178630], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 122 / 176], [train main loss -1.173189], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 123 / 176], [train main loss -1.198527], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 124 / 176], [train main loss -1.184682], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 125 / 176], [train main loss -1.195041], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 126 / 176], [train main loss -1.193133], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 127 / 176], [train main loss -1.200848], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 128 / 176], [train main loss -1.238865], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 129 / 176], [train main loss -1.237631], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 130 / 176], [train main loss -1.236323], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 131 / 176], [train main loss -1.243267], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 132 / 176], [train main loss -1.267022], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 133 / 176], [train main loss -1.275314], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 134 / 176], [train main loss -1.306646], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 135 / 176], [train main loss -1.330321], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 136 / 176], [train main loss -1.326107], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 137 / 176], [train main loss -1.319099], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 138 / 176], [train main loss -1.309247], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 139 / 176], [train main loss -1.303107], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 140 / 176], [train main loss -1.296002], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 141 / 176], [train main loss -1.272212], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 142 / 176], [train main loss -1.292875], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 143 / 176], [train main loss -1.307394], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 144 / 176], [train main loss -1.307948], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 145 / 176], [train main loss -1.299152], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 146 / 176], [train main loss -1.322390], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 147 / 176], [train main loss -1.331119], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 148 / 176], [train main loss -1.335749], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 149 / 176], [train main loss -1.343166], [lr 0.009543] [batchtime 0.418]
[epoch 8], [iter 150 / 176], [train main loss -1.341605], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 151 / 176], [train main loss -1.345958], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 152 / 176], [train main loss -1.326020], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 153 / 176], [train main loss -1.324944], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 154 / 176], [train main loss -1.326195], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 155 / 176], [train main loss -1.308873], [lr 0.009543] [batchtime 0.417]
[epoch 8], [iter 156 / 176], [train main loss -1.308566], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 157 / 176], [train main loss -1.319642], [lr 0.009543] [batchtime 0.424]
[epoch 8], [iter 158 / 176], [train main loss -1.314586], [lr 0.009543] [batchtime 0.423]
[epoch 8], [iter 159 / 176], [train main loss -1.309366], [lr 0.009543] [batchtime 0.423]
[epoch 8], [iter 160 / 176], [train main loss -1.305310], [lr 0.009543] [batchtime 0.423]
[epoch 8], [iter 161 / 176], [train main loss -1.295841], [lr 0.009543] [batchtime 0.423]
[epoch 8], [iter 162 / 176], [train main loss -1.294068], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 163 / 176], [train main loss -1.286032], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 164 / 176], [train main loss -1.299634], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 165 / 176], [train main loss -1.300648], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 166 / 176], [train main loss -1.313862], [lr 0.009543] [batchtime 0.422]
[epoch 8], [iter 167 / 176], [train main loss -1.303520], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 168 / 176], [train main loss -1.318504], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 169 / 176], [train main loss -1.303537], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 170 / 176], [train main loss -1.308152], [lr 0.009543] [batchtime 0.421]
[epoch 8], [iter 171 / 176], [train main loss -1.305800], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 172 / 176], [train main loss -1.307337], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 173 / 176], [train main loss -1.300241], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 174 / 176], [train main loss -1.300811], [lr 0.009543] [batchtime 0.42]
[epoch 8], [iter 175 / 176], [train main loss -1.302300], [lr 0.009543] [batchtime 0.419]
[epoch 8], [iter 176 / 176], [train main loss -1.302789], [lr 0.009543] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              84.86  35.12      0.04    0.14         0.97      0.87
   1  sidewalk          27.81   2.50      1.63    0.96         0.38      0.51
   2  building          73.30  23.43      0.13    0.23         0.88      0.81
   3  wall               0.00   0.00    inf     nan            0.00    nan
   4  fence              0.00   0.00    inf     nan            0.00    nan
   5  pole               0.09   0.00   1068.04    0.99         0.00      0.50
   6  traffic light      0.00   0.00    inf     nan            0.00    nan
   7  traffic sign       1.19   0.01     81.59    1.21         0.01      0.45
   8  vegetation        68.69  10.58      0.17    0.29         0.86      0.78
   9  terrain           11.21   0.10      6.51    1.41         0.13      0.41
  10  sky               88.11   3.67      0.05    0.08         0.95      0.93
  11  person             0.86   0.01    114.12    1.72         0.01      0.37
  12  rider              0.00   0.00    inf     nan            0.00    nan
  13  car               53.93   5.36      0.32    0.53         0.76      0.65
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.00   0.00    inf     nan            0.00    nan
  16  train              0.00   0.00    inf     nan            0.00    nan
  17  motorcycle         0.00   0.00    inf     nan            0.00    nan
  18  bicycle            0.01   0.00  11800.37    1.13         0.00      0.47
Mean: 21.58
-----------------------------------------------------------------------------------------------------------
this : [epoch 8], [val loss 0.66333], [acc 0.80793], [acc_cls 0.26023], [mean_iu 0.21581], [fwavacc 0.67992]
best : [epoch 8], [val loss 0.66333], [acc 0.80793], [acc_cls 0.26023], [mean_iu 0.21581], [fwavacc 0.67992]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 9], [iter 1 / 176], [train main loss -0.728323], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 2 / 176], [train main loss -0.735287], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 3 / 176], [train main loss -0.432996], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 4 / 176], [train main loss -0.422643], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 5 / 176], [train main loss -0.659351], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 6 / 176], [train main loss -0.639223], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 7 / 176], [train main loss -0.759127], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 8 / 176], [train main loss -0.562180], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 9 / 176], [train main loss -0.477790], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 10 / 176], [train main loss -0.351906], [lr 0.009486] [batchtime 0]
[epoch 9], [iter 11 / 176], [train main loss -0.600840], [lr 0.009486] [batchtime 0.367]
[epoch 9], [iter 12 / 176], [train main loss -0.519032], [lr 0.009486] [batchtime 0.382]
[epoch 9], [iter 13 / 176], [train main loss -0.489618], [lr 0.009486] [batchtime 0.385]
[epoch 9], [iter 14 / 176], [train main loss -0.562246], [lr 0.009486] [batchtime 0.387]
[epoch 9], [iter 15 / 176], [train main loss -0.678269], [lr 0.009486] [batchtime 0.389]
[epoch 9], [iter 16 / 176], [train main loss -0.867277], [lr 0.009486] [batchtime 0.39]
[epoch 9], [iter 17 / 176], [train main loss -0.829304], [lr 0.009486] [batchtime 0.39]
[epoch 9], [iter 18 / 176], [train main loss -0.898168], [lr 0.009486] [batchtime 0.411]
[epoch 9], [iter 19 / 176], [train main loss -0.953667], [lr 0.009486] [batchtime 0.408]
[epoch 9], [iter 20 / 176], [train main loss -0.977184], [lr 0.009486] [batchtime 0.406]
[epoch 9], [iter 21 / 176], [train main loss -1.123032], [lr 0.009486] [batchtime 0.405]
[epoch 9], [iter 22 / 176], [train main loss -1.230322], [lr 0.009486] [batchtime 0.403]
[epoch 9], [iter 23 / 176], [train main loss -1.163032], [lr 0.009486] [batchtime 0.404]
[epoch 9], [iter 24 / 176], [train main loss -1.183037], [lr 0.009486] [batchtime 0.403]
[epoch 9], [iter 25 / 176], [train main loss -1.227341], [lr 0.009486] [batchtime 0.402]
[epoch 9], [iter 26 / 176], [train main loss -1.174372], [lr 0.009486] [batchtime 0.402]
[epoch 9], [iter 27 / 176], [train main loss -1.191045], [lr 0.009486] [batchtime 0.401]
[epoch 9], [iter 28 / 176], [train main loss -1.114953], [lr 0.009486] [batchtime 0.401]
[epoch 9], [iter 29 / 176], [train main loss -1.239585], [lr 0.009486] [batchtime 0.401]
[epoch 9], [iter 30 / 176], [train main loss -1.205814], [lr 0.009486] [batchtime 0.401]
[epoch 9], [iter 31 / 176], [train main loss -1.223681], [lr 0.009486] [batchtime 0.409]
[epoch 9], [iter 32 / 176], [train main loss -1.142973], [lr 0.009486] [batchtime 0.474]
[epoch 9], [iter 33 / 176], [train main loss -1.182032], [lr 0.009486] [batchtime 0.47]
[epoch 9], [iter 34 / 176], [train main loss -1.115655], [lr 0.009486] [batchtime 0.467]
[epoch 9], [iter 35 / 176], [train main loss -1.194435], [lr 0.009486] [batchtime 0.464]
[epoch 9], [iter 36 / 176], [train main loss -1.147770], [lr 0.009486] [batchtime 0.461]
[epoch 9], [iter 37 / 176], [train main loss -1.139367], [lr 0.009486] [batchtime 0.458]
[epoch 9], [iter 38 / 176], [train main loss -1.126971], [lr 0.009486] [batchtime 0.456]
[epoch 9], [iter 39 / 176], [train main loss -1.126215], [lr 0.009486] [batchtime 0.454]
[epoch 9], [iter 40 / 176], [train main loss -1.119049], [lr 0.009486] [batchtime 0.452]
[epoch 9], [iter 41 / 176], [train main loss -1.142485], [lr 0.009486] [batchtime 0.451]
[epoch 9], [iter 42 / 176], [train main loss -1.213981], [lr 0.009486] [batchtime 0.449]
[epoch 9], [iter 43 / 176], [train main loss -1.247150], [lr 0.009486] [batchtime 0.447]
[epoch 9], [iter 44 / 176], [train main loss -1.209981], [lr 0.009486] [batchtime 0.445]
[epoch 9], [iter 45 / 176], [train main loss -1.270631], [lr 0.009486] [batchtime 0.444]
[epoch 9], [iter 46 / 176], [train main loss -1.224021], [lr 0.009486] [batchtime 0.442]
[epoch 9], [iter 47 / 176], [train main loss -1.214850], [lr 0.009486] [batchtime 0.441]
[epoch 9], [iter 48 / 176], [train main loss -1.273371], [lr 0.009486] [batchtime 0.44]
[epoch 9], [iter 49 / 176], [train main loss -1.248311], [lr 0.009486] [batchtime 0.438]
[epoch 9], [iter 50 / 176], [train main loss -1.221328], [lr 0.009486] [batchtime 0.437]
[epoch 9], [iter 51 / 176], [train main loss -1.216182], [lr 0.009486] [batchtime 0.436]
[epoch 9], [iter 52 / 176], [train main loss -1.160187], [lr 0.009486] [batchtime 0.436]
[epoch 9], [iter 53 / 176], [train main loss -1.158146], [lr 0.009486] [batchtime 0.435]
[epoch 9], [iter 54 / 176], [train main loss -1.207621], [lr 0.009486] [batchtime 0.434]
[epoch 9], [iter 55 / 176], [train main loss -1.164970], [lr 0.009486] [batchtime 0.433]
[epoch 9], [iter 56 / 176], [train main loss -1.143191], [lr 0.009486] [batchtime 0.432]
[epoch 9], [iter 57 / 176], [train main loss -1.175082], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 58 / 176], [train main loss -1.139121], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 59 / 176], [train main loss -1.150673], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 60 / 176], [train main loss -1.169252], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 61 / 176], [train main loss -1.152400], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 62 / 176], [train main loss -1.157162], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 63 / 176], [train main loss -1.181900], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 64 / 176], [train main loss -1.207038], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 65 / 176], [train main loss -1.187944], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 66 / 176], [train main loss -1.181494], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 67 / 176], [train main loss -1.212594], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 68 / 176], [train main loss -1.232150], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 69 / 176], [train main loss -1.215005], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 70 / 176], [train main loss -1.218660], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 71 / 176], [train main loss -1.226993], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 72 / 176], [train main loss -1.199963], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 73 / 176], [train main loss -1.172959], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 74 / 176], [train main loss -1.161930], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 75 / 176], [train main loss -1.211862], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 76 / 176], [train main loss -1.174548], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 77 / 176], [train main loss -1.188720], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 78 / 176], [train main loss -1.193489], [lr 0.009486] [batchtime 0.441]
[epoch 9], [iter 79 / 176], [train main loss -1.251817], [lr 0.009486] [batchtime 0.444]
[epoch 9], [iter 80 / 176], [train main loss -1.213509], [lr 0.009486] [batchtime 0.443]
[epoch 9], [iter 81 / 176], [train main loss -1.255468], [lr 0.009486] [batchtime 0.442]
[epoch 9], [iter 82 / 176], [train main loss -1.265342], [lr 0.009486] [batchtime 0.441]
[epoch 9], [iter 83 / 176], [train main loss -1.293158], [lr 0.009486] [batchtime 0.441]
[epoch 9], [iter 84 / 176], [train main loss -1.334975], [lr 0.009486] [batchtime 0.44]
[epoch 9], [iter 85 / 176], [train main loss -1.328193], [lr 0.009486] [batchtime 0.44]
[epoch 9], [iter 86 / 176], [train main loss -1.326649], [lr 0.009486] [batchtime 0.439]
[epoch 9], [iter 87 / 176], [train main loss -1.286917], [lr 0.009486] [batchtime 0.439]
[epoch 9], [iter 88 / 176], [train main loss -1.280966], [lr 0.009486] [batchtime 0.438]
[epoch 9], [iter 89 / 176], [train main loss -1.269062], [lr 0.009486] [batchtime 0.437]
[epoch 9], [iter 90 / 176], [train main loss -1.241645], [lr 0.009486] [batchtime 0.437]
[epoch 9], [iter 91 / 176], [train main loss -1.237192], [lr 0.009486] [batchtime 0.437]
[epoch 9], [iter 92 / 176], [train main loss -1.237234], [lr 0.009486] [batchtime 0.436]
[epoch 9], [iter 93 / 176], [train main loss -1.244505], [lr 0.009486] [batchtime 0.435]
[epoch 9], [iter 94 / 176], [train main loss -1.229745], [lr 0.009486] [batchtime 0.435]
[epoch 9], [iter 95 / 176], [train main loss -1.253260], [lr 0.009486] [batchtime 0.435]
[epoch 9], [iter 96 / 176], [train main loss -1.238055], [lr 0.009486] [batchtime 0.434]
[epoch 9], [iter 97 / 176], [train main loss -1.246585], [lr 0.009486] [batchtime 0.434]
[epoch 9], [iter 98 / 176], [train main loss -1.263194], [lr 0.009486] [batchtime 0.433]
[epoch 9], [iter 99 / 176], [train main loss -1.249747], [lr 0.009486] [batchtime 0.433]
[epoch 9], [iter 100 / 176], [train main loss -1.234239], [lr 0.009486] [batchtime 0.432]
[epoch 9], [iter 101 / 176], [train main loss -1.213659], [lr 0.009486] [batchtime 0.432]
[epoch 9], [iter 102 / 176], [train main loss -1.212083], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 103 / 176], [train main loss -1.193001], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 104 / 176], [train main loss -1.202096], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 105 / 176], [train main loss -1.193331], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 106 / 176], [train main loss -1.200647], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 107 / 176], [train main loss -1.203428], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 108 / 176], [train main loss -1.177372], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 109 / 176], [train main loss -1.166779], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 110 / 176], [train main loss -1.179447], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 111 / 176], [train main loss -1.160693], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 112 / 176], [train main loss -1.182141], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 113 / 176], [train main loss -1.170782], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 114 / 176], [train main loss -1.194169], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 115 / 176], [train main loss -1.195747], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 116 / 176], [train main loss -1.189582], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 117 / 176], [train main loss -1.197269], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 118 / 176], [train main loss -1.192554], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 119 / 176], [train main loss -1.196717], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 120 / 176], [train main loss -1.186769], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 121 / 176], [train main loss -1.163997], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 122 / 176], [train main loss -1.174464], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 123 / 176], [train main loss -1.197051], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 124 / 176], [train main loss -1.201818], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 125 / 176], [train main loss -1.195566], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 126 / 176], [train main loss -1.189035], [lr 0.009486] [batchtime 0.432]
[epoch 9], [iter 127 / 176], [train main loss -1.209245], [lr 0.009486] [batchtime 0.432]
[epoch 9], [iter 128 / 176], [train main loss -1.207939], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 129 / 176], [train main loss -1.213858], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 130 / 176], [train main loss -1.207385], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 131 / 176], [train main loss -1.198340], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 132 / 176], [train main loss -1.208935], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 133 / 176], [train main loss -1.192361], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 134 / 176], [train main loss -1.200853], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 135 / 176], [train main loss -1.183437], [lr 0.009486] [batchtime 0.43]
[epoch 9], [iter 136 / 176], [train main loss -1.178458], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 137 / 176], [train main loss -1.170321], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 138 / 176], [train main loss -1.181192], [lr 0.009486] [batchtime 0.429]
[epoch 9], [iter 139 / 176], [train main loss -1.157169], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 140 / 176], [train main loss -1.141003], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 141 / 176], [train main loss -1.128151], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 142 / 176], [train main loss -1.125514], [lr 0.009486] [batchtime 0.428]
[epoch 9], [iter 143 / 176], [train main loss -1.123447], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 144 / 176], [train main loss -1.121232], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 145 / 176], [train main loss -1.112750], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 146 / 176], [train main loss -1.099506], [lr 0.009486] [batchtime 0.427]
[epoch 9], [iter 147 / 176], [train main loss -1.091938], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 148 / 176], [train main loss -1.098872], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 149 / 176], [train main loss -1.113912], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 150 / 176], [train main loss -1.109484], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 151 / 176], [train main loss -1.121432], [lr 0.009486] [batchtime 0.426]
[epoch 9], [iter 152 / 176], [train main loss -1.097085], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 153 / 176], [train main loss -1.105763], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 154 / 176], [train main loss -1.086413], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 155 / 176], [train main loss -1.075284], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 156 / 176], [train main loss -1.061684], [lr 0.009486] [batchtime 0.425]
[epoch 9], [iter 157 / 176], [train main loss -1.054391], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 158 / 176], [train main loss -1.036361], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 159 / 176], [train main loss -1.037708], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 160 / 176], [train main loss -1.025795], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 161 / 176], [train main loss -1.024890], [lr 0.009486] [batchtime 0.424]
[epoch 9], [iter 162 / 176], [train main loss -1.035051], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 163 / 176], [train main loss -1.022241], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 164 / 176], [train main loss -1.026864], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 165 / 176], [train main loss -1.027481], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 166 / 176], [train main loss -1.031888], [lr 0.009486] [batchtime 0.423]
[epoch 9], [iter 167 / 176], [train main loss -1.032058], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 168 / 176], [train main loss -1.029654], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 169 / 176], [train main loss -1.036254], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 170 / 176], [train main loss -1.033695], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 171 / 176], [train main loss -1.034821], [lr 0.009486] [batchtime 0.421]
[epoch 9], [iter 172 / 176], [train main loss -1.032504], [lr 0.009486] [batchtime 0.421]
[epoch 9], [iter 173 / 176], [train main loss -1.034472], [lr 0.009486] [batchtime 0.422]
[epoch 9], [iter 174 / 176], [train main loss -1.038383], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 175 / 176], [train main loss -1.037344], [lr 0.009486] [batchtime 0.431]
[epoch 9], [iter 176 / 176], [train main loss -1.041161], [lr 0.009486] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              84.95  33.42        0.09    0.09         0.92      0.92
   1  sidewalk          33.36   3.40        0.94    1.06         0.52      0.49
   2  building          70.45  21.49        0.24    0.18         0.81      0.85
   3  wall               0.00   0.00      inf     nan            0.00    nan
   4  fence              0.00   0.00  7480576.50    0.00         0.00      1.00
   5  pole               0.27   0.00      361.84    1.75         0.00      0.36
   6  traffic light      0.00   0.00      inf     nan            0.00    nan
   7  traffic sign       1.58   0.01       60.77    1.43         0.02      0.41
   8  vegetation        63.17  11.40        0.08    0.50         0.92      0.67
   9  terrain           12.10   0.15        3.74    3.52         0.21      0.22
  10  sky               88.58   3.72        0.04    0.09         0.96      0.92
  11  person             0.33   0.01      297.92    1.63         0.00      0.38
  12  rider              0.00   0.00      inf     nan            0.00    nan
  13  car               55.84   5.88        0.20    0.59         0.83      0.63
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00      inf     nan            0.00    nan
  16  train              0.00   0.00      inf     nan            0.00    nan
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle            0.18   0.00      539.79    2.45         0.00      0.29
Mean: 21.62
-----------------------------------------------------------------------------------------------------------
this : [epoch 9], [val loss 0.66551], [acc 0.79473], [acc_cls 0.27327], [mean_iu 0.21622], [fwavacc 0.67109]
best : [epoch 9], [val loss 0.66551], [acc 0.79473], [acc_cls 0.27327], [mean_iu 0.21622], [fwavacc 0.67109]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 10], [iter 1 / 176], [train main loss -5.241828], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 2 / 176], [train main loss -3.947924], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 3 / 176], [train main loss -2.881440], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 4 / 176], [train main loss -2.326119], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 5 / 176], [train main loss -2.254962], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 6 / 176], [train main loss -1.990716], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 7 / 176], [train main loss -2.275999], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 8 / 176], [train main loss -2.270885], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 9 / 176], [train main loss -2.146204], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 10 / 176], [train main loss -2.345725], [lr 0.009429] [batchtime 0]
[epoch 10], [iter 11 / 176], [train main loss -2.245798], [lr 0.009429] [batchtime 0.364]
[epoch 10], [iter 12 / 176], [train main loss -2.326592], [lr 0.009429] [batchtime 0.383]
[epoch 10], [iter 13 / 176], [train main loss -2.322720], [lr 0.009429] [batchtime 0.389]
[epoch 10], [iter 14 / 176], [train main loss -2.340661], [lr 0.009429] [batchtime 0.392]
[epoch 10], [iter 15 / 176], [train main loss -2.280724], [lr 0.009429] [batchtime 0.394]
[epoch 10], [iter 16 / 176], [train main loss -2.363767], [lr 0.009429] [batchtime 0.394]
[epoch 10], [iter 17 / 176], [train main loss -2.268459], [lr 0.009429] [batchtime 0.395]
[epoch 10], [iter 18 / 176], [train main loss -2.187602], [lr 0.009429] [batchtime 0.395]
[epoch 10], [iter 19 / 176], [train main loss -2.169799], [lr 0.009429] [batchtime 0.396]
[epoch 10], [iter 20 / 176], [train main loss -2.241160], [lr 0.009429] [batchtime 0.396]
[epoch 10], [iter 21 / 176], [train main loss -2.133298], [lr 0.009429] [batchtime 0.396]
[epoch 10], [iter 22 / 176], [train main loss -2.047764], [lr 0.009429] [batchtime 0.396]
[epoch 10], [iter 23 / 176], [train main loss -2.093432], [lr 0.009429] [batchtime 0.396]
[epoch 10], [iter 24 / 176], [train main loss -2.003180], [lr 0.009429] [batchtime 0.402]
[epoch 10], [iter 25 / 176], [train main loss -1.990866], [lr 0.009429] [batchtime 0.41]
[epoch 10], [iter 26 / 176], [train main loss -1.994402], [lr 0.009429] [batchtime 0.408]
[epoch 10], [iter 27 / 176], [train main loss -1.970931], [lr 0.009429] [batchtime 0.408]
[epoch 10], [iter 28 / 176], [train main loss -1.974236], [lr 0.009429] [batchtime 0.407]
[epoch 10], [iter 29 / 176], [train main loss -1.947762], [lr 0.009429] [batchtime 0.406]
[epoch 10], [iter 30 / 176], [train main loss -1.801519], [lr 0.009429] [batchtime 0.406]
[epoch 10], [iter 31 / 176], [train main loss -1.917745], [lr 0.009429] [batchtime 0.406]
[epoch 10], [iter 32 / 176], [train main loss -1.847609], [lr 0.009429] [batchtime 0.406]
[epoch 10], [iter 33 / 176], [train main loss -1.881178], [lr 0.009429] [batchtime 0.406]
[epoch 10], [iter 34 / 176], [train main loss -1.800564], [lr 0.009429] [batchtime 0.405]
[epoch 10], [iter 35 / 176], [train main loss -1.714978], [lr 0.009429] [batchtime 0.405]
[epoch 10], [iter 36 / 176], [train main loss -1.716188], [lr 0.009429] [batchtime 0.405]
[epoch 10], [iter 37 / 176], [train main loss -1.691535], [lr 0.009429] [batchtime 0.404]
[epoch 10], [iter 38 / 176], [train main loss -1.710830], [lr 0.009429] [batchtime 0.404]
[epoch 10], [iter 39 / 176], [train main loss -1.728274], [lr 0.009429] [batchtime 0.404]
[epoch 10], [iter 40 / 176], [train main loss -1.785736], [lr 0.009429] [batchtime 0.404]
[epoch 10], [iter 41 / 176], [train main loss -1.790981], [lr 0.009429] [batchtime 0.404]
[epoch 10], [iter 42 / 176], [train main loss -1.787030], [lr 0.009429] [batchtime 0.403]
[epoch 10], [iter 43 / 176], [train main loss -1.761200], [lr 0.009429] [batchtime 0.403]
[epoch 10], [iter 44 / 176], [train main loss -1.810263], [lr 0.009429] [batchtime 0.403]
[epoch 10], [iter 45 / 176], [train main loss -1.751143], [lr 0.009429] [batchtime 0.403]
[epoch 10], [iter 46 / 176], [train main loss -1.713337], [lr 0.009429] [batchtime 0.402]
[epoch 10], [iter 47 / 176], [train main loss -1.695402], [lr 0.009429] [batchtime 0.402]
[epoch 10], [iter 48 / 176], [train main loss -1.681289], [lr 0.009429] [batchtime 0.405]
[epoch 10], [iter 49 / 176], [train main loss -1.667946], [lr 0.009429] [batchtime 0.436]
[epoch 10], [iter 50 / 176], [train main loss -1.600587], [lr 0.009429] [batchtime 0.434]
[epoch 10], [iter 51 / 176], [train main loss -1.621212], [lr 0.009429] [batchtime 0.433]
[epoch 10], [iter 52 / 176], [train main loss -1.600345], [lr 0.009429] [batchtime 0.432]
[epoch 10], [iter 53 / 176], [train main loss -1.546050], [lr 0.009429] [batchtime 0.431]
[epoch 10], [iter 54 / 176], [train main loss -1.531591], [lr 0.009429] [batchtime 0.431]
[epoch 10], [iter 55 / 176], [train main loss -1.566969], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 56 / 176], [train main loss -1.580442], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 57 / 176], [train main loss -1.625856], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 58 / 176], [train main loss -1.565823], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 59 / 176], [train main loss -1.549004], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 60 / 176], [train main loss -1.495453], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 61 / 176], [train main loss -1.509065], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 62 / 176], [train main loss -1.468383], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 63 / 176], [train main loss -1.484357], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 64 / 176], [train main loss -1.491478], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 65 / 176], [train main loss -1.525244], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 66 / 176], [train main loss -1.509089], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 67 / 176], [train main loss -1.510570], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 68 / 176], [train main loss -1.496394], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 69 / 176], [train main loss -1.499229], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 70 / 176], [train main loss -1.528071], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 71 / 176], [train main loss -1.559402], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 72 / 176], [train main loss -1.604223], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 73 / 176], [train main loss -1.556168], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 74 / 176], [train main loss -1.573043], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 75 / 176], [train main loss -1.568285], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 76 / 176], [train main loss -1.559655], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 77 / 176], [train main loss -1.575031], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 78 / 176], [train main loss -1.556022], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 79 / 176], [train main loss -1.543480], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 80 / 176], [train main loss -1.527792], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 81 / 176], [train main loss -1.527261], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 82 / 176], [train main loss -1.539918], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 83 / 176], [train main loss -1.568215], [lr 0.009429] [batchtime 0.421]
[epoch 10], [iter 84 / 176], [train main loss -1.577452], [lr 0.009429] [batchtime 0.421]
[epoch 10], [iter 85 / 176], [train main loss -1.570920], [lr 0.009429] [batchtime 0.421]
[epoch 10], [iter 86 / 176], [train main loss -1.598187], [lr 0.009429] [batchtime 0.42]
[epoch 10], [iter 87 / 176], [train main loss -1.608756], [lr 0.009429] [batchtime 0.42]
[epoch 10], [iter 88 / 176], [train main loss -1.613535], [lr 0.009429] [batchtime 0.42]
[epoch 10], [iter 89 / 176], [train main loss -1.624408], [lr 0.009429] [batchtime 0.419]
[epoch 10], [iter 90 / 176], [train main loss -1.632544], [lr 0.009429] [batchtime 0.419]
[epoch 10], [iter 91 / 176], [train main loss -1.605252], [lr 0.009429] [batchtime 0.419]
[epoch 10], [iter 92 / 176], [train main loss -1.584417], [lr 0.009429] [batchtime 0.419]
[epoch 10], [iter 93 / 176], [train main loss -1.569599], [lr 0.009429] [batchtime 0.418]
[epoch 10], [iter 94 / 176], [train main loss -1.542221], [lr 0.009429] [batchtime 0.418]
[epoch 10], [iter 95 / 176], [train main loss -1.547086], [lr 0.009429] [batchtime 0.433]
[epoch 10], [iter 96 / 176], [train main loss -1.564873], [lr 0.009429] [batchtime 0.434]
[epoch 10], [iter 97 / 176], [train main loss -1.577726], [lr 0.009429] [batchtime 0.434]
[epoch 10], [iter 98 / 176], [train main loss -1.564728], [lr 0.009429] [batchtime 0.433]
[epoch 10], [iter 99 / 176], [train main loss -1.576193], [lr 0.009429] [batchtime 0.433]
[epoch 10], [iter 100 / 176], [train main loss -1.560991], [lr 0.009429] [batchtime 0.432]
[epoch 10], [iter 101 / 176], [train main loss -1.551124], [lr 0.009429] [batchtime 0.432]
[epoch 10], [iter 102 / 176], [train main loss -1.559167], [lr 0.009429] [batchtime 0.431]
[epoch 10], [iter 103 / 176], [train main loss -1.539578], [lr 0.009429] [batchtime 0.431]
[epoch 10], [iter 104 / 176], [train main loss -1.536610], [lr 0.009429] [batchtime 0.431]
[epoch 10], [iter 105 / 176], [train main loss -1.531336], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 106 / 176], [train main loss -1.519500], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 107 / 176], [train main loss -1.501756], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 108 / 176], [train main loss -1.477955], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 109 / 176], [train main loss -1.489105], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 110 / 176], [train main loss -1.509578], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 111 / 176], [train main loss -1.508999], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 112 / 176], [train main loss -1.504991], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 113 / 176], [train main loss -1.476537], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 114 / 176], [train main loss -1.468165], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 115 / 176], [train main loss -1.462259], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 116 / 176], [train main loss -1.449853], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 117 / 176], [train main loss -1.455472], [lr 0.009429] [batchtime 0.43]
[epoch 10], [iter 118 / 176], [train main loss -1.422225], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 119 / 176], [train main loss -1.396262], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 120 / 176], [train main loss -1.405761], [lr 0.009429] [batchtime 0.429]
[epoch 10], [iter 121 / 176], [train main loss -1.391518], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 122 / 176], [train main loss -1.409428], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 123 / 176], [train main loss -1.405375], [lr 0.009429] [batchtime 0.428]
[epoch 10], [iter 124 / 176], [train main loss -1.435291], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 125 / 176], [train main loss -1.404132], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 126 / 176], [train main loss -1.395997], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 127 / 176], [train main loss -1.389046], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 128 / 176], [train main loss -1.391378], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 129 / 176], [train main loss -1.380765], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 130 / 176], [train main loss -1.394273], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 131 / 176], [train main loss -1.409778], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 132 / 176], [train main loss -1.400574], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 133 / 176], [train main loss -1.380139], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 134 / 176], [train main loss -1.404212], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 135 / 176], [train main loss -1.418188], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 136 / 176], [train main loss -1.423194], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 137 / 176], [train main loss -1.401378], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 138 / 176], [train main loss -1.391054], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 139 / 176], [train main loss -1.396854], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 140 / 176], [train main loss -1.397338], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 141 / 176], [train main loss -1.402363], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 142 / 176], [train main loss -1.399873], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 143 / 176], [train main loss -1.378755], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 144 / 176], [train main loss -1.364525], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 145 / 176], [train main loss -1.364458], [lr 0.009429] [batchtime 0.427]
[epoch 10], [iter 146 / 176], [train main loss -1.355375], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 147 / 176], [train main loss -1.337920], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 148 / 176], [train main loss -1.337661], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 149 / 176], [train main loss -1.334634], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 150 / 176], [train main loss -1.322200], [lr 0.009429] [batchtime 0.426]
[epoch 10], [iter 151 / 176], [train main loss -1.326936], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 152 / 176], [train main loss -1.328670], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 153 / 176], [train main loss -1.328753], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 154 / 176], [train main loss -1.319227], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 155 / 176], [train main loss -1.297267], [lr 0.009429] [batchtime 0.425]
[epoch 10], [iter 156 / 176], [train main loss -1.288743], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 157 / 176], [train main loss -1.286224], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 158 / 176], [train main loss -1.269032], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 159 / 176], [train main loss -1.267636], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 160 / 176], [train main loss -1.262925], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 161 / 176], [train main loss -1.263564], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 162 / 176], [train main loss -1.252839], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 163 / 176], [train main loss -1.255916], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 164 / 176], [train main loss -1.283935], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 165 / 176], [train main loss -1.279499], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 166 / 176], [train main loss -1.271656], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 167 / 176], [train main loss -1.271188], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 168 / 176], [train main loss -1.256899], [lr 0.009429] [batchtime 0.424]
[epoch 10], [iter 169 / 176], [train main loss -1.266977], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 170 / 176], [train main loss -1.257474], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 171 / 176], [train main loss -1.258699], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 172 / 176], [train main loss -1.257237], [lr 0.009429] [batchtime 0.423]
[epoch 10], [iter 173 / 176], [train main loss -1.252783], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 174 / 176], [train main loss -1.250719], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 175 / 176], [train main loss -1.260800], [lr 0.009429] [batchtime 0.422]
[epoch 10], [iter 176 / 176], [train main loss -1.268073], [lr 0.009429] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              86.52  33.99    0.07    0.09         0.93      0.92
   1  sidewalk          34.64   3.28    1.01    0.88         0.50      0.53
   2  building          72.59  22.37    0.19    0.19         0.84      0.84
   3  wall               0.00   0.00  inf     nan            0.00    nan
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               0.39   0.00  252.72    1.18         0.00      0.46
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       2.39   0.01   39.52    1.33         0.02      0.43
   8  vegetation        64.26  11.26    0.10    0.46         0.91      0.69
   9  terrain           13.11   0.19    2.81    3.82         0.26      0.21
  10  sky               86.44   3.74    0.03    0.12         0.97      0.89
  11  person             0.72   0.01  137.09    1.46         0.01      0.41
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               56.57   5.70    0.24    0.53         0.81      0.66
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            0.45   0.00  221.39    2.29         0.00      0.30
Mean: 22.00
-----------------------------------------------------------------------------------------------------------
this : [epoch 10], [val loss 0.65019], [acc 0.80565], [acc_cls 0.27683], [mean_iu 0.22004], [fwavacc 0.68457]
best : [epoch 10], [val loss 0.65019], [acc 0.80565], [acc_cls 0.27683], [mean_iu 0.22004], [fwavacc 0.68457]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 11], [iter 1 / 176], [train main loss 0.360482], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 2 / 176], [train main loss -0.657018], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 3 / 176], [train main loss -1.064135], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 4 / 176], [train main loss -0.834100], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 5 / 176], [train main loss -0.556967], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 6 / 176], [train main loss -0.413739], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 7 / 176], [train main loss -0.646841], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 8 / 176], [train main loss -0.665770], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 9 / 176], [train main loss -0.687145], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 10 / 176], [train main loss -0.616298], [lr 0.009371] [batchtime 0]
[epoch 11], [iter 11 / 176], [train main loss -0.588518], [lr 0.009371] [batchtime 0.371]
[epoch 11], [iter 12 / 176], [train main loss -0.488732], [lr 0.009371] [batchtime 0.385]
[epoch 11], [iter 13 / 176], [train main loss -0.677464], [lr 0.009371] [batchtime 0.396]
[epoch 11], [iter 14 / 176], [train main loss -1.063457], [lr 0.009371] [batchtime 0.415]
[epoch 11], [iter 15 / 176], [train main loss -0.976863], [lr 0.009371] [batchtime 0.445]
[epoch 11], [iter 16 / 176], [train main loss -1.075820], [lr 0.009371] [batchtime 0.439]
[epoch 11], [iter 17 / 176], [train main loss -1.087959], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 18 / 176], [train main loss -1.040151], [lr 0.009371] [batchtime 0.426]
[epoch 11], [iter 19 / 176], [train main loss -1.079341], [lr 0.009371] [batchtime 0.423]
[epoch 11], [iter 20 / 176], [train main loss -1.033366], [lr 0.009371] [batchtime 0.422]
[epoch 11], [iter 21 / 176], [train main loss -1.098242], [lr 0.009371] [batchtime 0.42]
[epoch 11], [iter 22 / 176], [train main loss -1.118961], [lr 0.009371] [batchtime 0.418]
[epoch 11], [iter 23 / 176], [train main loss -1.054128], [lr 0.009371] [batchtime 0.416]
[epoch 11], [iter 24 / 176], [train main loss -0.925637], [lr 0.009371] [batchtime 0.416]
[epoch 11], [iter 25 / 176], [train main loss -0.908088], [lr 0.009371] [batchtime 0.414]
[epoch 11], [iter 26 / 176], [train main loss -0.993994], [lr 0.009371] [batchtime 0.414]
[epoch 11], [iter 27 / 176], [train main loss -0.996853], [lr 0.009371] [batchtime 0.412]
[epoch 11], [iter 28 / 176], [train main loss -1.052774], [lr 0.009371] [batchtime 0.412]
[epoch 11], [iter 29 / 176], [train main loss -1.027097], [lr 0.009371] [batchtime 0.411]
[epoch 11], [iter 30 / 176], [train main loss -1.006291], [lr 0.009371] [batchtime 0.411]
[epoch 11], [iter 31 / 176], [train main loss -0.955897], [lr 0.009371] [batchtime 0.41]
[epoch 11], [iter 32 / 176], [train main loss -0.995355], [lr 0.009371] [batchtime 0.41]
[epoch 11], [iter 33 / 176], [train main loss -0.984364], [lr 0.009371] [batchtime 0.409]
[epoch 11], [iter 34 / 176], [train main loss -0.980223], [lr 0.009371] [batchtime 0.408]
[epoch 11], [iter 35 / 176], [train main loss -0.960509], [lr 0.009371] [batchtime 0.408]
[epoch 11], [iter 36 / 176], [train main loss -1.038876], [lr 0.009371] [batchtime 0.408]
[epoch 11], [iter 37 / 176], [train main loss -0.957477], [lr 0.009371] [batchtime 0.408]
[epoch 11], [iter 38 / 176], [train main loss -1.000440], [lr 0.009371] [batchtime 0.412]
[epoch 11], [iter 39 / 176], [train main loss -1.018609], [lr 0.009371] [batchtime 0.456]
[epoch 11], [iter 40 / 176], [train main loss -1.082717], [lr 0.009371] [batchtime 0.454]
[epoch 11], [iter 41 / 176], [train main loss -1.041932], [lr 0.009371] [batchtime 0.452]
[epoch 11], [iter 42 / 176], [train main loss -1.102112], [lr 0.009371] [batchtime 0.45]
[epoch 11], [iter 43 / 176], [train main loss -1.152940], [lr 0.009371] [batchtime 0.449]
[epoch 11], [iter 44 / 176], [train main loss -1.165414], [lr 0.009371] [batchtime 0.448]
[epoch 11], [iter 45 / 176], [train main loss -1.156052], [lr 0.009371] [batchtime 0.447]
[epoch 11], [iter 46 / 176], [train main loss -1.114742], [lr 0.009371] [batchtime 0.445]
[epoch 11], [iter 47 / 176], [train main loss -1.076407], [lr 0.009371] [batchtime 0.444]
[epoch 11], [iter 48 / 176], [train main loss -1.096064], [lr 0.009371] [batchtime 0.443]
[epoch 11], [iter 49 / 176], [train main loss -1.104127], [lr 0.009371] [batchtime 0.442]
[epoch 11], [iter 50 / 176], [train main loss -1.095516], [lr 0.009371] [batchtime 0.441]
[epoch 11], [iter 51 / 176], [train main loss -1.102226], [lr 0.009371] [batchtime 0.44]
[epoch 11], [iter 52 / 176], [train main loss -1.117709], [lr 0.009371] [batchtime 0.439]
[epoch 11], [iter 53 / 176], [train main loss -1.131811], [lr 0.009371] [batchtime 0.438]
[epoch 11], [iter 54 / 176], [train main loss -1.145875], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 55 / 176], [train main loss -1.097822], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 56 / 176], [train main loss -1.091103], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 57 / 176], [train main loss -1.139758], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 58 / 176], [train main loss -1.173651], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 59 / 176], [train main loss -1.169539], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 60 / 176], [train main loss -1.150916], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 61 / 176], [train main loss -1.193618], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 62 / 176], [train main loss -1.187502], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 63 / 176], [train main loss -1.210379], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 64 / 176], [train main loss -1.226991], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 65 / 176], [train main loss -1.236629], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 66 / 176], [train main loss -1.275465], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 67 / 176], [train main loss -1.277983], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 68 / 176], [train main loss -1.266843], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 69 / 176], [train main loss -1.223706], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 70 / 176], [train main loss -1.199044], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 71 / 176], [train main loss -1.238271], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 72 / 176], [train main loss -1.220062], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 73 / 176], [train main loss -1.172582], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 74 / 176], [train main loss -1.159877], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 75 / 176], [train main loss -1.107796], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 76 / 176], [train main loss -1.094940], [lr 0.009371] [batchtime 0.428]
[epoch 11], [iter 77 / 176], [train main loss -1.104163], [lr 0.009371] [batchtime 0.428]
[epoch 11], [iter 78 / 176], [train main loss -1.053386], [lr 0.009371] [batchtime 0.427]
[epoch 11], [iter 79 / 176], [train main loss -1.078270], [lr 0.009371] [batchtime 0.427]
[epoch 11], [iter 80 / 176], [train main loss -1.081766], [lr 0.009371] [batchtime 0.426]
[epoch 11], [iter 81 / 176], [train main loss -1.088302], [lr 0.009371] [batchtime 0.426]
[epoch 11], [iter 82 / 176], [train main loss -1.073783], [lr 0.009371] [batchtime 0.426]
[epoch 11], [iter 83 / 176], [train main loss -1.084604], [lr 0.009371] [batchtime 0.425]
[epoch 11], [iter 84 / 176], [train main loss -1.089178], [lr 0.009371] [batchtime 0.427]
[epoch 11], [iter 85 / 176], [train main loss -1.102173], [lr 0.009371] [batchtime 0.443]
[epoch 11], [iter 86 / 176], [train main loss -1.112009], [lr 0.009371] [batchtime 0.443]
[epoch 11], [iter 87 / 176], [train main loss -1.137718], [lr 0.009371] [batchtime 0.442]
[epoch 11], [iter 88 / 176], [train main loss -1.144936], [lr 0.009371] [batchtime 0.442]
[epoch 11], [iter 89 / 176], [train main loss -1.175211], [lr 0.009371] [batchtime 0.441]
[epoch 11], [iter 90 / 176], [train main loss -1.179950], [lr 0.009371] [batchtime 0.44]
[epoch 11], [iter 91 / 176], [train main loss -1.165349], [lr 0.009371] [batchtime 0.44]
[epoch 11], [iter 92 / 176], [train main loss -1.181977], [lr 0.009371] [batchtime 0.439]
[epoch 11], [iter 93 / 176], [train main loss -1.173840], [lr 0.009371] [batchtime 0.439]
[epoch 11], [iter 94 / 176], [train main loss -1.171145], [lr 0.009371] [batchtime 0.438]
[epoch 11], [iter 95 / 176], [train main loss -1.163499], [lr 0.009371] [batchtime 0.438]
[epoch 11], [iter 96 / 176], [train main loss -1.164043], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 97 / 176], [train main loss -1.144232], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 98 / 176], [train main loss -1.131451], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 99 / 176], [train main loss -1.120144], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 100 / 176], [train main loss -1.121176], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 101 / 176], [train main loss -1.119159], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 102 / 176], [train main loss -1.116750], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 103 / 176], [train main loss -1.111256], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 104 / 176], [train main loss -1.120221], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 105 / 176], [train main loss -1.125952], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 106 / 176], [train main loss -1.130298], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 107 / 176], [train main loss -1.139103], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 108 / 176], [train main loss -1.131391], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 109 / 176], [train main loss -1.132450], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 110 / 176], [train main loss -1.132794], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 111 / 176], [train main loss -1.114815], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 112 / 176], [train main loss -1.120272], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 113 / 176], [train main loss -1.135107], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 114 / 176], [train main loss -1.130759], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 115 / 176], [train main loss -1.130064], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 116 / 176], [train main loss -1.124051], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 117 / 176], [train main loss -1.150032], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 118 / 176], [train main loss -1.137721], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 119 / 176], [train main loss -1.149946], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 120 / 176], [train main loss -1.151933], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 121 / 176], [train main loss -1.156165], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 122 / 176], [train main loss -1.141336], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 123 / 176], [train main loss -1.153404], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 124 / 176], [train main loss -1.151122], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 125 / 176], [train main loss -1.119385], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 126 / 176], [train main loss -1.121218], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 127 / 176], [train main loss -1.118471], [lr 0.009371] [batchtime 0.428]
[epoch 11], [iter 128 / 176], [train main loss -1.112359], [lr 0.009371] [batchtime 0.428]
[epoch 11], [iter 129 / 176], [train main loss -1.113136], [lr 0.009371] [batchtime 0.428]
[epoch 11], [iter 130 / 176], [train main loss -1.116452], [lr 0.009371] [batchtime 0.428]
[epoch 11], [iter 131 / 176], [train main loss -1.131054], [lr 0.009371] [batchtime 0.439]
[epoch 11], [iter 132 / 176], [train main loss -1.111930], [lr 0.009371] [batchtime 0.439]
[epoch 11], [iter 133 / 176], [train main loss -1.112952], [lr 0.009371] [batchtime 0.438]
[epoch 11], [iter 134 / 176], [train main loss -1.113909], [lr 0.009371] [batchtime 0.438]
[epoch 11], [iter 135 / 176], [train main loss -1.108578], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 136 / 176], [train main loss -1.089903], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 137 / 176], [train main loss -1.093833], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 138 / 176], [train main loss -1.120153], [lr 0.009371] [batchtime 0.438]
[epoch 11], [iter 139 / 176], [train main loss -1.125423], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 140 / 176], [train main loss -1.159870], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 141 / 176], [train main loss -1.155438], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 142 / 176], [train main loss -1.161553], [lr 0.009371] [batchtime 0.437]
[epoch 11], [iter 143 / 176], [train main loss -1.162795], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 144 / 176], [train main loss -1.174601], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 145 / 176], [train main loss -1.186810], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 146 / 176], [train main loss -1.208473], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 147 / 176], [train main loss -1.209718], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 148 / 176], [train main loss -1.198478], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 149 / 176], [train main loss -1.197534], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 150 / 176], [train main loss -1.190577], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 151 / 176], [train main loss -1.201411], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 152 / 176], [train main loss -1.215986], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 153 / 176], [train main loss -1.212378], [lr 0.009371] [batchtime 0.436]
[epoch 11], [iter 154 / 176], [train main loss -1.215927], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 155 / 176], [train main loss -1.220551], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 156 / 176], [train main loss -1.218251], [lr 0.009371] [batchtime 0.435]
[epoch 11], [iter 157 / 176], [train main loss -1.234010], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 158 / 176], [train main loss -1.238998], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 159 / 176], [train main loss -1.243000], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 160 / 176], [train main loss -1.255073], [lr 0.009371] [batchtime 0.434]
[epoch 11], [iter 161 / 176], [train main loss -1.268141], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 162 / 176], [train main loss -1.276572], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 163 / 176], [train main loss -1.276989], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 164 / 176], [train main loss -1.277633], [lr 0.009371] [batchtime 0.433]
[epoch 11], [iter 165 / 176], [train main loss -1.279808], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 166 / 176], [train main loss -1.279118], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 167 / 176], [train main loss -1.271527], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 168 / 176], [train main loss -1.281550], [lr 0.009371] [batchtime 0.432]
[epoch 11], [iter 169 / 176], [train main loss -1.274262], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 170 / 176], [train main loss -1.276211], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 171 / 176], [train main loss -1.276224], [lr 0.009371] [batchtime 0.431]
[epoch 11], [iter 172 / 176], [train main loss -1.267965], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 173 / 176], [train main loss -1.274145], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 174 / 176], [train main loss -1.269167], [lr 0.009371] [batchtime 0.43]
[epoch 11], [iter 175 / 176], [train main loss -1.277501], [lr 0.009371] [batchtime 0.429]
[epoch 11], [iter 176 / 176], [train main loss -1.267954], [lr 0.009371] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              87.59  34.62    0.05    0.09         0.95      0.92
   1  sidewalk          37.97   3.68    0.79    0.84         0.56      0.54
   2  building          74.58  23.08    0.15    0.19         0.87      0.84
   3  wall               0.00   0.00  inf     inf            0.00      0.00
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               1.55   0.02   62.13    1.38         0.02      0.42
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       1.66   0.01   57.90    1.18         0.02      0.46
   8  vegetation        67.98  11.25    0.10    0.37         0.91      0.73
   9  terrain           14.72   0.13    4.49    1.30         0.18      0.43
  10  sky               88.67   3.68    0.05    0.07         0.95      0.93
  11  person             1.94   0.03   49.32    1.18         0.02      0.46
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               60.05   5.72    0.24    0.43         0.81      0.70
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            1.17   0.00   82.08    2.21         0.01      0.31
Mean: 23.05
-----------------------------------------------------------------------------------------------------------
this : [epoch 11], [val loss 0.60242], [acc 0.82214], [acc_cls 0.27858], [mean_iu 0.23047], [fwavacc 0.70429]
best : [epoch 11], [val loss 0.60242], [acc 0.82214], [acc_cls 0.27858], [mean_iu 0.23047], [fwavacc 0.70429]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 12], [iter 1 / 176], [train main loss -2.747346], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 2 / 176], [train main loss -3.013435], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 3 / 176], [train main loss -3.205023], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 4 / 176], [train main loss -2.221419], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 5 / 176], [train main loss -1.965791], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 6 / 176], [train main loss -1.869988], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 7 / 176], [train main loss -2.034419], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 8 / 176], [train main loss -2.328918], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 9 / 176], [train main loss -2.070403], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 10 / 176], [train main loss -1.858483], [lr 0.009314] [batchtime 0]
[epoch 12], [iter 11 / 176], [train main loss -1.810475], [lr 0.009314] [batchtime 0.377]
[epoch 12], [iter 12 / 176], [train main loss -1.868574], [lr 0.009314] [batchtime 0.389]
[epoch 12], [iter 13 / 176], [train main loss -1.967786], [lr 0.009314] [batchtime 0.395]
[epoch 12], [iter 14 / 176], [train main loss -1.846594], [lr 0.009314] [batchtime 0.397]
[epoch 12], [iter 15 / 176], [train main loss -1.754297], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 16 / 176], [train main loss -1.835636], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 17 / 176], [train main loss -1.854775], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 18 / 176], [train main loss -1.900426], [lr 0.009314] [batchtime 0.399]
[epoch 12], [iter 19 / 176], [train main loss -1.843395], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 20 / 176], [train main loss -1.864868], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 21 / 176], [train main loss -1.829273], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 22 / 176], [train main loss -1.858791], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 23 / 176], [train main loss -1.692475], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 24 / 176], [train main loss -1.661595], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 25 / 176], [train main loss -1.711983], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 26 / 176], [train main loss -1.644454], [lr 0.009314] [batchtime 0.398]
[epoch 12], [iter 27 / 176], [train main loss -1.602802], [lr 0.009314] [batchtime 0.407]
[epoch 12], [iter 28 / 176], [train main loss -1.545270], [lr 0.009314] [batchtime 0.475]
[epoch 12], [iter 29 / 176], [train main loss -1.568803], [lr 0.009314] [batchtime 0.471]
[epoch 12], [iter 30 / 176], [train main loss -1.622464], [lr 0.009314] [batchtime 0.467]
[epoch 12], [iter 31 / 176], [train main loss -1.659775], [lr 0.009314] [batchtime 0.463]
[epoch 12], [iter 32 / 176], [train main loss -1.733880], [lr 0.009314] [batchtime 0.46]
[epoch 12], [iter 33 / 176], [train main loss -1.759912], [lr 0.009314] [batchtime 0.457]
[epoch 12], [iter 34 / 176], [train main loss -1.718284], [lr 0.009314] [batchtime 0.455]
[epoch 12], [iter 35 / 176], [train main loss -1.706588], [lr 0.009314] [batchtime 0.454]
[epoch 12], [iter 36 / 176], [train main loss -1.695556], [lr 0.009314] [batchtime 0.451]
[epoch 12], [iter 37 / 176], [train main loss -1.718194], [lr 0.009314] [batchtime 0.449]
[epoch 12], [iter 38 / 176], [train main loss -1.663800], [lr 0.009314] [batchtime 0.447]
[epoch 12], [iter 39 / 176], [train main loss -1.584674], [lr 0.009314] [batchtime 0.446]
[epoch 12], [iter 40 / 176], [train main loss -1.645510], [lr 0.009314] [batchtime 0.444]
[epoch 12], [iter 41 / 176], [train main loss -1.612362], [lr 0.009314] [batchtime 0.443]
[epoch 12], [iter 42 / 176], [train main loss -1.609900], [lr 0.009314] [batchtime 0.442]
[epoch 12], [iter 43 / 176], [train main loss -1.617176], [lr 0.009314] [batchtime 0.441]
[epoch 12], [iter 44 / 176], [train main loss -1.582438], [lr 0.009314] [batchtime 0.44]
[epoch 12], [iter 45 / 176], [train main loss -1.579775], [lr 0.009314] [batchtime 0.438]
[epoch 12], [iter 46 / 176], [train main loss -1.597052], [lr 0.009314] [batchtime 0.437]
[epoch 12], [iter 47 / 176], [train main loss -1.613756], [lr 0.009314] [batchtime 0.436]
[epoch 12], [iter 48 / 176], [train main loss -1.655480], [lr 0.009314] [batchtime 0.435]
[epoch 12], [iter 49 / 176], [train main loss -1.643345], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 50 / 176], [train main loss -1.696330], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 51 / 176], [train main loss -1.696200], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 52 / 176], [train main loss -1.678205], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 53 / 176], [train main loss -1.691832], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 54 / 176], [train main loss -1.664584], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 55 / 176], [train main loss -1.679096], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 56 / 176], [train main loss -1.686154], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 57 / 176], [train main loss -1.628535], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 58 / 176], [train main loss -1.579937], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 59 / 176], [train main loss -1.555211], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 60 / 176], [train main loss -1.533458], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 61 / 176], [train main loss -1.494208], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 62 / 176], [train main loss -1.517469], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 63 / 176], [train main loss -1.579477], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 64 / 176], [train main loss -1.581751], [lr 0.009314] [batchtime 0.424]
[epoch 12], [iter 65 / 176], [train main loss -1.575591], [lr 0.009314] [batchtime 0.423]
[epoch 12], [iter 66 / 176], [train main loss -1.571542], [lr 0.009314] [batchtime 0.423]
[epoch 12], [iter 67 / 176], [train main loss -1.551740], [lr 0.009314] [batchtime 0.422]
[epoch 12], [iter 68 / 176], [train main loss -1.546597], [lr 0.009314] [batchtime 0.422]
[epoch 12], [iter 69 / 176], [train main loss -1.522361], [lr 0.009314] [batchtime 0.421]
[epoch 12], [iter 70 / 176], [train main loss -1.499052], [lr 0.009314] [batchtime 0.421]
[epoch 12], [iter 71 / 176], [train main loss -1.497555], [lr 0.009314] [batchtime 0.42]
[epoch 12], [iter 72 / 176], [train main loss -1.504948], [lr 0.009314] [batchtime 0.42]
[epoch 12], [iter 73 / 176], [train main loss -1.530630], [lr 0.009314] [batchtime 0.419]
[epoch 12], [iter 74 / 176], [train main loss -1.530736], [lr 0.009314] [batchtime 0.422]
[epoch 12], [iter 75 / 176], [train main loss -1.519023], [lr 0.009314] [batchtime 0.443]
[epoch 12], [iter 76 / 176], [train main loss -1.514983], [lr 0.009314] [batchtime 0.442]
[epoch 12], [iter 77 / 176], [train main loss -1.512983], [lr 0.009314] [batchtime 0.442]
[epoch 12], [iter 78 / 176], [train main loss -1.524965], [lr 0.009314] [batchtime 0.441]
[epoch 12], [iter 79 / 176], [train main loss -1.569917], [lr 0.009314] [batchtime 0.44]
[epoch 12], [iter 80 / 176], [train main loss -1.562487], [lr 0.009314] [batchtime 0.44]
[epoch 12], [iter 81 / 176], [train main loss -1.547943], [lr 0.009314] [batchtime 0.44]
[epoch 12], [iter 82 / 176], [train main loss -1.541031], [lr 0.009314] [batchtime 0.439]
[epoch 12], [iter 83 / 176], [train main loss -1.555433], [lr 0.009314] [batchtime 0.438]
[epoch 12], [iter 84 / 176], [train main loss -1.553070], [lr 0.009314] [batchtime 0.438]
[epoch 12], [iter 85 / 176], [train main loss -1.547792], [lr 0.009314] [batchtime 0.437]
[epoch 12], [iter 86 / 176], [train main loss -1.571033], [lr 0.009314] [batchtime 0.436]
[epoch 12], [iter 87 / 176], [train main loss -1.561270], [lr 0.009314] [batchtime 0.436]
[epoch 12], [iter 88 / 176], [train main loss -1.556333], [lr 0.009314] [batchtime 0.435]
[epoch 12], [iter 89 / 176], [train main loss -1.560039], [lr 0.009314] [batchtime 0.435]
[epoch 12], [iter 90 / 176], [train main loss -1.570543], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 91 / 176], [train main loss -1.571295], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 92 / 176], [train main loss -1.563555], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 93 / 176], [train main loss -1.541763], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 94 / 176], [train main loss -1.542923], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 95 / 176], [train main loss -1.541909], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 96 / 176], [train main loss -1.540067], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 97 / 176], [train main loss -1.531870], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 98 / 176], [train main loss -1.531121], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 99 / 176], [train main loss -1.509634], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 100 / 176], [train main loss -1.499060], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 101 / 176], [train main loss -1.499449], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 102 / 176], [train main loss -1.500750], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 103 / 176], [train main loss -1.482483], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 104 / 176], [train main loss -1.475987], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 105 / 176], [train main loss -1.466626], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 106 / 176], [train main loss -1.478964], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 107 / 176], [train main loss -1.462185], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 108 / 176], [train main loss -1.503363], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 109 / 176], [train main loss -1.513936], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 110 / 176], [train main loss -1.507574], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 111 / 176], [train main loss -1.470695], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 112 / 176], [train main loss -1.433038], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 113 / 176], [train main loss -1.454359], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 114 / 176], [train main loss -1.470824], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 115 / 176], [train main loss -1.460177], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 116 / 176], [train main loss -1.461684], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 117 / 176], [train main loss -1.465897], [lr 0.009314] [batchtime 0.424]
[epoch 12], [iter 118 / 176], [train main loss -1.471533], [lr 0.009314] [batchtime 0.424]
[epoch 12], [iter 119 / 176], [train main loss -1.472215], [lr 0.009314] [batchtime 0.424]
[epoch 12], [iter 120 / 176], [train main loss -1.452610], [lr 0.009314] [batchtime 0.423]
[epoch 12], [iter 121 / 176], [train main loss -1.418777], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 122 / 176], [train main loss -1.402599], [lr 0.009314] [batchtime 0.437]
[epoch 12], [iter 123 / 176], [train main loss -1.410117], [lr 0.009314] [batchtime 0.436]
[epoch 12], [iter 124 / 176], [train main loss -1.416738], [lr 0.009314] [batchtime 0.436]
[epoch 12], [iter 125 / 176], [train main loss -1.432250], [lr 0.009314] [batchtime 0.435]
[epoch 12], [iter 126 / 176], [train main loss -1.444068], [lr 0.009314] [batchtime 0.435]
[epoch 12], [iter 127 / 176], [train main loss -1.458762], [lr 0.009314] [batchtime 0.435]
[epoch 12], [iter 128 / 176], [train main loss -1.434868], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 129 / 176], [train main loss -1.410806], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 130 / 176], [train main loss -1.392656], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 131 / 176], [train main loss -1.388193], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 132 / 176], [train main loss -1.379515], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 133 / 176], [train main loss -1.364989], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 134 / 176], [train main loss -1.369758], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 135 / 176], [train main loss -1.369096], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 136 / 176], [train main loss -1.363589], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 137 / 176], [train main loss -1.345951], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 138 / 176], [train main loss -1.339225], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 139 / 176], [train main loss -1.326414], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 140 / 176], [train main loss -1.318475], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 141 / 176], [train main loss -1.323671], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 142 / 176], [train main loss -1.312692], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 143 / 176], [train main loss -1.318170], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 144 / 176], [train main loss -1.312851], [lr 0.009314] [batchtime 0.43]
[epoch 12], [iter 145 / 176], [train main loss -1.303793], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 146 / 176], [train main loss -1.296774], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 147 / 176], [train main loss -1.293339], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 148 / 176], [train main loss -1.296289], [lr 0.009314] [batchtime 0.429]
[epoch 12], [iter 149 / 176], [train main loss -1.302210], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 150 / 176], [train main loss -1.308107], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 151 / 176], [train main loss -1.317549], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 152 / 176], [train main loss -1.319685], [lr 0.009314] [batchtime 0.428]
[epoch 12], [iter 153 / 176], [train main loss -1.321745], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 154 / 176], [train main loss -1.307391], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 155 / 176], [train main loss -1.288896], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 156 / 176], [train main loss -1.307673], [lr 0.009314] [batchtime 0.427]
[epoch 12], [iter 157 / 176], [train main loss -1.295833], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 158 / 176], [train main loss -1.304587], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 159 / 176], [train main loss -1.304152], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 160 / 176], [train main loss -1.313924], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 161 / 176], [train main loss -1.308562], [lr 0.009314] [batchtime 0.426]
[epoch 12], [iter 162 / 176], [train main loss -1.306488], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 163 / 176], [train main loss -1.312638], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 164 / 176], [train main loss -1.304581], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 165 / 176], [train main loss -1.303368], [lr 0.009314] [batchtime 0.425]
[epoch 12], [iter 166 / 176], [train main loss -1.291564], [lr 0.009314] [batchtime 0.424]
[epoch 12], [iter 167 / 176], [train main loss -1.289696], [lr 0.009314] [batchtime 0.424]
[epoch 12], [iter 168 / 176], [train main loss -1.303476], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 169 / 176], [train main loss -1.302349], [lr 0.009314] [batchtime 0.434]
[epoch 12], [iter 170 / 176], [train main loss -1.287950], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 171 / 176], [train main loss -1.273395], [lr 0.009314] [batchtime 0.433]
[epoch 12], [iter 172 / 176], [train main loss -1.263565], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 173 / 176], [train main loss -1.271325], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 174 / 176], [train main loss -1.259309], [lr 0.009314] [batchtime 0.432]
[epoch 12], [iter 175 / 176], [train main loss -1.232041], [lr 0.009314] [batchtime 0.431]
[epoch 12], [iter 176 / 176], [train main loss -1.244163], [lr 0.009314] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP      FN    Precision    Recall
----  -------------  --------  -----  ------  ------  -----------  --------
   0  road              87.30  35.11    0.04    0.11         0.97      0.90
   1  sidewalk          34.63   3.13    1.10    0.78         0.48      0.56
   2  building          73.89  22.70    0.17    0.18         0.85      0.85
   3  wall               0.00   0.00  inf     nan            0.00    nan
   4  fence              0.00   0.00  inf     nan            0.00    nan
   5  pole               0.69   0.01  142.77    0.97         0.01      0.51
   6  traffic light      0.00   0.00  inf     nan            0.00    nan
   7  traffic sign       1.84   0.01   52.63    0.60         0.02      0.63
   8  vegetation        68.30  11.12    0.11    0.35         0.90      0.74
   9  terrain           13.59   0.16    3.56    2.80         0.22      0.26
  10  sky               87.44   3.69    0.05    0.09         0.95      0.91
  11  person             2.60   0.04   36.41    1.11         0.03      0.47
  12  rider              0.00   0.00  inf     nan            0.00    nan
  13  car               59.36   5.90    0.20    0.49         0.83      0.67
  14  truck              0.00   0.00  inf     nan            0.00    nan
  15  bus                0.00   0.00  inf     nan            0.00    nan
  16  train              0.00   0.00  inf     nan            0.00    nan
  17  motorcycle         0.00   0.00  inf     nan            0.00    nan
  18  bicycle            1.35   0.01   71.92    1.25         0.01      0.44
Mean: 22.68
-----------------------------------------------------------------------------------------------------------
this : [epoch 12], [val loss 0.66146], [acc 0.81885], [acc_cls 0.27724], [mean_iu 0.22684], [fwavacc 0.69857]
best : [epoch 11], [val loss 0.60242], [acc 0.82214], [acc_cls 0.27858], [mean_iu 0.23047], [fwavacc 0.70429]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 13], [iter 1 / 176], [train main loss -2.918134], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 2 / 176], [train main loss -2.093761], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 3 / 176], [train main loss -1.767811], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 4 / 176], [train main loss -1.414218], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 5 / 176], [train main loss -1.054899], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 6 / 176], [train main loss -0.593830], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 7 / 176], [train main loss -0.712944], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 8 / 176], [train main loss -1.052613], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 9 / 176], [train main loss -1.031051], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 10 / 176], [train main loss -0.974954], [lr 0.009257] [batchtime 0]
[epoch 13], [iter 11 / 176], [train main loss -0.858523], [lr 0.009257] [batchtime 0.372]
[epoch 13], [iter 12 / 176], [train main loss -0.852799], [lr 0.009257] [batchtime 0.39]
[epoch 13], [iter 13 / 176], [train main loss -1.137527], [lr 0.009257] [batchtime 0.398]
[epoch 13], [iter 14 / 176], [train main loss -1.158009], [lr 0.009257] [batchtime 0.398]
[epoch 13], [iter 15 / 176], [train main loss -1.286299], [lr 0.009257] [batchtime 0.398]
[epoch 13], [iter 16 / 176], [train main loss -1.155767], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 17 / 176], [train main loss -1.167546], [lr 0.009257] [batchtime 0.398]
[epoch 13], [iter 18 / 176], [train main loss -1.291203], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 19 / 176], [train main loss -1.308658], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 20 / 176], [train main loss -1.290336], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 21 / 176], [train main loss -1.217742], [lr 0.009257] [batchtime 0.398]
[epoch 13], [iter 22 / 176], [train main loss -1.219969], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 23 / 176], [train main loss -1.216686], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 24 / 176], [train main loss -1.242784], [lr 0.009257] [batchtime 0.399]
[epoch 13], [iter 25 / 176], [train main loss -1.188050], [lr 0.009257] [batchtime 0.403]
[epoch 13], [iter 26 / 176], [train main loss -1.225147], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 27 / 176], [train main loss -1.311038], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 28 / 176], [train main loss -1.232711], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 29 / 176], [train main loss -1.219437], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 30 / 176], [train main loss -1.185947], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 31 / 176], [train main loss -1.073034], [lr 0.009257] [batchtime 0.408]
[epoch 13], [iter 32 / 176], [train main loss -1.132378], [lr 0.009257] [batchtime 0.407]
[epoch 13], [iter 33 / 176], [train main loss -1.104060], [lr 0.009257] [batchtime 0.407]
[epoch 13], [iter 34 / 176], [train main loss -1.031857], [lr 0.009257] [batchtime 0.416]
[epoch 13], [iter 35 / 176], [train main loss -0.994932], [lr 0.009257] [batchtime 0.415]
[epoch 13], [iter 36 / 176], [train main loss -1.003106], [lr 0.009257] [batchtime 0.415]
[epoch 13], [iter 37 / 176], [train main loss -0.986368], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 38 / 176], [train main loss -1.027773], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 39 / 176], [train main loss -1.072383], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 40 / 176], [train main loss -1.010926], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 41 / 176], [train main loss -1.002556], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 42 / 176], [train main loss -1.013303], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 43 / 176], [train main loss -1.020337], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 44 / 176], [train main loss -0.930998], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 45 / 176], [train main loss -1.022036], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 46 / 176], [train main loss -1.068970], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 47 / 176], [train main loss -1.100440], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 48 / 176], [train main loss -1.061410], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 49 / 176], [train main loss -1.086579], [lr 0.009257] [batchtime 0.415]
[epoch 13], [iter 50 / 176], [train main loss -1.130741], [lr 0.009257] [batchtime 0.415]
[epoch 13], [iter 51 / 176], [train main loss -1.168878], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 52 / 176], [train main loss -1.151079], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 53 / 176], [train main loss -1.180948], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 54 / 176], [train main loss -1.147636], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 55 / 176], [train main loss -1.158225], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 56 / 176], [train main loss -1.209982], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 57 / 176], [train main loss -1.195249], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 58 / 176], [train main loss -1.212579], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 59 / 176], [train main loss -1.195284], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 60 / 176], [train main loss -1.183699], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 61 / 176], [train main loss -1.178215], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 62 / 176], [train main loss -1.194671], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 63 / 176], [train main loss -1.180185], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 64 / 176], [train main loss -1.155852], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 65 / 176], [train main loss -1.133213], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 66 / 176], [train main loss -1.107929], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 67 / 176], [train main loss -1.116253], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 68 / 176], [train main loss -1.138640], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 69 / 176], [train main loss -1.084338], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 70 / 176], [train main loss -1.079450], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 71 / 176], [train main loss -1.070267], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 72 / 176], [train main loss -1.077394], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 73 / 176], [train main loss -1.078380], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 74 / 176], [train main loss -1.066008], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 75 / 176], [train main loss -1.042420], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 76 / 176], [train main loss -1.040434], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 77 / 176], [train main loss -1.081347], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 78 / 176], [train main loss -1.073572], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 79 / 176], [train main loss -1.075318], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 80 / 176], [train main loss -1.077381], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 81 / 176], [train main loss -1.096305], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 82 / 176], [train main loss -1.113202], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 83 / 176], [train main loss -1.089687], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 84 / 176], [train main loss -1.073955], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 85 / 176], [train main loss -1.079346], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 86 / 176], [train main loss -1.052877], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 87 / 176], [train main loss -1.069722], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 88 / 176], [train main loss -1.053828], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 89 / 176], [train main loss -1.048348], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 90 / 176], [train main loss -1.065868], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 91 / 176], [train main loss -1.093164], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 92 / 176], [train main loss -1.106514], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 93 / 176], [train main loss -1.106990], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 94 / 176], [train main loss -1.103295], [lr 0.009257] [batchtime 0.409]
[epoch 13], [iter 95 / 176], [train main loss -1.136008], [lr 0.009257] [batchtime 0.408]
[epoch 13], [iter 96 / 176], [train main loss -1.127332], [lr 0.009257] [batchtime 0.408]
[epoch 13], [iter 97 / 176], [train main loss -1.144196], [lr 0.009257] [batchtime 0.408]
[epoch 13], [iter 98 / 176], [train main loss -1.138253], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 99 / 176], [train main loss -1.151337], [lr 0.009257] [batchtime 0.415]
[epoch 13], [iter 100 / 176], [train main loss -1.167377], [lr 0.009257] [batchtime 0.415]
[epoch 13], [iter 101 / 176], [train main loss -1.180036], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 102 / 176], [train main loss -1.188606], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 103 / 176], [train main loss -1.194937], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 104 / 176], [train main loss -1.198668], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 105 / 176], [train main loss -1.199162], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 106 / 176], [train main loss -1.207007], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 107 / 176], [train main loss -1.207296], [lr 0.009257] [batchtime 0.414]
[epoch 13], [iter 108 / 176], [train main loss -1.232780], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 109 / 176], [train main loss -1.256830], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 110 / 176], [train main loss -1.256829], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 111 / 176], [train main loss -1.282411], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 112 / 176], [train main loss -1.294880], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 113 / 176], [train main loss -1.307629], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 114 / 176], [train main loss -1.313043], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 115 / 176], [train main loss -1.314100], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 116 / 176], [train main loss -1.311123], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 117 / 176], [train main loss -1.303155], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 118 / 176], [train main loss -1.321812], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 119 / 176], [train main loss -1.317669], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 120 / 176], [train main loss -1.283448], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 121 / 176], [train main loss -1.287860], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 122 / 176], [train main loss -1.280267], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 123 / 176], [train main loss -1.293233], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 124 / 176], [train main loss -1.307892], [lr 0.009257] [batchtime 0.413]
[epoch 13], [iter 125 / 176], [train main loss -1.287274], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 126 / 176], [train main loss -1.294296], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 127 / 176], [train main loss -1.283935], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 128 / 176], [train main loss -1.272947], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 129 / 176], [train main loss -1.252892], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 130 / 176], [train main loss -1.281742], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 131 / 176], [train main loss -1.276412], [lr 0.009257] [batchtime 0.412]
[epoch 13], [iter 132 / 176], [train main loss -1.264538], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 133 / 176], [train main loss -1.274912], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 134 / 176], [train main loss -1.277985], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 135 / 176], [train main loss -1.307622], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 136 / 176], [train main loss -1.296996], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 137 / 176], [train main loss -1.307169], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 138 / 176], [train main loss -1.296216], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 139 / 176], [train main loss -1.307646], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 140 / 176], [train main loss -1.312225], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 141 / 176], [train main loss -1.314946], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 142 / 176], [train main loss -1.300614], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 143 / 176], [train main loss -1.302071], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 144 / 176], [train main loss -1.310737], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 145 / 176], [train main loss -1.309791], [lr 0.009257] [batchtime 0.41]
[epoch 13], [iter 146 / 176], [train main loss -1.295968], [lr 0.009257] [batchtime 0.411]
[epoch 13], [iter 147 / 176], [train main loss -1.301919], [lr 0.009257] [batchtime 0.42]
[epoch 13], [iter 148 / 176], [train main loss -1.305847], [lr 0.009257] [batchtime 0.42]
[epoch 13], [iter 149 / 176], [train main loss -1.298798], [lr 0.009257] [batchtime 0.419]
[epoch 13], [iter 150 / 176], [train main loss -1.293498], [lr 0.009257] [batchtime 0.419]
[epoch 13], [iter 151 / 176], [train main loss -1.289773], [lr 0.009257] [batchtime 0.419]
[epoch 13], [iter 152 / 176], [train main loss -1.288626], [lr 0.009257] [batchtime 0.419]
[epoch 13], [iter 153 / 176], [train main loss -1.292116], [lr 0.009257] [batchtime 0.419]
[epoch 13], [iter 154 / 176], [train main loss -1.311814], [lr 0.009257] [batchtime 0.419]
[epoch 13], [iter 155 / 176], [train main loss -1.302663], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 156 / 176], [train main loss -1.305971], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 157 / 176], [train main loss -1.299815], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 158 / 176], [train main loss -1.307584], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 159 / 176], [train main loss -1.301095], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 160 / 176], [train main loss -1.299703], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 161 / 176], [train main loss -1.305932], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 162 / 176], [train main loss -1.308017], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 163 / 176], [train main loss -1.295279], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 164 / 176], [train main loss -1.297652], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 165 / 176], [train main loss -1.298770], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 166 / 176], [train main loss -1.292901], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 167 / 176], [train main loss -1.303936], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 168 / 176], [train main loss -1.309575], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 169 / 176], [train main loss -1.308695], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 170 / 176], [train main loss -1.300681], [lr 0.009257] [batchtime 0.418]
[epoch 13], [iter 171 / 176], [train main loss -1.293974], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 172 / 176], [train main loss -1.284808], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 173 / 176], [train main loss -1.303727], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 174 / 176], [train main loss -1.298718], [lr 0.009257] [batchtime 0.417]
[epoch 13], [iter 175 / 176], [train main loss -1.294215], [lr 0.009257] [batchtime 0.416]
[epoch 13], [iter 176 / 176], [train main loss -1.297067], [lr 0.009257] [batchtime 0.416]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              87.94  34.52        0.05    0.08         0.95      0.92
   1  sidewalk          40.72   3.87        0.70    0.76         0.59      0.57
   2  building          75.32  23.15        0.15    0.18         0.87      0.85
   3  wall               0.00   0.00    84902.59    0.85         0.00      0.54
   4  fence              0.00   0.00  7480576.50   11.00         0.00      0.08
   5  pole               2.08   0.02       46.26    0.78         0.02      0.56
   6  traffic light      0.00   0.00      inf     nan            0.00    nan
   7  traffic sign       3.18   0.02       29.46    1.02         0.03      0.49
   8  vegetation        72.16  10.60        0.17    0.22         0.86      0.82
   9  terrain           10.57   0.09        7.05    1.42         0.12      0.41
  10  sky               87.89   3.70        0.05    0.09         0.96      0.92
  11  person             9.27   0.19        7.03    2.76         0.12      0.27
  12  rider              0.00   0.00      inf     nan            0.00    nan
  13  car               54.93   6.20        0.14    0.68         0.88      0.60
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00      inf     nan            0.00    nan
  16  train              0.00   0.00      inf     nan            0.00    nan
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle            4.59   0.02       18.86    1.90         0.05      0.34
Mean: 23.61
-----------------------------------------------------------------------------------------------------------
this : [epoch 13], [val loss 0.58259], [acc 0.82400], [acc_cls 0.28697], [mean_iu 0.23612], [fwavacc 0.71168]
best : [epoch 13], [val loss 0.58259], [acc 0.82400], [acc_cls 0.28697], [mean_iu 0.23612], [fwavacc 0.71168]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 14], [iter 1 / 176], [train main loss -1.395472], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 2 / 176], [train main loss -2.541290], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 3 / 176], [train main loss -2.561402], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 4 / 176], [train main loss -2.214013], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 5 / 176], [train main loss -2.014077], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 6 / 176], [train main loss -1.731993], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 7 / 176], [train main loss -1.586404], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 8 / 176], [train main loss -1.614135], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 9 / 176], [train main loss -1.733421], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 10 / 176], [train main loss -1.610850], [lr 0.009200] [batchtime 0]
[epoch 14], [iter 11 / 176], [train main loss -1.441196], [lr 0.009200] [batchtime 0.362]
[epoch 14], [iter 12 / 176], [train main loss -1.365371], [lr 0.009200] [batchtime 0.38]
[epoch 14], [iter 13 / 176], [train main loss -1.412922], [lr 0.009200] [batchtime 0.382]
[epoch 14], [iter 14 / 176], [train main loss -1.614529], [lr 0.009200] [batchtime 0.386]
[epoch 14], [iter 15 / 176], [train main loss -1.334324], [lr 0.009200] [batchtime 0.388]
[epoch 14], [iter 16 / 176], [train main loss -1.400111], [lr 0.009200] [batchtime 0.39]
[epoch 14], [iter 17 / 176], [train main loss -1.354490], [lr 0.009200] [batchtime 0.392]
[epoch 14], [iter 18 / 176], [train main loss -1.250189], [lr 0.009200] [batchtime 0.393]
[epoch 14], [iter 19 / 176], [train main loss -1.196395], [lr 0.009200] [batchtime 0.4]
[epoch 14], [iter 20 / 176], [train main loss -1.220425], [lr 0.009200] [batchtime 0.411]
[epoch 14], [iter 21 / 176], [train main loss -1.238649], [lr 0.009200] [batchtime 0.41]
[epoch 14], [iter 22 / 176], [train main loss -1.243667], [lr 0.009200] [batchtime 0.408]
[epoch 14], [iter 23 / 176], [train main loss -1.367374], [lr 0.009200] [batchtime 0.407]
[epoch 14], [iter 24 / 176], [train main loss -1.336718], [lr 0.009200] [batchtime 0.406]
[epoch 14], [iter 25 / 176], [train main loss -1.338276], [lr 0.009200] [batchtime 0.406]
[epoch 14], [iter 26 / 176], [train main loss -1.376985], [lr 0.009200] [batchtime 0.405]
[epoch 14], [iter 27 / 176], [train main loss -1.250745], [lr 0.009200] [batchtime 0.404]
[epoch 14], [iter 28 / 176], [train main loss -1.264293], [lr 0.009200] [batchtime 0.403]
[epoch 14], [iter 29 / 176], [train main loss -1.185187], [lr 0.009200] [batchtime 0.403]
[epoch 14], [iter 30 / 176], [train main loss -1.128846], [lr 0.009200] [batchtime 0.402]
[epoch 14], [iter 31 / 176], [train main loss -1.146180], [lr 0.009200] [batchtime 0.402]
[epoch 14], [iter 32 / 176], [train main loss -1.205631], [lr 0.009200] [batchtime 0.402]
[epoch 14], [iter 33 / 176], [train main loss -1.207405], [lr 0.009200] [batchtime 0.402]
[epoch 14], [iter 34 / 176], [train main loss -1.190249], [lr 0.009200] [batchtime 0.402]
[epoch 14], [iter 35 / 176], [train main loss -1.177967], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 36 / 176], [train main loss -1.191324], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 37 / 176], [train main loss -1.283958], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 38 / 176], [train main loss -1.336468], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 39 / 176], [train main loss -1.337902], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 40 / 176], [train main loss -1.323919], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 41 / 176], [train main loss -1.277261], [lr 0.009200] [batchtime 0.401]
[epoch 14], [iter 42 / 176], [train main loss -1.224145], [lr 0.009200] [batchtime 0.4]
[epoch 14], [iter 43 / 176], [train main loss -1.197391], [lr 0.009200] [batchtime 0.405]
[epoch 14], [iter 44 / 176], [train main loss -1.163279], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 45 / 176], [train main loss -1.145406], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 46 / 176], [train main loss -1.153642], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 47 / 176], [train main loss -1.190280], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 48 / 176], [train main loss -1.206017], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 49 / 176], [train main loss -1.182204], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 50 / 176], [train main loss -1.221310], [lr 0.009200] [batchtime 0.417]
[epoch 14], [iter 51 / 176], [train main loss -1.259766], [lr 0.009200] [batchtime 0.417]
[epoch 14], [iter 52 / 176], [train main loss -1.232712], [lr 0.009200] [batchtime 0.416]
[epoch 14], [iter 53 / 176], [train main loss -1.235255], [lr 0.009200] [batchtime 0.416]
[epoch 14], [iter 54 / 176], [train main loss -1.215042], [lr 0.009200] [batchtime 0.416]
[epoch 14], [iter 55 / 176], [train main loss -1.198293], [lr 0.009200] [batchtime 0.415]
[epoch 14], [iter 56 / 176], [train main loss -1.193133], [lr 0.009200] [batchtime 0.415]
[epoch 14], [iter 57 / 176], [train main loss -1.147738], [lr 0.009200] [batchtime 0.414]
[epoch 14], [iter 58 / 176], [train main loss -1.151619], [lr 0.009200] [batchtime 0.414]
[epoch 14], [iter 59 / 176], [train main loss -1.150340], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 60 / 176], [train main loss -1.174820], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 61 / 176], [train main loss -1.166172], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 62 / 176], [train main loss -1.171261], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 63 / 176], [train main loss -1.236207], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 64 / 176], [train main loss -1.191216], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 65 / 176], [train main loss -1.200124], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 66 / 176], [train main loss -1.255866], [lr 0.009200] [batchtime 0.411]
[epoch 14], [iter 67 / 176], [train main loss -1.255387], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 68 / 176], [train main loss -1.257496], [lr 0.009200] [batchtime 0.416]
[epoch 14], [iter 69 / 176], [train main loss -1.266277], [lr 0.009200] [batchtime 0.416]
[epoch 14], [iter 70 / 176], [train main loss -1.259054], [lr 0.009200] [batchtime 0.415]
[epoch 14], [iter 71 / 176], [train main loss -1.260274], [lr 0.009200] [batchtime 0.415]
[epoch 14], [iter 72 / 176], [train main loss -1.266332], [lr 0.009200] [batchtime 0.414]
[epoch 14], [iter 73 / 176], [train main loss -1.275418], [lr 0.009200] [batchtime 0.414]
[epoch 14], [iter 74 / 176], [train main loss -1.266732], [lr 0.009200] [batchtime 0.414]
[epoch 14], [iter 75 / 176], [train main loss -1.287455], [lr 0.009200] [batchtime 0.414]
[epoch 14], [iter 76 / 176], [train main loss -1.297556], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 77 / 176], [train main loss -1.294823], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 78 / 176], [train main loss -1.275787], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 79 / 176], [train main loss -1.262570], [lr 0.009200] [batchtime 0.413]
[epoch 14], [iter 80 / 176], [train main loss -1.273976], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 81 / 176], [train main loss -1.263189], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 82 / 176], [train main loss -1.266912], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 83 / 176], [train main loss -1.249152], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 84 / 176], [train main loss -1.254397], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 85 / 176], [train main loss -1.246039], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 86 / 176], [train main loss -1.214722], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 87 / 176], [train main loss -1.219059], [lr 0.009200] [batchtime 0.411]
[epoch 14], [iter 88 / 176], [train main loss -1.216424], [lr 0.009200] [batchtime 0.411]
[epoch 14], [iter 89 / 176], [train main loss -1.238155], [lr 0.009200] [batchtime 0.411]
[epoch 14], [iter 90 / 176], [train main loss -1.256279], [lr 0.009200] [batchtime 0.411]
[epoch 14], [iter 91 / 176], [train main loss -1.247990], [lr 0.009200] [batchtime 0.412]
[epoch 14], [iter 92 / 176], [train main loss -1.252502], [lr 0.009200] [batchtime 0.427]
[epoch 14], [iter 93 / 176], [train main loss -1.233948], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 94 / 176], [train main loss -1.245681], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 95 / 176], [train main loss -1.247181], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 96 / 176], [train main loss -1.228115], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 97 / 176], [train main loss -1.235674], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 98 / 176], [train main loss -1.221282], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 99 / 176], [train main loss -1.221491], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 100 / 176], [train main loss -1.202023], [lr 0.009200] [batchtime 0.423]
[epoch 14], [iter 101 / 176], [train main loss -1.185733], [lr 0.009200] [batchtime 0.423]
[epoch 14], [iter 102 / 176], [train main loss -1.229798], [lr 0.009200] [batchtime 0.423]
[epoch 14], [iter 103 / 176], [train main loss -1.221370], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 104 / 176], [train main loss -1.201463], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 105 / 176], [train main loss -1.195930], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 106 / 176], [train main loss -1.182061], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 107 / 176], [train main loss -1.173877], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 108 / 176], [train main loss -1.177463], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 109 / 176], [train main loss -1.194903], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 110 / 176], [train main loss -1.193739], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 111 / 176], [train main loss -1.188763], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 112 / 176], [train main loss -1.166800], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 113 / 176], [train main loss -1.168796], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 114 / 176], [train main loss -1.210898], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 115 / 176], [train main loss -1.201234], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 116 / 176], [train main loss -1.205294], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 117 / 176], [train main loss -1.204070], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 118 / 176], [train main loss -1.228371], [lr 0.009200] [batchtime 0.421]
[epoch 14], [iter 119 / 176], [train main loss -1.237818], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 120 / 176], [train main loss -1.254136], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 121 / 176], [train main loss -1.248636], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 122 / 176], [train main loss -1.233569], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 123 / 176], [train main loss -1.239404], [lr 0.009200] [batchtime 0.42]
[epoch 14], [iter 124 / 176], [train main loss -1.235127], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 125 / 176], [train main loss -1.239621], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 126 / 176], [train main loss -1.233799], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 127 / 176], [train main loss -1.229326], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 128 / 176], [train main loss -1.219178], [lr 0.009200] [batchtime 0.419]
[epoch 14], [iter 129 / 176], [train main loss -1.215747], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 130 / 176], [train main loss -1.236613], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 131 / 176], [train main loss -1.227997], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 132 / 176], [train main loss -1.237002], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 133 / 176], [train main loss -1.224933], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 134 / 176], [train main loss -1.215094], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 135 / 176], [train main loss -1.203849], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 136 / 176], [train main loss -1.213628], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 137 / 176], [train main loss -1.212820], [lr 0.009200] [batchtime 0.417]
[epoch 14], [iter 138 / 176], [train main loss -1.227858], [lr 0.009200] [batchtime 0.418]
[epoch 14], [iter 139 / 176], [train main loss -1.243403], [lr 0.009200] [batchtime 0.429]
[epoch 14], [iter 140 / 176], [train main loss -1.254930], [lr 0.009200] [batchtime 0.428]
[epoch 14], [iter 141 / 176], [train main loss -1.262252], [lr 0.009200] [batchtime 0.428]
[epoch 14], [iter 142 / 176], [train main loss -1.270188], [lr 0.009200] [batchtime 0.428]
[epoch 14], [iter 143 / 176], [train main loss -1.279399], [lr 0.009200] [batchtime 0.427]
[epoch 14], [iter 144 / 176], [train main loss -1.269992], [lr 0.009200] [batchtime 0.427]
[epoch 14], [iter 145 / 176], [train main loss -1.262999], [lr 0.009200] [batchtime 0.427]
[epoch 14], [iter 146 / 176], [train main loss -1.259643], [lr 0.009200] [batchtime 0.427]
[epoch 14], [iter 147 / 176], [train main loss -1.251275], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 148 / 176], [train main loss -1.246992], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 149 / 176], [train main loss -1.234607], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 150 / 176], [train main loss -1.233782], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 151 / 176], [train main loss -1.238681], [lr 0.009200] [batchtime 0.426]
[epoch 14], [iter 152 / 176], [train main loss -1.232753], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 153 / 176], [train main loss -1.242424], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 154 / 176], [train main loss -1.256484], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 155 / 176], [train main loss -1.258411], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 156 / 176], [train main loss -1.273290], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 157 / 176], [train main loss -1.272095], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 158 / 176], [train main loss -1.285494], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 159 / 176], [train main loss -1.292531], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 160 / 176], [train main loss -1.276730], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 161 / 176], [train main loss -1.272615], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 162 / 176], [train main loss -1.262257], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 163 / 176], [train main loss -1.249155], [lr 0.009200] [batchtime 0.425]
[epoch 14], [iter 164 / 176], [train main loss -1.263341], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 165 / 176], [train main loss -1.258355], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 166 / 176], [train main loss -1.259377], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 167 / 176], [train main loss -1.264968], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 168 / 176], [train main loss -1.267639], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 169 / 176], [train main loss -1.268281], [lr 0.009200] [batchtime 0.424]
[epoch 14], [iter 170 / 176], [train main loss -1.265938], [lr 0.009200] [batchtime 0.423]
[epoch 14], [iter 171 / 176], [train main loss -1.264373], [lr 0.009200] [batchtime 0.423]
[epoch 14], [iter 172 / 176], [train main loss -1.267547], [lr 0.009200] [batchtime 0.423]
[epoch 14], [iter 173 / 176], [train main loss -1.274921], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 174 / 176], [train main loss -1.287202], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 175 / 176], [train main loss -1.286577], [lr 0.009200] [batchtime 0.422]
[epoch 14], [iter 176 / 176], [train main loss -1.277910], [lr 0.009200] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              88.63  34.40        0.06    0.07         0.95      0.93
   1  sidewalk          43.07   4.26        0.55    0.78         0.65      0.56
   2  building          74.94  22.72        0.17    0.16         0.85      0.86
   3  wall               0.23   0.00      435.88    1.87         0.00      0.35
   4  fence              0.00   0.00  2992230.00    5.60         0.00      0.15
   5  pole               4.67   0.06       19.23    1.18         0.05      0.46
   6  traffic light      0.00   0.00      inf     nan            0.00    nan
   7  traffic sign       2.21   0.01       43.18    1.13         0.02      0.47
   8  vegetation        68.94  11.43        0.08    0.37         0.92      0.73
   9  terrain           17.32   0.19        2.93    1.85         0.25      0.35
  10  sky               88.87   3.61        0.07    0.05         0.93      0.95
  11  person             6.90   0.12       12.09    1.41         0.08      0.41
  12  rider              0.00   0.00      inf     nan            0.00    nan
  13  car               62.66   5.99        0.18    0.42         0.85      0.71
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00      inf     nan            0.00    nan
  16  train              0.00   0.00      inf     nan            0.00    nan
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle           11.99   0.07        4.97    2.37         0.17      0.30
Mean: 24.76
-----------------------------------------------------------------------------------------------------------
this : [epoch 14], [val loss 0.54656], [acc 0.82856], [acc_cls 0.30127], [mean_iu 0.24759], [fwavacc 0.71727]
best : [epoch 14], [val loss 0.54656], [acc 0.82856], [acc_cls 0.30127], [mean_iu 0.24759], [fwavacc 0.71727]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 15], [iter 1 / 176], [train main loss -3.038489], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 2 / 176], [train main loss -0.988846], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 3 / 176], [train main loss -1.243501], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 4 / 176], [train main loss -1.013013], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 5 / 176], [train main loss -1.025422], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 6 / 176], [train main loss -1.288256], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 7 / 176], [train main loss -1.556014], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 8 / 176], [train main loss -1.730900], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 9 / 176], [train main loss -2.170768], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 10 / 176], [train main loss -2.386727], [lr 0.009143] [batchtime 0]
[epoch 15], [iter 11 / 176], [train main loss -2.394108], [lr 0.009143] [batchtime 0.381]
[epoch 15], [iter 12 / 176], [train main loss -2.352880], [lr 0.009143] [batchtime 0.39]
[epoch 15], [iter 13 / 176], [train main loss -2.403572], [lr 0.009143] [batchtime 0.394]
[epoch 15], [iter 14 / 176], [train main loss -2.465674], [lr 0.009143] [batchtime 0.394]
[epoch 15], [iter 15 / 176], [train main loss -2.484328], [lr 0.009143] [batchtime 0.396]
[epoch 15], [iter 16 / 176], [train main loss -2.302696], [lr 0.009143] [batchtime 0.399]
[epoch 15], [iter 17 / 176], [train main loss -2.182010], [lr 0.009143] [batchtime 0.399]
[epoch 15], [iter 18 / 176], [train main loss -2.006380], [lr 0.009143] [batchtime 0.399]
[epoch 15], [iter 19 / 176], [train main loss -1.866576], [lr 0.009143] [batchtime 0.4]
[epoch 15], [iter 20 / 176], [train main loss -1.830532], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 21 / 176], [train main loss -1.777189], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 22 / 176], [train main loss -1.754843], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 23 / 176], [train main loss -1.720032], [lr 0.009143] [batchtime 0.402]
[epoch 15], [iter 24 / 176], [train main loss -1.754707], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 25 / 176], [train main loss -1.860665], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 26 / 176], [train main loss -1.925495], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 27 / 176], [train main loss -2.010699], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 28 / 176], [train main loss -2.058936], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 29 / 176], [train main loss -2.075750], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 30 / 176], [train main loss -2.087513], [lr 0.009143] [batchtime 0.402]
[epoch 15], [iter 31 / 176], [train main loss -2.094111], [lr 0.009143] [batchtime 0.401]
[epoch 15], [iter 32 / 176], [train main loss -2.052016], [lr 0.009143] [batchtime 0.402]
[epoch 15], [iter 33 / 176], [train main loss -2.015497], [lr 0.009143] [batchtime 0.441]
[epoch 15], [iter 34 / 176], [train main loss -1.931446], [lr 0.009143] [batchtime 0.451]
[epoch 15], [iter 35 / 176], [train main loss -1.896936], [lr 0.009143] [batchtime 0.449]
[epoch 15], [iter 36 / 176], [train main loss -1.884500], [lr 0.009143] [batchtime 0.447]
[epoch 15], [iter 37 / 176], [train main loss -1.906229], [lr 0.009143] [batchtime 0.445]
[epoch 15], [iter 38 / 176], [train main loss -1.903279], [lr 0.009143] [batchtime 0.444]
[epoch 15], [iter 39 / 176], [train main loss -1.874998], [lr 0.009143] [batchtime 0.442]
[epoch 15], [iter 40 / 176], [train main loss -1.875395], [lr 0.009143] [batchtime 0.441]
[epoch 15], [iter 41 / 176], [train main loss -1.857509], [lr 0.009143] [batchtime 0.44]
[epoch 15], [iter 42 / 176], [train main loss -1.775843], [lr 0.009143] [batchtime 0.438]
[epoch 15], [iter 43 / 176], [train main loss -1.804085], [lr 0.009143] [batchtime 0.437]
[epoch 15], [iter 44 / 176], [train main loss -1.820354], [lr 0.009143] [batchtime 0.436]
[epoch 15], [iter 45 / 176], [train main loss -1.845711], [lr 0.009143] [batchtime 0.435]
[epoch 15], [iter 46 / 176], [train main loss -1.864018], [lr 0.009143] [batchtime 0.434]
[epoch 15], [iter 47 / 176], [train main loss -1.899282], [lr 0.009143] [batchtime 0.433]
[epoch 15], [iter 48 / 176], [train main loss -1.893210], [lr 0.009143] [batchtime 0.432]
[epoch 15], [iter 49 / 176], [train main loss -1.900712], [lr 0.009143] [batchtime 0.431]
[epoch 15], [iter 50 / 176], [train main loss -1.893978], [lr 0.009143] [batchtime 0.43]
[epoch 15], [iter 51 / 176], [train main loss -1.909672], [lr 0.009143] [batchtime 0.43]
[epoch 15], [iter 52 / 176], [train main loss -1.947280], [lr 0.009143] [batchtime 0.429]
[epoch 15], [iter 53 / 176], [train main loss -1.964773], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 54 / 176], [train main loss -1.937788], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 55 / 176], [train main loss -1.926121], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 56 / 176], [train main loss -1.858865], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 57 / 176], [train main loss -1.821301], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 58 / 176], [train main loss -1.787753], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 59 / 176], [train main loss -1.743065], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 60 / 176], [train main loss -1.738650], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 61 / 176], [train main loss -1.775501], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 62 / 176], [train main loss -1.721492], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 63 / 176], [train main loss -1.715229], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 64 / 176], [train main loss -1.711459], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 65 / 176], [train main loss -1.714860], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 66 / 176], [train main loss -1.708411], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 67 / 176], [train main loss -1.703803], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 68 / 176], [train main loss -1.698128], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 69 / 176], [train main loss -1.688047], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 70 / 176], [train main loss -1.680902], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 71 / 176], [train main loss -1.685074], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 72 / 176], [train main loss -1.708862], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 73 / 176], [train main loss -1.705315], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 74 / 176], [train main loss -1.700034], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 75 / 176], [train main loss -1.686278], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 76 / 176], [train main loss -1.705703], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 77 / 176], [train main loss -1.695245], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 78 / 176], [train main loss -1.656289], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 79 / 176], [train main loss -1.662643], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 80 / 176], [train main loss -1.690033], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 81 / 176], [train main loss -1.677163], [lr 0.009143] [batchtime 0.429]
[epoch 15], [iter 82 / 176], [train main loss -1.683876], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 83 / 176], [train main loss -1.700411], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 84 / 176], [train main loss -1.685240], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 85 / 176], [train main loss -1.679407], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 86 / 176], [train main loss -1.679363], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 87 / 176], [train main loss -1.712983], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 88 / 176], [train main loss -1.682272], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 89 / 176], [train main loss -1.650280], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 90 / 176], [train main loss -1.669059], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 91 / 176], [train main loss -1.669085], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 92 / 176], [train main loss -1.649742], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 93 / 176], [train main loss -1.641327], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 94 / 176], [train main loss -1.667082], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 95 / 176], [train main loss -1.644575], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 96 / 176], [train main loss -1.652456], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 97 / 176], [train main loss -1.653664], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 98 / 176], [train main loss -1.612645], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 99 / 176], [train main loss -1.610285], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 100 / 176], [train main loss -1.624323], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 101 / 176], [train main loss -1.591776], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 102 / 176], [train main loss -1.606067], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 103 / 176], [train main loss -1.577234], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 104 / 176], [train main loss -1.572966], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 105 / 176], [train main loss -1.580753], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 106 / 176], [train main loss -1.577948], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 107 / 176], [train main loss -1.565460], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 108 / 176], [train main loss -1.583576], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 109 / 176], [train main loss -1.571607], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 110 / 176], [train main loss -1.549791], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 111 / 176], [train main loss -1.559576], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 112 / 176], [train main loss -1.558421], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 113 / 176], [train main loss -1.547133], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 114 / 176], [train main loss -1.544919], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 115 / 176], [train main loss -1.520787], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 116 / 176], [train main loss -1.519411], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 117 / 176], [train main loss -1.505100], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 118 / 176], [train main loss -1.515165], [lr 0.009143] [batchtime 0.418]
[epoch 15], [iter 119 / 176], [train main loss -1.528520], [lr 0.009143] [batchtime 0.417]
[epoch 15], [iter 120 / 176], [train main loss -1.526000], [lr 0.009143] [batchtime 0.417]
[epoch 15], [iter 121 / 176], [train main loss -1.518845], [lr 0.009143] [batchtime 0.417]
[epoch 15], [iter 122 / 176], [train main loss -1.528268], [lr 0.009143] [batchtime 0.417]
[epoch 15], [iter 123 / 176], [train main loss -1.542493], [lr 0.009143] [batchtime 0.417]
[epoch 15], [iter 124 / 176], [train main loss -1.514814], [lr 0.009143] [batchtime 0.417]
[epoch 15], [iter 125 / 176], [train main loss -1.500390], [lr 0.009143] [batchtime 0.416]
[epoch 15], [iter 126 / 176], [train main loss -1.495610], [lr 0.009143] [batchtime 0.416]
[epoch 15], [iter 127 / 176], [train main loss -1.522456], [lr 0.009143] [batchtime 0.416]
[epoch 15], [iter 128 / 176], [train main loss -1.496712], [lr 0.009143] [batchtime 0.416]
[epoch 15], [iter 129 / 176], [train main loss -1.525347], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 130 / 176], [train main loss -1.516675], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 131 / 176], [train main loss -1.520860], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 132 / 176], [train main loss -1.503459], [lr 0.009143] [batchtime 0.428]
[epoch 15], [iter 133 / 176], [train main loss -1.483109], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 134 / 176], [train main loss -1.479158], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 135 / 176], [train main loss -1.469384], [lr 0.009143] [batchtime 0.427]
[epoch 15], [iter 136 / 176], [train main loss -1.447645], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 137 / 176], [train main loss -1.458900], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 138 / 176], [train main loss -1.447573], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 139 / 176], [train main loss -1.452999], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 140 / 176], [train main loss -1.442218], [lr 0.009143] [batchtime 0.426]
[epoch 15], [iter 141 / 176], [train main loss -1.439487], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 142 / 176], [train main loss -1.445101], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 143 / 176], [train main loss -1.421562], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 144 / 176], [train main loss -1.429895], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 145 / 176], [train main loss -1.421908], [lr 0.009143] [batchtime 0.425]
[epoch 15], [iter 146 / 176], [train main loss -1.409420], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 147 / 176], [train main loss -1.409911], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 148 / 176], [train main loss -1.402122], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 149 / 176], [train main loss -1.413810], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 150 / 176], [train main loss -1.424416], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 151 / 176], [train main loss -1.437252], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 152 / 176], [train main loss -1.424921], [lr 0.009143] [batchtime 0.424]
[epoch 15], [iter 153 / 176], [train main loss -1.430214], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 154 / 176], [train main loss -1.431949], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 155 / 176], [train main loss -1.438494], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 156 / 176], [train main loss -1.435589], [lr 0.009143] [batchtime 0.423]
[epoch 15], [iter 157 / 176], [train main loss -1.421178], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 158 / 176], [train main loss -1.415510], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 159 / 176], [train main loss -1.434944], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 160 / 176], [train main loss -1.433799], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 161 / 176], [train main loss -1.429749], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 162 / 176], [train main loss -1.440906], [lr 0.009143] [batchtime 0.422]
[epoch 15], [iter 163 / 176], [train main loss -1.423029], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 164 / 176], [train main loss -1.421717], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 165 / 176], [train main loss -1.425071], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 166 / 176], [train main loss -1.440438], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 167 / 176], [train main loss -1.441016], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 168 / 176], [train main loss -1.431461], [lr 0.009143] [batchtime 0.421]
[epoch 15], [iter 169 / 176], [train main loss -1.432758], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 170 / 176], [train main loss -1.432577], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 171 / 176], [train main loss -1.433209], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 172 / 176], [train main loss -1.420665], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 173 / 176], [train main loss -1.421395], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 174 / 176], [train main loss -1.413974], [lr 0.009143] [batchtime 0.419]
[epoch 15], [iter 175 / 176], [train main loss -1.400258], [lr 0.009143] [batchtime 0.42]
[epoch 15], [iter 176 / 176], [train main loss -1.389939], [lr 0.009143] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              87.94  35.15        0.03    0.10         0.97      0.91
   1  sidewalk          36.47   3.28        1.01    0.73         0.50      0.58
   2  building          75.24  22.98        0.16    0.17         0.86      0.85
   3  wall               0.00   0.00   108781.72    2.80         0.00      0.26
   4  fence              0.00   0.00  1246761.88    0.83         0.00      0.55
   5  pole               2.78   0.03       34.07    0.84         0.03      0.54
   6  traffic light      0.00   0.00      inf     nan            0.00    nan
   7  traffic sign       2.65   0.02       35.89    0.84         0.03      0.54
   8  vegetation        69.32  11.43        0.08    0.36         0.92      0.73
   9  terrain           13.50   0.12        5.21    1.20         0.16      0.46
  10  sky               87.80   3.70        0.05    0.09         0.96      0.92
  11  person             5.12   0.08       17.61    0.93         0.05      0.52
  12  rider              0.00   0.00      inf     nan            0.00    nan
  13  car               62.29   5.93        0.19    0.41         0.84      0.71
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00      inf     nan            0.00    nan
  16  train              0.00   0.00      inf     nan            0.00    nan
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle           10.73   0.05        6.90    1.42         0.13      0.41
Mean: 23.89
-----------------------------------------------------------------------------------------------------------
this : [epoch 15], [val loss 0.61103], [acc 0.82778], [acc_cls 0.28656], [mean_iu 0.23887], [fwavacc 0.71023]
best : [epoch 14], [val loss 0.54656], [acc 0.82856], [acc_cls 0.30127], [mean_iu 0.24759], [fwavacc 0.71727]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 16], [iter 1 / 176], [train main loss 0.900157], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 2 / 176], [train main loss 0.037947], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 3 / 176], [train main loss -0.821889], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 4 / 176], [train main loss -0.567818], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 5 / 176], [train main loss -1.105397], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 6 / 176], [train main loss -0.865885], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 7 / 176], [train main loss -0.828686], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 8 / 176], [train main loss -1.003286], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 9 / 176], [train main loss -0.901302], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 10 / 176], [train main loss -0.809775], [lr 0.009086] [batchtime 0]
[epoch 16], [iter 11 / 176], [train main loss -0.765767], [lr 0.009086] [batchtime 0.379]
[epoch 16], [iter 12 / 176], [train main loss -0.897413], [lr 0.009086] [batchtime 0.392]
[epoch 16], [iter 13 / 176], [train main loss -1.095789], [lr 0.009086] [batchtime 0.396]
[epoch 16], [iter 14 / 176], [train main loss -1.112551], [lr 0.009086] [batchtime 0.398]
[epoch 16], [iter 15 / 176], [train main loss -1.148057], [lr 0.009086] [batchtime 0.402]
[epoch 16], [iter 16 / 176], [train main loss -1.145314], [lr 0.009086] [batchtime 0.403]
[epoch 16], [iter 17 / 176], [train main loss -1.194221], [lr 0.009086] [batchtime 0.404]
[epoch 16], [iter 18 / 176], [train main loss -1.468571], [lr 0.009086] [batchtime 0.402]
[epoch 16], [iter 19 / 176], [train main loss -1.457962], [lr 0.009086] [batchtime 0.4]
[epoch 16], [iter 20 / 176], [train main loss -1.446994], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 21 / 176], [train main loss -1.354625], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 22 / 176], [train main loss -1.310570], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 23 / 176], [train main loss -1.271740], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 24 / 176], [train main loss -1.290661], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 25 / 176], [train main loss -1.243203], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 26 / 176], [train main loss -1.282984], [lr 0.009086] [batchtime 0.399]
[epoch 16], [iter 27 / 176], [train main loss -1.293787], [lr 0.009086] [batchtime 0.398]
[epoch 16], [iter 28 / 176], [train main loss -1.343029], [lr 0.009086] [batchtime 0.398]
[epoch 16], [iter 29 / 176], [train main loss -1.346381], [lr 0.009086] [batchtime 0.398]
[epoch 16], [iter 30 / 176], [train main loss -1.224482], [lr 0.009086] [batchtime 0.398]
[epoch 16], [iter 31 / 176], [train main loss -1.192361], [lr 0.009086] [batchtime 0.397]
[epoch 16], [iter 32 / 176], [train main loss -1.219500], [lr 0.009086] [batchtime 0.464]
[epoch 16], [iter 33 / 176], [train main loss -1.210852], [lr 0.009086] [batchtime 0.465]
[epoch 16], [iter 34 / 176], [train main loss -1.174089], [lr 0.009086] [batchtime 0.462]
[epoch 16], [iter 35 / 176], [train main loss -1.292106], [lr 0.009086] [batchtime 0.459]
[epoch 16], [iter 36 / 176], [train main loss -1.320050], [lr 0.009086] [batchtime 0.456]
[epoch 16], [iter 37 / 176], [train main loss -1.322472], [lr 0.009086] [batchtime 0.454]
[epoch 16], [iter 38 / 176], [train main loss -1.345598], [lr 0.009086] [batchtime 0.452]
[epoch 16], [iter 39 / 176], [train main loss -1.336700], [lr 0.009086] [batchtime 0.45]
[epoch 16], [iter 40 / 176], [train main loss -1.336929], [lr 0.009086] [batchtime 0.448]
[epoch 16], [iter 41 / 176], [train main loss -1.349700], [lr 0.009086] [batchtime 0.447]
[epoch 16], [iter 42 / 176], [train main loss -1.312311], [lr 0.009086] [batchtime 0.445]
[epoch 16], [iter 43 / 176], [train main loss -1.288596], [lr 0.009086] [batchtime 0.443]
[epoch 16], [iter 44 / 176], [train main loss -1.265362], [lr 0.009086] [batchtime 0.442]
[epoch 16], [iter 45 / 176], [train main loss -1.297293], [lr 0.009086] [batchtime 0.441]
[epoch 16], [iter 46 / 176], [train main loss -1.334138], [lr 0.009086] [batchtime 0.439]
[epoch 16], [iter 47 / 176], [train main loss -1.305481], [lr 0.009086] [batchtime 0.438]
[epoch 16], [iter 48 / 176], [train main loss -1.299808], [lr 0.009086] [batchtime 0.437]
[epoch 16], [iter 49 / 176], [train main loss -1.315809], [lr 0.009086] [batchtime 0.437]
[epoch 16], [iter 50 / 176], [train main loss -1.350434], [lr 0.009086] [batchtime 0.435]
[epoch 16], [iter 51 / 176], [train main loss -1.303317], [lr 0.009086] [batchtime 0.435]
[epoch 16], [iter 52 / 176], [train main loss -1.292296], [lr 0.009086] [batchtime 0.434]
[epoch 16], [iter 53 / 176], [train main loss -1.291523], [lr 0.009086] [batchtime 0.433]
[epoch 16], [iter 54 / 176], [train main loss -1.285647], [lr 0.009086] [batchtime 0.432]
[epoch 16], [iter 55 / 176], [train main loss -1.223314], [lr 0.009086] [batchtime 0.431]
[epoch 16], [iter 56 / 176], [train main loss -1.259239], [lr 0.009086] [batchtime 0.431]
[epoch 16], [iter 57 / 176], [train main loss -1.261510], [lr 0.009086] [batchtime 0.43]
[epoch 16], [iter 58 / 176], [train main loss -1.268342], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 59 / 176], [train main loss -1.279020], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 60 / 176], [train main loss -1.305941], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 61 / 176], [train main loss -1.394396], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 62 / 176], [train main loss -1.356281], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 63 / 176], [train main loss -1.373513], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 64 / 176], [train main loss -1.375575], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 65 / 176], [train main loss -1.327676], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 66 / 176], [train main loss -1.368639], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 67 / 176], [train main loss -1.337622], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 68 / 176], [train main loss -1.340518], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 69 / 176], [train main loss -1.337099], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 70 / 176], [train main loss -1.331403], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 71 / 176], [train main loss -1.301464], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 72 / 176], [train main loss -1.309239], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 73 / 176], [train main loss -1.262199], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 74 / 176], [train main loss -1.244799], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 75 / 176], [train main loss -1.225565], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 76 / 176], [train main loss -1.241828], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 77 / 176], [train main loss -1.232283], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 78 / 176], [train main loss -1.210595], [lr 0.009086] [batchtime 0.43]
[epoch 16], [iter 79 / 176], [train main loss -1.189065], [lr 0.009086] [batchtime 0.432]
[epoch 16], [iter 80 / 176], [train main loss -1.200569], [lr 0.009086] [batchtime 0.431]
[epoch 16], [iter 81 / 176], [train main loss -1.233071], [lr 0.009086] [batchtime 0.431]
[epoch 16], [iter 82 / 176], [train main loss -1.215926], [lr 0.009086] [batchtime 0.43]
[epoch 16], [iter 83 / 176], [train main loss -1.211337], [lr 0.009086] [batchtime 0.43]
[epoch 16], [iter 84 / 176], [train main loss -1.209132], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 85 / 176], [train main loss -1.203697], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 86 / 176], [train main loss -1.200834], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 87 / 176], [train main loss -1.227334], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 88 / 176], [train main loss -1.248417], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 89 / 176], [train main loss -1.222429], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 90 / 176], [train main loss -1.213040], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 91 / 176], [train main loss -1.199544], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 92 / 176], [train main loss -1.164313], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 93 / 176], [train main loss -1.136050], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 94 / 176], [train main loss -1.159053], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 95 / 176], [train main loss -1.171732], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 96 / 176], [train main loss -1.168785], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 97 / 176], [train main loss -1.168322], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 98 / 176], [train main loss -1.167434], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 99 / 176], [train main loss -1.171793], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 100 / 176], [train main loss -1.200093], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 101 / 176], [train main loss -1.201931], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 102 / 176], [train main loss -1.218671], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 103 / 176], [train main loss -1.214990], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 104 / 176], [train main loss -1.229985], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 105 / 176], [train main loss -1.244000], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 106 / 176], [train main loss -1.233060], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 107 / 176], [train main loss -1.225757], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 108 / 176], [train main loss -1.221930], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 109 / 176], [train main loss -1.223189], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 110 / 176], [train main loss -1.240207], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 111 / 176], [train main loss -1.221925], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 112 / 176], [train main loss -1.223407], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 113 / 176], [train main loss -1.231296], [lr 0.009086] [batchtime 0.419]
[epoch 16], [iter 114 / 176], [train main loss -1.233707], [lr 0.009086] [batchtime 0.419]
[epoch 16], [iter 115 / 176], [train main loss -1.220990], [lr 0.009086] [batchtime 0.419]
[epoch 16], [iter 116 / 176], [train main loss -1.228992], [lr 0.009086] [batchtime 0.419]
[epoch 16], [iter 117 / 176], [train main loss -1.221775], [lr 0.009086] [batchtime 0.419]
[epoch 16], [iter 118 / 176], [train main loss -1.224164], [lr 0.009086] [batchtime 0.418]
[epoch 16], [iter 119 / 176], [train main loss -1.244145], [lr 0.009086] [batchtime 0.418]
[epoch 16], [iter 120 / 176], [train main loss -1.227110], [lr 0.009086] [batchtime 0.418]
[epoch 16], [iter 121 / 176], [train main loss -1.209000], [lr 0.009086] [batchtime 0.418]
[epoch 16], [iter 122 / 176], [train main loss -1.184799], [lr 0.009086] [batchtime 0.417]
[epoch 16], [iter 123 / 176], [train main loss -1.186721], [lr 0.009086] [batchtime 0.417]
[epoch 16], [iter 124 / 176], [train main loss -1.173013], [lr 0.009086] [batchtime 0.417]
[epoch 16], [iter 125 / 176], [train main loss -1.173187], [lr 0.009086] [batchtime 0.417]
[epoch 16], [iter 126 / 176], [train main loss -1.207162], [lr 0.009086] [batchtime 0.416]
[epoch 16], [iter 127 / 176], [train main loss -1.211298], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 128 / 176], [train main loss -1.210571], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 129 / 176], [train main loss -1.199979], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 130 / 176], [train main loss -1.211245], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 131 / 176], [train main loss -1.223479], [lr 0.009086] [batchtime 0.429]
[epoch 16], [iter 132 / 176], [train main loss -1.208611], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 133 / 176], [train main loss -1.210476], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 134 / 176], [train main loss -1.202144], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 135 / 176], [train main loss -1.210177], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 136 / 176], [train main loss -1.205927], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 137 / 176], [train main loss -1.201976], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 138 / 176], [train main loss -1.210174], [lr 0.009086] [batchtime 0.427]
[epoch 16], [iter 139 / 176], [train main loss -1.212824], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 140 / 176], [train main loss -1.219408], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 141 / 176], [train main loss -1.211723], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 142 / 176], [train main loss -1.199009], [lr 0.009086] [batchtime 0.426]
[epoch 16], [iter 143 / 176], [train main loss -1.205236], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 144 / 176], [train main loss -1.207762], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 145 / 176], [train main loss -1.205137], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 146 / 176], [train main loss -1.214585], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 147 / 176], [train main loss -1.231338], [lr 0.009086] [batchtime 0.425]
[epoch 16], [iter 148 / 176], [train main loss -1.222611], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 149 / 176], [train main loss -1.236479], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 150 / 176], [train main loss -1.230410], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 151 / 176], [train main loss -1.235861], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 152 / 176], [train main loss -1.237495], [lr 0.009086] [batchtime 0.424]
[epoch 16], [iter 153 / 176], [train main loss -1.236087], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 154 / 176], [train main loss -1.234706], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 155 / 176], [train main loss -1.252316], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 156 / 176], [train main loss -1.253553], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 157 / 176], [train main loss -1.255570], [lr 0.009086] [batchtime 0.423]
[epoch 16], [iter 158 / 176], [train main loss -1.264662], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 159 / 176], [train main loss -1.281778], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 160 / 176], [train main loss -1.281262], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 161 / 176], [train main loss -1.281155], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 162 / 176], [train main loss -1.260231], [lr 0.009086] [batchtime 0.422]
[epoch 16], [iter 163 / 176], [train main loss -1.262441], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 164 / 176], [train main loss -1.254643], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 165 / 176], [train main loss -1.265946], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 166 / 176], [train main loss -1.268249], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 167 / 176], [train main loss -1.281648], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 168 / 176], [train main loss -1.284528], [lr 0.009086] [batchtime 0.421]
[epoch 16], [iter 169 / 176], [train main loss -1.300027], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 170 / 176], [train main loss -1.293022], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 171 / 176], [train main loss -1.284586], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 172 / 176], [train main loss -1.266233], [lr 0.009086] [batchtime 0.42]
[epoch 16], [iter 173 / 176], [train main loss -1.250196], [lr 0.009086] [batchtime 0.419]
[epoch 16], [iter 174 / 176], [train main loss -1.268862], [lr 0.009086] [batchtime 0.428]
[epoch 16], [iter 175 / 176], [train main loss -1.277705], [lr 0.009086] [batchtime 0.43]
[epoch 16], [iter 176 / 176], [train main loss -1.281345], [lr 0.009086] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              88.46  34.76       0.05    0.08         0.96      0.92
   1  sidewalk          41.27   3.91       0.68    0.74         0.59      0.57
   2  building          75.76  23.19       0.15    0.17         0.87      0.85
   3  wall               0.39   0.00     255.06    1.21         0.00      0.45
   4  fence              0.00   0.00  103179.38    2.03         0.00      0.33
   5  pole               7.34   0.09      11.42    1.20         0.08      0.46
   6  traffic light      0.00   0.00  891000.50    1.50         0.00      0.40
   7  traffic sign       2.23   0.01      43.11    0.73         0.02      0.58
   8  vegetation        71.04  11.26       0.10    0.31         0.91      0.76
   9  terrain           16.46   0.15       3.96    1.11         0.20      0.47
  10  sky               89.74   3.66       0.06    0.06         0.94      0.95
  11  person             8.77   0.15       9.22    1.19         0.10      0.46
  12  rider              0.00   0.00     inf     nan            0.00    nan
  13  car               64.14   6.10       0.16    0.40         0.86      0.71
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00     inf     nan            0.00    nan
  16  train              0.00   0.00     inf     nan            0.00    nan
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle           12.88   0.07       4.27    2.50         0.19      0.29
Mean: 25.18
-----------------------------------------------------------------------------------------------------------
this : [epoch 16], [val loss 0.55740], [acc 0.83362], [acc_cls 0.30191], [mean_iu 0.25183], [fwavacc 0.72220]
best : [epoch 16], [val loss 0.55740], [acc 0.83362], [acc_cls 0.30191], [mean_iu 0.25183], [fwavacc 0.72220]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 17], [iter 1 / 176], [train main loss -6.337128], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 2 / 176], [train main loss -2.927395], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 3 / 176], [train main loss -2.605224], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 4 / 176], [train main loss -2.548289], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 5 / 176], [train main loss -2.282766], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 6 / 176], [train main loss -2.413906], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 7 / 176], [train main loss -2.585407], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 8 / 176], [train main loss -2.620371], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 9 / 176], [train main loss -2.501340], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 10 / 176], [train main loss -2.522757], [lr 0.009029] [batchtime 0]
[epoch 17], [iter 11 / 176], [train main loss -2.738875], [lr 0.009029] [batchtime 0.365]
[epoch 17], [iter 12 / 176], [train main loss -2.466545], [lr 0.009029] [batchtime 0.379]
[epoch 17], [iter 13 / 176], [train main loss -2.513569], [lr 0.009029] [batchtime 0.386]
[epoch 17], [iter 14 / 176], [train main loss -2.463369], [lr 0.009029] [batchtime 0.39]
[epoch 17], [iter 15 / 176], [train main loss -2.502344], [lr 0.009029] [batchtime 0.391]
[epoch 17], [iter 16 / 176], [train main loss -2.401140], [lr 0.009029] [batchtime 0.393]
[epoch 17], [iter 17 / 176], [train main loss -2.470709], [lr 0.009029] [batchtime 0.393]
[epoch 17], [iter 18 / 176], [train main loss -2.333720], [lr 0.009029] [batchtime 0.393]
[epoch 17], [iter 19 / 176], [train main loss -2.251818], [lr 0.009029] [batchtime 0.392]
[epoch 17], [iter 20 / 176], [train main loss -2.298013], [lr 0.009029] [batchtime 0.392]
[epoch 17], [iter 21 / 176], [train main loss -2.149043], [lr 0.009029] [batchtime 0.393]
[epoch 17], [iter 22 / 176], [train main loss -2.107529], [lr 0.009029] [batchtime 0.392]
[epoch 17], [iter 23 / 176], [train main loss -2.213685], [lr 0.009029] [batchtime 0.396]
[epoch 17], [iter 24 / 176], [train main loss -2.073516], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 25 / 176], [train main loss -1.962669], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 26 / 176], [train main loss -1.957055], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 27 / 176], [train main loss -1.898392], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 28 / 176], [train main loss -1.744289], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 29 / 176], [train main loss -1.835574], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 30 / 176], [train main loss -1.852915], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 31 / 176], [train main loss -1.885131], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 32 / 176], [train main loss -1.872626], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 33 / 176], [train main loss -1.862439], [lr 0.009029] [batchtime 0.4]
[epoch 17], [iter 34 / 176], [train main loss -1.854636], [lr 0.009029] [batchtime 0.4]
[epoch 17], [iter 35 / 176], [train main loss -1.868509], [lr 0.009029] [batchtime 0.4]
[epoch 17], [iter 36 / 176], [train main loss -1.842625], [lr 0.009029] [batchtime 0.4]
[epoch 17], [iter 37 / 176], [train main loss -1.810886], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 38 / 176], [train main loss -1.805195], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 39 / 176], [train main loss -1.832035], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 40 / 176], [train main loss -1.779579], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 41 / 176], [train main loss -1.715178], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 42 / 176], [train main loss -1.665778], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 43 / 176], [train main loss -1.621224], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 44 / 176], [train main loss -1.665292], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 45 / 176], [train main loss -1.683519], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 46 / 176], [train main loss -1.662314], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 47 / 176], [train main loss -1.664240], [lr 0.009029] [batchtime 0.399]
[epoch 17], [iter 48 / 176], [train main loss -1.667933], [lr 0.009029] [batchtime 0.402]
[epoch 17], [iter 49 / 176], [train main loss -1.696446], [lr 0.009029] [batchtime 0.439]
[epoch 17], [iter 50 / 176], [train main loss -1.731486], [lr 0.009029] [batchtime 0.437]
[epoch 17], [iter 51 / 176], [train main loss -1.758841], [lr 0.009029] [batchtime 0.436]
[epoch 17], [iter 52 / 176], [train main loss -1.747522], [lr 0.009029] [batchtime 0.435]
[epoch 17], [iter 53 / 176], [train main loss -1.723640], [lr 0.009029] [batchtime 0.434]
[epoch 17], [iter 54 / 176], [train main loss -1.744089], [lr 0.009029] [batchtime 0.433]
[epoch 17], [iter 55 / 176], [train main loss -1.725642], [lr 0.009029] [batchtime 0.432]
[epoch 17], [iter 56 / 176], [train main loss -1.699389], [lr 0.009029] [batchtime 0.432]
[epoch 17], [iter 57 / 176], [train main loss -1.724569], [lr 0.009029] [batchtime 0.431]
[epoch 17], [iter 58 / 176], [train main loss -1.700480], [lr 0.009029] [batchtime 0.43]
[epoch 17], [iter 59 / 176], [train main loss -1.662182], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 60 / 176], [train main loss -1.679837], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 61 / 176], [train main loss -1.644464], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 62 / 176], [train main loss -1.636359], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 63 / 176], [train main loss -1.618535], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 64 / 176], [train main loss -1.602568], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 65 / 176], [train main loss -1.579791], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 66 / 176], [train main loss -1.596263], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 67 / 176], [train main loss -1.626159], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 68 / 176], [train main loss -1.611654], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 69 / 176], [train main loss -1.610524], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 70 / 176], [train main loss -1.613703], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 71 / 176], [train main loss -1.607480], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 72 / 176], [train main loss -1.586622], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 73 / 176], [train main loss -1.574837], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 74 / 176], [train main loss -1.567668], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 75 / 176], [train main loss -1.582060], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 76 / 176], [train main loss -1.552197], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 77 / 176], [train main loss -1.569238], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 78 / 176], [train main loss -1.566289], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 79 / 176], [train main loss -1.571379], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 80 / 176], [train main loss -1.608093], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 81 / 176], [train main loss -1.609019], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 82 / 176], [train main loss -1.615475], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 83 / 176], [train main loss -1.603926], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 84 / 176], [train main loss -1.640556], [lr 0.009029] [batchtime 0.422]
[epoch 17], [iter 85 / 176], [train main loss -1.610479], [lr 0.009029] [batchtime 0.422]
[epoch 17], [iter 86 / 176], [train main loss -1.625921], [lr 0.009029] [batchtime 0.422]
[epoch 17], [iter 87 / 176], [train main loss -1.626783], [lr 0.009029] [batchtime 0.421]
[epoch 17], [iter 88 / 176], [train main loss -1.616326], [lr 0.009029] [batchtime 0.421]
[epoch 17], [iter 89 / 176], [train main loss -1.629830], [lr 0.009029] [batchtime 0.42]
[epoch 17], [iter 90 / 176], [train main loss -1.634563], [lr 0.009029] [batchtime 0.42]
[epoch 17], [iter 91 / 176], [train main loss -1.623067], [lr 0.009029] [batchtime 0.42]
[epoch 17], [iter 92 / 176], [train main loss -1.583163], [lr 0.009029] [batchtime 0.419]
[epoch 17], [iter 93 / 176], [train main loss -1.570909], [lr 0.009029] [batchtime 0.419]
[epoch 17], [iter 94 / 176], [train main loss -1.589489], [lr 0.009029] [batchtime 0.421]
[epoch 17], [iter 95 / 176], [train main loss -1.620966], [lr 0.009029] [batchtime 0.438]
[epoch 17], [iter 96 / 176], [train main loss -1.589698], [lr 0.009029] [batchtime 0.437]
[epoch 17], [iter 97 / 176], [train main loss -1.585449], [lr 0.009029] [batchtime 0.436]
[epoch 17], [iter 98 / 176], [train main loss -1.610755], [lr 0.009029] [batchtime 0.438]
[epoch 17], [iter 99 / 176], [train main loss -1.579386], [lr 0.009029] [batchtime 0.437]
[epoch 17], [iter 100 / 176], [train main loss -1.558915], [lr 0.009029] [batchtime 0.437]
[epoch 17], [iter 101 / 176], [train main loss -1.531588], [lr 0.009029] [batchtime 0.436]
[epoch 17], [iter 102 / 176], [train main loss -1.514673], [lr 0.009029] [batchtime 0.436]
[epoch 17], [iter 103 / 176], [train main loss -1.510042], [lr 0.009029] [batchtime 0.435]
[epoch 17], [iter 104 / 176], [train main loss -1.509088], [lr 0.009029] [batchtime 0.435]
[epoch 17], [iter 105 / 176], [train main loss -1.519726], [lr 0.009029] [batchtime 0.435]
[epoch 17], [iter 106 / 176], [train main loss -1.529167], [lr 0.009029] [batchtime 0.434]
[epoch 17], [iter 107 / 176], [train main loss -1.532689], [lr 0.009029] [batchtime 0.434]
[epoch 17], [iter 108 / 176], [train main loss -1.514539], [lr 0.009029] [batchtime 0.433]
[epoch 17], [iter 109 / 176], [train main loss -1.547723], [lr 0.009029] [batchtime 0.433]
[epoch 17], [iter 110 / 176], [train main loss -1.560151], [lr 0.009029] [batchtime 0.433]
[epoch 17], [iter 111 / 176], [train main loss -1.554747], [lr 0.009029] [batchtime 0.432]
[epoch 17], [iter 112 / 176], [train main loss -1.551294], [lr 0.009029] [batchtime 0.432]
[epoch 17], [iter 113 / 176], [train main loss -1.569783], [lr 0.009029] [batchtime 0.431]
[epoch 17], [iter 114 / 176], [train main loss -1.563503], [lr 0.009029] [batchtime 0.431]
[epoch 17], [iter 115 / 176], [train main loss -1.539756], [lr 0.009029] [batchtime 0.431]
[epoch 17], [iter 116 / 176], [train main loss -1.533356], [lr 0.009029] [batchtime 0.431]
[epoch 17], [iter 117 / 176], [train main loss -1.512165], [lr 0.009029] [batchtime 0.431]
[epoch 17], [iter 118 / 176], [train main loss -1.507501], [lr 0.009029] [batchtime 0.43]
[epoch 17], [iter 119 / 176], [train main loss -1.508237], [lr 0.009029] [batchtime 0.43]
[epoch 17], [iter 120 / 176], [train main loss -1.524189], [lr 0.009029] [batchtime 0.43]
[epoch 17], [iter 121 / 176], [train main loss -1.513004], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 122 / 176], [train main loss -1.502101], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 123 / 176], [train main loss -1.533925], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 124 / 176], [train main loss -1.547218], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 125 / 176], [train main loss -1.523681], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 126 / 176], [train main loss -1.519973], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 127 / 176], [train main loss -1.506609], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 128 / 176], [train main loss -1.501402], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 129 / 176], [train main loss -1.486686], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 130 / 176], [train main loss -1.481588], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 131 / 176], [train main loss -1.488098], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 132 / 176], [train main loss -1.483817], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 133 / 176], [train main loss -1.477637], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 134 / 176], [train main loss -1.474881], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 135 / 176], [train main loss -1.458266], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 136 / 176], [train main loss -1.455621], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 137 / 176], [train main loss -1.452161], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 138 / 176], [train main loss -1.451761], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 139 / 176], [train main loss -1.441151], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 140 / 176], [train main loss -1.433027], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 141 / 176], [train main loss -1.454712], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 142 / 176], [train main loss -1.446410], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 143 / 176], [train main loss -1.447207], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 144 / 176], [train main loss -1.445718], [lr 0.009029] [batchtime 0.429]
[epoch 17], [iter 145 / 176], [train main loss -1.469784], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 146 / 176], [train main loss -1.454044], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 147 / 176], [train main loss -1.441275], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 148 / 176], [train main loss -1.433746], [lr 0.009029] [batchtime 0.428]
[epoch 17], [iter 149 / 176], [train main loss -1.426942], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 150 / 176], [train main loss -1.447211], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 151 / 176], [train main loss -1.462383], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 152 / 176], [train main loss -1.469072], [lr 0.009029] [batchtime 0.427]
[epoch 17], [iter 153 / 176], [train main loss -1.466894], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 154 / 176], [train main loss -1.458020], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 155 / 176], [train main loss -1.467634], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 156 / 176], [train main loss -1.465206], [lr 0.009029] [batchtime 0.426]
[epoch 17], [iter 157 / 176], [train main loss -1.476251], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 158 / 176], [train main loss -1.488818], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 159 / 176], [train main loss -1.480831], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 160 / 176], [train main loss -1.515934], [lr 0.009029] [batchtime 0.425]
[epoch 17], [iter 161 / 176], [train main loss -1.506237], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 162 / 176], [train main loss -1.506746], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 163 / 176], [train main loss -1.518463], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 164 / 176], [train main loss -1.509776], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 165 / 176], [train main loss -1.517638], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 166 / 176], [train main loss -1.514184], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 167 / 176], [train main loss -1.504153], [lr 0.009029] [batchtime 0.424]
[epoch 17], [iter 168 / 176], [train main loss -1.490277], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 169 / 176], [train main loss -1.473350], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 170 / 176], [train main loss -1.499651], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 171 / 176], [train main loss -1.505017], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 172 / 176], [train main loss -1.507843], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 173 / 176], [train main loss -1.520628], [lr 0.009029] [batchtime 0.423]
[epoch 17], [iter 174 / 176], [train main loss -1.520259], [lr 0.009029] [batchtime 0.422]
[epoch 17], [iter 175 / 176], [train main loss -1.521280], [lr 0.009029] [batchtime 0.422]
[epoch 17], [iter 176 / 176], [train main loss -1.524368], [lr 0.009029] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              89.00  35.24       0.03    0.09         0.97      0.92
   1  sidewalk          41.12   3.58       0.84    0.59         0.54      0.63
   2  building          76.33  22.88       0.16    0.15         0.86      0.87
   3  wall               0.25   0.00     394.37    1.98         0.00      0.34
   4  fence              0.00   0.00  293354.97    2.65         0.00      0.27
   5  pole               7.32   0.09      11.85    0.81         0.08      0.55
   6  traffic light      0.00   0.00  222749.38    1.50         0.00      0.40
   7  traffic sign       2.90   0.02      32.50    0.94         0.03      0.52
   8  vegetation        69.73  11.52       0.07    0.36         0.93      0.73
   9  terrain           22.40   0.24       2.12    1.34         0.32      0.43
  10  sky               90.27   3.71       0.05    0.06         0.96      0.94
  11  person             8.24   0.14      10.07    1.06         0.09      0.48
  12  rider              0.00   0.00     inf     inf            0.00      0.00
  13  car               65.30   6.24       0.13    0.40         0.88      0.72
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00     inf     nan            0.00    nan
  16  train              0.00   0.00     inf     nan            0.00    nan
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle           13.04   0.07       4.81    1.85         0.17      0.35
Mean: 25.57
-----------------------------------------------------------------------------------------------------------
this : [epoch 17], [val loss 0.57094], [acc 0.83708], [acc_cls 0.30719], [mean_iu 0.25574], [fwavacc 0.72536]
best : [epoch 17], [val loss 0.57094], [acc 0.83708], [acc_cls 0.30719], [mean_iu 0.25574], [fwavacc 0.72536]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 18], [iter 1 / 176], [train main loss 0.704208], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 2 / 176], [train main loss 0.073265], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 3 / 176], [train main loss -0.765476], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 4 / 176], [train main loss -1.080763], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 5 / 176], [train main loss -1.715688], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 6 / 176], [train main loss -1.423529], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 7 / 176], [train main loss -1.397021], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 8 / 176], [train main loss -1.596004], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 9 / 176], [train main loss -1.438750], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 10 / 176], [train main loss -1.411264], [lr 0.008971] [batchtime 0]
[epoch 18], [iter 11 / 176], [train main loss -1.440801], [lr 0.008971] [batchtime 0.37]
[epoch 18], [iter 12 / 176], [train main loss -1.522021], [lr 0.008971] [batchtime 0.39]
[epoch 18], [iter 13 / 176], [train main loss -1.534585], [lr 0.008971] [batchtime 0.389]
[epoch 18], [iter 14 / 176], [train main loss -1.461642], [lr 0.008971] [batchtime 0.402]
[epoch 18], [iter 15 / 176], [train main loss -1.514005], [lr 0.008971] [batchtime 0.434]
[epoch 18], [iter 16 / 176], [train main loss -1.683281], [lr 0.008971] [batchtime 0.429]
[epoch 18], [iter 17 / 176], [train main loss -1.585210], [lr 0.008971] [batchtime 0.425]
[epoch 18], [iter 18 / 176], [train main loss -1.541851], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 19 / 176], [train main loss -1.465428], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 20 / 176], [train main loss -1.672275], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 21 / 176], [train main loss -1.549390], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 22 / 176], [train main loss -1.639709], [lr 0.008971] [batchtime 0.413]
[epoch 18], [iter 23 / 176], [train main loss -1.653864], [lr 0.008971] [batchtime 0.411]
[epoch 18], [iter 24 / 176], [train main loss -1.582337], [lr 0.008971] [batchtime 0.41]
[epoch 18], [iter 25 / 176], [train main loss -1.542855], [lr 0.008971] [batchtime 0.409]
[epoch 18], [iter 26 / 176], [train main loss -1.484008], [lr 0.008971] [batchtime 0.409]
[epoch 18], [iter 27 / 176], [train main loss -1.414411], [lr 0.008971] [batchtime 0.408]
[epoch 18], [iter 28 / 176], [train main loss -1.400375], [lr 0.008971] [batchtime 0.407]
[epoch 18], [iter 29 / 176], [train main loss -1.376494], [lr 0.008971] [batchtime 0.407]
[epoch 18], [iter 30 / 176], [train main loss -1.437889], [lr 0.008971] [batchtime 0.406]
[epoch 18], [iter 31 / 176], [train main loss -1.487126], [lr 0.008971] [batchtime 0.406]
[epoch 18], [iter 32 / 176], [train main loss -1.478810], [lr 0.008971] [batchtime 0.406]
[epoch 18], [iter 33 / 176], [train main loss -1.480541], [lr 0.008971] [batchtime 0.405]
[epoch 18], [iter 34 / 176], [train main loss -1.473141], [lr 0.008971] [batchtime 0.404]
[epoch 18], [iter 35 / 176], [train main loss -1.456689], [lr 0.008971] [batchtime 0.405]
[epoch 18], [iter 36 / 176], [train main loss -1.488615], [lr 0.008971] [batchtime 0.405]
[epoch 18], [iter 37 / 176], [train main loss -1.470718], [lr 0.008971] [batchtime 0.405]
[epoch 18], [iter 38 / 176], [train main loss -1.526531], [lr 0.008971] [batchtime 0.404]
[epoch 18], [iter 39 / 176], [train main loss -1.523015], [lr 0.008971] [batchtime 0.435]
[epoch 18], [iter 40 / 176], [train main loss -1.462478], [lr 0.008971] [batchtime 0.44]
[epoch 18], [iter 41 / 176], [train main loss -1.442700], [lr 0.008971] [batchtime 0.438]
[epoch 18], [iter 42 / 176], [train main loss -1.418845], [lr 0.008971] [batchtime 0.436]
[epoch 18], [iter 43 / 176], [train main loss -1.432930], [lr 0.008971] [batchtime 0.435]
[epoch 18], [iter 44 / 176], [train main loss -1.423132], [lr 0.008971] [batchtime 0.434]
[epoch 18], [iter 45 / 176], [train main loss -1.404315], [lr 0.008971] [batchtime 0.432]
[epoch 18], [iter 46 / 176], [train main loss -1.407592], [lr 0.008971] [batchtime 0.431]
[epoch 18], [iter 47 / 176], [train main loss -1.474648], [lr 0.008971] [batchtime 0.43]
[epoch 18], [iter 48 / 176], [train main loss -1.484870], [lr 0.008971] [batchtime 0.429]
[epoch 18], [iter 49 / 176], [train main loss -1.533734], [lr 0.008971] [batchtime 0.428]
[epoch 18], [iter 50 / 176], [train main loss -1.598061], [lr 0.008971] [batchtime 0.428]
[epoch 18], [iter 51 / 176], [train main loss -1.598289], [lr 0.008971] [batchtime 0.427]
[epoch 18], [iter 52 / 176], [train main loss -1.633230], [lr 0.008971] [batchtime 0.426]
[epoch 18], [iter 53 / 176], [train main loss -1.615913], [lr 0.008971] [batchtime 0.426]
[epoch 18], [iter 54 / 176], [train main loss -1.635297], [lr 0.008971] [batchtime 0.425]
[epoch 18], [iter 55 / 176], [train main loss -1.653256], [lr 0.008971] [batchtime 0.425]
[epoch 18], [iter 56 / 176], [train main loss -1.624753], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 57 / 176], [train main loss -1.644708], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 58 / 176], [train main loss -1.643006], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 59 / 176], [train main loss -1.608457], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 60 / 176], [train main loss -1.600076], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 61 / 176], [train main loss -1.641708], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 62 / 176], [train main loss -1.651678], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 63 / 176], [train main loss -1.645074], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 64 / 176], [train main loss -1.619871], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 65 / 176], [train main loss -1.648855], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 66 / 176], [train main loss -1.664157], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 67 / 176], [train main loss -1.643434], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 68 / 176], [train main loss -1.621689], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 69 / 176], [train main loss -1.633255], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 70 / 176], [train main loss -1.642731], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 71 / 176], [train main loss -1.607308], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 72 / 176], [train main loss -1.597900], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 73 / 176], [train main loss -1.608763], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 74 / 176], [train main loss -1.567180], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 75 / 176], [train main loss -1.551743], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 76 / 176], [train main loss -1.556828], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 77 / 176], [train main loss -1.537323], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 78 / 176], [train main loss -1.527619], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 79 / 176], [train main loss -1.559737], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 80 / 176], [train main loss -1.581861], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 81 / 176], [train main loss -1.585204], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 82 / 176], [train main loss -1.567116], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 83 / 176], [train main loss -1.580502], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 84 / 176], [train main loss -1.584088], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 85 / 176], [train main loss -1.587718], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 86 / 176], [train main loss -1.598951], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 87 / 176], [train main loss -1.590882], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 88 / 176], [train main loss -1.604266], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 89 / 176], [train main loss -1.618793], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 90 / 176], [train main loss -1.612489], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 91 / 176], [train main loss -1.608474], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 92 / 176], [train main loss -1.610314], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 93 / 176], [train main loss -1.594559], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 94 / 176], [train main loss -1.613573], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 95 / 176], [train main loss -1.621349], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 96 / 176], [train main loss -1.598973], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 97 / 176], [train main loss -1.602864], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 98 / 176], [train main loss -1.633389], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 99 / 176], [train main loss -1.641759], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 100 / 176], [train main loss -1.634672], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 101 / 176], [train main loss -1.652175], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 102 / 176], [train main loss -1.652055], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 103 / 176], [train main loss -1.648804], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 104 / 176], [train main loss -1.641879], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 105 / 176], [train main loss -1.656688], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 106 / 176], [train main loss -1.650145], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 107 / 176], [train main loss -1.661715], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 108 / 176], [train main loss -1.675068], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 109 / 176], [train main loss -1.678875], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 110 / 176], [train main loss -1.689595], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 111 / 176], [train main loss -1.670713], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 112 / 176], [train main loss -1.678204], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 113 / 176], [train main loss -1.688629], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 114 / 176], [train main loss -1.692013], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 115 / 176], [train main loss -1.681712], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 116 / 176], [train main loss -1.687157], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 117 / 176], [train main loss -1.665262], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 118 / 176], [train main loss -1.645766], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 119 / 176], [train main loss -1.632252], [lr 0.008971] [batchtime 0.417]
[epoch 18], [iter 120 / 176], [train main loss -1.646161], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 121 / 176], [train main loss -1.650598], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 122 / 176], [train main loss -1.633223], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 123 / 176], [train main loss -1.656323], [lr 0.008971] [batchtime 0.416]
[epoch 18], [iter 124 / 176], [train main loss -1.644456], [lr 0.008971] [batchtime 0.415]
[epoch 18], [iter 125 / 176], [train main loss -1.661214], [lr 0.008971] [batchtime 0.415]
[epoch 18], [iter 126 / 176], [train main loss -1.662268], [lr 0.008971] [batchtime 0.415]
[epoch 18], [iter 127 / 176], [train main loss -1.631062], [lr 0.008971] [batchtime 0.415]
[epoch 18], [iter 128 / 176], [train main loss -1.629942], [lr 0.008971] [batchtime 0.415]
[epoch 18], [iter 129 / 176], [train main loss -1.646785], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 130 / 176], [train main loss -1.629971], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 131 / 176], [train main loss -1.645540], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 132 / 176], [train main loss -1.637241], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 133 / 176], [train main loss -1.642742], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 134 / 176], [train main loss -1.645472], [lr 0.008971] [batchtime 0.414]
[epoch 18], [iter 135 / 176], [train main loss -1.646851], [lr 0.008971] [batchtime 0.415]
[epoch 18], [iter 136 / 176], [train main loss -1.639061], [lr 0.008971] [batchtime 0.425]
[epoch 18], [iter 137 / 176], [train main loss -1.632098], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 138 / 176], [train main loss -1.645416], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 139 / 176], [train main loss -1.655414], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 140 / 176], [train main loss -1.667530], [lr 0.008971] [batchtime 0.424]
[epoch 18], [iter 141 / 176], [train main loss -1.681888], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 142 / 176], [train main loss -1.663547], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 143 / 176], [train main loss -1.678040], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 144 / 176], [train main loss -1.685189], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 145 / 176], [train main loss -1.687523], [lr 0.008971] [batchtime 0.423]
[epoch 18], [iter 146 / 176], [train main loss -1.670150], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 147 / 176], [train main loss -1.640674], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 148 / 176], [train main loss -1.641913], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 149 / 176], [train main loss -1.629047], [lr 0.008971] [batchtime 0.422]
[epoch 18], [iter 150 / 176], [train main loss -1.624391], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 151 / 176], [train main loss -1.623483], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 152 / 176], [train main loss -1.622988], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 153 / 176], [train main loss -1.622426], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 154 / 176], [train main loss -1.636195], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 155 / 176], [train main loss -1.643135], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 156 / 176], [train main loss -1.651918], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 157 / 176], [train main loss -1.647620], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 158 / 176], [train main loss -1.648482], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 159 / 176], [train main loss -1.652420], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 160 / 176], [train main loss -1.647513], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 161 / 176], [train main loss -1.657747], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 162 / 176], [train main loss -1.658057], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 163 / 176], [train main loss -1.665429], [lr 0.008971] [batchtime 0.421]
[epoch 18], [iter 164 / 176], [train main loss -1.659381], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 165 / 176], [train main loss -1.658211], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 166 / 176], [train main loss -1.666120], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 167 / 176], [train main loss -1.646741], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 168 / 176], [train main loss -1.624388], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 169 / 176], [train main loss -1.627710], [lr 0.008971] [batchtime 0.42]
[epoch 18], [iter 170 / 176], [train main loss -1.613059], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 171 / 176], [train main loss -1.611329], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 172 / 176], [train main loss -1.616650], [lr 0.008971] [batchtime 0.419]
[epoch 18], [iter 173 / 176], [train main loss -1.618426], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 174 / 176], [train main loss -1.626714], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 175 / 176], [train main loss -1.639212], [lr 0.008971] [batchtime 0.418]
[epoch 18], [iter 176 / 176], [train main loss -1.632585], [lr 0.008971] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              87.47  33.83       0.07    0.07         0.93      0.94
   1  sidewalk          42.09   4.03       0.64    0.74         0.61      0.57
   2  building          74.30  22.22       0.20    0.15         0.84      0.87
   3  wall               1.16   0.01      80.71    4.16         0.01      0.19
   4  fence              0.02   0.00    5836.36    2.71         0.00      0.27
   5  pole              10.23   0.13       8.01    0.77         0.11      0.57
   6  traffic light      0.00   0.00  891000.50    0.00         0.00      1.00
   7  traffic sign       2.85   0.02      33.28    0.79         0.03      0.56
   8  vegetation        66.88  11.32       0.09    0.40         0.92      0.71
   9  terrain           20.51   0.20       2.67    1.20         0.27      0.45
  10  sky               89.26   3.74       0.04    0.09         0.97      0.92
  11  person             8.37   0.14       9.81    1.14         0.09      0.47
  12  rider              0.00   0.00     inf     inf            0.00      0.00
  13  car               59.96   6.50       0.09    0.58         0.92      0.63
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00     inf     nan            0.00    nan
  16  train              0.00   0.00     inf     nan            0.00    nan
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle            6.78   0.03      12.49    1.26         0.07      0.44
Mean: 24.73
-----------------------------------------------------------------------------------------------------------
this : [epoch 18], [val loss 0.58792], [acc 0.82156], [acc_cls 0.30367], [mean_iu 0.24731], [fwavacc 0.70739]
best : [epoch 17], [val loss 0.57094], [acc 0.83708], [acc_cls 0.30719], [mean_iu 0.25574], [fwavacc 0.72536]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 19], [iter 1 / 176], [train main loss -2.100658], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 2 / 176], [train main loss -2.431240], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 3 / 176], [train main loss -1.397618], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 4 / 176], [train main loss -1.037139], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 5 / 176], [train main loss -0.907722], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 6 / 176], [train main loss -1.021913], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 7 / 176], [train main loss -1.017488], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 8 / 176], [train main loss -0.819171], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 9 / 176], [train main loss -1.018195], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 10 / 176], [train main loss -1.259445], [lr 0.008914] [batchtime 0]
[epoch 19], [iter 11 / 176], [train main loss -1.012195], [lr 0.008914] [batchtime 0.363]
[epoch 19], [iter 12 / 176], [train main loss -1.054950], [lr 0.008914] [batchtime 0.384]
[epoch 19], [iter 13 / 176], [train main loss -1.222941], [lr 0.008914] [batchtime 0.393]
[epoch 19], [iter 14 / 176], [train main loss -1.116732], [lr 0.008914] [batchtime 0.394]
[epoch 19], [iter 15 / 176], [train main loss -1.195926], [lr 0.008914] [batchtime 0.394]
[epoch 19], [iter 16 / 176], [train main loss -1.209616], [lr 0.008914] [batchtime 0.394]
[epoch 19], [iter 17 / 176], [train main loss -1.212032], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 18 / 176], [train main loss -1.226286], [lr 0.008914] [batchtime 0.396]
[epoch 19], [iter 19 / 176], [train main loss -1.367669], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 20 / 176], [train main loss -1.330355], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 21 / 176], [train main loss -1.309659], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 22 / 176], [train main loss -1.391252], [lr 0.008914] [batchtime 0.396]
[epoch 19], [iter 23 / 176], [train main loss -1.417803], [lr 0.008914] [batchtime 0.396]
[epoch 19], [iter 24 / 176], [train main loss -1.336977], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 25 / 176], [train main loss -1.340318], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 26 / 176], [train main loss -1.420197], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 27 / 176], [train main loss -1.421689], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 28 / 176], [train main loss -1.384380], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 29 / 176], [train main loss -1.324199], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 30 / 176], [train main loss -1.402211], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 31 / 176], [train main loss -1.407265], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 32 / 176], [train main loss -1.460311], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 33 / 176], [train main loss -1.384213], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 34 / 176], [train main loss -1.291095], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 35 / 176], [train main loss -1.270494], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 36 / 176], [train main loss -1.352897], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 37 / 176], [train main loss -1.344318], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 38 / 176], [train main loss -1.307104], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 39 / 176], [train main loss -1.371091], [lr 0.008914] [batchtime 0.395]
[epoch 19], [iter 40 / 176], [train main loss -1.418409], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 41 / 176], [train main loss -1.464042], [lr 0.008914] [batchtime 0.424]
[epoch 19], [iter 42 / 176], [train main loss -1.506960], [lr 0.008914] [batchtime 0.422]
[epoch 19], [iter 43 / 176], [train main loss -1.484134], [lr 0.008914] [batchtime 0.421]
[epoch 19], [iter 44 / 176], [train main loss -1.453964], [lr 0.008914] [batchtime 0.42]
[epoch 19], [iter 45 / 176], [train main loss -1.480708], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 46 / 176], [train main loss -1.484852], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 47 / 176], [train main loss -1.506171], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 48 / 176], [train main loss -1.461771], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 49 / 176], [train main loss -1.464617], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 50 / 176], [train main loss -1.440913], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 51 / 176], [train main loss -1.476809], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 52 / 176], [train main loss -1.446075], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 53 / 176], [train main loss -1.447622], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 54 / 176], [train main loss -1.483264], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 55 / 176], [train main loss -1.477949], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 56 / 176], [train main loss -1.518674], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 57 / 176], [train main loss -1.546392], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 58 / 176], [train main loss -1.491880], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 59 / 176], [train main loss -1.485778], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 60 / 176], [train main loss -1.439198], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 61 / 176], [train main loss -1.450650], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 62 / 176], [train main loss -1.428929], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 63 / 176], [train main loss -1.476782], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 64 / 176], [train main loss -1.515896], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 65 / 176], [train main loss -1.511948], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 66 / 176], [train main loss -1.512716], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 67 / 176], [train main loss -1.477633], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 68 / 176], [train main loss -1.499116], [lr 0.008914] [batchtime 0.41]
[epoch 19], [iter 69 / 176], [train main loss -1.464278], [lr 0.008914] [batchtime 0.41]
[epoch 19], [iter 70 / 176], [train main loss -1.454265], [lr 0.008914] [batchtime 0.41]
[epoch 19], [iter 71 / 176], [train main loss -1.472168], [lr 0.008914] [batchtime 0.41]
[epoch 19], [iter 72 / 176], [train main loss -1.505145], [lr 0.008914] [batchtime 0.41]
[epoch 19], [iter 73 / 176], [train main loss -1.493474], [lr 0.008914] [batchtime 0.41]
[epoch 19], [iter 74 / 176], [train main loss -1.485705], [lr 0.008914] [batchtime 0.409]
[epoch 19], [iter 75 / 176], [train main loss -1.482809], [lr 0.008914] [batchtime 0.409]
[epoch 19], [iter 76 / 176], [train main loss -1.455828], [lr 0.008914] [batchtime 0.409]
[epoch 19], [iter 77 / 176], [train main loss -1.458282], [lr 0.008914] [batchtime 0.408]
[epoch 19], [iter 78 / 176], [train main loss -1.446392], [lr 0.008914] [batchtime 0.408]
[epoch 19], [iter 79 / 176], [train main loss -1.411626], [lr 0.008914] [batchtime 0.408]
[epoch 19], [iter 80 / 176], [train main loss -1.396116], [lr 0.008914] [batchtime 0.408]
[epoch 19], [iter 81 / 176], [train main loss -1.408387], [lr 0.008914] [batchtime 0.408]
[epoch 19], [iter 82 / 176], [train main loss -1.371597], [lr 0.008914] [batchtime 0.407]
[epoch 19], [iter 83 / 176], [train main loss -1.376000], [lr 0.008914] [batchtime 0.407]
[epoch 19], [iter 84 / 176], [train main loss -1.356253], [lr 0.008914] [batchtime 0.407]
[epoch 19], [iter 85 / 176], [train main loss -1.358881], [lr 0.008914] [batchtime 0.407]
[epoch 19], [iter 86 / 176], [train main loss -1.387400], [lr 0.008914] [batchtime 0.406]
[epoch 19], [iter 87 / 176], [train main loss -1.352933], [lr 0.008914] [batchtime 0.406]
[epoch 19], [iter 88 / 176], [train main loss -1.342429], [lr 0.008914] [batchtime 0.408]
[epoch 19], [iter 89 / 176], [train main loss -1.319982], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 90 / 176], [train main loss -1.311326], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 91 / 176], [train main loss -1.278517], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 92 / 176], [train main loss -1.284317], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 93 / 176], [train main loss -1.319454], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 94 / 176], [train main loss -1.310159], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 95 / 176], [train main loss -1.293159], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 96 / 176], [train main loss -1.271986], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 97 / 176], [train main loss -1.286587], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 98 / 176], [train main loss -1.301997], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 99 / 176], [train main loss -1.310796], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 100 / 176], [train main loss -1.303016], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 101 / 176], [train main loss -1.313508], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 102 / 176], [train main loss -1.289661], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 103 / 176], [train main loss -1.282216], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 104 / 176], [train main loss -1.262980], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 105 / 176], [train main loss -1.254329], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 106 / 176], [train main loss -1.246168], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 107 / 176], [train main loss -1.247449], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 108 / 176], [train main loss -1.244558], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 109 / 176], [train main loss -1.273331], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 110 / 176], [train main loss -1.293966], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 111 / 176], [train main loss -1.288459], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 112 / 176], [train main loss -1.293234], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 113 / 176], [train main loss -1.305653], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 114 / 176], [train main loss -1.330418], [lr 0.008914] [batchtime 0.415]
[epoch 19], [iter 115 / 176], [train main loss -1.328235], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 116 / 176], [train main loss -1.310059], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 117 / 176], [train main loss -1.289709], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 118 / 176], [train main loss -1.310533], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 119 / 176], [train main loss -1.302718], [lr 0.008914] [batchtime 0.414]
[epoch 19], [iter 120 / 176], [train main loss -1.310518], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 121 / 176], [train main loss -1.279443], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 122 / 176], [train main loss -1.264728], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 123 / 176], [train main loss -1.250954], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 124 / 176], [train main loss -1.263044], [lr 0.008914] [batchtime 0.413]
[epoch 19], [iter 125 / 176], [train main loss -1.265414], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 126 / 176], [train main loss -1.262179], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 127 / 176], [train main loss -1.281517], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 128 / 176], [train main loss -1.291674], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 129 / 176], [train main loss -1.294477], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 130 / 176], [train main loss -1.290860], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 131 / 176], [train main loss -1.293419], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 132 / 176], [train main loss -1.292513], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 133 / 176], [train main loss -1.285443], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 134 / 176], [train main loss -1.286458], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 135 / 176], [train main loss -1.281714], [lr 0.008914] [batchtime 0.411]
[epoch 19], [iter 136 / 176], [train main loss -1.288568], [lr 0.008914] [batchtime 0.412]
[epoch 19], [iter 137 / 176], [train main loss -1.288796], [lr 0.008914] [batchtime 0.423]
[epoch 19], [iter 138 / 176], [train main loss -1.305579], [lr 0.008914] [batchtime 0.423]
[epoch 19], [iter 139 / 176], [train main loss -1.311136], [lr 0.008914] [batchtime 0.423]
[epoch 19], [iter 140 / 176], [train main loss -1.327910], [lr 0.008914] [batchtime 0.423]
[epoch 19], [iter 141 / 176], [train main loss -1.312761], [lr 0.008914] [batchtime 0.422]
[epoch 19], [iter 142 / 176], [train main loss -1.316546], [lr 0.008914] [batchtime 0.422]
[epoch 19], [iter 143 / 176], [train main loss -1.301628], [lr 0.008914] [batchtime 0.422]
[epoch 19], [iter 144 / 176], [train main loss -1.307291], [lr 0.008914] [batchtime 0.422]
[epoch 19], [iter 145 / 176], [train main loss -1.320840], [lr 0.008914] [batchtime 0.421]
[epoch 19], [iter 146 / 176], [train main loss -1.332363], [lr 0.008914] [batchtime 0.421]
[epoch 19], [iter 147 / 176], [train main loss -1.328473], [lr 0.008914] [batchtime 0.421]
[epoch 19], [iter 148 / 176], [train main loss -1.334565], [lr 0.008914] [batchtime 0.421]
[epoch 19], [iter 149 / 176], [train main loss -1.313592], [lr 0.008914] [batchtime 0.421]
[epoch 19], [iter 150 / 176], [train main loss -1.319220], [lr 0.008914] [batchtime 0.42]
[epoch 19], [iter 151 / 176], [train main loss -1.317659], [lr 0.008914] [batchtime 0.42]
[epoch 19], [iter 152 / 176], [train main loss -1.328581], [lr 0.008914] [batchtime 0.42]
[epoch 19], [iter 153 / 176], [train main loss -1.348693], [lr 0.008914] [batchtime 0.42]
[epoch 19], [iter 154 / 176], [train main loss -1.355961], [lr 0.008914] [batchtime 0.42]
[epoch 19], [iter 155 / 176], [train main loss -1.356243], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 156 / 176], [train main loss -1.341831], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 157 / 176], [train main loss -1.333012], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 158 / 176], [train main loss -1.323667], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 159 / 176], [train main loss -1.318046], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 160 / 176], [train main loss -1.307926], [lr 0.008914] [batchtime 0.419]
[epoch 19], [iter 161 / 176], [train main loss -1.312181], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 162 / 176], [train main loss -1.314364], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 163 / 176], [train main loss -1.299351], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 164 / 176], [train main loss -1.295142], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 165 / 176], [train main loss -1.274545], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 166 / 176], [train main loss -1.295426], [lr 0.008914] [batchtime 0.418]
[epoch 19], [iter 167 / 176], [train main loss -1.287668], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 168 / 176], [train main loss -1.286230], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 169 / 176], [train main loss -1.274066], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 170 / 176], [train main loss -1.272851], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 171 / 176], [train main loss -1.299232], [lr 0.008914] [batchtime 0.417]
[epoch 19], [iter 172 / 176], [train main loss -1.323574], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 173 / 176], [train main loss -1.331381], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 174 / 176], [train main loss -1.342929], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 175 / 176], [train main loss -1.359057], [lr 0.008914] [batchtime 0.416]
[epoch 19], [iter 176 / 176], [train main loss -1.359577], [lr 0.008914] [batchtime 0.415]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              89.02  34.52       0.05    0.07         0.95      0.93
   1  sidewalk          45.93   4.03       0.64    0.54         0.61      0.65
   2  building          76.19  22.93       0.16    0.15         0.86      0.87
   3  wall               0.70   0.00     140.68    0.96         0.01      0.51
   4  fence              0.00   0.00  143856.27    0.36         0.00      0.74
   5  pole              11.06   0.13       7.45    0.59         0.12      0.63
   6  traffic light      0.00   0.00  445499.75    1.25         0.00      0.44
   7  traffic sign       3.83   0.02      23.82    1.27         0.04      0.44
   8  vegetation        69.97  11.58       0.07    0.36         0.94      0.73
   9  terrain           22.85   0.24       2.05    1.33         0.33      0.43
  10  sky               90.91   3.72       0.04    0.06         0.96      0.94
  11  person             9.29   0.16       8.75    1.01         0.10      0.50
  12  rider              0.00   0.00     inf     inf            0.00      0.00
  13  car               63.63   6.42       0.10    0.47         0.91      0.68
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00     inf     nan            0.00    nan
  16  train              0.00   0.00     inf     nan            0.00    nan
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle           11.52   0.05       6.22    1.46         0.14      0.41
Mean: 26.05
-----------------------------------------------------------------------------------------------------------
this : [epoch 19], [val loss 0.53354], [acc 0.83805], [acc_cls 0.31383], [mean_iu 0.26048], [fwavacc 0.72824]
best : [epoch 19], [val loss 0.53354], [acc 0.83805], [acc_cls 0.31383], [mean_iu 0.26048], [fwavacc 0.72824]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 20], [iter 1 / 176], [train main loss 0.849186], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 2 / 176], [train main loss 1.125144], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 3 / 176], [train main loss 0.073308], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 4 / 176], [train main loss -0.226123], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 5 / 176], [train main loss -0.737464], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 6 / 176], [train main loss -0.724251], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 7 / 176], [train main loss -0.901687], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 8 / 176], [train main loss -1.113146], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 9 / 176], [train main loss -1.447453], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 10 / 176], [train main loss -1.513877], [lr 0.008857] [batchtime 0]
[epoch 20], [iter 11 / 176], [train main loss -1.548992], [lr 0.008857] [batchtime 0.369]
[epoch 20], [iter 12 / 176], [train main loss -1.535427], [lr 0.008857] [batchtime 0.383]
[epoch 20], [iter 13 / 176], [train main loss -1.673986], [lr 0.008857] [batchtime 0.386]
[epoch 20], [iter 14 / 176], [train main loss -1.642452], [lr 0.008857] [batchtime 0.39]
[epoch 20], [iter 15 / 176], [train main loss -1.781182], [lr 0.008857] [batchtime 0.391]
[epoch 20], [iter 16 / 176], [train main loss -1.814534], [lr 0.008857] [batchtime 0.392]
[epoch 20], [iter 17 / 176], [train main loss -1.752929], [lr 0.008857] [batchtime 0.393]
[epoch 20], [iter 18 / 176], [train main loss -1.799636], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 19 / 176], [train main loss -1.788409], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 20 / 176], [train main loss -1.812626], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 21 / 176], [train main loss -1.839649], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 22 / 176], [train main loss -1.823716], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 23 / 176], [train main loss -1.753440], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 24 / 176], [train main loss -1.609562], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 25 / 176], [train main loss -1.585532], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 26 / 176], [train main loss -1.526605], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 27 / 176], [train main loss -1.497840], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 28 / 176], [train main loss -1.361659], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 29 / 176], [train main loss -1.406572], [lr 0.008857] [batchtime 0.394]
[epoch 20], [iter 30 / 176], [train main loss -1.336354], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 31 / 176], [train main loss -1.285274], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 32 / 176], [train main loss -1.385141], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 33 / 176], [train main loss -1.360017], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 34 / 176], [train main loss -1.374382], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 35 / 176], [train main loss -1.386215], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 36 / 176], [train main loss -1.428818], [lr 0.008857] [batchtime 0.395]
[epoch 20], [iter 37 / 176], [train main loss -1.407506], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 38 / 176], [train main loss -1.489781], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 39 / 176], [train main loss -1.481473], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 40 / 176], [train main loss -1.502415], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 41 / 176], [train main loss -1.520876], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 42 / 176], [train main loss -1.489937], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 43 / 176], [train main loss -1.479500], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 44 / 176], [train main loss -1.492602], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 45 / 176], [train main loss -1.475109], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 46 / 176], [train main loss -1.592351], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 47 / 176], [train main loss -1.629506], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 48 / 176], [train main loss -1.620501], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 49 / 176], [train main loss -1.593166], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 50 / 176], [train main loss -1.568775], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 51 / 176], [train main loss -1.566465], [lr 0.008857] [batchtime 0.418]
[epoch 20], [iter 52 / 176], [train main loss -1.534278], [lr 0.008857] [batchtime 0.418]
[epoch 20], [iter 53 / 176], [train main loss -1.545204], [lr 0.008857] [batchtime 0.417]
[epoch 20], [iter 54 / 176], [train main loss -1.528377], [lr 0.008857] [batchtime 0.417]
[epoch 20], [iter 55 / 176], [train main loss -1.557576], [lr 0.008857] [batchtime 0.416]
[epoch 20], [iter 56 / 176], [train main loss -1.537612], [lr 0.008857] [batchtime 0.416]
[epoch 20], [iter 57 / 176], [train main loss -1.511618], [lr 0.008857] [batchtime 0.415]
[epoch 20], [iter 58 / 176], [train main loss -1.503063], [lr 0.008857] [batchtime 0.415]
[epoch 20], [iter 59 / 176], [train main loss -1.446817], [lr 0.008857] [batchtime 0.414]
[epoch 20], [iter 60 / 176], [train main loss -1.453087], [lr 0.008857] [batchtime 0.415]
[epoch 20], [iter 61 / 176], [train main loss -1.473731], [lr 0.008857] [batchtime 0.415]
[epoch 20], [iter 62 / 176], [train main loss -1.470006], [lr 0.008857] [batchtime 0.414]
[epoch 20], [iter 63 / 176], [train main loss -1.498036], [lr 0.008857] [batchtime 0.414]
[epoch 20], [iter 64 / 176], [train main loss -1.497913], [lr 0.008857] [batchtime 0.413]
[epoch 20], [iter 65 / 176], [train main loss -1.460311], [lr 0.008857] [batchtime 0.413]
[epoch 20], [iter 66 / 176], [train main loss -1.440819], [lr 0.008857] [batchtime 0.413]
[epoch 20], [iter 67 / 176], [train main loss -1.437783], [lr 0.008857] [batchtime 0.412]
[epoch 20], [iter 68 / 176], [train main loss -1.399219], [lr 0.008857] [batchtime 0.412]
[epoch 20], [iter 69 / 176], [train main loss -1.416868], [lr 0.008857] [batchtime 0.411]
[epoch 20], [iter 70 / 176], [train main loss -1.436807], [lr 0.008857] [batchtime 0.411]
[epoch 20], [iter 71 / 176], [train main loss -1.422851], [lr 0.008857] [batchtime 0.411]
[epoch 20], [iter 72 / 176], [train main loss -1.392096], [lr 0.008857] [batchtime 0.411]
[epoch 20], [iter 73 / 176], [train main loss -1.371911], [lr 0.008857] [batchtime 0.411]
[epoch 20], [iter 74 / 176], [train main loss -1.352632], [lr 0.008857] [batchtime 0.411]
[epoch 20], [iter 75 / 176], [train main loss -1.349399], [lr 0.008857] [batchtime 0.41]
[epoch 20], [iter 76 / 176], [train main loss -1.334840], [lr 0.008857] [batchtime 0.41]
[epoch 20], [iter 77 / 176], [train main loss -1.312736], [lr 0.008857] [batchtime 0.41]
[epoch 20], [iter 78 / 176], [train main loss -1.353090], [lr 0.008857] [batchtime 0.41]
[epoch 20], [iter 79 / 176], [train main loss -1.348529], [lr 0.008857] [batchtime 0.409]
[epoch 20], [iter 80 / 176], [train main loss -1.357581], [lr 0.008857] [batchtime 0.409]
[epoch 20], [iter 81 / 176], [train main loss -1.358091], [lr 0.008857] [batchtime 0.409]
[epoch 20], [iter 82 / 176], [train main loss -1.391457], [lr 0.008857] [batchtime 0.409]
[epoch 20], [iter 83 / 176], [train main loss -1.387894], [lr 0.008857] [batchtime 0.408]
[epoch 20], [iter 84 / 176], [train main loss -1.415091], [lr 0.008857] [batchtime 0.408]
[epoch 20], [iter 85 / 176], [train main loss -1.398328], [lr 0.008857] [batchtime 0.41]
[epoch 20], [iter 86 / 176], [train main loss -1.408740], [lr 0.008857] [batchtime 0.428]
[epoch 20], [iter 87 / 176], [train main loss -1.418949], [lr 0.008857] [batchtime 0.431]
[epoch 20], [iter 88 / 176], [train main loss -1.446868], [lr 0.008857] [batchtime 0.43]
[epoch 20], [iter 89 / 176], [train main loss -1.477931], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 90 / 176], [train main loss -1.489419], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 91 / 176], [train main loss -1.522888], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 92 / 176], [train main loss -1.533074], [lr 0.008857] [batchtime 0.428]
[epoch 20], [iter 93 / 176], [train main loss -1.572449], [lr 0.008857] [batchtime 0.428]
[epoch 20], [iter 94 / 176], [train main loss -1.586541], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 95 / 176], [train main loss -1.584684], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 96 / 176], [train main loss -1.591071], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 97 / 176], [train main loss -1.548347], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 98 / 176], [train main loss -1.555509], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 99 / 176], [train main loss -1.553765], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 100 / 176], [train main loss -1.552525], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 101 / 176], [train main loss -1.550380], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 102 / 176], [train main loss -1.558438], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 103 / 176], [train main loss -1.552989], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 104 / 176], [train main loss -1.582978], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 105 / 176], [train main loss -1.580332], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 106 / 176], [train main loss -1.573782], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 107 / 176], [train main loss -1.569732], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 108 / 176], [train main loss -1.546344], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 109 / 176], [train main loss -1.531883], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 110 / 176], [train main loss -1.520636], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 111 / 176], [train main loss -1.515491], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 112 / 176], [train main loss -1.493267], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 113 / 176], [train main loss -1.473953], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 114 / 176], [train main loss -1.464463], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 115 / 176], [train main loss -1.460918], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 116 / 176], [train main loss -1.480454], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 117 / 176], [train main loss -1.484544], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 118 / 176], [train main loss -1.501492], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 119 / 176], [train main loss -1.494007], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 120 / 176], [train main loss -1.502745], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 121 / 176], [train main loss -1.515980], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 122 / 176], [train main loss -1.507866], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 123 / 176], [train main loss -1.527512], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 124 / 176], [train main loss -1.518059], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 125 / 176], [train main loss -1.530423], [lr 0.008857] [batchtime 0.418]
[epoch 20], [iter 126 / 176], [train main loss -1.526543], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 127 / 176], [train main loss -1.530302], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 128 / 176], [train main loss -1.539633], [lr 0.008857] [batchtime 0.418]
[epoch 20], [iter 129 / 176], [train main loss -1.531185], [lr 0.008857] [batchtime 0.418]
[epoch 20], [iter 130 / 176], [train main loss -1.539579], [lr 0.008857] [batchtime 0.418]
[epoch 20], [iter 131 / 176], [train main loss -1.535942], [lr 0.008857] [batchtime 0.419]
[epoch 20], [iter 132 / 176], [train main loss -1.540584], [lr 0.008857] [batchtime 0.43]
[epoch 20], [iter 133 / 176], [train main loss -1.546204], [lr 0.008857] [batchtime 0.43]
[epoch 20], [iter 134 / 176], [train main loss -1.541106], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 135 / 176], [train main loss -1.541441], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 136 / 176], [train main loss -1.548396], [lr 0.008857] [batchtime 0.429]
[epoch 20], [iter 137 / 176], [train main loss -1.538491], [lr 0.008857] [batchtime 0.428]
[epoch 20], [iter 138 / 176], [train main loss -1.516987], [lr 0.008857] [batchtime 0.428]
[epoch 20], [iter 139 / 176], [train main loss -1.525357], [lr 0.008857] [batchtime 0.428]
[epoch 20], [iter 140 / 176], [train main loss -1.518509], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 141 / 176], [train main loss -1.514229], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 142 / 176], [train main loss -1.516291], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 143 / 176], [train main loss -1.510407], [lr 0.008857] [batchtime 0.427]
[epoch 20], [iter 144 / 176], [train main loss -1.507275], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 145 / 176], [train main loss -1.497239], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 146 / 176], [train main loss -1.482219], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 147 / 176], [train main loss -1.477828], [lr 0.008857] [batchtime 0.426]
[epoch 20], [iter 148 / 176], [train main loss -1.492056], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 149 / 176], [train main loss -1.511403], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 150 / 176], [train main loss -1.506453], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 151 / 176], [train main loss -1.518659], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 152 / 176], [train main loss -1.522199], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 153 / 176], [train main loss -1.527749], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 154 / 176], [train main loss -1.527806], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 155 / 176], [train main loss -1.555977], [lr 0.008857] [batchtime 0.425]
[epoch 20], [iter 156 / 176], [train main loss -1.548268], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 157 / 176], [train main loss -1.552412], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 158 / 176], [train main loss -1.546551], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 159 / 176], [train main loss -1.547812], [lr 0.008857] [batchtime 0.424]
[epoch 20], [iter 160 / 176], [train main loss -1.538999], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 161 / 176], [train main loss -1.541501], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 162 / 176], [train main loss -1.551758], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 163 / 176], [train main loss -1.563695], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 164 / 176], [train main loss -1.570774], [lr 0.008857] [batchtime 0.423]
[epoch 20], [iter 165 / 176], [train main loss -1.576198], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 166 / 176], [train main loss -1.567867], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 167 / 176], [train main loss -1.568970], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 168 / 176], [train main loss -1.572145], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 169 / 176], [train main loss -1.574220], [lr 0.008857] [batchtime 0.422]
[epoch 20], [iter 170 / 176], [train main loss -1.567843], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 171 / 176], [train main loss -1.570671], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 172 / 176], [train main loss -1.553554], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 173 / 176], [train main loss -1.558810], [lr 0.008857] [batchtime 0.421]
[epoch 20], [iter 174 / 176], [train main loss -1.555170], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 175 / 176], [train main loss -1.572705], [lr 0.008857] [batchtime 0.42]
[epoch 20], [iter 176 / 176], [train main loss -1.562595], [lr 0.008857] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              89.40  35.22      0.03    0.09         0.97      0.92
   1  sidewalk          42.33   3.63      0.82    0.55         0.55      0.65
   2  building          78.20  23.64      0.12    0.15         0.89      0.87
   3  wall               0.34   0.00    291.43    2.12         0.00      0.32
   4  fence              0.06   0.00   1658.40    1.78         0.00      0.36
   5  pole              13.95   0.18      5.30    0.87         0.16      0.54
   6  traffic light      0.00   0.00  74249.12    1.50         0.00      0.40
   7  traffic sign       4.11   0.02     22.16    1.14         0.04      0.47
   8  vegetation        73.52  11.30      0.09    0.27         0.91      0.79
   9  terrain           21.19   0.25      1.91    1.81         0.34      0.36
  10  sky               90.75   3.70      0.05    0.05         0.96      0.95
  11  person            15.78   0.29      4.23    1.11         0.19      0.48
  12  rider              0.00   0.00    inf     inf            0.00      0.00
  13  car               66.38   6.29      0.13    0.38         0.89      0.72
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.00   0.00    inf     nan            0.00    nan
  16  train              0.00   0.00    inf     nan            0.00    nan
  17  motorcycle         0.00   0.00    inf     nan            0.00    nan
  18  bicycle           16.16   0.09      3.46    1.73         0.22      0.37
Mean: 26.96
-----------------------------------------------------------------------------------------------------------
this : [epoch 20], [val loss 0.52704], [acc 0.84611], [acc_cls 0.32268], [mean_iu 0.26956], [fwavacc 0.74027]
best : [epoch 20], [val loss 0.52704], [acc 0.84611], [acc_cls 0.32268], [mean_iu 0.26956], [fwavacc 0.74027]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 21], [iter 1 / 176], [train main loss 1.158210], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 2 / 176], [train main loss -1.020708], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 3 / 176], [train main loss -1.448102], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 4 / 176], [train main loss -1.573885], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 5 / 176], [train main loss -1.834979], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 6 / 176], [train main loss -1.695952], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 7 / 176], [train main loss -1.429655], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 8 / 176], [train main loss -1.361794], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 9 / 176], [train main loss -1.191207], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 10 / 176], [train main loss -1.323441], [lr 0.008800] [batchtime 0]
[epoch 21], [iter 11 / 176], [train main loss -1.263153], [lr 0.008800] [batchtime 0.367]
[epoch 21], [iter 12 / 176], [train main loss -1.370486], [lr 0.008800] [batchtime 0.392]
[epoch 21], [iter 13 / 176], [train main loss -1.476318], [lr 0.008800] [batchtime 0.392]
[epoch 21], [iter 14 / 176], [train main loss -1.432428], [lr 0.008800] [batchtime 0.392]
[epoch 21], [iter 15 / 176], [train main loss -1.414829], [lr 0.008800] [batchtime 0.393]
[epoch 21], [iter 16 / 176], [train main loss -1.440883], [lr 0.008800] [batchtime 0.395]
[epoch 21], [iter 17 / 176], [train main loss -1.361938], [lr 0.008800] [batchtime 0.396]
[epoch 21], [iter 18 / 176], [train main loss -1.268644], [lr 0.008800] [batchtime 0.397]
[epoch 21], [iter 19 / 176], [train main loss -1.377157], [lr 0.008800] [batchtime 0.397]
[epoch 21], [iter 20 / 176], [train main loss -1.394899], [lr 0.008800] [batchtime 0.398]
[epoch 21], [iter 21 / 176], [train main loss -1.430732], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 22 / 176], [train main loss -1.448516], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 23 / 176], [train main loss -1.345841], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 24 / 176], [train main loss -1.327128], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 25 / 176], [train main loss -1.362882], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 26 / 176], [train main loss -1.406658], [lr 0.008800] [batchtime 0.398]
[epoch 21], [iter 27 / 176], [train main loss -1.341573], [lr 0.008800] [batchtime 0.398]
[epoch 21], [iter 28 / 176], [train main loss -1.300407], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 29 / 176], [train main loss -1.348292], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 30 / 176], [train main loss -1.397090], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 31 / 176], [train main loss -1.319606], [lr 0.008800] [batchtime 0.399]
[epoch 21], [iter 32 / 176], [train main loss -1.258060], [lr 0.008800] [batchtime 0.409]
[epoch 21], [iter 33 / 176], [train main loss -1.205058], [lr 0.008800] [batchtime 0.457]
[epoch 21], [iter 34 / 176], [train main loss -1.202376], [lr 0.008800] [batchtime 0.453]
[epoch 21], [iter 35 / 176], [train main loss -1.280896], [lr 0.008800] [batchtime 0.451]
[epoch 21], [iter 36 / 176], [train main loss -1.241056], [lr 0.008800] [batchtime 0.449]
[epoch 21], [iter 37 / 176], [train main loss -1.267323], [lr 0.008800] [batchtime 0.447]
[epoch 21], [iter 38 / 176], [train main loss -1.214224], [lr 0.008800] [batchtime 0.445]
[epoch 21], [iter 39 / 176], [train main loss -1.264810], [lr 0.008800] [batchtime 0.443]
[epoch 21], [iter 40 / 176], [train main loss -1.219336], [lr 0.008800] [batchtime 0.442]
[epoch 21], [iter 41 / 176], [train main loss -1.220063], [lr 0.008800] [batchtime 0.44]
[epoch 21], [iter 42 / 176], [train main loss -1.185944], [lr 0.008800] [batchtime 0.439]
[epoch 21], [iter 43 / 176], [train main loss -1.182814], [lr 0.008800] [batchtime 0.438]
[epoch 21], [iter 44 / 176], [train main loss -1.182165], [lr 0.008800] [batchtime 0.437]
[epoch 21], [iter 45 / 176], [train main loss -1.200245], [lr 0.008800] [batchtime 0.435]
[epoch 21], [iter 46 / 176], [train main loss -1.177835], [lr 0.008800] [batchtime 0.434]
[epoch 21], [iter 47 / 176], [train main loss -1.153044], [lr 0.008800] [batchtime 0.433]
[epoch 21], [iter 48 / 176], [train main loss -1.171991], [lr 0.008800] [batchtime 0.433]
[epoch 21], [iter 49 / 176], [train main loss -1.169486], [lr 0.008800] [batchtime 0.432]
[epoch 21], [iter 50 / 176], [train main loss -1.152028], [lr 0.008800] [batchtime 0.431]
[epoch 21], [iter 51 / 176], [train main loss -1.097465], [lr 0.008800] [batchtime 0.43]
[epoch 21], [iter 52 / 176], [train main loss -1.101810], [lr 0.008800] [batchtime 0.429]
[epoch 21], [iter 53 / 176], [train main loss -1.080512], [lr 0.008800] [batchtime 0.429]
[epoch 21], [iter 54 / 176], [train main loss -1.053668], [lr 0.008800] [batchtime 0.428]
[epoch 21], [iter 55 / 176], [train main loss -1.065022], [lr 0.008800] [batchtime 0.428]
[epoch 21], [iter 56 / 176], [train main loss -1.041782], [lr 0.008800] [batchtime 0.427]
[epoch 21], [iter 57 / 176], [train main loss -1.005468], [lr 0.008800] [batchtime 0.426]
[epoch 21], [iter 58 / 176], [train main loss -1.001953], [lr 0.008800] [batchtime 0.426]
[epoch 21], [iter 59 / 176], [train main loss -0.963888], [lr 0.008800] [batchtime 0.425]
[epoch 21], [iter 60 / 176], [train main loss -0.933624], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 61 / 176], [train main loss -0.992502], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 62 / 176], [train main loss -1.016521], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 63 / 176], [train main loss -1.038569], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 64 / 176], [train main loss -1.048130], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 65 / 176], [train main loss -1.059634], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 66 / 176], [train main loss -1.111617], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 67 / 176], [train main loss -1.083228], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 68 / 176], [train main loss -1.119186], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 69 / 176], [train main loss -1.133921], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 70 / 176], [train main loss -1.126566], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 71 / 176], [train main loss -1.129070], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 72 / 176], [train main loss -1.098627], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 73 / 176], [train main loss -1.126224], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 74 / 176], [train main loss -1.142617], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 75 / 176], [train main loss -1.150974], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 76 / 176], [train main loss -1.173055], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 77 / 176], [train main loss -1.199946], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 78 / 176], [train main loss -1.178515], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 79 / 176], [train main loss -1.202756], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 80 / 176], [train main loss -1.210739], [lr 0.008800] [batchtime 0.425]
[epoch 21], [iter 81 / 176], [train main loss -1.213696], [lr 0.008800] [batchtime 0.425]
[epoch 21], [iter 82 / 176], [train main loss -1.230430], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 83 / 176], [train main loss -1.247331], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 84 / 176], [train main loss -1.264026], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 85 / 176], [train main loss -1.242027], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 86 / 176], [train main loss -1.258616], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 87 / 176], [train main loss -1.233641], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 88 / 176], [train main loss -1.238218], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 89 / 176], [train main loss -1.253507], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 90 / 176], [train main loss -1.271957], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 91 / 176], [train main loss -1.243285], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 92 / 176], [train main loss -1.247835], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 93 / 176], [train main loss -1.255304], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 94 / 176], [train main loss -1.254026], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 95 / 176], [train main loss -1.243813], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 96 / 176], [train main loss -1.277966], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 97 / 176], [train main loss -1.269413], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 98 / 176], [train main loss -1.260839], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 99 / 176], [train main loss -1.252536], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 100 / 176], [train main loss -1.261804], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 101 / 176], [train main loss -1.250731], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 102 / 176], [train main loss -1.238121], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 103 / 176], [train main loss -1.249497], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 104 / 176], [train main loss -1.234659], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 105 / 176], [train main loss -1.217609], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 106 / 176], [train main loss -1.215370], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 107 / 176], [train main loss -1.216591], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 108 / 176], [train main loss -1.202310], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 109 / 176], [train main loss -1.206721], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 110 / 176], [train main loss -1.216017], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 111 / 176], [train main loss -1.217186], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 112 / 176], [train main loss -1.223370], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 113 / 176], [train main loss -1.243196], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 114 / 176], [train main loss -1.244311], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 115 / 176], [train main loss -1.235290], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 116 / 176], [train main loss -1.230955], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 117 / 176], [train main loss -1.233530], [lr 0.008800] [batchtime 0.417]
[epoch 21], [iter 118 / 176], [train main loss -1.242769], [lr 0.008800] [batchtime 0.417]
[epoch 21], [iter 119 / 176], [train main loss -1.234824], [lr 0.008800] [batchtime 0.417]
[epoch 21], [iter 120 / 176], [train main loss -1.224028], [lr 0.008800] [batchtime 0.417]
[epoch 21], [iter 121 / 176], [train main loss -1.236413], [lr 0.008800] [batchtime 0.417]
[epoch 21], [iter 122 / 176], [train main loss -1.237597], [lr 0.008800] [batchtime 0.416]
[epoch 21], [iter 123 / 176], [train main loss -1.249873], [lr 0.008800] [batchtime 0.416]
[epoch 21], [iter 124 / 176], [train main loss -1.247683], [lr 0.008800] [batchtime 0.416]
[epoch 21], [iter 125 / 176], [train main loss -1.255565], [lr 0.008800] [batchtime 0.416]
[epoch 21], [iter 126 / 176], [train main loss -1.268376], [lr 0.008800] [batchtime 0.416]
[epoch 21], [iter 127 / 176], [train main loss -1.287539], [lr 0.008800] [batchtime 0.415]
[epoch 21], [iter 128 / 176], [train main loss -1.295974], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 129 / 176], [train main loss -1.282533], [lr 0.008800] [batchtime 0.425]
[epoch 21], [iter 130 / 176], [train main loss -1.291753], [lr 0.008800] [batchtime 0.425]
[epoch 21], [iter 131 / 176], [train main loss -1.289595], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 132 / 176], [train main loss -1.290261], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 133 / 176], [train main loss -1.290840], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 134 / 176], [train main loss -1.287263], [lr 0.008800] [batchtime 0.424]
[epoch 21], [iter 135 / 176], [train main loss -1.279084], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 136 / 176], [train main loss -1.266948], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 137 / 176], [train main loss -1.283331], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 138 / 176], [train main loss -1.297479], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 139 / 176], [train main loss -1.311849], [lr 0.008800] [batchtime 0.423]
[epoch 21], [iter 140 / 176], [train main loss -1.327604], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 141 / 176], [train main loss -1.317324], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 142 / 176], [train main loss -1.301622], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 143 / 176], [train main loss -1.285941], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 144 / 176], [train main loss -1.270568], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 145 / 176], [train main loss -1.293185], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 146 / 176], [train main loss -1.295727], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 147 / 176], [train main loss -1.299746], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 148 / 176], [train main loss -1.294641], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 149 / 176], [train main loss -1.316363], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 150 / 176], [train main loss -1.321891], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 151 / 176], [train main loss -1.316773], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 152 / 176], [train main loss -1.325185], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 153 / 176], [train main loss -1.340469], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 154 / 176], [train main loss -1.343582], [lr 0.008800] [batchtime 0.422]
[epoch 21], [iter 155 / 176], [train main loss -1.334591], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 156 / 176], [train main loss -1.346267], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 157 / 176], [train main loss -1.342623], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 158 / 176], [train main loss -1.331429], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 159 / 176], [train main loss -1.323845], [lr 0.008800] [batchtime 0.421]
[epoch 21], [iter 160 / 176], [train main loss -1.313177], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 161 / 176], [train main loss -1.313644], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 162 / 176], [train main loss -1.319907], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 163 / 176], [train main loss -1.326115], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 164 / 176], [train main loss -1.332661], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 165 / 176], [train main loss -1.336318], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 166 / 176], [train main loss -1.338253], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 167 / 176], [train main loss -1.316505], [lr 0.008800] [batchtime 0.42]
[epoch 21], [iter 168 / 176], [train main loss -1.311319], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 169 / 176], [train main loss -1.297330], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 170 / 176], [train main loss -1.294577], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 171 / 176], [train main loss -1.307628], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 172 / 176], [train main loss -1.306891], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 173 / 176], [train main loss -1.312497], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 174 / 176], [train main loss -1.319843], [lr 0.008800] [batchtime 0.418]
[epoch 21], [iter 175 / 176], [train main loss -1.310566], [lr 0.008800] [batchtime 0.419]
[epoch 21], [iter 176 / 176], [train main loss -1.330034], [lr 0.008800] [batchtime 0.428]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              89.90  35.10        0.04    0.08         0.97      0.93
   1  sidewalk          45.75   3.87        0.70    0.48         0.59      0.67
   2  building          77.98  23.42        0.14    0.15         0.88      0.87
   3  wall               0.44   0.00      224.01    1.09         0.00      0.48
   4  fence              0.10   0.00      962.68    1.48         0.00      0.40
   5  pole              15.34   0.20        4.66    0.86         0.18      0.54
   6  traffic light      0.00   0.00    28740.98    0.84         0.00      0.54
   7  traffic sign       4.21   0.02       21.66    1.08         0.04      0.48
   8  vegetation        72.35  11.55        0.07    0.31         0.93      0.76
   9  terrain           24.79   0.30        1.48    1.55         0.40      0.39
  10  sky               90.26   3.70        0.05    0.06         0.96      0.94
  11  person            18.29   0.36        3.20    1.26         0.24      0.44
  12  rider              0.00   0.00   532273.00  636.50         0.00      0.00
  13  car               70.33   6.30        0.12    0.30         0.89      0.77
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00  1021158.00    0.00         0.00      1.00
  16  train              0.00   0.00      inf     nan            0.00    nan
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle           17.26   0.11        2.60    2.19         0.28      0.31
Mean: 27.74
-----------------------------------------------------------------------------------------------------------
this : [epoch 21], [val loss 0.51055], [acc 0.84933], [acc_cls 0.33463], [mean_iu 0.27738], [fwavacc 0.74578]
best : [epoch 21], [val loss 0.51055], [acc 0.84933], [acc_cls 0.33463], [mean_iu 0.27738], [fwavacc 0.74578]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 22], [iter 1 / 176], [train main loss -3.400706], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 2 / 176], [train main loss -1.533771], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 3 / 176], [train main loss -1.525857], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 4 / 176], [train main loss -1.472889], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 5 / 176], [train main loss -1.552804], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 6 / 176], [train main loss -1.745076], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 7 / 176], [train main loss -1.555120], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 8 / 176], [train main loss -1.558577], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 9 / 176], [train main loss -1.497046], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 10 / 176], [train main loss -1.397198], [lr 0.008743] [batchtime 0]
[epoch 22], [iter 11 / 176], [train main loss -1.594393], [lr 0.008743] [batchtime 0.366]
[epoch 22], [iter 12 / 176], [train main loss -1.474630], [lr 0.008743] [batchtime 0.381]
[epoch 22], [iter 13 / 176], [train main loss -1.567652], [lr 0.008743] [batchtime 0.387]
[epoch 22], [iter 14 / 176], [train main loss -1.699214], [lr 0.008743] [batchtime 0.388]
[epoch 22], [iter 15 / 176], [train main loss -1.576771], [lr 0.008743] [batchtime 0.389]
[epoch 22], [iter 16 / 176], [train main loss -1.402361], [lr 0.008743] [batchtime 0.391]
[epoch 22], [iter 17 / 176], [train main loss -1.342141], [lr 0.008743] [batchtime 0.393]
[epoch 22], [iter 18 / 176], [train main loss -1.227163], [lr 0.008743] [batchtime 0.393]
[epoch 22], [iter 19 / 176], [train main loss -1.332576], [lr 0.008743] [batchtime 0.393]
[epoch 22], [iter 20 / 176], [train main loss -1.131825], [lr 0.008743] [batchtime 0.394]
[epoch 22], [iter 21 / 176], [train main loss -1.226346], [lr 0.008743] [batchtime 0.393]
[epoch 22], [iter 22 / 176], [train main loss -1.172793], [lr 0.008743] [batchtime 0.392]
[epoch 22], [iter 23 / 176], [train main loss -1.240062], [lr 0.008743] [batchtime 0.392]
[epoch 22], [iter 24 / 176], [train main loss -1.225218], [lr 0.008743] [batchtime 0.393]
[epoch 22], [iter 25 / 176], [train main loss -1.205348], [lr 0.008743] [batchtime 0.392]
[epoch 22], [iter 26 / 176], [train main loss -1.162523], [lr 0.008743] [batchtime 0.398]
[epoch 22], [iter 27 / 176], [train main loss -1.171398], [lr 0.008743] [batchtime 0.405]
[epoch 22], [iter 28 / 176], [train main loss -1.201669], [lr 0.008743] [batchtime 0.404]
[epoch 22], [iter 29 / 176], [train main loss -1.214434], [lr 0.008743] [batchtime 0.403]
[epoch 22], [iter 30 / 176], [train main loss -1.262840], [lr 0.008743] [batchtime 0.402]
[epoch 22], [iter 31 / 176], [train main loss -1.231159], [lr 0.008743] [batchtime 0.402]
[epoch 22], [iter 32 / 176], [train main loss -1.294056], [lr 0.008743] [batchtime 0.402]
[epoch 22], [iter 33 / 176], [train main loss -1.254758], [lr 0.008743] [batchtime 0.401]
[epoch 22], [iter 34 / 176], [train main loss -1.305488], [lr 0.008743] [batchtime 0.401]
[epoch 22], [iter 35 / 176], [train main loss -1.225451], [lr 0.008743] [batchtime 0.401]
[epoch 22], [iter 36 / 176], [train main loss -1.254369], [lr 0.008743] [batchtime 0.401]
[epoch 22], [iter 37 / 176], [train main loss -1.276676], [lr 0.008743] [batchtime 0.4]
[epoch 22], [iter 38 / 176], [train main loss -1.291753], [lr 0.008743] [batchtime 0.4]
[epoch 22], [iter 39 / 176], [train main loss -1.223720], [lr 0.008743] [batchtime 0.4]
[epoch 22], [iter 40 / 176], [train main loss -1.243538], [lr 0.008743] [batchtime 0.4]
[epoch 22], [iter 41 / 176], [train main loss -1.180647], [lr 0.008743] [batchtime 0.4]
[epoch 22], [iter 42 / 176], [train main loss -1.097398], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 43 / 176], [train main loss -1.176013], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 44 / 176], [train main loss -1.146927], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 45 / 176], [train main loss -1.080246], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 46 / 176], [train main loss -1.086165], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 47 / 176], [train main loss -1.087717], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 48 / 176], [train main loss -1.087440], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 49 / 176], [train main loss -1.052706], [lr 0.008743] [batchtime 0.399]
[epoch 22], [iter 50 / 176], [train main loss -1.061503], [lr 0.008743] [batchtime 0.4]
[epoch 22], [iter 51 / 176], [train main loss -1.094475], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 52 / 176], [train main loss -1.074682], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 53 / 176], [train main loss -1.088567], [lr 0.008743] [batchtime 0.412]
[epoch 22], [iter 54 / 176], [train main loss -1.067430], [lr 0.008743] [batchtime 0.412]
[epoch 22], [iter 55 / 176], [train main loss -1.072407], [lr 0.008743] [batchtime 0.411]
[epoch 22], [iter 56 / 176], [train main loss -1.091047], [lr 0.008743] [batchtime 0.411]
[epoch 22], [iter 57 / 176], [train main loss -1.077806], [lr 0.008743] [batchtime 0.411]
[epoch 22], [iter 58 / 176], [train main loss -1.094574], [lr 0.008743] [batchtime 0.41]
[epoch 22], [iter 59 / 176], [train main loss -1.099160], [lr 0.008743] [batchtime 0.41]
[epoch 22], [iter 60 / 176], [train main loss -1.106386], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 61 / 176], [train main loss -1.081725], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 62 / 176], [train main loss -1.117229], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 63 / 176], [train main loss -1.137218], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 64 / 176], [train main loss -1.127353], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 65 / 176], [train main loss -1.124708], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 66 / 176], [train main loss -1.128032], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 67 / 176], [train main loss -1.180353], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 68 / 176], [train main loss -1.188481], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 69 / 176], [train main loss -1.192270], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 70 / 176], [train main loss -1.199562], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 71 / 176], [train main loss -1.213528], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 72 / 176], [train main loss -1.202373], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 73 / 176], [train main loss -1.238183], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 74 / 176], [train main loss -1.229995], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 75 / 176], [train main loss -1.245572], [lr 0.008743] [batchtime 0.411]
[epoch 22], [iter 76 / 176], [train main loss -1.240483], [lr 0.008743] [batchtime 0.411]
[epoch 22], [iter 77 / 176], [train main loss -1.266757], [lr 0.008743] [batchtime 0.41]
[epoch 22], [iter 78 / 176], [train main loss -1.268776], [lr 0.008743] [batchtime 0.41]
[epoch 22], [iter 79 / 176], [train main loss -1.300709], [lr 0.008743] [batchtime 0.41]
[epoch 22], [iter 80 / 176], [train main loss -1.272577], [lr 0.008743] [batchtime 0.41]
[epoch 22], [iter 81 / 176], [train main loss -1.283800], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 82 / 176], [train main loss -1.294318], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 83 / 176], [train main loss -1.292724], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 84 / 176], [train main loss -1.330647], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 85 / 176], [train main loss -1.316308], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 86 / 176], [train main loss -1.306455], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 87 / 176], [train main loss -1.280228], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 88 / 176], [train main loss -1.243974], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 89 / 176], [train main loss -1.246216], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 90 / 176], [train main loss -1.232466], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 91 / 176], [train main loss -1.243709], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 92 / 176], [train main loss -1.238840], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 93 / 176], [train main loss -1.238225], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 94 / 176], [train main loss -1.238516], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 95 / 176], [train main loss -1.214882], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 96 / 176], [train main loss -1.247438], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 97 / 176], [train main loss -1.245640], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 98 / 176], [train main loss -1.272860], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 99 / 176], [train main loss -1.274386], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 100 / 176], [train main loss -1.277247], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 101 / 176], [train main loss -1.281725], [lr 0.008743] [batchtime 0.409]
[epoch 22], [iter 102 / 176], [train main loss -1.287243], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 103 / 176], [train main loss -1.303512], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 104 / 176], [train main loss -1.327720], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 105 / 176], [train main loss -1.354345], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 106 / 176], [train main loss -1.366544], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 107 / 176], [train main loss -1.381013], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 108 / 176], [train main loss -1.380326], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 109 / 176], [train main loss -1.390751], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 110 / 176], [train main loss -1.385062], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 111 / 176], [train main loss -1.371061], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 112 / 176], [train main loss -1.372748], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 113 / 176], [train main loss -1.369815], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 114 / 176], [train main loss -1.349745], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 115 / 176], [train main loss -1.350708], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 116 / 176], [train main loss -1.377860], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 117 / 176], [train main loss -1.380539], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 118 / 176], [train main loss -1.376317], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 119 / 176], [train main loss -1.369431], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 120 / 176], [train main loss -1.370835], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 121 / 176], [train main loss -1.390503], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 122 / 176], [train main loss -1.380332], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 123 / 176], [train main loss -1.405514], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 124 / 176], [train main loss -1.401761], [lr 0.008743] [batchtime 0.406]
[epoch 22], [iter 125 / 176], [train main loss -1.389153], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 126 / 176], [train main loss -1.399949], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 127 / 176], [train main loss -1.410051], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 128 / 176], [train main loss -1.413583], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 129 / 176], [train main loss -1.434257], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 130 / 176], [train main loss -1.426464], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 131 / 176], [train main loss -1.435204], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 132 / 176], [train main loss -1.438021], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 133 / 176], [train main loss -1.427563], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 134 / 176], [train main loss -1.415655], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 135 / 176], [train main loss -1.403929], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 136 / 176], [train main loss -1.423162], [lr 0.008743] [batchtime 0.408]
[epoch 22], [iter 137 / 176], [train main loss -1.432649], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 138 / 176], [train main loss -1.423492], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 139 / 176], [train main loss -1.454354], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 140 / 176], [train main loss -1.450028], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 141 / 176], [train main loss -1.447745], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 142 / 176], [train main loss -1.455921], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 143 / 176], [train main loss -1.470753], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 144 / 176], [train main loss -1.477519], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 145 / 176], [train main loss -1.487414], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 146 / 176], [train main loss -1.489168], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 147 / 176], [train main loss -1.490729], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 148 / 176], [train main loss -1.490495], [lr 0.008743] [batchtime 0.407]
[epoch 22], [iter 149 / 176], [train main loss -1.492751], [lr 0.008743] [batchtime 0.415]
[epoch 22], [iter 150 / 176], [train main loss -1.519820], [lr 0.008743] [batchtime 0.415]
[epoch 22], [iter 151 / 176], [train main loss -1.517410], [lr 0.008743] [batchtime 0.415]
[epoch 22], [iter 152 / 176], [train main loss -1.513251], [lr 0.008743] [batchtime 0.415]
[epoch 22], [iter 153 / 176], [train main loss -1.512423], [lr 0.008743] [batchtime 0.415]
[epoch 22], [iter 154 / 176], [train main loss -1.507200], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 155 / 176], [train main loss -1.512239], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 156 / 176], [train main loss -1.504917], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 157 / 176], [train main loss -1.496596], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 158 / 176], [train main loss -1.500754], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 159 / 176], [train main loss -1.501233], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 160 / 176], [train main loss -1.501590], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 161 / 176], [train main loss -1.497673], [lr 0.008743] [batchtime 0.414]
[epoch 22], [iter 162 / 176], [train main loss -1.488448], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 163 / 176], [train main loss -1.510301], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 164 / 176], [train main loss -1.524877], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 165 / 176], [train main loss -1.530225], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 166 / 176], [train main loss -1.514634], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 167 / 176], [train main loss -1.509168], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 168 / 176], [train main loss -1.505355], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 169 / 176], [train main loss -1.498793], [lr 0.008743] [batchtime 0.412]
[epoch 22], [iter 170 / 176], [train main loss -1.485265], [lr 0.008743] [batchtime 0.412]
[epoch 22], [iter 171 / 176], [train main loss -1.488540], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 172 / 176], [train main loss -1.500564], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 173 / 176], [train main loss -1.508587], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 174 / 176], [train main loss -1.515771], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 175 / 176], [train main loss -1.511392], [lr 0.008743] [batchtime 0.413]
[epoch 22], [iter 176 / 176], [train main loss -1.512296], [lr 0.008743] [batchtime 0.412]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP      FN    Precision    Recall
----  -------------  --------  -----  -------  ------  -----------  --------
   0  road              89.82  35.09     0.04    0.08         0.97      0.93
   1  sidewalk          46.79   4.00     0.65    0.49         0.61      0.67
   2  building          78.04  23.98     0.11    0.17         0.90      0.85
   3  wall               0.25   0.00   401.25    3.53         0.00      0.22
   4  fence              0.03   0.00  3641.84    1.41         0.00      0.42
   5  pole              12.98   0.16     6.06    0.65         0.14      0.61
   6  traffic light      0.01   0.00  9899.02    0.45         0.00      0.69
   7  traffic sign       3.60   0.02    26.00    0.80         0.04      0.56
   8  vegetation        76.05  11.18     0.11    0.21         0.90      0.83
   9  terrain           22.28   0.20     2.70    0.79         0.27      0.56
  10  sky               90.79   3.65     0.06    0.04         0.94      0.96
  11  person            17.44   0.33     3.67    1.07         0.21      0.48
  12  rider              0.01   0.00  7340.71    9.65         0.00      0.09
  13  car               64.77   6.44     0.10    0.45         0.91      0.69
  14  truck              0.00   0.00   inf     nan            0.00    nan
  15  bus                0.00   0.00   inf     inf            0.00      0.00
  16  train              0.00   0.00   inf     nan            0.00    nan
  17  motorcycle         0.00   0.00   inf     nan            0.00    nan
  18  bicycle           14.37   0.07     4.71    1.25         0.18      0.44
Mean: 27.22
-----------------------------------------------------------------------------------------------------------
this : [epoch 22], [val loss 0.50077], [acc 0.85119], [acc_cls 0.31960], [mean_iu 0.27222], [fwavacc 0.74644]
best : [epoch 21], [val loss 0.51055], [acc 0.84933], [acc_cls 0.33463], [mean_iu 0.27738], [fwavacc 0.74578]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 23], [iter 1 / 176], [train main loss 0.067417], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 2 / 176], [train main loss -0.460091], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 3 / 176], [train main loss -0.502935], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 4 / 176], [train main loss -0.623389], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 5 / 176], [train main loss -0.645292], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 6 / 176], [train main loss -0.818535], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 7 / 176], [train main loss -1.076215], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 8 / 176], [train main loss -1.112023], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 9 / 176], [train main loss -0.956855], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 10 / 176], [train main loss -1.320941], [lr 0.008686] [batchtime 0]
[epoch 23], [iter 11 / 176], [train main loss -1.079245], [lr 0.008686] [batchtime 0.374]
[epoch 23], [iter 12 / 176], [train main loss -1.365881], [lr 0.008686] [batchtime 0.386]
[epoch 23], [iter 13 / 176], [train main loss -1.183513], [lr 0.008686] [batchtime 0.39]
[epoch 23], [iter 14 / 176], [train main loss -1.211495], [lr 0.008686] [batchtime 0.391]
[epoch 23], [iter 15 / 176], [train main loss -1.287731], [lr 0.008686] [batchtime 0.392]
[epoch 23], [iter 16 / 176], [train main loss -1.193916], [lr 0.008686] [batchtime 0.393]
[epoch 23], [iter 17 / 176], [train main loss -1.227249], [lr 0.008686] [batchtime 0.393]
[epoch 23], [iter 18 / 176], [train main loss -1.233343], [lr 0.008686] [batchtime 0.393]
[epoch 23], [iter 19 / 176], [train main loss -1.262897], [lr 0.008686] [batchtime 0.393]
[epoch 23], [iter 20 / 176], [train main loss -1.219417], [lr 0.008686] [batchtime 0.394]
[epoch 23], [iter 21 / 176], [train main loss -1.236451], [lr 0.008686] [batchtime 0.394]
[epoch 23], [iter 22 / 176], [train main loss -1.258407], [lr 0.008686] [batchtime 0.395]
[epoch 23], [iter 23 / 176], [train main loss -1.334235], [lr 0.008686] [batchtime 0.396]
[epoch 23], [iter 24 / 176], [train main loss -1.348611], [lr 0.008686] [batchtime 0.395]
[epoch 23], [iter 25 / 176], [train main loss -1.280119], [lr 0.008686] [batchtime 0.396]
[epoch 23], [iter 26 / 176], [train main loss -1.315212], [lr 0.008686] [batchtime 0.396]
[epoch 23], [iter 27 / 176], [train main loss -1.279088], [lr 0.008686] [batchtime 0.396]
[epoch 23], [iter 28 / 176], [train main loss -1.385725], [lr 0.008686] [batchtime 0.396]
[epoch 23], [iter 29 / 176], [train main loss -1.416039], [lr 0.008686] [batchtime 0.396]
[epoch 23], [iter 30 / 176], [train main loss -1.493611], [lr 0.008686] [batchtime 0.46]
[epoch 23], [iter 31 / 176], [train main loss -1.572758], [lr 0.008686] [batchtime 0.472]
[epoch 23], [iter 32 / 176], [train main loss -1.603014], [lr 0.008686] [batchtime 0.469]
[epoch 23], [iter 33 / 176], [train main loss -1.594223], [lr 0.008686] [batchtime 0.465]
[epoch 23], [iter 34 / 176], [train main loss -1.596634], [lr 0.008686] [batchtime 0.462]
[epoch 23], [iter 35 / 176], [train main loss -1.630065], [lr 0.008686] [batchtime 0.46]
[epoch 23], [iter 36 / 176], [train main loss -1.634079], [lr 0.008686] [batchtime 0.457]
[epoch 23], [iter 37 / 176], [train main loss -1.614615], [lr 0.008686] [batchtime 0.455]
[epoch 23], [iter 38 / 176], [train main loss -1.571381], [lr 0.008686] [batchtime 0.453]
[epoch 23], [iter 39 / 176], [train main loss -1.574828], [lr 0.008686] [batchtime 0.451]
[epoch 23], [iter 40 / 176], [train main loss -1.570194], [lr 0.008686] [batchtime 0.45]
[epoch 23], [iter 41 / 176], [train main loss -1.626327], [lr 0.008686] [batchtime 0.448]
[epoch 23], [iter 42 / 176], [train main loss -1.748487], [lr 0.008686] [batchtime 0.446]
[epoch 23], [iter 43 / 176], [train main loss -1.755168], [lr 0.008686] [batchtime 0.445]
[epoch 23], [iter 44 / 176], [train main loss -1.789168], [lr 0.008686] [batchtime 0.444]
[epoch 23], [iter 45 / 176], [train main loss -1.794427], [lr 0.008686] [batchtime 0.443]
[epoch 23], [iter 46 / 176], [train main loss -1.744229], [lr 0.008686] [batchtime 0.442]
[epoch 23], [iter 47 / 176], [train main loss -1.720634], [lr 0.008686] [batchtime 0.441]
[epoch 23], [iter 48 / 176], [train main loss -1.715086], [lr 0.008686] [batchtime 0.44]
[epoch 23], [iter 49 / 176], [train main loss -1.698705], [lr 0.008686] [batchtime 0.439]
[epoch 23], [iter 50 / 176], [train main loss -1.717327], [lr 0.008686] [batchtime 0.438]
[epoch 23], [iter 51 / 176], [train main loss -1.654330], [lr 0.008686] [batchtime 0.437]
[epoch 23], [iter 52 / 176], [train main loss -1.617219], [lr 0.008686] [batchtime 0.437]
[epoch 23], [iter 53 / 176], [train main loss -1.593020], [lr 0.008686] [batchtime 0.436]
[epoch 23], [iter 54 / 176], [train main loss -1.619511], [lr 0.008686] [batchtime 0.435]
[epoch 23], [iter 55 / 176], [train main loss -1.604643], [lr 0.008686] [batchtime 0.434]
[epoch 23], [iter 56 / 176], [train main loss -1.620402], [lr 0.008686] [batchtime 0.433]
[epoch 23], [iter 57 / 176], [train main loss -1.626955], [lr 0.008686] [batchtime 0.433]
[epoch 23], [iter 58 / 176], [train main loss -1.589861], [lr 0.008686] [batchtime 0.432]
[epoch 23], [iter 59 / 176], [train main loss -1.629479], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 60 / 176], [train main loss -1.654758], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 61 / 176], [train main loss -1.628853], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 62 / 176], [train main loss -1.630937], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 63 / 176], [train main loss -1.589379], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 64 / 176], [train main loss -1.586049], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 65 / 176], [train main loss -1.595414], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 66 / 176], [train main loss -1.548143], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 67 / 176], [train main loss -1.511872], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 68 / 176], [train main loss -1.498271], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 69 / 176], [train main loss -1.481355], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 70 / 176], [train main loss -1.482784], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 71 / 176], [train main loss -1.505806], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 72 / 176], [train main loss -1.483883], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 73 / 176], [train main loss -1.487191], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 74 / 176], [train main loss -1.473344], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 75 / 176], [train main loss -1.498254], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 76 / 176], [train main loss -1.511717], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 77 / 176], [train main loss -1.512602], [lr 0.008686] [batchtime 0.432]
[epoch 23], [iter 78 / 176], [train main loss -1.513964], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 79 / 176], [train main loss -1.539770], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 80 / 176], [train main loss -1.535246], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 81 / 176], [train main loss -1.540486], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 82 / 176], [train main loss -1.524103], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 83 / 176], [train main loss -1.519746], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 84 / 176], [train main loss -1.521148], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 85 / 176], [train main loss -1.467913], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 86 / 176], [train main loss -1.462137], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 87 / 176], [train main loss -1.476111], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 88 / 176], [train main loss -1.457006], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 89 / 176], [train main loss -1.445098], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 90 / 176], [train main loss -1.439075], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 91 / 176], [train main loss -1.492433], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 92 / 176], [train main loss -1.458389], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 93 / 176], [train main loss -1.450133], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 94 / 176], [train main loss -1.461323], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 95 / 176], [train main loss -1.454562], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 96 / 176], [train main loss -1.438307], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 97 / 176], [train main loss -1.414434], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 98 / 176], [train main loss -1.412340], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 99 / 176], [train main loss -1.391694], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 100 / 176], [train main loss -1.374620], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 101 / 176], [train main loss -1.356685], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 102 / 176], [train main loss -1.340242], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 103 / 176], [train main loss -1.367409], [lr 0.008686] [batchtime 0.422]
[epoch 23], [iter 104 / 176], [train main loss -1.365340], [lr 0.008686] [batchtime 0.422]
[epoch 23], [iter 105 / 176], [train main loss -1.357545], [lr 0.008686] [batchtime 0.422]
[epoch 23], [iter 106 / 176], [train main loss -1.354142], [lr 0.008686] [batchtime 0.422]
[epoch 23], [iter 107 / 176], [train main loss -1.352242], [lr 0.008686] [batchtime 0.421]
[epoch 23], [iter 108 / 176], [train main loss -1.369546], [lr 0.008686] [batchtime 0.421]
[epoch 23], [iter 109 / 176], [train main loss -1.361297], [lr 0.008686] [batchtime 0.421]
[epoch 23], [iter 110 / 176], [train main loss -1.355948], [lr 0.008686] [batchtime 0.421]
[epoch 23], [iter 111 / 176], [train main loss -1.365162], [lr 0.008686] [batchtime 0.42]
[epoch 23], [iter 112 / 176], [train main loss -1.379875], [lr 0.008686] [batchtime 0.42]
[epoch 23], [iter 113 / 176], [train main loss -1.359024], [lr 0.008686] [batchtime 0.42]
[epoch 23], [iter 114 / 176], [train main loss -1.350916], [lr 0.008686] [batchtime 0.42]
[epoch 23], [iter 115 / 176], [train main loss -1.356306], [lr 0.008686] [batchtime 0.42]
[epoch 23], [iter 116 / 176], [train main loss -1.368584], [lr 0.008686] [batchtime 0.419]
[epoch 23], [iter 117 / 176], [train main loss -1.372657], [lr 0.008686] [batchtime 0.419]
[epoch 23], [iter 118 / 176], [train main loss -1.391870], [lr 0.008686] [batchtime 0.419]
[epoch 23], [iter 119 / 176], [train main loss -1.370295], [lr 0.008686] [batchtime 0.419]
[epoch 23], [iter 120 / 176], [train main loss -1.384036], [lr 0.008686] [batchtime 0.419]
[epoch 23], [iter 121 / 176], [train main loss -1.373597], [lr 0.008686] [batchtime 0.418]
[epoch 23], [iter 122 / 176], [train main loss -1.367697], [lr 0.008686] [batchtime 0.418]
[epoch 23], [iter 123 / 176], [train main loss -1.364519], [lr 0.008686] [batchtime 0.418]
[epoch 23], [iter 124 / 176], [train main loss -1.375464], [lr 0.008686] [batchtime 0.418]
[epoch 23], [iter 125 / 176], [train main loss -1.363088], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 126 / 176], [train main loss -1.370234], [lr 0.008686] [batchtime 0.432]
[epoch 23], [iter 127 / 176], [train main loss -1.370464], [lr 0.008686] [batchtime 0.432]
[epoch 23], [iter 128 / 176], [train main loss -1.362939], [lr 0.008686] [batchtime 0.432]
[epoch 23], [iter 129 / 176], [train main loss -1.355660], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 130 / 176], [train main loss -1.372499], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 131 / 176], [train main loss -1.348997], [lr 0.008686] [batchtime 0.431]
[epoch 23], [iter 132 / 176], [train main loss -1.371834], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 133 / 176], [train main loss -1.372735], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 134 / 176], [train main loss -1.352538], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 135 / 176], [train main loss -1.345068], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 136 / 176], [train main loss -1.354828], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 137 / 176], [train main loss -1.381210], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 138 / 176], [train main loss -1.370299], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 139 / 176], [train main loss -1.357389], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 140 / 176], [train main loss -1.344638], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 141 / 176], [train main loss -1.341758], [lr 0.008686] [batchtime 0.428]
[epoch 23], [iter 142 / 176], [train main loss -1.344970], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 143 / 176], [train main loss -1.327261], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 144 / 176], [train main loss -1.335031], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 145 / 176], [train main loss -1.335304], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 146 / 176], [train main loss -1.325039], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 147 / 176], [train main loss -1.343444], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 148 / 176], [train main loss -1.344781], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 149 / 176], [train main loss -1.338344], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 150 / 176], [train main loss -1.360492], [lr 0.008686] [batchtime 0.427]
[epoch 23], [iter 151 / 176], [train main loss -1.366322], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 152 / 176], [train main loss -1.352655], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 153 / 176], [train main loss -1.362393], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 154 / 176], [train main loss -1.360696], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 155 / 176], [train main loss -1.354569], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 156 / 176], [train main loss -1.346914], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 157 / 176], [train main loss -1.344040], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 158 / 176], [train main loss -1.350232], [lr 0.008686] [batchtime 0.425]
[epoch 23], [iter 159 / 176], [train main loss -1.337375], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 160 / 176], [train main loss -1.330004], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 161 / 176], [train main loss -1.334203], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 162 / 176], [train main loss -1.336852], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 163 / 176], [train main loss -1.334728], [lr 0.008686] [batchtime 0.424]
[epoch 23], [iter 164 / 176], [train main loss -1.349971], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 165 / 176], [train main loss -1.347333], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 166 / 176], [train main loss -1.348693], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 167 / 176], [train main loss -1.349157], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 168 / 176], [train main loss -1.359221], [lr 0.008686] [batchtime 0.423]
[epoch 23], [iter 169 / 176], [train main loss -1.351443], [lr 0.008686] [batchtime 0.422]
[epoch 23], [iter 170 / 176], [train main loss -1.368908], [lr 0.008686] [batchtime 0.422]
[epoch 23], [iter 171 / 176], [train main loss -1.375745], [lr 0.008686] [batchtime 0.426]
[epoch 23], [iter 172 / 176], [train main loss -1.372062], [lr 0.008686] [batchtime 0.43]
[epoch 23], [iter 173 / 176], [train main loss -1.389972], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 174 / 176], [train main loss -1.390463], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 175 / 176], [train main loss -1.380804], [lr 0.008686] [batchtime 0.429]
[epoch 23], [iter 176 / 176], [train main loss -1.377455], [lr 0.008686] [batchtime 0.428]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP      FN    Precision    Recall
----  -------------  --------  -----  -------  ------  -----------  --------
   0  road              89.53  35.60     0.02    0.10         0.98      0.91
   1  sidewalk          44.73   3.61     0.82    0.41         0.55      0.71
   2  building          78.08  23.69     0.12    0.16         0.89      0.86
   3  wall               0.91   0.01   106.74    2.30         0.01      0.30
   4  fence              0.13   0.00   788.42    1.08         0.00      0.48
   5  pole              14.60   0.18     5.23    0.62         0.16      0.62
   6  traffic light      0.01   0.00  7780.67    0.37         0.00      0.73
   7  traffic sign       3.67   0.02    25.21    1.02         0.04      0.49
   8  vegetation        73.36  11.50     0.08    0.29         0.93      0.78
   9  terrain           24.66   0.28     1.62    1.43         0.38      0.41
  10  sky               91.04   3.68     0.05    0.05         0.95      0.96
  11  person            17.58   0.31     3.92    0.76         0.20      0.57
  12  rider              0.01   0.00  7095.99   40.77         0.00      0.02
  13  car               69.73   6.18     0.15    0.29         0.87      0.78
  14  truck              0.00   0.00   inf     nan            0.00    nan
  15  bus                0.00   0.00   inf     inf            0.00      0.00
  16  train              0.00   0.00   inf     nan            0.00    nan
  17  motorcycle         0.00   0.00   inf     nan            0.00    nan
  18  bicycle           17.92   0.10     3.09    1.49         0.24      0.40
Mean: 27.68
-----------------------------------------------------------------------------------------------------------
this : [epoch 23], [val loss 0.52779], [acc 0.85155], [acc_cls 0.32689], [mean_iu 0.27683], [fwavacc 0.74498]
best : [epoch 21], [val loss 0.51055], [acc 0.84933], [acc_cls 0.33463], [mean_iu 0.27738], [fwavacc 0.74578]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 24], [iter 1 / 176], [train main loss -0.787272], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 2 / 176], [train main loss -2.127854], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 3 / 176], [train main loss -2.691877], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 4 / 176], [train main loss -2.223824], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 5 / 176], [train main loss -1.748076], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 6 / 176], [train main loss -1.676475], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 7 / 176], [train main loss -1.907409], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 8 / 176], [train main loss -1.618455], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 9 / 176], [train main loss -1.498134], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 10 / 176], [train main loss -1.722522], [lr 0.008629] [batchtime 0]
[epoch 24], [iter 11 / 176], [train main loss -1.627030], [lr 0.008629] [batchtime 0.365]
[epoch 24], [iter 12 / 176], [train main loss -1.659459], [lr 0.008629] [batchtime 0.383]
[epoch 24], [iter 13 / 176], [train main loss -1.571825], [lr 0.008629] [batchtime 0.385]
[epoch 24], [iter 14 / 176], [train main loss -1.514615], [lr 0.008629] [batchtime 0.39]
[epoch 24], [iter 15 / 176], [train main loss -1.327372], [lr 0.008629] [batchtime 0.392]
[epoch 24], [iter 16 / 176], [train main loss -1.300573], [lr 0.008629] [batchtime 0.391]
[epoch 24], [iter 17 / 176], [train main loss -1.059906], [lr 0.008629] [batchtime 0.392]
[epoch 24], [iter 18 / 176], [train main loss -1.115132], [lr 0.008629] [batchtime 0.392]
[epoch 24], [iter 19 / 176], [train main loss -1.205156], [lr 0.008629] [batchtime 0.393]
[epoch 24], [iter 20 / 176], [train main loss -1.256171], [lr 0.008629] [batchtime 0.393]
[epoch 24], [iter 21 / 176], [train main loss -1.184052], [lr 0.008629] [batchtime 0.393]
[epoch 24], [iter 22 / 176], [train main loss -1.300175], [lr 0.008629] [batchtime 0.394]
[epoch 24], [iter 23 / 176], [train main loss -1.223656], [lr 0.008629] [batchtime 0.394]
[epoch 24], [iter 24 / 176], [train main loss -1.222991], [lr 0.008629] [batchtime 0.394]
[epoch 24], [iter 25 / 176], [train main loss -1.165983], [lr 0.008629] [batchtime 0.394]
[epoch 24], [iter 26 / 176], [train main loss -1.228065], [lr 0.008629] [batchtime 0.394]
[epoch 24], [iter 27 / 176], [train main loss -1.193915], [lr 0.008629] [batchtime 0.394]
[epoch 24], [iter 28 / 176], [train main loss -1.213190], [lr 0.008629] [batchtime 0.395]
[epoch 24], [iter 29 / 176], [train main loss -1.231277], [lr 0.008629] [batchtime 0.395]
[epoch 24], [iter 30 / 176], [train main loss -1.138239], [lr 0.008629] [batchtime 0.411]
[epoch 24], [iter 31 / 176], [train main loss -1.193216], [lr 0.008629] [batchtime 0.484]
[epoch 24], [iter 32 / 176], [train main loss -1.145053], [lr 0.008629] [batchtime 0.479]
[epoch 24], [iter 33 / 176], [train main loss -1.079188], [lr 0.008629] [batchtime 0.475]
[epoch 24], [iter 34 / 176], [train main loss -1.148577], [lr 0.008629] [batchtime 0.471]
[epoch 24], [iter 35 / 176], [train main loss -1.249156], [lr 0.008629] [batchtime 0.468]
[epoch 24], [iter 36 / 176], [train main loss -1.217442], [lr 0.008629] [batchtime 0.466]
[epoch 24], [iter 37 / 176], [train main loss -1.168459], [lr 0.008629] [batchtime 0.463]
[epoch 24], [iter 38 / 176], [train main loss -1.211092], [lr 0.008629] [batchtime 0.46]
[epoch 24], [iter 39 / 176], [train main loss -1.236049], [lr 0.008629] [batchtime 0.458]
[epoch 24], [iter 40 / 176], [train main loss -1.291899], [lr 0.008629] [batchtime 0.456]
[epoch 24], [iter 41 / 176], [train main loss -1.332461], [lr 0.008629] [batchtime 0.454]
[epoch 24], [iter 42 / 176], [train main loss -1.337553], [lr 0.008629] [batchtime 0.452]
[epoch 24], [iter 43 / 176], [train main loss -1.350125], [lr 0.008629] [batchtime 0.451]
[epoch 24], [iter 44 / 176], [train main loss -1.345866], [lr 0.008629] [batchtime 0.449]
[epoch 24], [iter 45 / 176], [train main loss -1.367848], [lr 0.008629] [batchtime 0.448]
[epoch 24], [iter 46 / 176], [train main loss -1.297420], [lr 0.008629] [batchtime 0.446]
[epoch 24], [iter 47 / 176], [train main loss -1.299084], [lr 0.008629] [batchtime 0.445]
[epoch 24], [iter 48 / 176], [train main loss -1.364040], [lr 0.008629] [batchtime 0.444]
[epoch 24], [iter 49 / 176], [train main loss -1.430091], [lr 0.008629] [batchtime 0.443]
[epoch 24], [iter 50 / 176], [train main loss -1.446097], [lr 0.008629] [batchtime 0.441]
[epoch 24], [iter 51 / 176], [train main loss -1.460470], [lr 0.008629] [batchtime 0.441]
[epoch 24], [iter 52 / 176], [train main loss -1.416188], [lr 0.008629] [batchtime 0.439]
[epoch 24], [iter 53 / 176], [train main loss -1.406474], [lr 0.008629] [batchtime 0.438]
[epoch 24], [iter 54 / 176], [train main loss -1.369584], [lr 0.008629] [batchtime 0.437]
[epoch 24], [iter 55 / 176], [train main loss -1.322027], [lr 0.008629] [batchtime 0.436]
[epoch 24], [iter 56 / 176], [train main loss -1.292457], [lr 0.008629] [batchtime 0.435]
[epoch 24], [iter 57 / 176], [train main loss -1.273648], [lr 0.008629] [batchtime 0.435]
[epoch 24], [iter 58 / 176], [train main loss -1.251212], [lr 0.008629] [batchtime 0.434]
[epoch 24], [iter 59 / 176], [train main loss -1.219836], [lr 0.008629] [batchtime 0.433]
[epoch 24], [iter 60 / 176], [train main loss -1.265292], [lr 0.008629] [batchtime 0.432]
[epoch 24], [iter 61 / 176], [train main loss -1.268794], [lr 0.008629] [batchtime 0.432]
[epoch 24], [iter 62 / 176], [train main loss -1.287243], [lr 0.008629] [batchtime 0.431]
[epoch 24], [iter 63 / 176], [train main loss -1.257993], [lr 0.008629] [batchtime 0.43]
[epoch 24], [iter 64 / 176], [train main loss -1.257821], [lr 0.008629] [batchtime 0.429]
[epoch 24], [iter 65 / 176], [train main loss -1.235670], [lr 0.008629] [batchtime 0.429]
[epoch 24], [iter 66 / 176], [train main loss -1.255729], [lr 0.008629] [batchtime 0.428]
[epoch 24], [iter 67 / 176], [train main loss -1.238132], [lr 0.008629] [batchtime 0.429]
[epoch 24], [iter 68 / 176], [train main loss -1.263356], [lr 0.008629] [batchtime 0.428]
[epoch 24], [iter 69 / 176], [train main loss -1.271550], [lr 0.008629] [batchtime 0.428]
[epoch 24], [iter 70 / 176], [train main loss -1.300184], [lr 0.008629] [batchtime 0.427]
[epoch 24], [iter 71 / 176], [train main loss -1.318519], [lr 0.008629] [batchtime 0.427]
[epoch 24], [iter 72 / 176], [train main loss -1.298807], [lr 0.008629] [batchtime 0.426]
[epoch 24], [iter 73 / 176], [train main loss -1.304422], [lr 0.008629] [batchtime 0.426]
[epoch 24], [iter 74 / 176], [train main loss -1.277251], [lr 0.008629] [batchtime 0.425]
[epoch 24], [iter 75 / 176], [train main loss -1.248966], [lr 0.008629] [batchtime 0.425]
[epoch 24], [iter 76 / 176], [train main loss -1.249536], [lr 0.008629] [batchtime 0.432]
[epoch 24], [iter 77 / 176], [train main loss -1.309094], [lr 0.008629] [batchtime 0.434]
[epoch 24], [iter 78 / 176], [train main loss -1.329693], [lr 0.008629] [batchtime 0.433]
[epoch 24], [iter 79 / 176], [train main loss -1.322411], [lr 0.008629] [batchtime 0.432]
[epoch 24], [iter 80 / 176], [train main loss -1.318507], [lr 0.008629] [batchtime 0.432]
[epoch 24], [iter 81 / 176], [train main loss -1.304573], [lr 0.008629] [batchtime 0.431]
[epoch 24], [iter 82 / 176], [train main loss -1.316325], [lr 0.008629] [batchtime 0.431]
[epoch 24], [iter 83 / 176], [train main loss -1.319022], [lr 0.008629] [batchtime 0.43]
[epoch 24], [iter 84 / 176], [train main loss -1.320074], [lr 0.008629] [batchtime 0.43]
[epoch 24], [iter 85 / 176], [train main loss -1.310850], [lr 0.008629] [batchtime 0.429]
[epoch 24], [iter 86 / 176], [train main loss -1.326849], [lr 0.008629] [batchtime 0.429]
[epoch 24], [iter 87 / 176], [train main loss -1.314354], [lr 0.008629] [batchtime 0.428]
[epoch 24], [iter 88 / 176], [train main loss -1.317173], [lr 0.008629] [batchtime 0.428]
[epoch 24], [iter 89 / 176], [train main loss -1.328932], [lr 0.008629] [batchtime 0.427]
[epoch 24], [iter 90 / 176], [train main loss -1.364305], [lr 0.008629] [batchtime 0.427]
[epoch 24], [iter 91 / 176], [train main loss -1.332975], [lr 0.008629] [batchtime 0.426]
[epoch 24], [iter 92 / 176], [train main loss -1.317091], [lr 0.008629] [batchtime 0.426]
[epoch 24], [iter 93 / 176], [train main loss -1.306265], [lr 0.008629] [batchtime 0.426]
[epoch 24], [iter 94 / 176], [train main loss -1.264410], [lr 0.008629] [batchtime 0.425]
[epoch 24], [iter 95 / 176], [train main loss -1.258061], [lr 0.008629] [batchtime 0.425]
[epoch 24], [iter 96 / 176], [train main loss -1.243541], [lr 0.008629] [batchtime 0.424]
[epoch 24], [iter 97 / 176], [train main loss -1.240087], [lr 0.008629] [batchtime 0.424]
[epoch 24], [iter 98 / 176], [train main loss -1.250835], [lr 0.008629] [batchtime 0.424]
[epoch 24], [iter 99 / 176], [train main loss -1.241482], [lr 0.008629] [batchtime 0.423]
[epoch 24], [iter 100 / 176], [train main loss -1.232776], [lr 0.008629] [batchtime 0.424]
[epoch 24], [iter 101 / 176], [train main loss -1.256628], [lr 0.008629] [batchtime 0.424]
[epoch 24], [iter 102 / 176], [train main loss -1.260098], [lr 0.008629] [batchtime 0.423]
[epoch 24], [iter 103 / 176], [train main loss -1.247971], [lr 0.008629] [batchtime 0.423]
[epoch 24], [iter 104 / 176], [train main loss -1.259906], [lr 0.008629] [batchtime 0.423]
[epoch 24], [iter 105 / 176], [train main loss -1.274079], [lr 0.008629] [batchtime 0.422]
[epoch 24], [iter 106 / 176], [train main loss -1.278329], [lr 0.008629] [batchtime 0.422]
[epoch 24], [iter 107 / 176], [train main loss -1.290261], [lr 0.008629] [batchtime 0.422]
[epoch 24], [iter 108 / 176], [train main loss -1.269805], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 109 / 176], [train main loss -1.301940], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 110 / 176], [train main loss -1.295440], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 111 / 176], [train main loss -1.279678], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 112 / 176], [train main loss -1.269802], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 113 / 176], [train main loss -1.276434], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 114 / 176], [train main loss -1.299975], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 115 / 176], [train main loss -1.296651], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 116 / 176], [train main loss -1.306107], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 117 / 176], [train main loss -1.320284], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 118 / 176], [train main loss -1.296554], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 119 / 176], [train main loss -1.283701], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 120 / 176], [train main loss -1.297380], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 121 / 176], [train main loss -1.293855], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 122 / 176], [train main loss -1.307958], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 123 / 176], [train main loss -1.295539], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 124 / 176], [train main loss -1.301750], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 125 / 176], [train main loss -1.306481], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 126 / 176], [train main loss -1.342093], [lr 0.008629] [batchtime 0.422]
[epoch 24], [iter 127 / 176], [train main loss -1.331077], [lr 0.008629] [batchtime 0.422]
[epoch 24], [iter 128 / 176], [train main loss -1.326223], [lr 0.008629] [batchtime 0.422]
[epoch 24], [iter 129 / 176], [train main loss -1.327031], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 130 / 176], [train main loss -1.345106], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 131 / 176], [train main loss -1.363054], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 132 / 176], [train main loss -1.351952], [lr 0.008629] [batchtime 0.421]
[epoch 24], [iter 133 / 176], [train main loss -1.342524], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 134 / 176], [train main loss -1.362899], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 135 / 176], [train main loss -1.382695], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 136 / 176], [train main loss -1.371200], [lr 0.008629] [batchtime 0.42]
[epoch 24], [iter 137 / 176], [train main loss -1.371596], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 138 / 176], [train main loss -1.359161], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 139 / 176], [train main loss -1.364131], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 140 / 176], [train main loss -1.368457], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 141 / 176], [train main loss -1.355126], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 142 / 176], [train main loss -1.341347], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 143 / 176], [train main loss -1.340537], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 144 / 176], [train main loss -1.324599], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 145 / 176], [train main loss -1.321036], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 146 / 176], [train main loss -1.318014], [lr 0.008629] [batchtime 0.418]
[epoch 24], [iter 147 / 176], [train main loss -1.307740], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 148 / 176], [train main loss -1.292758], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 149 / 176], [train main loss -1.288538], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 150 / 176], [train main loss -1.292163], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 151 / 176], [train main loss -1.271791], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 152 / 176], [train main loss -1.276501], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 153 / 176], [train main loss -1.296899], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 154 / 176], [train main loss -1.292336], [lr 0.008629] [batchtime 0.417]
[epoch 24], [iter 155 / 176], [train main loss -1.297598], [lr 0.008629] [batchtime 0.416]
[epoch 24], [iter 156 / 176], [train main loss -1.296774], [lr 0.008629] [batchtime 0.416]
[epoch 24], [iter 157 / 176], [train main loss -1.298966], [lr 0.008629] [batchtime 0.416]
[epoch 24], [iter 158 / 176], [train main loss -1.288474], [lr 0.008629] [batchtime 0.416]
[epoch 24], [iter 159 / 176], [train main loss -1.313183], [lr 0.008629] [batchtime 0.416]
[epoch 24], [iter 160 / 176], [train main loss -1.305629], [lr 0.008629] [batchtime 0.416]
[epoch 24], [iter 161 / 176], [train main loss -1.307256], [lr 0.008629] [batchtime 0.415]
[epoch 24], [iter 162 / 176], [train main loss -1.301657], [lr 0.008629] [batchtime 0.415]
[epoch 24], [iter 163 / 176], [train main loss -1.304868], [lr 0.008629] [batchtime 0.415]
[epoch 24], [iter 164 / 176], [train main loss -1.307416], [lr 0.008629] [batchtime 0.415]
[epoch 24], [iter 165 / 176], [train main loss -1.310745], [lr 0.008629] [batchtime 0.415]
[epoch 24], [iter 166 / 176], [train main loss -1.330736], [lr 0.008629] [batchtime 0.415]
[epoch 24], [iter 167 / 176], [train main loss -1.349362], [lr 0.008629] [batchtime 0.414]
[epoch 24], [iter 168 / 176], [train main loss -1.352491], [lr 0.008629] [batchtime 0.414]
[epoch 24], [iter 169 / 176], [train main loss -1.344860], [lr 0.008629] [batchtime 0.414]
[epoch 24], [iter 170 / 176], [train main loss -1.342514], [lr 0.008629] [batchtime 0.414]
[epoch 24], [iter 171 / 176], [train main loss -1.351346], [lr 0.008629] [batchtime 0.414]
[epoch 24], [iter 172 / 176], [train main loss -1.349515], [lr 0.008629] [batchtime 0.413]
[epoch 24], [iter 173 / 176], [train main loss -1.342259], [lr 0.008629] [batchtime 0.413]
[epoch 24], [iter 174 / 176], [train main loss -1.341446], [lr 0.008629] [batchtime 0.413]
[epoch 24], [iter 175 / 176], [train main loss -1.354412], [lr 0.008629] [batchtime 0.419]
[epoch 24], [iter 176 / 176], [train main loss -1.346667], [lr 0.008629] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP      FN    Precision    Recall
----  -------------  --------  -----  -------  ------  -----------  --------
   0  road              90.40  34.96     0.04    0.07         0.96      0.94
   1  sidewalk          49.06   4.19     0.57    0.47         0.64      0.68
   2  building          79.10  23.91     0.11    0.15         0.90      0.87
   3  wall               2.73   0.02    33.51    2.15         0.03      0.32
   4  fence              1.47   0.02    65.59    1.66         0.02      0.38
   5  pole              18.44   0.25     3.58    0.84         0.22      0.54
   6  traffic light      0.02   0.00  6060.23    0.33         0.00      0.75
   7  traffic sign       3.79   0.02    24.79    0.58         0.04      0.63
   8  vegetation        76.00  11.04     0.12    0.20         0.89      0.84
   9  terrain           25.25   0.29     1.53    1.43         0.40      0.41
  10  sky               90.03   3.76     0.03    0.08         0.97      0.93
  11  person            17.21   0.31     3.97    0.84         0.20      0.54
  12  rider              0.01   0.00  9503.89   17.47         0.00      0.05
  13  car               65.45   6.64     0.07    0.46         0.94      0.68
  14  truck              0.00   0.00   inf     nan            0.00    nan
  15  bus                0.00   0.00   inf     inf            0.00      0.00
  16  train              0.00   0.00   inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00   inf     nan            0.00    nan
  18  bicycle           15.79   0.08     4.02    1.32         0.20      0.43
Mean: 28.14
-----------------------------------------------------------------------------------------------------------
this : [epoch 24], [val loss 0.48363], [acc 0.85482], [acc_cls 0.33668], [mean_iu 0.28145], [fwavacc 0.75418]
best : [epoch 24], [val loss 0.48363], [acc 0.85482], [acc_cls 0.33668], [mean_iu 0.28145], [fwavacc 0.75418]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 25], [iter 1 / 176], [train main loss -2.688326], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 2 / 176], [train main loss -1.927791], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 3 / 176], [train main loss -2.871168], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 4 / 176], [train main loss -2.860937], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 5 / 176], [train main loss -3.397970], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 6 / 176], [train main loss -3.037421], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 7 / 176], [train main loss -3.156624], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 8 / 176], [train main loss -3.118608], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 9 / 176], [train main loss -2.865229], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 10 / 176], [train main loss -2.830496], [lr 0.008571] [batchtime 0]
[epoch 25], [iter 11 / 176], [train main loss -3.005276], [lr 0.008571] [batchtime 0.363]
[epoch 25], [iter 12 / 176], [train main loss -3.002780], [lr 0.008571] [batchtime 0.384]
[epoch 25], [iter 13 / 176], [train main loss -2.749189], [lr 0.008571] [batchtime 0.385]
[epoch 25], [iter 14 / 176], [train main loss -2.692368], [lr 0.008571] [batchtime 0.385]
[epoch 25], [iter 15 / 176], [train main loss -2.631401], [lr 0.008571] [batchtime 0.388]
[epoch 25], [iter 16 / 176], [train main loss -2.642351], [lr 0.008571] [batchtime 0.392]
[epoch 25], [iter 17 / 176], [train main loss -2.570994], [lr 0.008571] [batchtime 0.393]
[epoch 25], [iter 18 / 176], [train main loss -2.523053], [lr 0.008571] [batchtime 0.393]
[epoch 25], [iter 19 / 176], [train main loss -2.414219], [lr 0.008571] [batchtime 0.392]
[epoch 25], [iter 20 / 176], [train main loss -2.338806], [lr 0.008571] [batchtime 0.392]
[epoch 25], [iter 21 / 176], [train main loss -2.265590], [lr 0.008571] [batchtime 0.393]
[epoch 25], [iter 22 / 176], [train main loss -2.108239], [lr 0.008571] [batchtime 0.393]
[epoch 25], [iter 23 / 176], [train main loss -1.995783], [lr 0.008571] [batchtime 0.394]
[epoch 25], [iter 24 / 176], [train main loss -1.995859], [lr 0.008571] [batchtime 0.398]
[epoch 25], [iter 25 / 176], [train main loss -1.921242], [lr 0.008571] [batchtime 0.41]
[epoch 25], [iter 26 / 176], [train main loss -1.968947], [lr 0.008571] [batchtime 0.408]
[epoch 25], [iter 27 / 176], [train main loss -1.971231], [lr 0.008571] [batchtime 0.408]
[epoch 25], [iter 28 / 176], [train main loss -1.956894], [lr 0.008571] [batchtime 0.407]
[epoch 25], [iter 29 / 176], [train main loss -1.939150], [lr 0.008571] [batchtime 0.406]
[epoch 25], [iter 30 / 176], [train main loss -1.890357], [lr 0.008571] [batchtime 0.406]
[epoch 25], [iter 31 / 176], [train main loss -1.943653], [lr 0.008571] [batchtime 0.405]
[epoch 25], [iter 32 / 176], [train main loss -1.933793], [lr 0.008571] [batchtime 0.405]
[epoch 25], [iter 33 / 176], [train main loss -1.860508], [lr 0.008571] [batchtime 0.405]
[epoch 25], [iter 34 / 176], [train main loss -1.833417], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 35 / 176], [train main loss -1.859159], [lr 0.008571] [batchtime 0.405]
[epoch 25], [iter 36 / 176], [train main loss -1.822083], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 37 / 176], [train main loss -1.822217], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 38 / 176], [train main loss -1.746156], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 39 / 176], [train main loss -1.724437], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 40 / 176], [train main loss -1.761283], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 41 / 176], [train main loss -1.702559], [lr 0.008571] [batchtime 0.403]
[epoch 25], [iter 42 / 176], [train main loss -1.693087], [lr 0.008571] [batchtime 0.403]
[epoch 25], [iter 43 / 176], [train main loss -1.798508], [lr 0.008571] [batchtime 0.403]
[epoch 25], [iter 44 / 176], [train main loss -1.801030], [lr 0.008571] [batchtime 0.403]
[epoch 25], [iter 45 / 176], [train main loss -1.851123], [lr 0.008571] [batchtime 0.402]
[epoch 25], [iter 46 / 176], [train main loss -1.827412], [lr 0.008571] [batchtime 0.402]
[epoch 25], [iter 47 / 176], [train main loss -1.834924], [lr 0.008571] [batchtime 0.402]
[epoch 25], [iter 48 / 176], [train main loss -1.831540], [lr 0.008571] [batchtime 0.401]
[epoch 25], [iter 49 / 176], [train main loss -1.840146], [lr 0.008571] [batchtime 0.404]
[epoch 25], [iter 50 / 176], [train main loss -1.805185], [lr 0.008571] [batchtime 0.436]
[epoch 25], [iter 51 / 176], [train main loss -1.803006], [lr 0.008571] [batchtime 0.434]
[epoch 25], [iter 52 / 176], [train main loss -1.767957], [lr 0.008571] [batchtime 0.433]
[epoch 25], [iter 53 / 176], [train main loss -1.766246], [lr 0.008571] [batchtime 0.432]
[epoch 25], [iter 54 / 176], [train main loss -1.805823], [lr 0.008571] [batchtime 0.432]
[epoch 25], [iter 55 / 176], [train main loss -1.811438], [lr 0.008571] [batchtime 0.431]
[epoch 25], [iter 56 / 176], [train main loss -1.831556], [lr 0.008571] [batchtime 0.43]
[epoch 25], [iter 57 / 176], [train main loss -1.816768], [lr 0.008571] [batchtime 0.43]
[epoch 25], [iter 58 / 176], [train main loss -1.823162], [lr 0.008571] [batchtime 0.429]
[epoch 25], [iter 59 / 176], [train main loss -1.827899], [lr 0.008571] [batchtime 0.428]
[epoch 25], [iter 60 / 176], [train main loss -1.825756], [lr 0.008571] [batchtime 0.428]
[epoch 25], [iter 61 / 176], [train main loss -1.775940], [lr 0.008571] [batchtime 0.427]
[epoch 25], [iter 62 / 176], [train main loss -1.802549], [lr 0.008571] [batchtime 0.427]
[epoch 25], [iter 63 / 176], [train main loss -1.788659], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 64 / 176], [train main loss -1.759728], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 65 / 176], [train main loss -1.699399], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 66 / 176], [train main loss -1.659473], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 67 / 176], [train main loss -1.647518], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 68 / 176], [train main loss -1.632522], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 69 / 176], [train main loss -1.639764], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 70 / 176], [train main loss -1.655348], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 71 / 176], [train main loss -1.655751], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 72 / 176], [train main loss -1.687688], [lr 0.008571] [batchtime 0.427]
[epoch 25], [iter 73 / 176], [train main loss -1.696949], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 74 / 176], [train main loss -1.690223], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 75 / 176], [train main loss -1.694190], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 76 / 176], [train main loss -1.687470], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 77 / 176], [train main loss -1.723175], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 78 / 176], [train main loss -1.729571], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 79 / 176], [train main loss -1.694986], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 80 / 176], [train main loss -1.697155], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 81 / 176], [train main loss -1.667469], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 82 / 176], [train main loss -1.683163], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 83 / 176], [train main loss -1.710782], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 84 / 176], [train main loss -1.676001], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 85 / 176], [train main loss -1.664893], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 86 / 176], [train main loss -1.696585], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 87 / 176], [train main loss -1.673406], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 88 / 176], [train main loss -1.670083], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 89 / 176], [train main loss -1.695414], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 90 / 176], [train main loss -1.678705], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 91 / 176], [train main loss -1.678329], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 92 / 176], [train main loss -1.671105], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 93 / 176], [train main loss -1.655667], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 94 / 176], [train main loss -1.651085], [lr 0.008571] [batchtime 0.418]
[epoch 25], [iter 95 / 176], [train main loss -1.645593], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 96 / 176], [train main loss -1.662221], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 97 / 176], [train main loss -1.633438], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 98 / 176], [train main loss -1.623251], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 99 / 176], [train main loss -1.609089], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 100 / 176], [train main loss -1.601546], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 101 / 176], [train main loss -1.622427], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 102 / 176], [train main loss -1.604639], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 103 / 176], [train main loss -1.633818], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 104 / 176], [train main loss -1.600549], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 105 / 176], [train main loss -1.612021], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 106 / 176], [train main loss -1.586820], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 107 / 176], [train main loss -1.568806], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 108 / 176], [train main loss -1.576600], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 109 / 176], [train main loss -1.566713], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 110 / 176], [train main loss -1.578022], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 111 / 176], [train main loss -1.595425], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 112 / 176], [train main loss -1.591748], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 113 / 176], [train main loss -1.596938], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 114 / 176], [train main loss -1.616367], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 115 / 176], [train main loss -1.620488], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 116 / 176], [train main loss -1.616697], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 117 / 176], [train main loss -1.603109], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 118 / 176], [train main loss -1.613500], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 119 / 176], [train main loss -1.598532], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 120 / 176], [train main loss -1.611673], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 121 / 176], [train main loss -1.611897], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 122 / 176], [train main loss -1.608338], [lr 0.008571] [batchtime 0.421]
[epoch 25], [iter 123 / 176], [train main loss -1.600009], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 124 / 176], [train main loss -1.611374], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 125 / 176], [train main loss -1.595956], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 126 / 176], [train main loss -1.594881], [lr 0.008571] [batchtime 0.42]
[epoch 25], [iter 127 / 176], [train main loss -1.594593], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 128 / 176], [train main loss -1.586270], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 129 / 176], [train main loss -1.604600], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 130 / 176], [train main loss -1.589704], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 131 / 176], [train main loss -1.573793], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 132 / 176], [train main loss -1.577988], [lr 0.008571] [batchtime 0.419]
[epoch 25], [iter 133 / 176], [train main loss -1.555888], [lr 0.008571] [batchtime 0.418]
[epoch 25], [iter 134 / 176], [train main loss -1.554496], [lr 0.008571] [batchtime 0.418]
[epoch 25], [iter 135 / 176], [train main loss -1.585038], [lr 0.008571] [batchtime 0.418]
[epoch 25], [iter 136 / 176], [train main loss -1.576570], [lr 0.008571] [batchtime 0.418]
[epoch 25], [iter 137 / 176], [train main loss -1.581273], [lr 0.008571] [batchtime 0.418]
[epoch 25], [iter 138 / 176], [train main loss -1.594873], [lr 0.008571] [batchtime 0.417]
[epoch 25], [iter 139 / 176], [train main loss -1.613299], [lr 0.008571] [batchtime 0.417]
[epoch 25], [iter 140 / 176], [train main loss -1.615002], [lr 0.008571] [batchtime 0.417]
[epoch 25], [iter 141 / 176], [train main loss -1.631532], [lr 0.008571] [batchtime 0.417]
[epoch 25], [iter 142 / 176], [train main loss -1.619042], [lr 0.008571] [batchtime 0.417]
[epoch 25], [iter 143 / 176], [train main loss -1.612690], [lr 0.008571] [batchtime 0.416]
[epoch 25], [iter 144 / 176], [train main loss -1.600783], [lr 0.008571] [batchtime 0.417]
[epoch 25], [iter 145 / 176], [train main loss -1.578296], [lr 0.008571] [batchtime 0.427]
[epoch 25], [iter 146 / 176], [train main loss -1.572229], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 147 / 176], [train main loss -1.579242], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 148 / 176], [train main loss -1.576613], [lr 0.008571] [batchtime 0.426]
[epoch 25], [iter 149 / 176], [train main loss -1.565485], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 150 / 176], [train main loss -1.570440], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 151 / 176], [train main loss -1.566212], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 152 / 176], [train main loss -1.562024], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 153 / 176], [train main loss -1.557583], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 154 / 176], [train main loss -1.551147], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 155 / 176], [train main loss -1.545158], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 156 / 176], [train main loss -1.544436], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 157 / 176], [train main loss -1.542026], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 158 / 176], [train main loss -1.541939], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 159 / 176], [train main loss -1.540209], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 160 / 176], [train main loss -1.527692], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 161 / 176], [train main loss -1.548102], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 162 / 176], [train main loss -1.551223], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 163 / 176], [train main loss -1.546971], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 164 / 176], [train main loss -1.542218], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 165 / 176], [train main loss -1.565867], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 166 / 176], [train main loss -1.562299], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 167 / 176], [train main loss -1.565012], [lr 0.008571] [batchtime 0.425]
[epoch 25], [iter 168 / 176], [train main loss -1.570437], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 169 / 176], [train main loss -1.567334], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 170 / 176], [train main loss -1.570953], [lr 0.008571] [batchtime 0.424]
[epoch 25], [iter 171 / 176], [train main loss -1.566911], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 172 / 176], [train main loss -1.579755], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 173 / 176], [train main loss -1.573042], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 174 / 176], [train main loss -1.565723], [lr 0.008571] [batchtime 0.423]
[epoch 25], [iter 175 / 176], [train main loss -1.560511], [lr 0.008571] [batchtime 0.422]
[epoch 25], [iter 176 / 176], [train main loss -1.562254], [lr 0.008571] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              89.97  35.59      0.02    0.09         0.98      0.92
   1  sidewalk          44.74   3.59      0.83    0.40         0.54      0.71
   2  building          79.29  24.15      0.10    0.16         0.91      0.86
   3  wall               1.85   0.01     51.26    1.82         0.02      0.35
   4  fence              0.10   0.00   1002.97    1.04         0.00      0.49
   5  pole              19.86   0.27      3.23    0.80         0.24      0.55
   6  traffic light      0.03   0.00   3599.01    0.34         0.00      0.75
   7  traffic sign       4.11   0.02     22.44    0.90         0.04      0.53
   8  vegetation        74.75  11.42      0.08    0.26         0.92      0.80
   9  terrain           26.81   0.28      1.66    1.07         0.38      0.48
  10  sky               90.90   3.70      0.05    0.05         0.96      0.95
  11  person            21.13   0.39      2.93    0.81         0.25      0.55
  12  rider              0.00   0.00  34339.26   59.32         0.00      0.02
  13  car               73.05   6.26      0.13    0.24         0.88      0.81
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.00   0.00    inf     inf            0.00      0.00
  16  train              0.00   0.00    inf     nan            0.00    nan
  17  motorcycle         0.00   0.00    inf     nan            0.00    nan
  18  bicycle           18.47   0.11      2.51    1.91         0.29      0.34
Mean: 28.69
-----------------------------------------------------------------------------------------------------------
this : [epoch 25], [val loss 0.49414], [acc 0.85796], [acc_cls 0.33747], [mean_iu 0.28687], [fwavacc 0.75520]
best : [epoch 25], [val loss 0.49414], [acc 0.85796], [acc_cls 0.33747], [mean_iu 0.28687], [fwavacc 0.75520]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 26], [iter 1 / 176], [train main loss -0.056669], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 2 / 176], [train main loss 0.010708], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 3 / 176], [train main loss -1.044393], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 4 / 176], [train main loss -0.927258], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 5 / 176], [train main loss -1.277892], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 6 / 176], [train main loss -1.082527], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 7 / 176], [train main loss -0.421699], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 8 / 176], [train main loss -0.507178], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 9 / 176], [train main loss -0.735588], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 10 / 176], [train main loss -0.470859], [lr 0.008514] [batchtime 0]
[epoch 26], [iter 11 / 176], [train main loss -0.573871], [lr 0.008514] [batchtime 0.366]
[epoch 26], [iter 12 / 176], [train main loss -0.695622], [lr 0.008514] [batchtime 0.379]
[epoch 26], [iter 13 / 176], [train main loss -0.676760], [lr 0.008514] [batchtime 0.389]
[epoch 26], [iter 14 / 176], [train main loss -0.850490], [lr 0.008514] [batchtime 0.393]
[epoch 26], [iter 15 / 176], [train main loss -0.762010], [lr 0.008514] [batchtime 0.396]
[epoch 26], [iter 16 / 176], [train main loss -0.614062], [lr 0.008514] [batchtime 0.397]
[epoch 26], [iter 17 / 176], [train main loss -0.577189], [lr 0.008514] [batchtime 0.407]
[epoch 26], [iter 18 / 176], [train main loss -0.594347], [lr 0.008514] [batchtime 0.426]
[epoch 26], [iter 19 / 176], [train main loss -0.617307], [lr 0.008514] [batchtime 0.421]
[epoch 26], [iter 20 / 176], [train main loss -0.757642], [lr 0.008514] [batchtime 0.418]
[epoch 26], [iter 21 / 176], [train main loss -0.844326], [lr 0.008514] [batchtime 0.416]
[epoch 26], [iter 22 / 176], [train main loss -0.823848], [lr 0.008514] [batchtime 0.414]
[epoch 26], [iter 23 / 176], [train main loss -0.740846], [lr 0.008514] [batchtime 0.413]
[epoch 26], [iter 24 / 176], [train main loss -0.769441], [lr 0.008514] [batchtime 0.412]
[epoch 26], [iter 25 / 176], [train main loss -0.789707], [lr 0.008514] [batchtime 0.411]
[epoch 26], [iter 26 / 176], [train main loss -0.812558], [lr 0.008514] [batchtime 0.41]
[epoch 26], [iter 27 / 176], [train main loss -0.847696], [lr 0.008514] [batchtime 0.409]
[epoch 26], [iter 28 / 176], [train main loss -0.799277], [lr 0.008514] [batchtime 0.409]
[epoch 26], [iter 29 / 176], [train main loss -0.910137], [lr 0.008514] [batchtime 0.416]
[epoch 26], [iter 30 / 176], [train main loss -0.947654], [lr 0.008514] [batchtime 0.462]
[epoch 26], [iter 31 / 176], [train main loss -1.034520], [lr 0.008514] [batchtime 0.458]
[epoch 26], [iter 32 / 176], [train main loss -1.093586], [lr 0.008514] [batchtime 0.454]
[epoch 26], [iter 33 / 176], [train main loss -1.130636], [lr 0.008514] [batchtime 0.452]
[epoch 26], [iter 34 / 176], [train main loss -1.189133], [lr 0.008514] [batchtime 0.449]
[epoch 26], [iter 35 / 176], [train main loss -1.147798], [lr 0.008514] [batchtime 0.447]
[epoch 26], [iter 36 / 176], [train main loss -1.233162], [lr 0.008514] [batchtime 0.445]
[epoch 26], [iter 37 / 176], [train main loss -1.210503], [lr 0.008514] [batchtime 0.443]
[epoch 26], [iter 38 / 176], [train main loss -1.292745], [lr 0.008514] [batchtime 0.441]
[epoch 26], [iter 39 / 176], [train main loss -1.348336], [lr 0.008514] [batchtime 0.44]
[epoch 26], [iter 40 / 176], [train main loss -1.324907], [lr 0.008514] [batchtime 0.446]
[epoch 26], [iter 41 / 176], [train main loss -1.339951], [lr 0.008514] [batchtime 0.444]
[epoch 26], [iter 42 / 176], [train main loss -1.415366], [lr 0.008514] [batchtime 0.443]
[epoch 26], [iter 43 / 176], [train main loss -1.365041], [lr 0.008514] [batchtime 0.441]
[epoch 26], [iter 44 / 176], [train main loss -1.358520], [lr 0.008514] [batchtime 0.439]
[epoch 26], [iter 45 / 176], [train main loss -1.338145], [lr 0.008514] [batchtime 0.438]
[epoch 26], [iter 46 / 176], [train main loss -1.345922], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 47 / 176], [train main loss -1.371616], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 48 / 176], [train main loss -1.452779], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 49 / 176], [train main loss -1.458817], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 50 / 176], [train main loss -1.397115], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 51 / 176], [train main loss -1.370059], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 52 / 176], [train main loss -1.395701], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 53 / 176], [train main loss -1.374985], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 54 / 176], [train main loss -1.437429], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 55 / 176], [train main loss -1.432966], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 56 / 176], [train main loss -1.391046], [lr 0.008514] [batchtime 0.427]
[epoch 26], [iter 57 / 176], [train main loss -1.392002], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 58 / 176], [train main loss -1.304251], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 59 / 176], [train main loss -1.277945], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 60 / 176], [train main loss -1.273172], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 61 / 176], [train main loss -1.296796], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 62 / 176], [train main loss -1.310388], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 63 / 176], [train main loss -1.334450], [lr 0.008514] [batchtime 0.427]
[epoch 26], [iter 64 / 176], [train main loss -1.336556], [lr 0.008514] [batchtime 0.449]
[epoch 26], [iter 65 / 176], [train main loss -1.319537], [lr 0.008514] [batchtime 0.454]
[epoch 26], [iter 66 / 176], [train main loss -1.284903], [lr 0.008514] [batchtime 0.452]
[epoch 26], [iter 67 / 176], [train main loss -1.307212], [lr 0.008514] [batchtime 0.451]
[epoch 26], [iter 68 / 176], [train main loss -1.261086], [lr 0.008514] [batchtime 0.45]
[epoch 26], [iter 69 / 176], [train main loss -1.215611], [lr 0.008514] [batchtime 0.449]
[epoch 26], [iter 70 / 176], [train main loss -1.176685], [lr 0.008514] [batchtime 0.448]
[epoch 26], [iter 71 / 176], [train main loss -1.193143], [lr 0.008514] [batchtime 0.447]
[epoch 26], [iter 72 / 176], [train main loss -1.201521], [lr 0.008514] [batchtime 0.446]
[epoch 26], [iter 73 / 176], [train main loss -1.200945], [lr 0.008514] [batchtime 0.446]
[epoch 26], [iter 74 / 176], [train main loss -1.187987], [lr 0.008514] [batchtime 0.445]
[epoch 26], [iter 75 / 176], [train main loss -1.230615], [lr 0.008514] [batchtime 0.444]
[epoch 26], [iter 76 / 176], [train main loss -1.238486], [lr 0.008514] [batchtime 0.443]
[epoch 26], [iter 77 / 176], [train main loss -1.240100], [lr 0.008514] [batchtime 0.443]
[epoch 26], [iter 78 / 176], [train main loss -1.242657], [lr 0.008514] [batchtime 0.442]
[epoch 26], [iter 79 / 176], [train main loss -1.278824], [lr 0.008514] [batchtime 0.441]
[epoch 26], [iter 80 / 176], [train main loss -1.271416], [lr 0.008514] [batchtime 0.44]
[epoch 26], [iter 81 / 176], [train main loss -1.241219], [lr 0.008514] [batchtime 0.44]
[epoch 26], [iter 82 / 176], [train main loss -1.238441], [lr 0.008514] [batchtime 0.439]
[epoch 26], [iter 83 / 176], [train main loss -1.253130], [lr 0.008514] [batchtime 0.438]
[epoch 26], [iter 84 / 176], [train main loss -1.267207], [lr 0.008514] [batchtime 0.438]
[epoch 26], [iter 85 / 176], [train main loss -1.253305], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 86 / 176], [train main loss -1.247698], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 87 / 176], [train main loss -1.239134], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 88 / 176], [train main loss -1.250734], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 89 / 176], [train main loss -1.271697], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 90 / 176], [train main loss -1.275658], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 91 / 176], [train main loss -1.282529], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 92 / 176], [train main loss -1.295116], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 93 / 176], [train main loss -1.298017], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 94 / 176], [train main loss -1.311995], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 95 / 176], [train main loss -1.327606], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 96 / 176], [train main loss -1.347659], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 97 / 176], [train main loss -1.365758], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 98 / 176], [train main loss -1.344799], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 99 / 176], [train main loss -1.370916], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 100 / 176], [train main loss -1.348050], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 101 / 176], [train main loss -1.340448], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 102 / 176], [train main loss -1.320561], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 103 / 176], [train main loss -1.333322], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 104 / 176], [train main loss -1.323452], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 105 / 176], [train main loss -1.294888], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 106 / 176], [train main loss -1.342492], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 107 / 176], [train main loss -1.365826], [lr 0.008514] [batchtime 0.427]
[epoch 26], [iter 108 / 176], [train main loss -1.356014], [lr 0.008514] [batchtime 0.427]
[epoch 26], [iter 109 / 176], [train main loss -1.352287], [lr 0.008514] [batchtime 0.427]
[epoch 26], [iter 110 / 176], [train main loss -1.355326], [lr 0.008514] [batchtime 0.427]
[epoch 26], [iter 111 / 176], [train main loss -1.347095], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 112 / 176], [train main loss -1.346963], [lr 0.008514] [batchtime 0.443]
[epoch 26], [iter 113 / 176], [train main loss -1.349800], [lr 0.008514] [batchtime 0.442]
[epoch 26], [iter 114 / 176], [train main loss -1.348315], [lr 0.008514] [batchtime 0.441]
[epoch 26], [iter 115 / 176], [train main loss -1.340625], [lr 0.008514] [batchtime 0.441]
[epoch 26], [iter 116 / 176], [train main loss -1.340181], [lr 0.008514] [batchtime 0.44]
[epoch 26], [iter 117 / 176], [train main loss -1.332611], [lr 0.008514] [batchtime 0.44]
[epoch 26], [iter 118 / 176], [train main loss -1.317512], [lr 0.008514] [batchtime 0.44]
[epoch 26], [iter 119 / 176], [train main loss -1.322795], [lr 0.008514] [batchtime 0.439]
[epoch 26], [iter 120 / 176], [train main loss -1.349875], [lr 0.008514] [batchtime 0.439]
[epoch 26], [iter 121 / 176], [train main loss -1.357221], [lr 0.008514] [batchtime 0.438]
[epoch 26], [iter 122 / 176], [train main loss -1.353256], [lr 0.008514] [batchtime 0.438]
[epoch 26], [iter 123 / 176], [train main loss -1.357280], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 124 / 176], [train main loss -1.348923], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 125 / 176], [train main loss -1.370741], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 126 / 176], [train main loss -1.370944], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 127 / 176], [train main loss -1.386577], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 128 / 176], [train main loss -1.375066], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 129 / 176], [train main loss -1.370323], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 130 / 176], [train main loss -1.363591], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 131 / 176], [train main loss -1.349611], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 132 / 176], [train main loss -1.349357], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 133 / 176], [train main loss -1.342004], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 134 / 176], [train main loss -1.338532], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 135 / 176], [train main loss -1.340628], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 136 / 176], [train main loss -1.329514], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 137 / 176], [train main loss -1.342640], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 138 / 176], [train main loss -1.329016], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 139 / 176], [train main loss -1.332049], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 140 / 176], [train main loss -1.321507], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 141 / 176], [train main loss -1.331531], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 142 / 176], [train main loss -1.325603], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 143 / 176], [train main loss -1.331897], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 144 / 176], [train main loss -1.348859], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 145 / 176], [train main loss -1.354659], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 146 / 176], [train main loss -1.349513], [lr 0.008514] [batchtime 0.431]
[epoch 26], [iter 147 / 176], [train main loss -1.359519], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 148 / 176], [train main loss -1.365221], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 149 / 176], [train main loss -1.370985], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 150 / 176], [train main loss -1.369825], [lr 0.008514] [batchtime 0.43]
[epoch 26], [iter 151 / 176], [train main loss -1.377633], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 152 / 176], [train main loss -1.394372], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 153 / 176], [train main loss -1.381890], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 154 / 176], [train main loss -1.366622], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 155 / 176], [train main loss -1.374708], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 156 / 176], [train main loss -1.379356], [lr 0.008514] [batchtime 0.428]
[epoch 26], [iter 157 / 176], [train main loss -1.383185], [lr 0.008514] [batchtime 0.429]
[epoch 26], [iter 158 / 176], [train main loss -1.393512], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 159 / 176], [train main loss -1.413732], [lr 0.008514] [batchtime 0.437]
[epoch 26], [iter 160 / 176], [train main loss -1.421117], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 161 / 176], [train main loss -1.428682], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 162 / 176], [train main loss -1.428250], [lr 0.008514] [batchtime 0.436]
[epoch 26], [iter 163 / 176], [train main loss -1.437204], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 164 / 176], [train main loss -1.446363], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 165 / 176], [train main loss -1.443292], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 166 / 176], [train main loss -1.434023], [lr 0.008514] [batchtime 0.435]
[epoch 26], [iter 167 / 176], [train main loss -1.447041], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 168 / 176], [train main loss -1.442374], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 169 / 176], [train main loss -1.426539], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 170 / 176], [train main loss -1.414855], [lr 0.008514] [batchtime 0.434]
[epoch 26], [iter 171 / 176], [train main loss -1.424529], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 172 / 176], [train main loss -1.434642], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 173 / 176], [train main loss -1.420746], [lr 0.008514] [batchtime 0.433]
[epoch 26], [iter 174 / 176], [train main loss -1.426536], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 175 / 176], [train main loss -1.420222], [lr 0.008514] [batchtime 0.432]
[epoch 26], [iter 176 / 176], [train main loss -1.411439], [lr 0.008514] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              90.49  35.35      0.03    0.08         0.97      0.93
   1  sidewalk          47.04   3.89      0.69    0.43         0.59      0.70
   2  building          78.97  24.33      0.09    0.17         0.92      0.85
   3  wall               1.97   0.01     47.48    2.40         0.02      0.29
   4  fence              0.20   0.00    488.07    0.89         0.00      0.53
   5  pole              18.37   0.24      3.74    0.71         0.21      0.59
   6  traffic light      0.08   0.00   1228.82    0.21         0.00      0.82
   7  traffic sign       2.60   0.01     36.84    0.58         0.03      0.63
   8  vegetation        75.48  11.27      0.10    0.23         0.91      0.81
   9  terrain           25.25   0.22      2.27    0.69         0.31      0.59
  10  sky               90.49   3.65      0.06    0.04         0.94      0.96
  11  person            23.10   0.45      2.44    0.89         0.29      0.53
  12  rider              0.00   0.00  30414.66   66.17         0.00      0.01
  13  car               71.93   6.37      0.11    0.28         0.90      0.78
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.00   0.00  42547.29   22.21         0.00      0.04
  16  train              0.00   0.00    inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00    inf     nan            0.00    nan
  18  bicycle           19.68   0.11      2.44    1.64         0.29      0.38
Mean: 28.72
-----------------------------------------------------------------------------------------------------------
this : [epoch 26], [val loss 0.49661], [acc 0.85917], [acc_cls 0.33581], [mean_iu 0.28718], [fwavacc 0.75771]
best : [epoch 26], [val loss 0.49661], [acc 0.85917], [acc_cls 0.33581], [mean_iu 0.28718], [fwavacc 0.75771]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 27], [iter 1 / 176], [train main loss -1.736497], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 2 / 176], [train main loss -1.151300], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 3 / 176], [train main loss -1.661902], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 4 / 176], [train main loss -1.639634], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 5 / 176], [train main loss -1.645850], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 6 / 176], [train main loss -1.856319], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 7 / 176], [train main loss -1.523139], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 8 / 176], [train main loss -1.964986], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 9 / 176], [train main loss -2.347064], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 10 / 176], [train main loss -2.365277], [lr 0.008457] [batchtime 0]
[epoch 27], [iter 11 / 176], [train main loss -2.307112], [lr 0.008457] [batchtime 0.474]
[epoch 27], [iter 12 / 176], [train main loss -2.301991], [lr 0.008457] [batchtime 0.436]
[epoch 27], [iter 13 / 176], [train main loss -2.130482], [lr 0.008457] [batchtime 0.422]
[epoch 27], [iter 14 / 176], [train main loss -1.982298], [lr 0.008457] [batchtime 0.417]
[epoch 27], [iter 15 / 176], [train main loss -2.042625], [lr 0.008457] [batchtime 0.412]
[epoch 27], [iter 16 / 176], [train main loss -1.992441], [lr 0.008457] [batchtime 0.412]
[epoch 27], [iter 17 / 176], [train main loss -2.027872], [lr 0.008457] [batchtime 0.539]
[epoch 27], [iter 18 / 176], [train main loss -2.069940], [lr 0.008457] [batchtime 0.522]
[epoch 27], [iter 19 / 176], [train main loss -2.055905], [lr 0.008457] [batchtime 0.507]
[epoch 27], [iter 20 / 176], [train main loss -2.075259], [lr 0.008457] [batchtime 0.496]
[epoch 27], [iter 21 / 176], [train main loss -2.093728], [lr 0.008457] [batchtime 0.486]
[epoch 27], [iter 22 / 176], [train main loss -2.047863], [lr 0.008457] [batchtime 0.479]
[epoch 27], [iter 23 / 176], [train main loss -2.056607], [lr 0.008457] [batchtime 0.473]
[epoch 27], [iter 24 / 176], [train main loss -2.233258], [lr 0.008457] [batchtime 0.468]
[epoch 27], [iter 25 / 176], [train main loss -2.296978], [lr 0.008457] [batchtime 0.463]
[epoch 27], [iter 26 / 176], [train main loss -2.208578], [lr 0.008457] [batchtime 0.459]
[epoch 27], [iter 27 / 176], [train main loss -2.182997], [lr 0.008457] [batchtime 0.455]
[epoch 27], [iter 28 / 176], [train main loss -2.067880], [lr 0.008457] [batchtime 0.453]
[epoch 27], [iter 29 / 176], [train main loss -2.064035], [lr 0.008457] [batchtime 0.45]
[epoch 27], [iter 30 / 176], [train main loss -2.050510], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 31 / 176], [train main loss -1.971675], [lr 0.008457] [batchtime 0.466]
[epoch 27], [iter 32 / 176], [train main loss -2.005672], [lr 0.008457] [batchtime 0.529]
[epoch 27], [iter 33 / 176], [train main loss -1.891207], [lr 0.008457] [batchtime 0.523]
[epoch 27], [iter 34 / 176], [train main loss -1.898336], [lr 0.008457] [batchtime 0.517]
[epoch 27], [iter 35 / 176], [train main loss -1.986689], [lr 0.008457] [batchtime 0.513]
[epoch 27], [iter 36 / 176], [train main loss -1.960034], [lr 0.008457] [batchtime 0.508]
[epoch 27], [iter 37 / 176], [train main loss -2.019327], [lr 0.008457] [batchtime 0.504]
[epoch 27], [iter 38 / 176], [train main loss -1.998198], [lr 0.008457] [batchtime 0.5]
[epoch 27], [iter 39 / 176], [train main loss -1.968794], [lr 0.008457] [batchtime 0.496]
[epoch 27], [iter 40 / 176], [train main loss -2.038720], [lr 0.008457] [batchtime 0.494]
[epoch 27], [iter 41 / 176], [train main loss -2.004276], [lr 0.008457] [batchtime 0.491]
[epoch 27], [iter 42 / 176], [train main loss -1.970207], [lr 0.008457] [batchtime 0.488]
[epoch 27], [iter 43 / 176], [train main loss -1.950230], [lr 0.008457] [batchtime 0.485]
[epoch 27], [iter 44 / 176], [train main loss -1.971021], [lr 0.008457] [batchtime 0.483]
[epoch 27], [iter 45 / 176], [train main loss -1.968835], [lr 0.008457] [batchtime 0.48]
[epoch 27], [iter 46 / 176], [train main loss -1.951171], [lr 0.008457] [batchtime 0.478]
[epoch 27], [iter 47 / 176], [train main loss -1.936358], [lr 0.008457] [batchtime 0.477]
[epoch 27], [iter 48 / 176], [train main loss -1.965124], [lr 0.008457] [batchtime 0.474]
[epoch 27], [iter 49 / 176], [train main loss -1.914463], [lr 0.008457] [batchtime 0.472]
[epoch 27], [iter 50 / 176], [train main loss -1.881381], [lr 0.008457] [batchtime 0.47]
[epoch 27], [iter 51 / 176], [train main loss -1.885938], [lr 0.008457] [batchtime 0.469]
[epoch 27], [iter 52 / 176], [train main loss -1.896319], [lr 0.008457] [batchtime 0.467]
[epoch 27], [iter 53 / 176], [train main loss -1.875133], [lr 0.008457] [batchtime 0.466]
[epoch 27], [iter 54 / 176], [train main loss -1.798821], [lr 0.008457] [batchtime 0.465]
[epoch 27], [iter 55 / 176], [train main loss -1.792129], [lr 0.008457] [batchtime 0.463]
[epoch 27], [iter 56 / 176], [train main loss -1.844834], [lr 0.008457] [batchtime 0.462]
[epoch 27], [iter 57 / 176], [train main loss -1.833963], [lr 0.008457] [batchtime 0.46]
[epoch 27], [iter 58 / 176], [train main loss -1.893750], [lr 0.008457] [batchtime 0.459]
[epoch 27], [iter 59 / 176], [train main loss -1.850055], [lr 0.008457] [batchtime 0.458]
[epoch 27], [iter 60 / 176], [train main loss -1.832193], [lr 0.008457] [batchtime 0.457]
[epoch 27], [iter 61 / 176], [train main loss -1.872962], [lr 0.008457] [batchtime 0.455]
[epoch 27], [iter 62 / 176], [train main loss -1.897948], [lr 0.008457] [batchtime 0.455]
[epoch 27], [iter 63 / 176], [train main loss -1.887942], [lr 0.008457] [batchtime 0.454]
[epoch 27], [iter 64 / 176], [train main loss -1.864676], [lr 0.008457] [batchtime 0.453]
[epoch 27], [iter 65 / 176], [train main loss -1.896169], [lr 0.008457] [batchtime 0.452]
[epoch 27], [iter 66 / 176], [train main loss -1.931082], [lr 0.008457] [batchtime 0.451]
[epoch 27], [iter 67 / 176], [train main loss -1.919986], [lr 0.008457] [batchtime 0.45]
[epoch 27], [iter 68 / 176], [train main loss -1.935671], [lr 0.008457] [batchtime 0.449]
[epoch 27], [iter 69 / 176], [train main loss -1.945457], [lr 0.008457] [batchtime 0.448]
[epoch 27], [iter 70 / 176], [train main loss -1.940829], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 71 / 176], [train main loss -1.929887], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 72 / 176], [train main loss -1.952065], [lr 0.008457] [batchtime 0.446]
[epoch 27], [iter 73 / 176], [train main loss -1.954653], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 74 / 176], [train main loss -1.983019], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 75 / 176], [train main loss -1.990152], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 76 / 176], [train main loss -1.942983], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 77 / 176], [train main loss -1.939816], [lr 0.008457] [batchtime 0.456]
[epoch 27], [iter 78 / 176], [train main loss -1.941954], [lr 0.008457] [batchtime 0.457]
[epoch 27], [iter 79 / 176], [train main loss -1.920990], [lr 0.008457] [batchtime 0.456]
[epoch 27], [iter 80 / 176], [train main loss -1.933327], [lr 0.008457] [batchtime 0.456]
[epoch 27], [iter 81 / 176], [train main loss -1.904900], [lr 0.008457] [batchtime 0.455]
[epoch 27], [iter 82 / 176], [train main loss -1.918794], [lr 0.008457] [batchtime 0.454]
[epoch 27], [iter 83 / 176], [train main loss -1.941876], [lr 0.008457] [batchtime 0.453]
[epoch 27], [iter 84 / 176], [train main loss -1.970478], [lr 0.008457] [batchtime 0.452]
[epoch 27], [iter 85 / 176], [train main loss -1.957325], [lr 0.008457] [batchtime 0.452]
[epoch 27], [iter 86 / 176], [train main loss -1.983522], [lr 0.008457] [batchtime 0.451]
[epoch 27], [iter 87 / 176], [train main loss -1.969875], [lr 0.008457] [batchtime 0.45]
[epoch 27], [iter 88 / 176], [train main loss -1.998439], [lr 0.008457] [batchtime 0.45]
[epoch 27], [iter 89 / 176], [train main loss -1.978211], [lr 0.008457] [batchtime 0.449]
[epoch 27], [iter 90 / 176], [train main loss -1.959659], [lr 0.008457] [batchtime 0.448]
[epoch 27], [iter 91 / 176], [train main loss -1.933169], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 92 / 176], [train main loss -1.929276], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 93 / 176], [train main loss -1.922045], [lr 0.008457] [batchtime 0.446]
[epoch 27], [iter 94 / 176], [train main loss -1.914442], [lr 0.008457] [batchtime 0.446]
[epoch 27], [iter 95 / 176], [train main loss -1.904409], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 96 / 176], [train main loss -1.887495], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 97 / 176], [train main loss -1.883779], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 98 / 176], [train main loss -1.880960], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 99 / 176], [train main loss -1.870744], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 100 / 176], [train main loss -1.872291], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 101 / 176], [train main loss -1.847916], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 102 / 176], [train main loss -1.865405], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 103 / 176], [train main loss -1.861308], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 104 / 176], [train main loss -1.840759], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 105 / 176], [train main loss -1.833754], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 106 / 176], [train main loss -1.834428], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 107 / 176], [train main loss -1.855208], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 108 / 176], [train main loss -1.846164], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 109 / 176], [train main loss -1.851089], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 110 / 176], [train main loss -1.862862], [lr 0.008457] [batchtime 0.44]
[epoch 27], [iter 111 / 176], [train main loss -1.853566], [lr 0.008457] [batchtime 0.44]
[epoch 27], [iter 112 / 176], [train main loss -1.847654], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 113 / 176], [train main loss -1.820347], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 114 / 176], [train main loss -1.839829], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 115 / 176], [train main loss -1.826165], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 116 / 176], [train main loss -1.821966], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 117 / 176], [train main loss -1.793266], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 118 / 176], [train main loss -1.818100], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 119 / 176], [train main loss -1.816236], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 120 / 176], [train main loss -1.820801], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 121 / 176], [train main loss -1.843854], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 122 / 176], [train main loss -1.840618], [lr 0.008457] [batchtime 0.437]
[epoch 27], [iter 123 / 176], [train main loss -1.852472], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 124 / 176], [train main loss -1.831742], [lr 0.008457] [batchtime 0.45]
[epoch 27], [iter 125 / 176], [train main loss -1.870698], [lr 0.008457] [batchtime 0.449]
[epoch 27], [iter 126 / 176], [train main loss -1.873016], [lr 0.008457] [batchtime 0.449]
[epoch 27], [iter 127 / 176], [train main loss -1.877863], [lr 0.008457] [batchtime 0.448]
[epoch 27], [iter 128 / 176], [train main loss -1.869528], [lr 0.008457] [batchtime 0.448]
[epoch 27], [iter 129 / 176], [train main loss -1.861807], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 130 / 176], [train main loss -1.853954], [lr 0.008457] [batchtime 0.447]
[epoch 27], [iter 131 / 176], [train main loss -1.852456], [lr 0.008457] [batchtime 0.446]
[epoch 27], [iter 132 / 176], [train main loss -1.841158], [lr 0.008457] [batchtime 0.446]
[epoch 27], [iter 133 / 176], [train main loss -1.844045], [lr 0.008457] [batchtime 0.446]
[epoch 27], [iter 134 / 176], [train main loss -1.861265], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 135 / 176], [train main loss -1.850999], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 136 / 176], [train main loss -1.867328], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 137 / 176], [train main loss -1.879626], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 138 / 176], [train main loss -1.879479], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 139 / 176], [train main loss -1.881456], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 140 / 176], [train main loss -1.880796], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 141 / 176], [train main loss -1.876147], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 142 / 176], [train main loss -1.869302], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 143 / 176], [train main loss -1.857477], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 144 / 176], [train main loss -1.842582], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 145 / 176], [train main loss -1.837606], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 146 / 176], [train main loss -1.814708], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 147 / 176], [train main loss -1.807504], [lr 0.008457] [batchtime 0.442]
[epoch 27], [iter 148 / 176], [train main loss -1.802797], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 149 / 176], [train main loss -1.815211], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 150 / 176], [train main loss -1.815061], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 151 / 176], [train main loss -1.794472], [lr 0.008457] [batchtime 0.441]
[epoch 27], [iter 152 / 176], [train main loss -1.806746], [lr 0.008457] [batchtime 0.44]
[epoch 27], [iter 153 / 176], [train main loss -1.803040], [lr 0.008457] [batchtime 0.44]
[epoch 27], [iter 154 / 176], [train main loss -1.815201], [lr 0.008457] [batchtime 0.44]
[epoch 27], [iter 155 / 176], [train main loss -1.824812], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 156 / 176], [train main loss -1.818394], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 157 / 176], [train main loss -1.821886], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 158 / 176], [train main loss -1.824554], [lr 0.008457] [batchtime 0.439]
[epoch 27], [iter 159 / 176], [train main loss -1.855054], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 160 / 176], [train main loss -1.831386], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 161 / 176], [train main loss -1.814224], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 162 / 176], [train main loss -1.811116], [lr 0.008457] [batchtime 0.438]
[epoch 27], [iter 163 / 176], [train main loss -1.807018], [lr 0.008457] [batchtime 0.437]
[epoch 27], [iter 164 / 176], [train main loss -1.791864], [lr 0.008457] [batchtime 0.437]
[epoch 27], [iter 165 / 176], [train main loss -1.799699], [lr 0.008457] [batchtime 0.437]
[epoch 27], [iter 166 / 176], [train main loss -1.789772], [lr 0.008457] [batchtime 0.436]
[epoch 27], [iter 167 / 176], [train main loss -1.791877], [lr 0.008457] [batchtime 0.436]
[epoch 27], [iter 168 / 176], [train main loss -1.771104], [lr 0.008457] [batchtime 0.436]
[epoch 27], [iter 169 / 176], [train main loss -1.774641], [lr 0.008457] [batchtime 0.436]
[epoch 27], [iter 170 / 176], [train main loss -1.765077], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 171 / 176], [train main loss -1.782601], [lr 0.008457] [batchtime 0.445]
[epoch 27], [iter 172 / 176], [train main loss -1.785171], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 173 / 176], [train main loss -1.773548], [lr 0.008457] [batchtime 0.444]
[epoch 27], [iter 174 / 176], [train main loss -1.760400], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 175 / 176], [train main loss -1.752868], [lr 0.008457] [batchtime 0.443]
[epoch 27], [iter 176 / 176], [train main loss -1.739976], [lr 0.008457] [batchtime 0.443]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              90.99  35.37      0.03    0.07         0.97      0.93
   1  sidewalk          50.35   4.18      0.58    0.41         0.63      0.71
   2  building          79.59  23.91      0.11    0.14         0.90      0.87
   3  wall               3.12   0.02     28.57    2.51         0.03      0.28
   4  fence              0.87   0.01    113.12    1.38         0.01      0.42
   5  pole              21.79   0.30      2.78    0.81         0.26      0.55
   6  traffic light      0.11   0.00    927.13    0.53         0.00      0.66
   7  traffic sign       3.65   0.02     25.69    0.71         0.04      0.59
   8  vegetation        75.44  11.43      0.08    0.24         0.92      0.80
   9  terrain           27.29   0.30      1.44    1.23         0.41      0.45
  10  sky               91.54   3.72      0.04    0.05         0.96      0.95
  11  person            25.80   0.51      1.99    0.89         0.33      0.53
  12  rider              0.00   0.00  56027.84   71.53         0.00      0.01
  13  car               72.92   6.43      0.10    0.27         0.91      0.79
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.00   0.00    inf     inf            0.00      0.00
  16  train              0.00   0.00    inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00    inf     nan            0.00    nan
  18  bicycle           19.79   0.11      2.66    1.39         0.27      0.42
Mean: 29.64
-----------------------------------------------------------------------------------------------------------
this : [epoch 27], [val loss 0.47682], [acc 0.86304], [acc_cls 0.35066], [mean_iu 0.29644], [fwavacc 0.76557]
best : [epoch 27], [val loss 0.47682], [acc 0.86304], [acc_cls 0.35066], [mean_iu 0.29644], [fwavacc 0.76557]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 28], [iter 1 / 176], [train main loss -0.146169], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 2 / 176], [train main loss -1.034929], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 3 / 176], [train main loss -1.097504], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 4 / 176], [train main loss -1.061303], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 5 / 176], [train main loss -0.979796], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 6 / 176], [train main loss -0.953567], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 7 / 176], [train main loss -1.035920], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 8 / 176], [train main loss -0.813391], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 9 / 176], [train main loss -0.748500], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 10 / 176], [train main loss -0.901253], [lr 0.008400] [batchtime 0]
[epoch 28], [iter 11 / 176], [train main loss -0.973432], [lr 0.008400] [batchtime 0.368]
[epoch 28], [iter 12 / 176], [train main loss -0.940592], [lr 0.008400] [batchtime 0.39]
[epoch 28], [iter 13 / 176], [train main loss -0.934553], [lr 0.008400] [batchtime 0.388]
[epoch 28], [iter 14 / 176], [train main loss -0.902574], [lr 0.008400] [batchtime 0.39]
[epoch 28], [iter 15 / 176], [train main loss -1.074731], [lr 0.008400] [batchtime 0.39]
[epoch 28], [iter 16 / 176], [train main loss -0.917318], [lr 0.008400] [batchtime 0.391]
[epoch 28], [iter 17 / 176], [train main loss -0.845446], [lr 0.008400] [batchtime 0.393]
[epoch 28], [iter 18 / 176], [train main loss -0.875208], [lr 0.008400] [batchtime 0.401]
[epoch 28], [iter 19 / 176], [train main loss -1.079475], [lr 0.008400] [batchtime 0.418]
[epoch 28], [iter 20 / 176], [train main loss -1.070670], [lr 0.008400] [batchtime 0.416]
[epoch 28], [iter 21 / 176], [train main loss -1.206861], [lr 0.008400] [batchtime 0.414]
[epoch 28], [iter 22 / 176], [train main loss -1.250503], [lr 0.008400] [batchtime 0.412]
[epoch 28], [iter 23 / 176], [train main loss -1.183256], [lr 0.008400] [batchtime 0.411]
[epoch 28], [iter 24 / 176], [train main loss -1.160060], [lr 0.008400] [batchtime 0.41]
[epoch 28], [iter 25 / 176], [train main loss -1.062268], [lr 0.008400] [batchtime 0.409]
[epoch 28], [iter 26 / 176], [train main loss -1.099977], [lr 0.008400] [batchtime 0.408]
[epoch 28], [iter 27 / 176], [train main loss -1.181097], [lr 0.008400] [batchtime 0.408]
[epoch 28], [iter 28 / 176], [train main loss -1.254840], [lr 0.008400] [batchtime 0.407]
[epoch 28], [iter 29 / 176], [train main loss -1.159389], [lr 0.008400] [batchtime 0.406]
[epoch 28], [iter 30 / 176], [train main loss -1.173714], [lr 0.008400] [batchtime 0.406]
[epoch 28], [iter 31 / 176], [train main loss -1.180175], [lr 0.008400] [batchtime 0.405]
[epoch 28], [iter 32 / 176], [train main loss -1.166855], [lr 0.008400] [batchtime 0.405]
[epoch 28], [iter 33 / 176], [train main loss -1.230010], [lr 0.008400] [batchtime 0.404]
[epoch 28], [iter 34 / 176], [train main loss -1.260983], [lr 0.008400] [batchtime 0.404]
[epoch 28], [iter 35 / 176], [train main loss -1.240417], [lr 0.008400] [batchtime 0.404]
[epoch 28], [iter 36 / 176], [train main loss -1.336808], [lr 0.008400] [batchtime 0.403]
[epoch 28], [iter 37 / 176], [train main loss -1.325240], [lr 0.008400] [batchtime 0.402]
[epoch 28], [iter 38 / 176], [train main loss -1.375623], [lr 0.008400] [batchtime 0.402]
[epoch 28], [iter 39 / 176], [train main loss -1.332562], [lr 0.008400] [batchtime 0.402]
[epoch 28], [iter 40 / 176], [train main loss -1.325573], [lr 0.008400] [batchtime 0.402]
[epoch 28], [iter 41 / 176], [train main loss -1.272488], [lr 0.008400] [batchtime 0.402]
[epoch 28], [iter 42 / 176], [train main loss -1.323955], [lr 0.008400] [batchtime 0.401]
[epoch 28], [iter 43 / 176], [train main loss -1.359341], [lr 0.008400] [batchtime 0.405]
[epoch 28], [iter 44 / 176], [train main loss -1.425705], [lr 0.008400] [batchtime 0.437]
[epoch 28], [iter 45 / 176], [train main loss -1.464587], [lr 0.008400] [batchtime 0.436]
[epoch 28], [iter 46 / 176], [train main loss -1.517010], [lr 0.008400] [batchtime 0.434]
[epoch 28], [iter 47 / 176], [train main loss -1.530725], [lr 0.008400] [batchtime 0.433]
[epoch 28], [iter 48 / 176], [train main loss -1.548437], [lr 0.008400] [batchtime 0.432]
[epoch 28], [iter 49 / 176], [train main loss -1.592078], [lr 0.008400] [batchtime 0.431]
[epoch 28], [iter 50 / 176], [train main loss -1.602622], [lr 0.008400] [batchtime 0.43]
[epoch 28], [iter 51 / 176], [train main loss -1.556759], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 52 / 176], [train main loss -1.588635], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 53 / 176], [train main loss -1.620116], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 54 / 176], [train main loss -1.642833], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 55 / 176], [train main loss -1.659544], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 56 / 176], [train main loss -1.596496], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 57 / 176], [train main loss -1.587944], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 58 / 176], [train main loss -1.554468], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 59 / 176], [train main loss -1.526525], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 60 / 176], [train main loss -1.604084], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 61 / 176], [train main loss -1.651938], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 62 / 176], [train main loss -1.676140], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 63 / 176], [train main loss -1.653116], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 64 / 176], [train main loss -1.637622], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 65 / 176], [train main loss -1.658606], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 66 / 176], [train main loss -1.670410], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 67 / 176], [train main loss -1.707462], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 68 / 176], [train main loss -1.693093], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 69 / 176], [train main loss -1.699874], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 70 / 176], [train main loss -1.671112], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 71 / 176], [train main loss -1.616279], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 72 / 176], [train main loss -1.614951], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 73 / 176], [train main loss -1.617686], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 74 / 176], [train main loss -1.578037], [lr 0.008400] [batchtime 0.421]
[epoch 28], [iter 75 / 176], [train main loss -1.593322], [lr 0.008400] [batchtime 0.421]
[epoch 28], [iter 76 / 176], [train main loss -1.612506], [lr 0.008400] [batchtime 0.421]
[epoch 28], [iter 77 / 176], [train main loss -1.588307], [lr 0.008400] [batchtime 0.42]
[epoch 28], [iter 78 / 176], [train main loss -1.566631], [lr 0.008400] [batchtime 0.42]
[epoch 28], [iter 79 / 176], [train main loss -1.527312], [lr 0.008400] [batchtime 0.42]
[epoch 28], [iter 80 / 176], [train main loss -1.501415], [lr 0.008400] [batchtime 0.42]
[epoch 28], [iter 81 / 176], [train main loss -1.501681], [lr 0.008400] [batchtime 0.419]
[epoch 28], [iter 82 / 176], [train main loss -1.534538], [lr 0.008400] [batchtime 0.419]
[epoch 28], [iter 83 / 176], [train main loss -1.517421], [lr 0.008400] [batchtime 0.418]
[epoch 28], [iter 84 / 176], [train main loss -1.500763], [lr 0.008400] [batchtime 0.418]
[epoch 28], [iter 85 / 176], [train main loss -1.495313], [lr 0.008400] [batchtime 0.418]
[epoch 28], [iter 86 / 176], [train main loss -1.535363], [lr 0.008400] [batchtime 0.418]
[epoch 28], [iter 87 / 176], [train main loss -1.561336], [lr 0.008400] [batchtime 0.417]
[epoch 28], [iter 88 / 176], [train main loss -1.555428], [lr 0.008400] [batchtime 0.417]
[epoch 28], [iter 89 / 176], [train main loss -1.546578], [lr 0.008400] [batchtime 0.417]
[epoch 28], [iter 90 / 176], [train main loss -1.549319], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 91 / 176], [train main loss -1.552140], [lr 0.008400] [batchtime 0.435]
[epoch 28], [iter 92 / 176], [train main loss -1.562020], [lr 0.008400] [batchtime 0.434]
[epoch 28], [iter 93 / 176], [train main loss -1.578839], [lr 0.008400] [batchtime 0.434]
[epoch 28], [iter 94 / 176], [train main loss -1.574240], [lr 0.008400] [batchtime 0.433]
[epoch 28], [iter 95 / 176], [train main loss -1.589200], [lr 0.008400] [batchtime 0.433]
[epoch 28], [iter 96 / 176], [train main loss -1.612756], [lr 0.008400] [batchtime 0.432]
[epoch 28], [iter 97 / 176], [train main loss -1.591880], [lr 0.008400] [batchtime 0.432]
[epoch 28], [iter 98 / 176], [train main loss -1.576307], [lr 0.008400] [batchtime 0.432]
[epoch 28], [iter 99 / 176], [train main loss -1.589555], [lr 0.008400] [batchtime 0.431]
[epoch 28], [iter 100 / 176], [train main loss -1.586766], [lr 0.008400] [batchtime 0.431]
[epoch 28], [iter 101 / 176], [train main loss -1.594823], [lr 0.008400] [batchtime 0.43]
[epoch 28], [iter 102 / 176], [train main loss -1.587072], [lr 0.008400] [batchtime 0.43]
[epoch 28], [iter 103 / 176], [train main loss -1.602239], [lr 0.008400] [batchtime 0.43]
[epoch 28], [iter 104 / 176], [train main loss -1.604377], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 105 / 176], [train main loss -1.597683], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 106 / 176], [train main loss -1.571596], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 107 / 176], [train main loss -1.544516], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 108 / 176], [train main loss -1.565664], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 109 / 176], [train main loss -1.554521], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 110 / 176], [train main loss -1.550085], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 111 / 176], [train main loss -1.554467], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 112 / 176], [train main loss -1.552782], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 113 / 176], [train main loss -1.570374], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 114 / 176], [train main loss -1.556972], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 115 / 176], [train main loss -1.535464], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 116 / 176], [train main loss -1.531504], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 117 / 176], [train main loss -1.535107], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 118 / 176], [train main loss -1.541351], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 119 / 176], [train main loss -1.522295], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 120 / 176], [train main loss -1.519728], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 121 / 176], [train main loss -1.529787], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 122 / 176], [train main loss -1.541971], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 123 / 176], [train main loss -1.544170], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 124 / 176], [train main loss -1.540214], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 125 / 176], [train main loss -1.516098], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 126 / 176], [train main loss -1.512269], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 127 / 176], [train main loss -1.513313], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 128 / 176], [train main loss -1.500305], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 129 / 176], [train main loss -1.483729], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 130 / 176], [train main loss -1.491633], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 131 / 176], [train main loss -1.496711], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 132 / 176], [train main loss -1.494480], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 133 / 176], [train main loss -1.484657], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 134 / 176], [train main loss -1.488650], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 135 / 176], [train main loss -1.499633], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 136 / 176], [train main loss -1.484922], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 137 / 176], [train main loss -1.481062], [lr 0.008400] [batchtime 0.43]
[epoch 28], [iter 138 / 176], [train main loss -1.492053], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 139 / 176], [train main loss -1.480273], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 140 / 176], [train main loss -1.483540], [lr 0.008400] [batchtime 0.429]
[epoch 28], [iter 141 / 176], [train main loss -1.464592], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 142 / 176], [train main loss -1.476089], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 143 / 176], [train main loss -1.478725], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 144 / 176], [train main loss -1.471604], [lr 0.008400] [batchtime 0.428]
[epoch 28], [iter 145 / 176], [train main loss -1.455477], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 146 / 176], [train main loss -1.449171], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 147 / 176], [train main loss -1.441997], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 148 / 176], [train main loss -1.430950], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 149 / 176], [train main loss -1.434495], [lr 0.008400] [batchtime 0.427]
[epoch 28], [iter 150 / 176], [train main loss -1.440839], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 151 / 176], [train main loss -1.441217], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 152 / 176], [train main loss -1.444260], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 153 / 176], [train main loss -1.449206], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 154 / 176], [train main loss -1.446457], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 155 / 176], [train main loss -1.450421], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 156 / 176], [train main loss -1.446588], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 157 / 176], [train main loss -1.438495], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 158 / 176], [train main loss -1.454179], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 159 / 176], [train main loss -1.448598], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 160 / 176], [train main loss -1.453640], [lr 0.008400] [batchtime 0.426]
[epoch 28], [iter 161 / 176], [train main loss -1.452428], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 162 / 176], [train main loss -1.456728], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 163 / 176], [train main loss -1.448768], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 164 / 176], [train main loss -1.461180], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 165 / 176], [train main loss -1.451494], [lr 0.008400] [batchtime 0.425]
[epoch 28], [iter 166 / 176], [train main loss -1.455794], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 167 / 176], [train main loss -1.454190], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 168 / 176], [train main loss -1.452694], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 169 / 176], [train main loss -1.461130], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 170 / 176], [train main loss -1.459844], [lr 0.008400] [batchtime 0.424]
[epoch 28], [iter 171 / 176], [train main loss -1.458535], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 172 / 176], [train main loss -1.457060], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 173 / 176], [train main loss -1.430974], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 174 / 176], [train main loss -1.423666], [lr 0.008400] [batchtime 0.423]
[epoch 28], [iter 175 / 176], [train main loss -1.413579], [lr 0.008400] [batchtime 0.422]
[epoch 28], [iter 176 / 176], [train main loss -1.418423], [lr 0.008400] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              90.77  35.15       0.03    0.07         0.97      0.94
   1  sidewalk          50.32   4.23       0.56    0.43         0.64      0.70
   2  building          79.29  24.15       0.10    0.16         0.91      0.86
   3  wall               4.40   0.03      18.97    2.73         0.05      0.27
   4  fence              1.41   0.02      68.60    1.38         0.01      0.42
   5  pole              21.45   0.30       2.74    0.92         0.27      0.52
   6  traffic light      0.12   0.00     856.14    0.66         0.00      0.60
   7  traffic sign       3.78   0.02      24.54    0.89         0.04      0.53
   8  vegetation        74.89  11.37       0.09    0.25         0.92      0.80
   9  terrain           26.48   0.29       1.52    1.25         0.40      0.44
  10  sky               90.35   3.63       0.07    0.04         0.94      0.96
  11  person            24.39   0.45       2.38    0.72         0.30      0.58
  12  rider              0.01   0.00   12824.88   16.49         0.00      0.06
  13  car               72.68   6.33       0.12    0.26         0.89      0.79
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00  127643.88   19.00         0.00      0.05
  16  train              0.00   0.00     inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle           20.24   0.11       2.56    1.38         0.28      0.42
Mean: 29.50
-----------------------------------------------------------------------------------------------------------
this : [epoch 28], [val loss 0.46826], [acc 0.86089], [acc_cls 0.34811], [mean_iu 0.29504], [fwavacc 0.76252]
best : [epoch 27], [val loss 0.47682], [acc 0.86304], [acc_cls 0.35066], [mean_iu 0.29644], [fwavacc 0.76557]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 29], [iter 1 / 176], [train main loss -0.661183], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 2 / 176], [train main loss -0.666198], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 3 / 176], [train main loss -1.247359], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 4 / 176], [train main loss -1.855024], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 5 / 176], [train main loss -2.062129], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 6 / 176], [train main loss -1.790379], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 7 / 176], [train main loss -2.012617], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 8 / 176], [train main loss -1.736681], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 9 / 176], [train main loss -1.634212], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 10 / 176], [train main loss -1.522315], [lr 0.008343] [batchtime 0]
[epoch 29], [iter 11 / 176], [train main loss -1.618099], [lr 0.008343] [batchtime 0.368]
[epoch 29], [iter 12 / 176], [train main loss -1.759769], [lr 0.008343] [batchtime 0.384]
[epoch 29], [iter 13 / 176], [train main loss -1.698699], [lr 0.008343] [batchtime 0.389]
[epoch 29], [iter 14 / 176], [train main loss -1.695626], [lr 0.008343] [batchtime 0.39]
[epoch 29], [iter 15 / 176], [train main loss -1.594537], [lr 0.008343] [batchtime 0.39]
[epoch 29], [iter 16 / 176], [train main loss -1.590948], [lr 0.008343] [batchtime 0.392]
[epoch 29], [iter 17 / 176], [train main loss -1.389946], [lr 0.008343] [batchtime 0.393]
[epoch 29], [iter 18 / 176], [train main loss -1.305634], [lr 0.008343] [batchtime 0.393]
[epoch 29], [iter 19 / 176], [train main loss -1.208632], [lr 0.008343] [batchtime 0.393]
[epoch 29], [iter 20 / 176], [train main loss -1.081945], [lr 0.008343] [batchtime 0.393]
[epoch 29], [iter 21 / 176], [train main loss -1.041727], [lr 0.008343] [batchtime 0.397]
[epoch 29], [iter 22 / 176], [train main loss -1.075780], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 23 / 176], [train main loss -1.169512], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 24 / 176], [train main loss -1.122604], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 25 / 176], [train main loss -1.141021], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 26 / 176], [train main loss -1.167954], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 27 / 176], [train main loss -1.163367], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 28 / 176], [train main loss -1.233684], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 29 / 176], [train main loss -1.266490], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 30 / 176], [train main loss -1.277251], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 31 / 176], [train main loss -1.333567], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 32 / 176], [train main loss -1.350817], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 33 / 176], [train main loss -1.321598], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 34 / 176], [train main loss -1.350751], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 35 / 176], [train main loss -1.338791], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 36 / 176], [train main loss -1.335547], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 37 / 176], [train main loss -1.440017], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 38 / 176], [train main loss -1.357684], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 39 / 176], [train main loss -1.321257], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 40 / 176], [train main loss -1.356590], [lr 0.008343] [batchtime 0.395]
[epoch 29], [iter 41 / 176], [train main loss -1.337347], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 42 / 176], [train main loss -1.402227], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 43 / 176], [train main loss -1.394592], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 44 / 176], [train main loss -1.426924], [lr 0.008343] [batchtime 0.396]
[epoch 29], [iter 45 / 176], [train main loss -1.472317], [lr 0.008343] [batchtime 0.428]
[epoch 29], [iter 46 / 176], [train main loss -1.465886], [lr 0.008343] [batchtime 0.433]
[epoch 29], [iter 47 / 176], [train main loss -1.488173], [lr 0.008343] [batchtime 0.431]
[epoch 29], [iter 48 / 176], [train main loss -1.487563], [lr 0.008343] [batchtime 0.43]
[epoch 29], [iter 49 / 176], [train main loss -1.504090], [lr 0.008343] [batchtime 0.429]
[epoch 29], [iter 50 / 176], [train main loss -1.484498], [lr 0.008343] [batchtime 0.428]
[epoch 29], [iter 51 / 176], [train main loss -1.543310], [lr 0.008343] [batchtime 0.427]
[epoch 29], [iter 52 / 176], [train main loss -1.521247], [lr 0.008343] [batchtime 0.427]
[epoch 29], [iter 53 / 176], [train main loss -1.492497], [lr 0.008343] [batchtime 0.426]
[epoch 29], [iter 54 / 176], [train main loss -1.462324], [lr 0.008343] [batchtime 0.426]
[epoch 29], [iter 55 / 176], [train main loss -1.486780], [lr 0.008343] [batchtime 0.425]
[epoch 29], [iter 56 / 176], [train main loss -1.475562], [lr 0.008343] [batchtime 0.425]
[epoch 29], [iter 57 / 176], [train main loss -1.506174], [lr 0.008343] [batchtime 0.424]
[epoch 29], [iter 58 / 176], [train main loss -1.540997], [lr 0.008343] [batchtime 0.423]
[epoch 29], [iter 59 / 176], [train main loss -1.546440], [lr 0.008343] [batchtime 0.423]
[epoch 29], [iter 60 / 176], [train main loss -1.566208], [lr 0.008343] [batchtime 0.423]
[epoch 29], [iter 61 / 176], [train main loss -1.587448], [lr 0.008343] [batchtime 0.422]
[epoch 29], [iter 62 / 176], [train main loss -1.594035], [lr 0.008343] [batchtime 0.422]
[epoch 29], [iter 63 / 176], [train main loss -1.648381], [lr 0.008343] [batchtime 0.421]
[epoch 29], [iter 64 / 176], [train main loss -1.661259], [lr 0.008343] [batchtime 0.421]
[epoch 29], [iter 65 / 176], [train main loss -1.650592], [lr 0.008343] [batchtime 0.42]
[epoch 29], [iter 66 / 176], [train main loss -1.665359], [lr 0.008343] [batchtime 0.42]
[epoch 29], [iter 67 / 176], [train main loss -1.675578], [lr 0.008343] [batchtime 0.42]
[epoch 29], [iter 68 / 176], [train main loss -1.668780], [lr 0.008343] [batchtime 0.42]
[epoch 29], [iter 69 / 176], [train main loss -1.658702], [lr 0.008343] [batchtime 0.42]
[epoch 29], [iter 70 / 176], [train main loss -1.639347], [lr 0.008343] [batchtime 0.419]
[epoch 29], [iter 71 / 176], [train main loss -1.626409], [lr 0.008343] [batchtime 0.419]
[epoch 29], [iter 72 / 176], [train main loss -1.602060], [lr 0.008343] [batchtime 0.418]
[epoch 29], [iter 73 / 176], [train main loss -1.637756], [lr 0.008343] [batchtime 0.418]
[epoch 29], [iter 74 / 176], [train main loss -1.611028], [lr 0.008343] [batchtime 0.418]
[epoch 29], [iter 75 / 176], [train main loss -1.636236], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 76 / 176], [train main loss -1.625816], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 77 / 176], [train main loss -1.570491], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 78 / 176], [train main loss -1.586451], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 79 / 176], [train main loss -1.603856], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 80 / 176], [train main loss -1.599910], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 81 / 176], [train main loss -1.578347], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 82 / 176], [train main loss -1.557632], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 83 / 176], [train main loss -1.554913], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 84 / 176], [train main loss -1.549198], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 85 / 176], [train main loss -1.558027], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 86 / 176], [train main loss -1.536201], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 87 / 176], [train main loss -1.538223], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 88 / 176], [train main loss -1.533518], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 89 / 176], [train main loss -1.536868], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 90 / 176], [train main loss -1.521963], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 91 / 176], [train main loss -1.543826], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 92 / 176], [train main loss -1.540932], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 93 / 176], [train main loss -1.549821], [lr 0.008343] [batchtime 0.419]
[epoch 29], [iter 94 / 176], [train main loss -1.548717], [lr 0.008343] [batchtime 0.418]
[epoch 29], [iter 95 / 176], [train main loss -1.556948], [lr 0.008343] [batchtime 0.418]
[epoch 29], [iter 96 / 176], [train main loss -1.556243], [lr 0.008343] [batchtime 0.418]
[epoch 29], [iter 97 / 176], [train main loss -1.594487], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 98 / 176], [train main loss -1.617708], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 99 / 176], [train main loss -1.663161], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 100 / 176], [train main loss -1.677264], [lr 0.008343] [batchtime 0.417]
[epoch 29], [iter 101 / 176], [train main loss -1.689988], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 102 / 176], [train main loss -1.708496], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 103 / 176], [train main loss -1.715412], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 104 / 176], [train main loss -1.727217], [lr 0.008343] [batchtime 0.416]
[epoch 29], [iter 105 / 176], [train main loss -1.732766], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 106 / 176], [train main loss -1.736123], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 107 / 176], [train main loss -1.717847], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 108 / 176], [train main loss -1.702618], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 109 / 176], [train main loss -1.699960], [lr 0.008343] [batchtime 0.415]
[epoch 29], [iter 110 / 176], [train main loss -1.680013], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 111 / 176], [train main loss -1.662758], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 112 / 176], [train main loss -1.645699], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 113 / 176], [train main loss -1.640430], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 114 / 176], [train main loss -1.638553], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 115 / 176], [train main loss -1.647726], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 116 / 176], [train main loss -1.642965], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 117 / 176], [train main loss -1.646334], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 118 / 176], [train main loss -1.665268], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 119 / 176], [train main loss -1.664437], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 120 / 176], [train main loss -1.676383], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 121 / 176], [train main loss -1.671056], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 122 / 176], [train main loss -1.662833], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 123 / 176], [train main loss -1.662224], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 124 / 176], [train main loss -1.644255], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 125 / 176], [train main loss -1.671712], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 126 / 176], [train main loss -1.683543], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 127 / 176], [train main loss -1.674880], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 128 / 176], [train main loss -1.663422], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 129 / 176], [train main loss -1.662852], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 130 / 176], [train main loss -1.652090], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 131 / 176], [train main loss -1.663379], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 132 / 176], [train main loss -1.671895], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 133 / 176], [train main loss -1.668582], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 134 / 176], [train main loss -1.671094], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 135 / 176], [train main loss -1.651598], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 136 / 176], [train main loss -1.643842], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 137 / 176], [train main loss -1.641963], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 138 / 176], [train main loss -1.616799], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 139 / 176], [train main loss -1.621808], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 140 / 176], [train main loss -1.619578], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 141 / 176], [train main loss -1.643555], [lr 0.008343] [batchtime 0.409]
[epoch 29], [iter 142 / 176], [train main loss -1.650292], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 143 / 176], [train main loss -1.651742], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 144 / 176], [train main loss -1.643994], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 145 / 176], [train main loss -1.641403], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 146 / 176], [train main loss -1.644558], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 147 / 176], [train main loss -1.637384], [lr 0.008343] [batchtime 0.414]
[epoch 29], [iter 148 / 176], [train main loss -1.639137], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 149 / 176], [train main loss -1.649921], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 150 / 176], [train main loss -1.650912], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 151 / 176], [train main loss -1.673813], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 152 / 176], [train main loss -1.674361], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 153 / 176], [train main loss -1.670356], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 154 / 176], [train main loss -1.683858], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 155 / 176], [train main loss -1.693226], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 156 / 176], [train main loss -1.694215], [lr 0.008343] [batchtime 0.413]
[epoch 29], [iter 157 / 176], [train main loss -1.682146], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 158 / 176], [train main loss -1.703006], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 159 / 176], [train main loss -1.691981], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 160 / 176], [train main loss -1.678237], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 161 / 176], [train main loss -1.669449], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 162 / 176], [train main loss -1.673921], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 163 / 176], [train main loss -1.689780], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 164 / 176], [train main loss -1.701383], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 165 / 176], [train main loss -1.701382], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 166 / 176], [train main loss -1.701432], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 167 / 176], [train main loss -1.697123], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 168 / 176], [train main loss -1.687032], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 169 / 176], [train main loss -1.689800], [lr 0.008343] [batchtime 0.412]
[epoch 29], [iter 170 / 176], [train main loss -1.682557], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 171 / 176], [train main loss -1.681604], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 172 / 176], [train main loss -1.703640], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 173 / 176], [train main loss -1.699797], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 174 / 176], [train main loss -1.701032], [lr 0.008343] [batchtime 0.411]
[epoch 29], [iter 175 / 176], [train main loss -1.705360], [lr 0.008343] [batchtime 0.41]
[epoch 29], [iter 176 / 176], [train main loss -1.695977], [lr 0.008343] [batchtime 0.41]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP          FP      FN    Precision    Recall
----  -------------  --------  -----  ----------  ------  -----------  --------
   0  road              91.38  35.38        0.03    0.07         0.97      0.94
   1  sidewalk          53.01   4.43        0.49    0.40         0.67      0.72
   2  building          79.48  23.96        0.11    0.15         0.90      0.87
   3  wall               3.64   0.02       24.23    2.21         0.04      0.31
   4  fence              0.29   0.00      338.25    1.87         0.00      0.35
   5  pole              20.77   0.27        3.21    0.60         0.24      0.62
   6  traffic light      0.12   0.00      807.53    0.63         0.00      0.61
   7  traffic sign       3.63   0.02       25.84    0.70         0.04      0.59
   8  vegetation        75.10  11.57        0.07    0.26         0.94      0.79
   9  terrain           25.03   0.27        1.71    1.28         0.37      0.44
  10  sky               91.51   3.68        0.05    0.04         0.95      0.96
  11  person            24.08   0.44        2.46    0.69         0.29      0.59
  12  rider              0.03   0.00     2923.58    8.90         0.00      0.10
  13  car               74.12   6.37        0.11    0.24         0.90      0.81
  14  truck              0.00   0.00      inf     nan            0.00    nan
  15  bus                0.00   0.00  1021158.00    3.00         0.00      0.25
  16  train              0.00   0.00      inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00      inf     nan            0.00    nan
  18  bicycle           19.60   0.11        2.43    1.68         0.29      0.37
Mean: 29.57
-----------------------------------------------------------------------------------------------------------
this : [epoch 29], [val loss 0.50138], [acc 0.86530], [acc_cls 0.34740], [mean_iu 0.29569], [fwavacc 0.76829]
best : [epoch 27], [val loss 0.47682], [acc 0.86304], [acc_cls 0.35066], [mean_iu 0.29644], [fwavacc 0.76557]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 30], [iter 1 / 176], [train main loss -3.962345], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 2 / 176], [train main loss -2.578844], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 3 / 176], [train main loss -2.164341], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 4 / 176], [train main loss -2.182830], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 5 / 176], [train main loss -1.901599], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 6 / 176], [train main loss -1.795655], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 7 / 176], [train main loss -1.894638], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 8 / 176], [train main loss -1.716545], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 9 / 176], [train main loss -1.934432], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 10 / 176], [train main loss -1.744075], [lr 0.008286] [batchtime 0]
[epoch 30], [iter 11 / 176], [train main loss -1.721753], [lr 0.008286] [batchtime 0.369]
[epoch 30], [iter 12 / 176], [train main loss -1.690059], [lr 0.008286] [batchtime 0.383]
[epoch 30], [iter 13 / 176], [train main loss -1.905921], [lr 0.008286] [batchtime 0.386]
[epoch 30], [iter 14 / 176], [train main loss -1.994152], [lr 0.008286] [batchtime 0.389]
[epoch 30], [iter 15 / 176], [train main loss -1.902338], [lr 0.008286] [batchtime 0.392]
[epoch 30], [iter 16 / 176], [train main loss -1.876576], [lr 0.008286] [batchtime 0.393]
[epoch 30], [iter 17 / 176], [train main loss -1.869678], [lr 0.008286] [batchtime 0.393]
[epoch 30], [iter 18 / 176], [train main loss -1.867805], [lr 0.008286] [batchtime 0.394]
[epoch 30], [iter 19 / 176], [train main loss -1.782897], [lr 0.008286] [batchtime 0.394]
[epoch 30], [iter 20 / 176], [train main loss -1.636075], [lr 0.008286] [batchtime 0.394]
[epoch 30], [iter 21 / 176], [train main loss -1.666058], [lr 0.008286] [batchtime 0.394]
[epoch 30], [iter 22 / 176], [train main loss -1.752259], [lr 0.008286] [batchtime 0.395]
[epoch 30], [iter 23 / 176], [train main loss -1.770440], [lr 0.008286] [batchtime 0.396]
[epoch 30], [iter 24 / 176], [train main loss -1.861878], [lr 0.008286] [batchtime 0.396]
[epoch 30], [iter 25 / 176], [train main loss -1.825372], [lr 0.008286] [batchtime 0.395]
[epoch 30], [iter 26 / 176], [train main loss -1.771633], [lr 0.008286] [batchtime 0.404]
[epoch 30], [iter 27 / 176], [train main loss -1.768308], [lr 0.008286] [batchtime 0.414]
[epoch 30], [iter 28 / 176], [train main loss -1.784472], [lr 0.008286] [batchtime 0.413]
[epoch 30], [iter 29 / 176], [train main loss -1.797407], [lr 0.008286] [batchtime 0.412]
[epoch 30], [iter 30 / 176], [train main loss -1.726722], [lr 0.008286] [batchtime 0.411]
[epoch 30], [iter 31 / 176], [train main loss -1.696166], [lr 0.008286] [batchtime 0.41]
[epoch 30], [iter 32 / 176], [train main loss -1.688192], [lr 0.008286] [batchtime 0.41]
[epoch 30], [iter 33 / 176], [train main loss -1.690233], [lr 0.008286] [batchtime 0.41]
[epoch 30], [iter 34 / 176], [train main loss -1.688372], [lr 0.008286] [batchtime 0.409]
[epoch 30], [iter 35 / 176], [train main loss -1.694138], [lr 0.008286] [batchtime 0.408]
[epoch 30], [iter 36 / 176], [train main loss -1.715356], [lr 0.008286] [batchtime 0.408]
[epoch 30], [iter 37 / 176], [train main loss -1.703698], [lr 0.008286] [batchtime 0.407]
[epoch 30], [iter 38 / 176], [train main loss -1.804222], [lr 0.008286] [batchtime 0.407]
[epoch 30], [iter 39 / 176], [train main loss -1.760767], [lr 0.008286] [batchtime 0.407]
[epoch 30], [iter 40 / 176], [train main loss -1.801009], [lr 0.008286] [batchtime 0.407]
[epoch 30], [iter 41 / 176], [train main loss -1.761722], [lr 0.008286] [batchtime 0.407]
[epoch 30], [iter 42 / 176], [train main loss -1.786035], [lr 0.008286] [batchtime 0.406]
[epoch 30], [iter 43 / 176], [train main loss -1.755329], [lr 0.008286] [batchtime 0.406]
[epoch 30], [iter 44 / 176], [train main loss -1.770585], [lr 0.008286] [batchtime 0.405]
[epoch 30], [iter 45 / 176], [train main loss -1.798718], [lr 0.008286] [batchtime 0.405]
[epoch 30], [iter 46 / 176], [train main loss -1.819023], [lr 0.008286] [batchtime 0.405]
[epoch 30], [iter 47 / 176], [train main loss -1.831106], [lr 0.008286] [batchtime 0.405]
[epoch 30], [iter 48 / 176], [train main loss -1.823030], [lr 0.008286] [batchtime 0.405]
[epoch 30], [iter 49 / 176], [train main loss -1.796413], [lr 0.008286] [batchtime 0.405]
[epoch 30], [iter 50 / 176], [train main loss -1.802442], [lr 0.008286] [batchtime 0.408]
[epoch 30], [iter 51 / 176], [train main loss -1.791136], [lr 0.008286] [batchtime 0.438]
[epoch 30], [iter 52 / 176], [train main loss -1.814015], [lr 0.008286] [batchtime 0.436]
[epoch 30], [iter 53 / 176], [train main loss -1.812859], [lr 0.008286] [batchtime 0.435]
[epoch 30], [iter 54 / 176], [train main loss -1.800444], [lr 0.008286] [batchtime 0.434]
[epoch 30], [iter 55 / 176], [train main loss -1.801262], [lr 0.008286] [batchtime 0.433]
[epoch 30], [iter 56 / 176], [train main loss -1.780286], [lr 0.008286] [batchtime 0.433]
[epoch 30], [iter 57 / 176], [train main loss -1.744869], [lr 0.008286] [batchtime 0.432]
[epoch 30], [iter 58 / 176], [train main loss -1.725619], [lr 0.008286] [batchtime 0.431]
[epoch 30], [iter 59 / 176], [train main loss -1.701165], [lr 0.008286] [batchtime 0.43]
[epoch 30], [iter 60 / 176], [train main loss -1.670799], [lr 0.008286] [batchtime 0.429]
[epoch 30], [iter 61 / 176], [train main loss -1.667489], [lr 0.008286] [batchtime 0.429]
[epoch 30], [iter 62 / 176], [train main loss -1.667517], [lr 0.008286] [batchtime 0.428]
[epoch 30], [iter 63 / 176], [train main loss -1.701352], [lr 0.008286] [batchtime 0.428]
[epoch 30], [iter 64 / 176], [train main loss -1.684138], [lr 0.008286] [batchtime 0.427]
[epoch 30], [iter 65 / 176], [train main loss -1.716546], [lr 0.008286] [batchtime 0.427]
[epoch 30], [iter 66 / 176], [train main loss -1.722083], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 67 / 176], [train main loss -1.753689], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 68 / 176], [train main loss -1.777301], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 69 / 176], [train main loss -1.785714], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 70 / 176], [train main loss -1.757956], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 71 / 176], [train main loss -1.764578], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 72 / 176], [train main loss -1.772337], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 73 / 176], [train main loss -1.808933], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 74 / 176], [train main loss -1.846448], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 75 / 176], [train main loss -1.857015], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 76 / 176], [train main loss -1.863120], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 77 / 176], [train main loss -1.856626], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 78 / 176], [train main loss -1.862155], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 79 / 176], [train main loss -1.870071], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 80 / 176], [train main loss -1.883306], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 81 / 176], [train main loss -1.904962], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 82 / 176], [train main loss -1.929599], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 83 / 176], [train main loss -1.954690], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 84 / 176], [train main loss -1.932340], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 85 / 176], [train main loss -1.951946], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 86 / 176], [train main loss -1.924501], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 87 / 176], [train main loss -1.905008], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 88 / 176], [train main loss -1.845253], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 89 / 176], [train main loss -1.859240], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 90 / 176], [train main loss -1.856426], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 91 / 176], [train main loss -1.847730], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 92 / 176], [train main loss -1.858202], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 93 / 176], [train main loss -1.853802], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 94 / 176], [train main loss -1.825754], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 95 / 176], [train main loss -1.836227], [lr 0.008286] [batchtime 0.418]
[epoch 30], [iter 96 / 176], [train main loss -1.830268], [lr 0.008286] [batchtime 0.418]
[epoch 30], [iter 97 / 176], [train main loss -1.837506], [lr 0.008286] [batchtime 0.427]
[epoch 30], [iter 98 / 176], [train main loss -1.816857], [lr 0.008286] [batchtime 0.428]
[epoch 30], [iter 99 / 176], [train main loss -1.813150], [lr 0.008286] [batchtime 0.428]
[epoch 30], [iter 100 / 176], [train main loss -1.833914], [lr 0.008286] [batchtime 0.427]
[epoch 30], [iter 101 / 176], [train main loss -1.824575], [lr 0.008286] [batchtime 0.427]
[epoch 30], [iter 102 / 176], [train main loss -1.827997], [lr 0.008286] [batchtime 0.427]
[epoch 30], [iter 103 / 176], [train main loss -1.823177], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 104 / 176], [train main loss -1.809717], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 105 / 176], [train main loss -1.826443], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 106 / 176], [train main loss -1.787628], [lr 0.008286] [batchtime 0.426]
[epoch 30], [iter 107 / 176], [train main loss -1.796923], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 108 / 176], [train main loss -1.812483], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 109 / 176], [train main loss -1.809806], [lr 0.008286] [batchtime 0.425]
[epoch 30], [iter 110 / 176], [train main loss -1.788799], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 111 / 176], [train main loss -1.793299], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 112 / 176], [train main loss -1.794275], [lr 0.008286] [batchtime 0.424]
[epoch 30], [iter 113 / 176], [train main loss -1.809015], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 114 / 176], [train main loss -1.800039], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 115 / 176], [train main loss -1.801278], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 116 / 176], [train main loss -1.782167], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 117 / 176], [train main loss -1.778472], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 118 / 176], [train main loss -1.790646], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 119 / 176], [train main loss -1.812152], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 120 / 176], [train main loss -1.796056], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 121 / 176], [train main loss -1.777786], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 122 / 176], [train main loss -1.789231], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 123 / 176], [train main loss -1.808016], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 124 / 176], [train main loss -1.811779], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 125 / 176], [train main loss -1.804423], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 126 / 176], [train main loss -1.788777], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 127 / 176], [train main loss -1.784724], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 128 / 176], [train main loss -1.790192], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 129 / 176], [train main loss -1.772132], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 130 / 176], [train main loss -1.773436], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 131 / 176], [train main loss -1.773318], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 132 / 176], [train main loss -1.765674], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 133 / 176], [train main loss -1.768949], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 134 / 176], [train main loss -1.748052], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 135 / 176], [train main loss -1.753871], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 136 / 176], [train main loss -1.753624], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 137 / 176], [train main loss -1.743507], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 138 / 176], [train main loss -1.751773], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 139 / 176], [train main loss -1.759457], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 140 / 176], [train main loss -1.766112], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 141 / 176], [train main loss -1.756595], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 142 / 176], [train main loss -1.746780], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 143 / 176], [train main loss -1.744798], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 144 / 176], [train main loss -1.738492], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 145 / 176], [train main loss -1.739252], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 146 / 176], [train main loss -1.738002], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 147 / 176], [train main loss -1.741084], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 148 / 176], [train main loss -1.757477], [lr 0.008286] [batchtime 0.423]
[epoch 30], [iter 149 / 176], [train main loss -1.750676], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 150 / 176], [train main loss -1.747088], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 151 / 176], [train main loss -1.747128], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 152 / 176], [train main loss -1.737333], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 153 / 176], [train main loss -1.718890], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 154 / 176], [train main loss -1.714359], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 155 / 176], [train main loss -1.713244], [lr 0.008286] [batchtime 0.422]
[epoch 30], [iter 156 / 176], [train main loss -1.700169], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 157 / 176], [train main loss -1.714460], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 158 / 176], [train main loss -1.726134], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 159 / 176], [train main loss -1.721782], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 160 / 176], [train main loss -1.715505], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 161 / 176], [train main loss -1.709010], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 162 / 176], [train main loss -1.704283], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 163 / 176], [train main loss -1.708820], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 164 / 176], [train main loss -1.690141], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 165 / 176], [train main loss -1.689165], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 166 / 176], [train main loss -1.696523], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 167 / 176], [train main loss -1.687879], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 168 / 176], [train main loss -1.690692], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 169 / 176], [train main loss -1.672185], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 170 / 176], [train main loss -1.661347], [lr 0.008286] [batchtime 0.421]
[epoch 30], [iter 171 / 176], [train main loss -1.662301], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 172 / 176], [train main loss -1.657084], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 173 / 176], [train main loss -1.654932], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 174 / 176], [train main loss -1.652853], [lr 0.008286] [batchtime 0.42]
[epoch 30], [iter 175 / 176], [train main loss -1.651256], [lr 0.008286] [batchtime 0.419]
[epoch 30], [iter 176 / 176], [train main loss -1.661590], [lr 0.008286] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              91.53  34.97       0.04    0.05         0.96      0.95
   1  sidewalk          55.50   4.73       0.39    0.41         0.72      0.71
   2  building          79.78  23.86       0.11    0.14         0.90      0.88
   3  wall               3.06   0.02      29.34    2.30         0.03      0.30
   4  fence              0.38   0.00     264.26    1.07         0.00      0.48
   5  pole              21.79   0.29       2.89    0.70         0.26      0.59
   6  traffic light      0.17   0.00     587.90    0.59         0.00      0.63
   7  traffic sign       4.35   0.03      21.27    0.71         0.04      0.59
   8  vegetation        76.52  11.43       0.08    0.22         0.92      0.82
   9  terrain           28.48   0.28       1.63    0.88         0.38      0.53
  10  sky               90.09   3.77       0.03    0.08         0.97      0.92
  11  person            26.05   0.50       2.08    0.76         0.32      0.57
  12  rider              0.15   0.00     647.32   10.35         0.00      0.09
  13  car               70.17   6.56       0.08    0.35         0.93      0.74
  14  truck              0.00   0.00     inf     nan            0.00    nan
  15  bus                0.00   0.00  170192.17   47.00         0.00      0.02
  16  train              0.00   0.00     inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00     inf     nan            0.00    nan
  18  bicycle           21.06   0.14       1.81    1.94         0.36      0.34
Mean: 29.95
-----------------------------------------------------------------------------------------------------------
this : [epoch 30], [val loss 0.47027], [acc 0.86573], [acc_cls 0.35815], [mean_iu 0.29952], [fwavacc 0.77043]
best : [epoch 30], [val loss 0.47027], [acc 0.86573], [acc_cls 0.35815], [mean_iu 0.29952], [fwavacc 0.77043]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 31], [iter 1 / 176], [train main loss -0.308024], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 2 / 176], [train main loss -2.501567], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 3 / 176], [train main loss -1.568854], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 4 / 176], [train main loss -1.511474], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 5 / 176], [train main loss -1.780710], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 6 / 176], [train main loss -1.693308], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 7 / 176], [train main loss -2.039185], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 8 / 176], [train main loss -1.982080], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 9 / 176], [train main loss -1.733939], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 10 / 176], [train main loss -1.690341], [lr 0.008229] [batchtime 0]
[epoch 31], [iter 11 / 176], [train main loss -1.887189], [lr 0.008229] [batchtime 0.395]
[epoch 31], [iter 12 / 176], [train main loss -1.941593], [lr 0.008229] [batchtime 0.397]
[epoch 31], [iter 13 / 176], [train main loss -1.942491], [lr 0.008229] [batchtime 0.396]
[epoch 31], [iter 14 / 176], [train main loss -1.834213], [lr 0.008229] [batchtime 0.396]
[epoch 31], [iter 15 / 176], [train main loss -1.782316], [lr 0.008229] [batchtime 0.397]
[epoch 31], [iter 16 / 176], [train main loss -1.864544], [lr 0.008229] [batchtime 0.398]
[epoch 31], [iter 17 / 176], [train main loss -1.843010], [lr 0.008229] [batchtime 0.397]
[epoch 31], [iter 18 / 176], [train main loss -1.942248], [lr 0.008229] [batchtime 0.396]
[epoch 31], [iter 19 / 176], [train main loss -2.008543], [lr 0.008229] [batchtime 0.397]
[epoch 31], [iter 20 / 176], [train main loss -1.934028], [lr 0.008229] [batchtime 0.397]
[epoch 31], [iter 21 / 176], [train main loss -2.043695], [lr 0.008229] [batchtime 0.397]
[epoch 31], [iter 22 / 176], [train main loss -2.090151], [lr 0.008229] [batchtime 0.402]
[epoch 31], [iter 23 / 176], [train main loss -2.031052], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 24 / 176], [train main loss -2.017055], [lr 0.008229] [batchtime 0.412]
[epoch 31], [iter 25 / 176], [train main loss -2.010916], [lr 0.008229] [batchtime 0.411]
[epoch 31], [iter 26 / 176], [train main loss -1.936653], [lr 0.008229] [batchtime 0.409]
[epoch 31], [iter 27 / 176], [train main loss -2.003783], [lr 0.008229] [batchtime 0.408]
[epoch 31], [iter 28 / 176], [train main loss -2.027872], [lr 0.008229] [batchtime 0.407]
[epoch 31], [iter 29 / 176], [train main loss -1.963476], [lr 0.008229] [batchtime 0.406]
[epoch 31], [iter 30 / 176], [train main loss -1.971915], [lr 0.008229] [batchtime 0.405]
[epoch 31], [iter 31 / 176], [train main loss -2.061390], [lr 0.008229] [batchtime 0.405]
[epoch 31], [iter 32 / 176], [train main loss -2.033057], [lr 0.008229] [batchtime 0.405]
[epoch 31], [iter 33 / 176], [train main loss -2.095831], [lr 0.008229] [batchtime 0.404]
[epoch 31], [iter 34 / 176], [train main loss -2.113087], [lr 0.008229] [batchtime 0.404]
[epoch 31], [iter 35 / 176], [train main loss -2.099549], [lr 0.008229] [batchtime 0.403]
[epoch 31], [iter 36 / 176], [train main loss -2.080502], [lr 0.008229] [batchtime 0.403]
[epoch 31], [iter 37 / 176], [train main loss -2.107249], [lr 0.008229] [batchtime 0.403]
[epoch 31], [iter 38 / 176], [train main loss -2.104300], [lr 0.008229] [batchtime 0.403]
[epoch 31], [iter 39 / 176], [train main loss -2.100640], [lr 0.008229] [batchtime 0.402]
[epoch 31], [iter 40 / 176], [train main loss -2.128995], [lr 0.008229] [batchtime 0.402]
[epoch 31], [iter 41 / 176], [train main loss -2.106105], [lr 0.008229] [batchtime 0.401]
[epoch 31], [iter 42 / 176], [train main loss -2.141567], [lr 0.008229] [batchtime 0.401]
[epoch 31], [iter 43 / 176], [train main loss -2.118971], [lr 0.008229] [batchtime 0.4]
[epoch 31], [iter 44 / 176], [train main loss -2.045379], [lr 0.008229] [batchtime 0.4]
[epoch 31], [iter 45 / 176], [train main loss -1.999698], [lr 0.008229] [batchtime 0.4]
[epoch 31], [iter 46 / 176], [train main loss -1.991463], [lr 0.008229] [batchtime 0.4]
[epoch 31], [iter 47 / 176], [train main loss -2.009192], [lr 0.008229] [batchtime 0.403]
[epoch 31], [iter 48 / 176], [train main loss -2.023010], [lr 0.008229] [batchtime 0.432]
[epoch 31], [iter 49 / 176], [train main loss -1.998600], [lr 0.008229] [batchtime 0.431]
[epoch 31], [iter 50 / 176], [train main loss -1.925820], [lr 0.008229] [batchtime 0.43]
[epoch 31], [iter 51 / 176], [train main loss -1.935716], [lr 0.008229] [batchtime 0.429]
[epoch 31], [iter 52 / 176], [train main loss -1.977355], [lr 0.008229] [batchtime 0.428]
[epoch 31], [iter 53 / 176], [train main loss -1.988027], [lr 0.008229] [batchtime 0.427]
[epoch 31], [iter 54 / 176], [train main loss -2.009122], [lr 0.008229] [batchtime 0.426]
[epoch 31], [iter 55 / 176], [train main loss -1.987302], [lr 0.008229] [batchtime 0.425]
[epoch 31], [iter 56 / 176], [train main loss -2.024321], [lr 0.008229] [batchtime 0.425]
[epoch 31], [iter 57 / 176], [train main loss -2.043377], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 58 / 176], [train main loss -1.985301], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 59 / 176], [train main loss -1.993373], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 60 / 176], [train main loss -1.951708], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 61 / 176], [train main loss -1.906217], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 62 / 176], [train main loss -1.885411], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 63 / 176], [train main loss -1.891487], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 64 / 176], [train main loss -1.893159], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 65 / 176], [train main loss -1.898206], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 66 / 176], [train main loss -1.917182], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 67 / 176], [train main loss -1.932393], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 68 / 176], [train main loss -1.936706], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 69 / 176], [train main loss -1.905744], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 70 / 176], [train main loss -1.890922], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 71 / 176], [train main loss -1.853104], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 72 / 176], [train main loss -1.812627], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 73 / 176], [train main loss -1.839751], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 74 / 176], [train main loss -1.833742], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 75 / 176], [train main loss -1.856432], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 76 / 176], [train main loss -1.847000], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 77 / 176], [train main loss -1.802639], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 78 / 176], [train main loss -1.765888], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 79 / 176], [train main loss -1.787389], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 80 / 176], [train main loss -1.799563], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 81 / 176], [train main loss -1.797480], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 82 / 176], [train main loss -1.817695], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 83 / 176], [train main loss -1.835871], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 84 / 176], [train main loss -1.836739], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 85 / 176], [train main loss -1.857148], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 86 / 176], [train main loss -1.854430], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 87 / 176], [train main loss -1.841790], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 88 / 176], [train main loss -1.807651], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 89 / 176], [train main loss -1.808771], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 90 / 176], [train main loss -1.813280], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 91 / 176], [train main loss -1.818585], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 92 / 176], [train main loss -1.802370], [lr 0.008229] [batchtime 0.413]
[epoch 31], [iter 93 / 176], [train main loss -1.837415], [lr 0.008229] [batchtime 0.413]
[epoch 31], [iter 94 / 176], [train main loss -1.826929], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 95 / 176], [train main loss -1.820307], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 96 / 176], [train main loss -1.818026], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 97 / 176], [train main loss -1.777110], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 98 / 176], [train main loss -1.752905], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 99 / 176], [train main loss -1.732245], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 100 / 176], [train main loss -1.739910], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 101 / 176], [train main loss -1.769246], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 102 / 176], [train main loss -1.761888], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 103 / 176], [train main loss -1.722171], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 104 / 176], [train main loss -1.732839], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 105 / 176], [train main loss -1.715919], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 106 / 176], [train main loss -1.716728], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 107 / 176], [train main loss -1.695939], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 108 / 176], [train main loss -1.715879], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 109 / 176], [train main loss -1.703553], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 110 / 176], [train main loss -1.716516], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 111 / 176], [train main loss -1.716646], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 112 / 176], [train main loss -1.713834], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 113 / 176], [train main loss -1.698413], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 114 / 176], [train main loss -1.687051], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 115 / 176], [train main loss -1.693023], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 116 / 176], [train main loss -1.678502], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 117 / 176], [train main loss -1.669120], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 118 / 176], [train main loss -1.660671], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 119 / 176], [train main loss -1.634536], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 120 / 176], [train main loss -1.643969], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 121 / 176], [train main loss -1.669968], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 122 / 176], [train main loss -1.667635], [lr 0.008229] [batchtime 0.418]
[epoch 31], [iter 123 / 176], [train main loss -1.680970], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 124 / 176], [train main loss -1.682818], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 125 / 176], [train main loss -1.684660], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 126 / 176], [train main loss -1.678663], [lr 0.008229] [batchtime 0.417]
[epoch 31], [iter 127 / 176], [train main loss -1.678528], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 128 / 176], [train main loss -1.675236], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 129 / 176], [train main loss -1.677686], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 130 / 176], [train main loss -1.676031], [lr 0.008229] [batchtime 0.416]
[epoch 31], [iter 131 / 176], [train main loss -1.706366], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 132 / 176], [train main loss -1.699163], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 133 / 176], [train main loss -1.685654], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 134 / 176], [train main loss -1.682926], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 135 / 176], [train main loss -1.691330], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 136 / 176], [train main loss -1.685991], [lr 0.008229] [batchtime 0.415]
[epoch 31], [iter 137 / 176], [train main loss -1.698915], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 138 / 176], [train main loss -1.696320], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 139 / 176], [train main loss -1.706429], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 140 / 176], [train main loss -1.700133], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 141 / 176], [train main loss -1.711353], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 142 / 176], [train main loss -1.727274], [lr 0.008229] [batchtime 0.414]
[epoch 31], [iter 143 / 176], [train main loss -1.730762], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 144 / 176], [train main loss -1.751476], [lr 0.008229] [batchtime 0.425]
[epoch 31], [iter 145 / 176], [train main loss -1.737193], [lr 0.008229] [batchtime 0.425]
[epoch 31], [iter 146 / 176], [train main loss -1.737505], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 147 / 176], [train main loss -1.732595], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 148 / 176], [train main loss -1.739035], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 149 / 176], [train main loss -1.722905], [lr 0.008229] [batchtime 0.424]
[epoch 31], [iter 150 / 176], [train main loss -1.738008], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 151 / 176], [train main loss -1.738292], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 152 / 176], [train main loss -1.720858], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 153 / 176], [train main loss -1.709888], [lr 0.008229] [batchtime 0.423]
[epoch 31], [iter 154 / 176], [train main loss -1.715929], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 155 / 176], [train main loss -1.724577], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 156 / 176], [train main loss -1.722059], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 157 / 176], [train main loss -1.714357], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 158 / 176], [train main loss -1.713851], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 159 / 176], [train main loss -1.709893], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 160 / 176], [train main loss -1.703395], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 161 / 176], [train main loss -1.709939], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 162 / 176], [train main loss -1.708508], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 163 / 176], [train main loss -1.711413], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 164 / 176], [train main loss -1.699286], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 165 / 176], [train main loss -1.694751], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 166 / 176], [train main loss -1.695480], [lr 0.008229] [batchtime 0.422]
[epoch 31], [iter 167 / 176], [train main loss -1.696056], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 168 / 176], [train main loss -1.702147], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 169 / 176], [train main loss -1.705061], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 170 / 176], [train main loss -1.709327], [lr 0.008229] [batchtime 0.421]
[epoch 31], [iter 171 / 176], [train main loss -1.700972], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 172 / 176], [train main loss -1.696154], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 173 / 176], [train main loss -1.715524], [lr 0.008229] [batchtime 0.42]
[epoch 31], [iter 174 / 176], [train main loss -1.735517], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 175 / 176], [train main loss -1.722080], [lr 0.008229] [batchtime 0.419]
[epoch 31], [iter 176 / 176], [train main loss -1.711175], [lr 0.008229] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP      FN    Precision    Recall
----  -------------  --------  -----  -------  ------  -----------  --------
   0  road              91.58  35.32     0.03    0.06         0.97      0.94
   1  sidewalk          52.91   4.41     0.50    0.39         0.67      0.72
   2  building          79.91  23.74     0.12    0.13         0.89      0.88
   3  wall               5.83   0.04    13.05    3.11         0.07      0.24
   4  fence              1.69   0.02    57.27    0.93         0.02      0.52
   5  pole              23.48   0.34     2.36    0.90         0.30      0.53
   6  traffic light      0.26   0.00   384.80    1.16         0.00      0.46
   7  traffic sign       3.79   0.02    24.96    0.45         0.04      0.69
   8  vegetation        76.75  11.46     0.08    0.22         0.93      0.82
   9  terrain           26.26   0.27     1.76    1.04         0.36      0.49
  10  sky               90.49   3.72     0.04    0.06         0.96      0.94
  11  person            31.36   0.70     1.18    1.01         0.46      0.50
  12  rider              0.04   0.00  2558.01   13.15         0.00      0.07
  13  car               73.15   6.55     0.08    0.29         0.93      0.78
  14  truck              0.00   0.00   inf     nan            0.00    nan
  15  bus                0.07   0.00  1441.31    8.05         0.00      0.11
  16  train              0.00   0.00   inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00   inf     nan            0.00    nan
  18  bicycle           18.81   0.10     3.08    1.24         0.25      0.45
Mean: 30.34
-----------------------------------------------------------------------------------------------------------
this : [epoch 31], [val loss 0.45082], [acc 0.86677], [acc_cls 0.35995], [mean_iu 0.30335], [fwavacc 0.77285]
best : [epoch 31], [val loss 0.45082], [acc 0.86677], [acc_cls 0.35995], [mean_iu 0.30335], [fwavacc 0.77285]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 32], [iter 1 / 176], [train main loss -3.737307], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 2 / 176], [train main loss -1.799272], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 3 / 176], [train main loss -1.426304], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 4 / 176], [train main loss -1.831789], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 5 / 176], [train main loss -2.109265], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 6 / 176], [train main loss -1.584329], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 7 / 176], [train main loss -0.974303], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 8 / 176], [train main loss -1.147133], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 9 / 176], [train main loss -1.152315], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 10 / 176], [train main loss -0.931905], [lr 0.008171] [batchtime 0]
[epoch 32], [iter 11 / 176], [train main loss -1.155271], [lr 0.008171] [batchtime 0.373]
[epoch 32], [iter 12 / 176], [train main loss -1.228927], [lr 0.008171] [batchtime 0.388]
[epoch 32], [iter 13 / 176], [train main loss -1.199450], [lr 0.008171] [batchtime 0.392]
[epoch 32], [iter 14 / 176], [train main loss -1.096165], [lr 0.008171] [batchtime 0.393]
[epoch 32], [iter 15 / 176], [train main loss -1.070932], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 16 / 176], [train main loss -0.977250], [lr 0.008171] [batchtime 0.446]
[epoch 32], [iter 17 / 176], [train main loss -1.030535], [lr 0.008171] [batchtime 0.439]
[epoch 32], [iter 18 / 176], [train main loss -1.011782], [lr 0.008171] [batchtime 0.434]
[epoch 32], [iter 19 / 176], [train main loss -0.987617], [lr 0.008171] [batchtime 0.431]
[epoch 32], [iter 20 / 176], [train main loss -1.099080], [lr 0.008171] [batchtime 0.428]
[epoch 32], [iter 21 / 176], [train main loss -1.207406], [lr 0.008171] [batchtime 0.424]
[epoch 32], [iter 22 / 176], [train main loss -1.295255], [lr 0.008171] [batchtime 0.421]
[epoch 32], [iter 23 / 176], [train main loss -1.343083], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 24 / 176], [train main loss -1.452160], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 25 / 176], [train main loss -1.455800], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 26 / 176], [train main loss -1.537463], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 27 / 176], [train main loss -1.558332], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 28 / 176], [train main loss -1.498114], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 29 / 176], [train main loss -1.480563], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 30 / 176], [train main loss -1.560373], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 31 / 176], [train main loss -1.543587], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 32 / 176], [train main loss -1.545556], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 33 / 176], [train main loss -1.542681], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 34 / 176], [train main loss -1.578360], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 35 / 176], [train main loss -1.571121], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 36 / 176], [train main loss -1.560523], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 37 / 176], [train main loss -1.451001], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 38 / 176], [train main loss -1.557509], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 39 / 176], [train main loss -1.509748], [lr 0.008171] [batchtime 0.427]
[epoch 32], [iter 40 / 176], [train main loss -1.433889], [lr 0.008171] [batchtime 0.429]
[epoch 32], [iter 41 / 176], [train main loss -1.446405], [lr 0.008171] [batchtime 0.427]
[epoch 32], [iter 42 / 176], [train main loss -1.448352], [lr 0.008171] [batchtime 0.426]
[epoch 32], [iter 43 / 176], [train main loss -1.490206], [lr 0.008171] [batchtime 0.425]
[epoch 32], [iter 44 / 176], [train main loss -1.491889], [lr 0.008171] [batchtime 0.424]
[epoch 32], [iter 45 / 176], [train main loss -1.477767], [lr 0.008171] [batchtime 0.424]
[epoch 32], [iter 46 / 176], [train main loss -1.489612], [lr 0.008171] [batchtime 0.423]
[epoch 32], [iter 47 / 176], [train main loss -1.493998], [lr 0.008171] [batchtime 0.422]
[epoch 32], [iter 48 / 176], [train main loss -1.471960], [lr 0.008171] [batchtime 0.422]
[epoch 32], [iter 49 / 176], [train main loss -1.516185], [lr 0.008171] [batchtime 0.421]
[epoch 32], [iter 50 / 176], [train main loss -1.512903], [lr 0.008171] [batchtime 0.421]
[epoch 32], [iter 51 / 176], [train main loss -1.542787], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 52 / 176], [train main loss -1.580515], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 53 / 176], [train main loss -1.637432], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 54 / 176], [train main loss -1.669734], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 55 / 176], [train main loss -1.673007], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 56 / 176], [train main loss -1.671956], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 57 / 176], [train main loss -1.708007], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 58 / 176], [train main loss -1.715429], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 59 / 176], [train main loss -1.771563], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 60 / 176], [train main loss -1.766316], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 61 / 176], [train main loss -1.768845], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 62 / 176], [train main loss -1.757206], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 63 / 176], [train main loss -1.741209], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 64 / 176], [train main loss -1.741312], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 65 / 176], [train main loss -1.725015], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 66 / 176], [train main loss -1.727908], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 67 / 176], [train main loss -1.712046], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 68 / 176], [train main loss -1.738752], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 69 / 176], [train main loss -1.706451], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 70 / 176], [train main loss -1.718345], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 71 / 176], [train main loss -1.706494], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 72 / 176], [train main loss -1.703306], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 73 / 176], [train main loss -1.681389], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 74 / 176], [train main loss -1.718804], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 75 / 176], [train main loss -1.709554], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 76 / 176], [train main loss -1.754903], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 77 / 176], [train main loss -1.740050], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 78 / 176], [train main loss -1.731598], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 79 / 176], [train main loss -1.714011], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 80 / 176], [train main loss -1.701021], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 81 / 176], [train main loss -1.710335], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 82 / 176], [train main loss -1.710902], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 83 / 176], [train main loss -1.721389], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 84 / 176], [train main loss -1.734810], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 85 / 176], [train main loss -1.725752], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 86 / 176], [train main loss -1.726773], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 87 / 176], [train main loss -1.734450], [lr 0.008171] [batchtime 0.412]
[epoch 32], [iter 88 / 176], [train main loss -1.771485], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 89 / 176], [train main loss -1.772646], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 90 / 176], [train main loss -1.756827], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 91 / 176], [train main loss -1.735669], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 92 / 176], [train main loss -1.729068], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 93 / 176], [train main loss -1.716488], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 94 / 176], [train main loss -1.727102], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 95 / 176], [train main loss -1.721660], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 96 / 176], [train main loss -1.711004], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 97 / 176], [train main loss -1.678746], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 98 / 176], [train main loss -1.678252], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 99 / 176], [train main loss -1.681993], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 100 / 176], [train main loss -1.690794], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 101 / 176], [train main loss -1.696160], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 102 / 176], [train main loss -1.683573], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 103 / 176], [train main loss -1.695750], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 104 / 176], [train main loss -1.716007], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 105 / 176], [train main loss -1.705932], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 106 / 176], [train main loss -1.696971], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 107 / 176], [train main loss -1.707306], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 108 / 176], [train main loss -1.724856], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 109 / 176], [train main loss -1.727514], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 110 / 176], [train main loss -1.719374], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 111 / 176], [train main loss -1.734064], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 112 / 176], [train main loss -1.739956], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 113 / 176], [train main loss -1.717987], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 114 / 176], [train main loss -1.722965], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 115 / 176], [train main loss -1.743998], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 116 / 176], [train main loss -1.746554], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 117 / 176], [train main loss -1.755259], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 118 / 176], [train main loss -1.766698], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 119 / 176], [train main loss -1.786696], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 120 / 176], [train main loss -1.771815], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 121 / 176], [train main loss -1.774598], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 122 / 176], [train main loss -1.775750], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 123 / 176], [train main loss -1.803359], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 124 / 176], [train main loss -1.821631], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 125 / 176], [train main loss -1.827804], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 126 / 176], [train main loss -1.828824], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 127 / 176], [train main loss -1.817663], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 128 / 176], [train main loss -1.828995], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 129 / 176], [train main loss -1.840149], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 130 / 176], [train main loss -1.836057], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 131 / 176], [train main loss -1.860492], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 132 / 176], [train main loss -1.876600], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 133 / 176], [train main loss -1.873098], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 134 / 176], [train main loss -1.874418], [lr 0.008171] [batchtime 0.414]
[epoch 32], [iter 135 / 176], [train main loss -1.874388], [lr 0.008171] [batchtime 0.413]
[epoch 32], [iter 136 / 176], [train main loss -1.863672], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 137 / 176], [train main loss -1.853855], [lr 0.008171] [batchtime 0.421]
[epoch 32], [iter 138 / 176], [train main loss -1.858964], [lr 0.008171] [batchtime 0.421]
[epoch 32], [iter 139 / 176], [train main loss -1.856892], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 140 / 176], [train main loss -1.859430], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 141 / 176], [train main loss -1.829891], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 142 / 176], [train main loss -1.828430], [lr 0.008171] [batchtime 0.42]
[epoch 32], [iter 143 / 176], [train main loss -1.833421], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 144 / 176], [train main loss -1.838790], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 145 / 176], [train main loss -1.851958], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 146 / 176], [train main loss -1.860553], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 147 / 176], [train main loss -1.863128], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 148 / 176], [train main loss -1.872032], [lr 0.008171] [batchtime 0.419]
[epoch 32], [iter 149 / 176], [train main loss -1.865247], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 150 / 176], [train main loss -1.873646], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 151 / 176], [train main loss -1.881196], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 152 / 176], [train main loss -1.867880], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 153 / 176], [train main loss -1.888002], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 154 / 176], [train main loss -1.896189], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 155 / 176], [train main loss -1.899622], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 156 / 176], [train main loss -1.910015], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 157 / 176], [train main loss -1.913536], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 158 / 176], [train main loss -1.904360], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 159 / 176], [train main loss -1.921552], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 160 / 176], [train main loss -1.922186], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 161 / 176], [train main loss -1.908624], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 162 / 176], [train main loss -1.917366], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 163 / 176], [train main loss -1.909236], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 164 / 176], [train main loss -1.890158], [lr 0.008171] [batchtime 0.418]
[epoch 32], [iter 165 / 176], [train main loss -1.884922], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 166 / 176], [train main loss -1.889928], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 167 / 176], [train main loss -1.879028], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 168 / 176], [train main loss -1.858829], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 169 / 176], [train main loss -1.847168], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 170 / 176], [train main loss -1.850384], [lr 0.008171] [batchtime 0.417]
[epoch 32], [iter 171 / 176], [train main loss -1.856669], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 172 / 176], [train main loss -1.841654], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 173 / 176], [train main loss -1.841635], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 174 / 176], [train main loss -1.831650], [lr 0.008171] [batchtime 0.416]
[epoch 32], [iter 175 / 176], [train main loss -1.837657], [lr 0.008171] [batchtime 0.415]
[epoch 32], [iter 176 / 176], [train main loss -1.849215], [lr 0.008171] [batchtime 0.415]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP      FN    Precision    Recall
----  -------------  --------  -----  -------  ------  -----------  --------
   0  road              91.53  35.13     0.04    0.06         0.97      0.95
   1  sidewalk          55.39   4.55     0.45    0.36         0.69      0.74
   2  building          80.18  24.47     0.09    0.16         0.92      0.86
   3  wall               5.62   0.04    13.88    2.92         0.07      0.26
   4  fence              1.70   0.02    56.63    1.07         0.02      0.48
   5  pole              22.37   0.30     2.82    0.65         0.26      0.61
   6  traffic light      0.23   0.00   439.33    0.99         0.00      0.50
   7  traffic sign       3.18   0.02    29.88    0.56         0.03      0.64
   8  vegetation        76.53  11.47     0.08    0.23         0.93      0.81
   9  terrain           24.98   0.26     1.85    1.15         0.35      0.46
  10  sky               91.44   3.71     0.04    0.05         0.96      0.95
  11  person            27.33   0.52     1.95    0.71         0.34      0.59
  12  rider              0.03   0.00  3747.41   23.30         0.00      0.04
  13  car               75.00   6.39     0.11    0.23         0.90      0.82
  14  truck              0.00   0.00   inf     nan            0.00    nan
  15  bus                0.09   0.00  1121.15    7.78         0.00      0.11
  16  train              0.00   0.00   inf     nan            0.00    nan
  17  motorcycle         0.00   0.00   inf     nan            0.00    nan
  18  bicycle           20.37   0.11     2.42    1.49         0.29      0.40
Mean: 30.31
-----------------------------------------------------------------------------------------------------------
this : [epoch 32], [val loss 0.45169], [acc 0.86987], [acc_cls 0.35419], [mean_iu 0.30315], [fwavacc 0.77560]
best : [epoch 31], [val loss 0.45082], [acc 0.86677], [acc_cls 0.35995], [mean_iu 0.30335], [fwavacc 0.77285]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 33], [iter 1 / 176], [train main loss -2.964817], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 2 / 176], [train main loss -2.953135], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 3 / 176], [train main loss -2.576355], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 4 / 176], [train main loss -1.897201], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 5 / 176], [train main loss -1.446372], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 6 / 176], [train main loss -1.462145], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 7 / 176], [train main loss -1.724052], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 8 / 176], [train main loss -1.642878], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 9 / 176], [train main loss -1.754854], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 10 / 176], [train main loss -1.935636], [lr 0.008114] [batchtime 0]
[epoch 33], [iter 11 / 176], [train main loss -1.879145], [lr 0.008114] [batchtime 0.37]
[epoch 33], [iter 12 / 176], [train main loss -1.912483], [lr 0.008114] [batchtime 0.384]
[epoch 33], [iter 13 / 176], [train main loss -1.874476], [lr 0.008114] [batchtime 0.389]
[epoch 33], [iter 14 / 176], [train main loss -1.809611], [lr 0.008114] [batchtime 0.389]
[epoch 33], [iter 15 / 176], [train main loss -1.769594], [lr 0.008114] [batchtime 0.392]
[epoch 33], [iter 16 / 176], [train main loss -1.791397], [lr 0.008114] [batchtime 0.394]
[epoch 33], [iter 17 / 176], [train main loss -1.828647], [lr 0.008114] [batchtime 0.396]
[epoch 33], [iter 18 / 176], [train main loss -1.943366], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 19 / 176], [train main loss -1.682715], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 20 / 176], [train main loss -1.655374], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 21 / 176], [train main loss -1.695157], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 22 / 176], [train main loss -1.719359], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 23 / 176], [train main loss -1.635271], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 24 / 176], [train main loss -1.662555], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 25 / 176], [train main loss -1.561045], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 26 / 176], [train main loss -1.548948], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 27 / 176], [train main loss -1.633770], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 28 / 176], [train main loss -1.565719], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 29 / 176], [train main loss -1.567891], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 30 / 176], [train main loss -1.643940], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 31 / 176], [train main loss -1.562161], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 32 / 176], [train main loss -1.496239], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 33 / 176], [train main loss -1.453991], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 34 / 176], [train main loss -1.435059], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 35 / 176], [train main loss -1.353474], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 36 / 176], [train main loss -1.319927], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 37 / 176], [train main loss -1.306914], [lr 0.008114] [batchtime 0.398]
[epoch 33], [iter 38 / 176], [train main loss -1.290975], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 39 / 176], [train main loss -1.286377], [lr 0.008114] [batchtime 0.397]
[epoch 33], [iter 40 / 176], [train main loss -1.234876], [lr 0.008114] [batchtime 0.403]
[epoch 33], [iter 41 / 176], [train main loss -1.250987], [lr 0.008114] [batchtime 0.446]
[epoch 33], [iter 42 / 176], [train main loss -1.220825], [lr 0.008114] [batchtime 0.443]
[epoch 33], [iter 43 / 176], [train main loss -1.147817], [lr 0.008114] [batchtime 0.442]
[epoch 33], [iter 44 / 176], [train main loss -1.113063], [lr 0.008114] [batchtime 0.44]
[epoch 33], [iter 45 / 176], [train main loss -1.142000], [lr 0.008114] [batchtime 0.439]
[epoch 33], [iter 46 / 176], [train main loss -1.150244], [lr 0.008114] [batchtime 0.438]
[epoch 33], [iter 47 / 176], [train main loss -1.191450], [lr 0.008114] [batchtime 0.437]
[epoch 33], [iter 48 / 176], [train main loss -1.138480], [lr 0.008114] [batchtime 0.435]
[epoch 33], [iter 49 / 176], [train main loss -1.143385], [lr 0.008114] [batchtime 0.435]
[epoch 33], [iter 50 / 176], [train main loss -1.128634], [lr 0.008114] [batchtime 0.433]
[epoch 33], [iter 51 / 176], [train main loss -1.147936], [lr 0.008114] [batchtime 0.433]
[epoch 33], [iter 52 / 176], [train main loss -1.145894], [lr 0.008114] [batchtime 0.432]
[epoch 33], [iter 53 / 176], [train main loss -1.160367], [lr 0.008114] [batchtime 0.431]
[epoch 33], [iter 54 / 176], [train main loss -1.166780], [lr 0.008114] [batchtime 0.43]
[epoch 33], [iter 55 / 176], [train main loss -1.210536], [lr 0.008114] [batchtime 0.43]
[epoch 33], [iter 56 / 176], [train main loss -1.205892], [lr 0.008114] [batchtime 0.429]
[epoch 33], [iter 57 / 176], [train main loss -1.230578], [lr 0.008114] [batchtime 0.429]
[epoch 33], [iter 58 / 176], [train main loss -1.237406], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 59 / 176], [train main loss -1.222550], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 60 / 176], [train main loss -1.260703], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 61 / 176], [train main loss -1.329679], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 62 / 176], [train main loss -1.322437], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 63 / 176], [train main loss -1.309542], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 64 / 176], [train main loss -1.303202], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 65 / 176], [train main loss -1.264394], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 66 / 176], [train main loss -1.221021], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 67 / 176], [train main loss -1.226016], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 68 / 176], [train main loss -1.269348], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 69 / 176], [train main loss -1.301250], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 70 / 176], [train main loss -1.339068], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 71 / 176], [train main loss -1.385477], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 72 / 176], [train main loss -1.380457], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 73 / 176], [train main loss -1.358921], [lr 0.008114] [batchtime 0.421]
[epoch 33], [iter 74 / 176], [train main loss -1.367480], [lr 0.008114] [batchtime 0.421]
[epoch 33], [iter 75 / 176], [train main loss -1.355683], [lr 0.008114] [batchtime 0.421]
[epoch 33], [iter 76 / 176], [train main loss -1.330572], [lr 0.008114] [batchtime 0.421]
[epoch 33], [iter 77 / 176], [train main loss -1.335663], [lr 0.008114] [batchtime 0.42]
[epoch 33], [iter 78 / 176], [train main loss -1.329535], [lr 0.008114] [batchtime 0.42]
[epoch 33], [iter 79 / 176], [train main loss -1.340375], [lr 0.008114] [batchtime 0.419]
[epoch 33], [iter 80 / 176], [train main loss -1.353192], [lr 0.008114] [batchtime 0.419]
[epoch 33], [iter 81 / 176], [train main loss -1.332655], [lr 0.008114] [batchtime 0.419]
[epoch 33], [iter 82 / 176], [train main loss -1.334184], [lr 0.008114] [batchtime 0.418]
[epoch 33], [iter 83 / 176], [train main loss -1.326186], [lr 0.008114] [batchtime 0.418]
[epoch 33], [iter 84 / 176], [train main loss -1.308958], [lr 0.008114] [batchtime 0.418]
[epoch 33], [iter 85 / 176], [train main loss -1.328922], [lr 0.008114] [batchtime 0.418]
[epoch 33], [iter 86 / 176], [train main loss -1.344571], [lr 0.008114] [batchtime 0.418]
[epoch 33], [iter 87 / 176], [train main loss -1.347218], [lr 0.008114] [batchtime 0.435]
[epoch 33], [iter 88 / 176], [train main loss -1.400348], [lr 0.008114] [batchtime 0.438]
[epoch 33], [iter 89 / 176], [train main loss -1.386016], [lr 0.008114] [batchtime 0.437]
[epoch 33], [iter 90 / 176], [train main loss -1.397412], [lr 0.008114] [batchtime 0.437]
[epoch 33], [iter 91 / 176], [train main loss -1.400271], [lr 0.008114] [batchtime 0.436]
[epoch 33], [iter 92 / 176], [train main loss -1.422538], [lr 0.008114] [batchtime 0.436]
[epoch 33], [iter 93 / 176], [train main loss -1.434062], [lr 0.008114] [batchtime 0.435]
[epoch 33], [iter 94 / 176], [train main loss -1.440558], [lr 0.008114] [batchtime 0.435]
[epoch 33], [iter 95 / 176], [train main loss -1.462495], [lr 0.008114] [batchtime 0.435]
[epoch 33], [iter 96 / 176], [train main loss -1.460636], [lr 0.008114] [batchtime 0.434]
[epoch 33], [iter 97 / 176], [train main loss -1.464082], [lr 0.008114] [batchtime 0.434]
[epoch 33], [iter 98 / 176], [train main loss -1.448162], [lr 0.008114] [batchtime 0.433]
[epoch 33], [iter 99 / 176], [train main loss -1.449392], [lr 0.008114] [batchtime 0.433]
[epoch 33], [iter 100 / 176], [train main loss -1.491283], [lr 0.008114] [batchtime 0.433]
[epoch 33], [iter 101 / 176], [train main loss -1.532760], [lr 0.008114] [batchtime 0.432]
[epoch 33], [iter 102 / 176], [train main loss -1.534312], [lr 0.008114] [batchtime 0.432]
[epoch 33], [iter 103 / 176], [train main loss -1.525835], [lr 0.008114] [batchtime 0.431]
[epoch 33], [iter 104 / 176], [train main loss -1.546915], [lr 0.008114] [batchtime 0.431]
[epoch 33], [iter 105 / 176], [train main loss -1.548450], [lr 0.008114] [batchtime 0.431]
[epoch 33], [iter 106 / 176], [train main loss -1.554874], [lr 0.008114] [batchtime 0.43]
[epoch 33], [iter 107 / 176], [train main loss -1.529813], [lr 0.008114] [batchtime 0.43]
[epoch 33], [iter 108 / 176], [train main loss -1.525743], [lr 0.008114] [batchtime 0.43]
[epoch 33], [iter 109 / 176], [train main loss -1.529241], [lr 0.008114] [batchtime 0.43]
[epoch 33], [iter 110 / 176], [train main loss -1.538629], [lr 0.008114] [batchtime 0.429]
[epoch 33], [iter 111 / 176], [train main loss -1.547589], [lr 0.008114] [batchtime 0.429]
[epoch 33], [iter 112 / 176], [train main loss -1.525909], [lr 0.008114] [batchtime 0.429]
[epoch 33], [iter 113 / 176], [train main loss -1.521132], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 114 / 176], [train main loss -1.503804], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 115 / 176], [train main loss -1.495265], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 116 / 176], [train main loss -1.493266], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 117 / 176], [train main loss -1.505696], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 118 / 176], [train main loss -1.480840], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 119 / 176], [train main loss -1.462724], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 120 / 176], [train main loss -1.453621], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 121 / 176], [train main loss -1.464645], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 122 / 176], [train main loss -1.445034], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 123 / 176], [train main loss -1.439222], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 124 / 176], [train main loss -1.451511], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 125 / 176], [train main loss -1.421623], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 126 / 176], [train main loss -1.411090], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 127 / 176], [train main loss -1.409867], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 128 / 176], [train main loss -1.419887], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 129 / 176], [train main loss -1.432705], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 130 / 176], [train main loss -1.439776], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 131 / 176], [train main loss -1.460773], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 132 / 176], [train main loss -1.450600], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 133 / 176], [train main loss -1.428270], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 134 / 176], [train main loss -1.439765], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 135 / 176], [train main loss -1.444836], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 136 / 176], [train main loss -1.444625], [lr 0.008114] [batchtime 0.428]
[epoch 33], [iter 137 / 176], [train main loss -1.462865], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 138 / 176], [train main loss -1.478920], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 139 / 176], [train main loss -1.474159], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 140 / 176], [train main loss -1.479921], [lr 0.008114] [batchtime 0.427]
[epoch 33], [iter 141 / 176], [train main loss -1.473527], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 142 / 176], [train main loss -1.478827], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 143 / 176], [train main loss -1.487609], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 144 / 176], [train main loss -1.502118], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 145 / 176], [train main loss -1.497272], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 146 / 176], [train main loss -1.523039], [lr 0.008114] [batchtime 0.426]
[epoch 33], [iter 147 / 176], [train main loss -1.523916], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 148 / 176], [train main loss -1.506980], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 149 / 176], [train main loss -1.510821], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 150 / 176], [train main loss -1.511216], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 151 / 176], [train main loss -1.509161], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 152 / 176], [train main loss -1.500180], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 153 / 176], [train main loss -1.516132], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 154 / 176], [train main loss -1.508092], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 155 / 176], [train main loss -1.506345], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 156 / 176], [train main loss -1.514293], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 157 / 176], [train main loss -1.536005], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 158 / 176], [train main loss -1.543737], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 159 / 176], [train main loss -1.535315], [lr 0.008114] [batchtime 0.425]
[epoch 33], [iter 160 / 176], [train main loss -1.539537], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 161 / 176], [train main loss -1.537511], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 162 / 176], [train main loss -1.546134], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 163 / 176], [train main loss -1.533700], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 164 / 176], [train main loss -1.529932], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 165 / 176], [train main loss -1.539724], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 166 / 176], [train main loss -1.551608], [lr 0.008114] [batchtime 0.424]
[epoch 33], [iter 167 / 176], [train main loss -1.533129], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 168 / 176], [train main loss -1.531126], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 169 / 176], [train main loss -1.538570], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 170 / 176], [train main loss -1.532169], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 171 / 176], [train main loss -1.528906], [lr 0.008114] [batchtime 0.423]
[epoch 33], [iter 172 / 176], [train main loss -1.540563], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 173 / 176], [train main loss -1.559275], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 174 / 176], [train main loss -1.559091], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 175 / 176], [train main loss -1.550539], [lr 0.008114] [batchtime 0.422]
[epoch 33], [iter 176 / 176], [train main loss -1.553330], [lr 0.008114] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              91.28  35.62       0.02    0.07         0.98      0.93
   1  sidewalk          50.92   4.02       0.64    0.33         0.61      0.75
   2  building          80.13  24.67       0.08    0.17         0.93      0.85
   3  wall               5.73   0.04      13.85    2.61         0.07      0.28
   4  fence              1.31   0.02      74.26    0.88         0.01      0.53
   5  pole              23.24   0.32       2.53    0.77         0.28      0.57
   6  traffic light      0.23   0.00     427.57    0.60         0.00      0.62
   7  traffic sign       2.47   0.01      39.11    0.32         0.02      0.76
   8  vegetation        76.84  11.31       0.09    0.21         0.91      0.83
   9  terrain           27.32   0.27       1.72    0.94         0.37      0.51
  10  sky               91.50   3.68       0.05    0.04         0.95      0.96
  11  person            24.94   0.44       2.48    0.53         0.29      0.65
  12  rider              0.01   0.00   16632.56   43.33         0.00      0.02
  13  car               76.57   6.42       0.10    0.20         0.91      0.83
  14  truck              0.00   0.00   25397.81    0.01         0.00      0.99
  15  bus                0.02   0.00    5801.04    2.70         0.00      0.27
  16  train              0.00   0.00     inf     inf            0.00      0.00
  17  motorcycle         0.00   0.00  333162.25    1.75         0.00      0.36
  18  bicycle           21.36   0.13       2.08    1.60         0.32      0.38
Mean: 30.20
-----------------------------------------------------------------------------------------------------------
this : [epoch 33], [val loss 0.46712], [acc 0.86948], [acc_cls 0.35065], [mean_iu 0.30204], [fwavacc 0.77299]
best : [epoch 31], [val loss 0.45082], [acc 0.86677], [acc_cls 0.35995], [mean_iu 0.30335], [fwavacc 0.77285]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 34], [iter 1 / 176], [train main loss -2.315781], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 2 / 176], [train main loss -2.427190], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 3 / 176], [train main loss -2.235544], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 4 / 176], [train main loss -1.823781], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 5 / 176], [train main loss -0.623718], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 6 / 176], [train main loss -0.956720], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 7 / 176], [train main loss -1.085695], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 8 / 176], [train main loss -0.949455], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 9 / 176], [train main loss -1.154528], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 10 / 176], [train main loss -1.279192], [lr 0.008057] [batchtime 0]
[epoch 34], [iter 11 / 176], [train main loss -1.398727], [lr 0.008057] [batchtime 0.379]
[epoch 34], [iter 12 / 176], [train main loss -1.421206], [lr 0.008057] [batchtime 0.388]
[epoch 34], [iter 13 / 176], [train main loss -1.356056], [lr 0.008057] [batchtime 0.394]
[epoch 34], [iter 14 / 176], [train main loss -1.315462], [lr 0.008057] [batchtime 0.398]
[epoch 34], [iter 15 / 176], [train main loss -1.403691], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 16 / 176], [train main loss -1.348711], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 17 / 176], [train main loss -1.328270], [lr 0.008057] [batchtime 0.4]
[epoch 34], [iter 18 / 176], [train main loss -1.398191], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 19 / 176], [train main loss -1.432565], [lr 0.008057] [batchtime 0.4]
[epoch 34], [iter 20 / 176], [train main loss -1.327459], [lr 0.008057] [batchtime 0.4]
[epoch 34], [iter 21 / 176], [train main loss -1.389471], [lr 0.008057] [batchtime 0.4]
[epoch 34], [iter 22 / 176], [train main loss -1.396204], [lr 0.008057] [batchtime 0.4]
[epoch 34], [iter 23 / 176], [train main loss -1.383649], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 24 / 176], [train main loss -1.439288], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 25 / 176], [train main loss -1.454374], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 26 / 176], [train main loss -1.381736], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 27 / 176], [train main loss -1.387576], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 28 / 176], [train main loss -1.454589], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 29 / 176], [train main loss -1.304165], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 30 / 176], [train main loss -1.331209], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 31 / 176], [train main loss -1.294469], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 32 / 176], [train main loss -1.293542], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 33 / 176], [train main loss -1.234860], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 34 / 176], [train main loss -1.271839], [lr 0.008057] [batchtime 0.401]
[epoch 34], [iter 35 / 176], [train main loss -1.290352], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 36 / 176], [train main loss -1.312080], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 37 / 176], [train main loss -1.350662], [lr 0.008057] [batchtime 0.402]
[epoch 34], [iter 38 / 176], [train main loss -1.379709], [lr 0.008057] [batchtime 0.409]
[epoch 34], [iter 39 / 176], [train main loss -1.348214], [lr 0.008057] [batchtime 0.409]
[epoch 34], [iter 40 / 176], [train main loss -1.335304], [lr 0.008057] [batchtime 0.408]
[epoch 34], [iter 41 / 176], [train main loss -1.347653], [lr 0.008057] [batchtime 0.408]
[epoch 34], [iter 42 / 176], [train main loss -1.402129], [lr 0.008057] [batchtime 0.407]
[epoch 34], [iter 43 / 176], [train main loss -1.435091], [lr 0.008057] [batchtime 0.407]
[epoch 34], [iter 44 / 176], [train main loss -1.470473], [lr 0.008057] [batchtime 0.407]
[epoch 34], [iter 45 / 176], [train main loss -1.496824], [lr 0.008057] [batchtime 0.407]
[epoch 34], [iter 46 / 176], [train main loss -1.482561], [lr 0.008057] [batchtime 0.406]
[epoch 34], [iter 47 / 176], [train main loss -1.504783], [lr 0.008057] [batchtime 0.406]
[epoch 34], [iter 48 / 176], [train main loss -1.501061], [lr 0.008057] [batchtime 0.406]
[epoch 34], [iter 49 / 176], [train main loss -1.512084], [lr 0.008057] [batchtime 0.406]
[epoch 34], [iter 50 / 176], [train main loss -1.500581], [lr 0.008057] [batchtime 0.406]
[epoch 34], [iter 51 / 176], [train main loss -1.491543], [lr 0.008057] [batchtime 0.406]
[epoch 34], [iter 52 / 176], [train main loss -1.475509], [lr 0.008057] [batchtime 0.405]
[epoch 34], [iter 53 / 176], [train main loss -1.474648], [lr 0.008057] [batchtime 0.405]
[epoch 34], [iter 54 / 176], [train main loss -1.496197], [lr 0.008057] [batchtime 0.418]
[epoch 34], [iter 55 / 176], [train main loss -1.473212], [lr 0.008057] [batchtime 0.417]
[epoch 34], [iter 56 / 176], [train main loss -1.470834], [lr 0.008057] [batchtime 0.417]
[epoch 34], [iter 57 / 176], [train main loss -1.491814], [lr 0.008057] [batchtime 0.416]
[epoch 34], [iter 58 / 176], [train main loss -1.474784], [lr 0.008057] [batchtime 0.416]
[epoch 34], [iter 59 / 176], [train main loss -1.466685], [lr 0.008057] [batchtime 0.415]
[epoch 34], [iter 60 / 176], [train main loss -1.473650], [lr 0.008057] [batchtime 0.415]
[epoch 34], [iter 61 / 176], [train main loss -1.475734], [lr 0.008057] [batchtime 0.415]
[epoch 34], [iter 62 / 176], [train main loss -1.453321], [lr 0.008057] [batchtime 0.414]
[epoch 34], [iter 63 / 176], [train main loss -1.443702], [lr 0.008057] [batchtime 0.414]
[epoch 34], [iter 64 / 176], [train main loss -1.438842], [lr 0.008057] [batchtime 0.414]
[epoch 34], [iter 65 / 176], [train main loss -1.432389], [lr 0.008057] [batchtime 0.413]
[epoch 34], [iter 66 / 176], [train main loss -1.410630], [lr 0.008057] [batchtime 0.413]
[epoch 34], [iter 67 / 176], [train main loss -1.409852], [lr 0.008057] [batchtime 0.413]
[epoch 34], [iter 68 / 176], [train main loss -1.418953], [lr 0.008057] [batchtime 0.413]
[epoch 34], [iter 69 / 176], [train main loss -1.450968], [lr 0.008057] [batchtime 0.413]
[epoch 34], [iter 70 / 176], [train main loss -1.426169], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 71 / 176], [train main loss -1.423177], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 72 / 176], [train main loss -1.450865], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 73 / 176], [train main loss -1.482376], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 74 / 176], [train main loss -1.485606], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 75 / 176], [train main loss -1.506071], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 76 / 176], [train main loss -1.484195], [lr 0.008057] [batchtime 0.412]
[epoch 34], [iter 77 / 176], [train main loss -1.483808], [lr 0.008057] [batchtime 0.411]
[epoch 34], [iter 78 / 176], [train main loss -1.467780], [lr 0.008057] [batchtime 0.411]
[epoch 34], [iter 79 / 176], [train main loss -1.492455], [lr 0.008057] [batchtime 0.411]
[epoch 34], [iter 80 / 176], [train main loss -1.480423], [lr 0.008057] [batchtime 0.411]
[epoch 34], [iter 81 / 176], [train main loss -1.498456], [lr 0.008057] [batchtime 0.411]
[epoch 34], [iter 82 / 176], [train main loss -1.477601], [lr 0.008057] [batchtime 0.41]
[epoch 34], [iter 83 / 176], [train main loss -1.471038], [lr 0.008057] [batchtime 0.41]
[epoch 34], [iter 84 / 176], [train main loss -1.480094], [lr 0.008057] [batchtime 0.41]
[epoch 34], [iter 85 / 176], [train main loss -1.462659], [lr 0.008057] [batchtime 0.413]
[epoch 34], [iter 86 / 176], [train main loss -1.452496], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 87 / 176], [train main loss -1.438607], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 88 / 176], [train main loss -1.442738], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 89 / 176], [train main loss -1.465700], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 90 / 176], [train main loss -1.467644], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 91 / 176], [train main loss -1.438520], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 92 / 176], [train main loss -1.443298], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 93 / 176], [train main loss -1.429914], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 94 / 176], [train main loss -1.436215], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 95 / 176], [train main loss -1.451190], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 96 / 176], [train main loss -1.426623], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 97 / 176], [train main loss -1.427104], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 98 / 176], [train main loss -1.400844], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 99 / 176], [train main loss -1.384530], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 100 / 176], [train main loss -1.395833], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 101 / 176], [train main loss -1.400528], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 102 / 176], [train main loss -1.422795], [lr 0.008057] [batchtime 0.426]
[epoch 34], [iter 103 / 176], [train main loss -1.430736], [lr 0.008057] [batchtime 0.426]
[epoch 34], [iter 104 / 176], [train main loss -1.438692], [lr 0.008057] [batchtime 0.426]
[epoch 34], [iter 105 / 176], [train main loss -1.449015], [lr 0.008057] [batchtime 0.425]
[epoch 34], [iter 106 / 176], [train main loss -1.467304], [lr 0.008057] [batchtime 0.425]
[epoch 34], [iter 107 / 176], [train main loss -1.462266], [lr 0.008057] [batchtime 0.425]
[epoch 34], [iter 108 / 176], [train main loss -1.468578], [lr 0.008057] [batchtime 0.425]
[epoch 34], [iter 109 / 176], [train main loss -1.473210], [lr 0.008057] [batchtime 0.424]
[epoch 34], [iter 110 / 176], [train main loss -1.485966], [lr 0.008057] [batchtime 0.424]
[epoch 34], [iter 111 / 176], [train main loss -1.485241], [lr 0.008057] [batchtime 0.424]
[epoch 34], [iter 112 / 176], [train main loss -1.473837], [lr 0.008057] [batchtime 0.424]
[epoch 34], [iter 113 / 176], [train main loss -1.477534], [lr 0.008057] [batchtime 0.423]
[epoch 34], [iter 114 / 176], [train main loss -1.469696], [lr 0.008057] [batchtime 0.423]
[epoch 34], [iter 115 / 176], [train main loss -1.462860], [lr 0.008057] [batchtime 0.423]
[epoch 34], [iter 116 / 176], [train main loss -1.427463], [lr 0.008057] [batchtime 0.423]
[epoch 34], [iter 117 / 176], [train main loss -1.432826], [lr 0.008057] [batchtime 0.423]
[epoch 34], [iter 118 / 176], [train main loss -1.443410], [lr 0.008057] [batchtime 0.422]
[epoch 34], [iter 119 / 176], [train main loss -1.454289], [lr 0.008057] [batchtime 0.422]
[epoch 34], [iter 120 / 176], [train main loss -1.434084], [lr 0.008057] [batchtime 0.422]
[epoch 34], [iter 121 / 176], [train main loss -1.447015], [lr 0.008057] [batchtime 0.422]
[epoch 34], [iter 122 / 176], [train main loss -1.435197], [lr 0.008057] [batchtime 0.422]
[epoch 34], [iter 123 / 176], [train main loss -1.426567], [lr 0.008057] [batchtime 0.421]
[epoch 34], [iter 124 / 176], [train main loss -1.442582], [lr 0.008057] [batchtime 0.421]
[epoch 34], [iter 125 / 176], [train main loss -1.435873], [lr 0.008057] [batchtime 0.421]
[epoch 34], [iter 126 / 176], [train main loss -1.452963], [lr 0.008057] [batchtime 0.421]
[epoch 34], [iter 127 / 176], [train main loss -1.471304], [lr 0.008057] [batchtime 0.421]
[epoch 34], [iter 128 / 176], [train main loss -1.466069], [lr 0.008057] [batchtime 0.42]
[epoch 34], [iter 129 / 176], [train main loss -1.471006], [lr 0.008057] [batchtime 0.42]
[epoch 34], [iter 130 / 176], [train main loss -1.472965], [lr 0.008057] [batchtime 0.42]
[epoch 34], [iter 131 / 176], [train main loss -1.478200], [lr 0.008057] [batchtime 0.421]
[epoch 34], [iter 132 / 176], [train main loss -1.467736], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 133 / 176], [train main loss -1.456803], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 134 / 176], [train main loss -1.467675], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 135 / 176], [train main loss -1.479770], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 136 / 176], [train main loss -1.489941], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 137 / 176], [train main loss -1.515149], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 138 / 176], [train main loss -1.503399], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 139 / 176], [train main loss -1.502194], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 140 / 176], [train main loss -1.517819], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 141 / 176], [train main loss -1.511990], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 142 / 176], [train main loss -1.517574], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 143 / 176], [train main loss -1.494933], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 144 / 176], [train main loss -1.501771], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 145 / 176], [train main loss -1.516744], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 146 / 176], [train main loss -1.532691], [lr 0.008057] [batchtime 0.429]
[epoch 34], [iter 147 / 176], [train main loss -1.536198], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 148 / 176], [train main loss -1.551059], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 149 / 176], [train main loss -1.571082], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 150 / 176], [train main loss -1.569947], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 151 / 176], [train main loss -1.569507], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 152 / 176], [train main loss -1.568671], [lr 0.008057] [batchtime 0.428]
[epoch 34], [iter 153 / 176], [train main loss -1.580317], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 154 / 176], [train main loss -1.573779], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 155 / 176], [train main loss -1.560582], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 156 / 176], [train main loss -1.553986], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 157 / 176], [train main loss -1.547792], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 158 / 176], [train main loss -1.549918], [lr 0.008057] [batchtime 0.427]
[epoch 34], [iter 159 / 176], [train main loss -1.556199], [lr 0.008057] [batchtime 0.434]
[epoch 34], [iter 160 / 176], [train main loss -1.548099], [lr 0.008057] [batchtime 0.434]
[epoch 34], [iter 161 / 176], [train main loss -1.533384], [lr 0.008057] [batchtime 0.434]
[epoch 34], [iter 162 / 176], [train main loss -1.532423], [lr 0.008057] [batchtime 0.433]
[epoch 34], [iter 163 / 176], [train main loss -1.534579], [lr 0.008057] [batchtime 0.433]
[epoch 34], [iter 164 / 176], [train main loss -1.534466], [lr 0.008057] [batchtime 0.433]
[epoch 34], [iter 165 / 176], [train main loss -1.519840], [lr 0.008057] [batchtime 0.433]
[epoch 34], [iter 166 / 176], [train main loss -1.509239], [lr 0.008057] [batchtime 0.433]
[epoch 34], [iter 167 / 176], [train main loss -1.505838], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 168 / 176], [train main loss -1.484763], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 169 / 176], [train main loss -1.477876], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 170 / 176], [train main loss -1.487256], [lr 0.008057] [batchtime 0.432]
[epoch 34], [iter 171 / 176], [train main loss -1.493098], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 172 / 176], [train main loss -1.493942], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 173 / 176], [train main loss -1.503875], [lr 0.008057] [batchtime 0.431]
[epoch 34], [iter 174 / 176], [train main loss -1.503255], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 175 / 176], [train main loss -1.492783], [lr 0.008057] [batchtime 0.43]
[epoch 34], [iter 176 / 176], [train main loss -1.496624], [lr 0.008057] [batchtime 0.432]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP      FN    Precision    Recall
----  -------------  --------  -----  -------  ------  -----------  --------
   0  road              92.13  34.75     0.05    0.04         0.96      0.96
   1  sidewalk          58.90   4.94     0.33    0.37         0.75      0.73
   2  building          80.64  24.87     0.07    0.17         0.94      0.85
   3  wall               5.21   0.04    15.56    2.65         0.06      0.27
   4  fence              2.18   0.03    43.92    0.97         0.02      0.51
   5  pole              23.63   0.32     2.57    0.66         0.28      0.60
   6  traffic light      0.44   0.00   223.92    0.75         0.00      0.57
   7  traffic sign       3.83   0.02    24.64    0.45         0.04      0.69
   8  vegetation        78.12  11.34     0.09    0.19         0.92      0.84
   9  terrain           32.13   0.35     1.10    1.01         0.48      0.50
  10  sky               91.74   3.72     0.04    0.05         0.96      0.95
  11  person            29.24   0.55     1.79    0.63         0.36      0.61
  12  rider              0.02   0.00  6450.81   14.83         0.00      0.06
  13  car               76.48   6.50     0.09    0.22         0.92      0.82
  14  truck              0.12   0.00   823.25    0.01         0.00      0.99
  15  bus                0.03   0.00  2967.49   10.47         0.00      0.09
  16  train              0.00   0.00   inf     nan            0.00    nan
  17  motorcycle         0.00   0.00   inf     nan            0.00    nan
  18  bicycle           22.45   0.13     1.93    1.52         0.34      0.40
Mean: 31.44
-----------------------------------------------------------------------------------------------------------
this : [epoch 34], [val loss 0.43587], [acc 0.87565], [acc_cls 0.36960], [mean_iu 0.31436], [fwavacc 0.78557]
best : [epoch 34], [val loss 0.43587], [acc 0.87565], [acc_cls 0.36960], [mean_iu 0.31436], [fwavacc 0.78557]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 35], [iter 1 / 176], [train main loss -2.601684], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 2 / 176], [train main loss -3.251634], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 3 / 176], [train main loss -2.237975], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 4 / 176], [train main loss -2.208405], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 5 / 176], [train main loss -2.547756], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 6 / 176], [train main loss -2.367699], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 7 / 176], [train main loss -2.422216], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 8 / 176], [train main loss -2.323130], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 9 / 176], [train main loss -2.624161], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 10 / 176], [train main loss -2.379485], [lr 0.008000] [batchtime 0]
[epoch 35], [iter 11 / 176], [train main loss -2.279749], [lr 0.008000] [batchtime 0.362]
[epoch 35], [iter 12 / 176], [train main loss -2.296200], [lr 0.008000] [batchtime 0.379]
[epoch 35], [iter 13 / 176], [train main loss -2.194208], [lr 0.008000] [batchtime 0.387]
[epoch 35], [iter 14 / 176], [train main loss -2.484082], [lr 0.008000] [batchtime 0.392]
[epoch 35], [iter 15 / 176], [train main loss -2.296912], [lr 0.008000] [batchtime 0.394]
[epoch 35], [iter 16 / 176], [train main loss -2.403779], [lr 0.008000] [batchtime 0.458]
[epoch 35], [iter 17 / 176], [train main loss -2.325830], [lr 0.008000] [batchtime 0.449]
[epoch 35], [iter 18 / 176], [train main loss -2.229126], [lr 0.008000] [batchtime 0.441]
[epoch 35], [iter 19 / 176], [train main loss -2.198973], [lr 0.008000] [batchtime 0.437]
[epoch 35], [iter 20 / 176], [train main loss -2.121192], [lr 0.008000] [batchtime 0.433]
[epoch 35], [iter 21 / 176], [train main loss -1.936506], [lr 0.008000] [batchtime 0.43]
[epoch 35], [iter 22 / 176], [train main loss -1.919276], [lr 0.008000] [batchtime 0.427]
[epoch 35], [iter 23 / 176], [train main loss -1.830013], [lr 0.008000] [batchtime 0.426]
[epoch 35], [iter 24 / 176], [train main loss -1.838595], [lr 0.008000] [batchtime 0.434]
[epoch 35], [iter 25 / 176], [train main loss -1.792258], [lr 0.008000] [batchtime 0.432]
[epoch 35], [iter 26 / 176], [train main loss -1.751744], [lr 0.008000] [batchtime 0.434]
[epoch 35], [iter 27 / 176], [train main loss -1.776345], [lr 0.008000] [batchtime 0.443]
[epoch 35], [iter 28 / 176], [train main loss -1.757045], [lr 0.008000] [batchtime 0.441]
[epoch 35], [iter 29 / 176], [train main loss -1.739659], [lr 0.008000] [batchtime 0.439]
[epoch 35], [iter 30 / 176], [train main loss -1.743495], [lr 0.008000] [batchtime 0.437]
[epoch 35], [iter 31 / 176], [train main loss -1.819519], [lr 0.008000] [batchtime 0.435]
[epoch 35], [iter 32 / 176], [train main loss -1.761831], [lr 0.008000] [batchtime 0.434]
[epoch 35], [iter 33 / 176], [train main loss -1.850927], [lr 0.008000] [batchtime 0.433]
[epoch 35], [iter 34 / 176], [train main loss -1.811429], [lr 0.008000] [batchtime 0.431]
[epoch 35], [iter 35 / 176], [train main loss -1.891974], [lr 0.008000] [batchtime 0.43]
[epoch 35], [iter 36 / 176], [train main loss -1.869056], [lr 0.008000] [batchtime 0.428]
[epoch 35], [iter 37 / 176], [train main loss -1.862248], [lr 0.008000] [batchtime 0.428]
[epoch 35], [iter 38 / 176], [train main loss -1.821437], [lr 0.008000] [batchtime 0.427]
[epoch 35], [iter 39 / 176], [train main loss -1.758195], [lr 0.008000] [batchtime 0.425]
[epoch 35], [iter 40 / 176], [train main loss -1.719979], [lr 0.008000] [batchtime 0.425]
[epoch 35], [iter 41 / 176], [train main loss -1.732202], [lr 0.008000] [batchtime 0.424]
[epoch 35], [iter 42 / 176], [train main loss -1.759798], [lr 0.008000] [batchtime 0.423]
[epoch 35], [iter 43 / 176], [train main loss -1.754443], [lr 0.008000] [batchtime 0.423]
[epoch 35], [iter 44 / 176], [train main loss -1.672599], [lr 0.008000] [batchtime 0.422]
[epoch 35], [iter 45 / 176], [train main loss -1.599706], [lr 0.008000] [batchtime 0.421]
[epoch 35], [iter 46 / 176], [train main loss -1.588625], [lr 0.008000] [batchtime 0.421]
[epoch 35], [iter 47 / 176], [train main loss -1.545235], [lr 0.008000] [batchtime 0.421]
[epoch 35], [iter 48 / 176], [train main loss -1.523819], [lr 0.008000] [batchtime 0.42]
[epoch 35], [iter 49 / 176], [train main loss -1.488354], [lr 0.008000] [batchtime 0.42]
[epoch 35], [iter 50 / 176], [train main loss -1.570838], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 51 / 176], [train main loss -1.608412], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 52 / 176], [train main loss -1.621749], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 53 / 176], [train main loss -1.635343], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 54 / 176], [train main loss -1.618351], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 55 / 176], [train main loss -1.594062], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 56 / 176], [train main loss -1.534673], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 57 / 176], [train main loss -1.523184], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 58 / 176], [train main loss -1.563983], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 59 / 176], [train main loss -1.585438], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 60 / 176], [train main loss -1.602415], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 61 / 176], [train main loss -1.540888], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 62 / 176], [train main loss -1.537113], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 63 / 176], [train main loss -1.518188], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 64 / 176], [train main loss -1.526893], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 65 / 176], [train main loss -1.519389], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 66 / 176], [train main loss -1.496541], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 67 / 176], [train main loss -1.485734], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 68 / 176], [train main loss -1.465578], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 69 / 176], [train main loss -1.480239], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 70 / 176], [train main loss -1.509409], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 71 / 176], [train main loss -1.517331], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 72 / 176], [train main loss -1.518831], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 73 / 176], [train main loss -1.526750], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 74 / 176], [train main loss -1.539831], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 75 / 176], [train main loss -1.579151], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 76 / 176], [train main loss -1.602507], [lr 0.008000] [batchtime 0.42]
[epoch 35], [iter 77 / 176], [train main loss -1.624077], [lr 0.008000] [batchtime 0.42]
[epoch 35], [iter 78 / 176], [train main loss -1.625731], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 79 / 176], [train main loss -1.623488], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 80 / 176], [train main loss -1.631026], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 81 / 176], [train main loss -1.616036], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 82 / 176], [train main loss -1.634104], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 83 / 176], [train main loss -1.637339], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 84 / 176], [train main loss -1.667048], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 85 / 176], [train main loss -1.655515], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 86 / 176], [train main loss -1.645684], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 87 / 176], [train main loss -1.613577], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 88 / 176], [train main loss -1.599116], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 89 / 176], [train main loss -1.611132], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 90 / 176], [train main loss -1.608700], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 91 / 176], [train main loss -1.568138], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 92 / 176], [train main loss -1.560627], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 93 / 176], [train main loss -1.566366], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 94 / 176], [train main loss -1.555486], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 95 / 176], [train main loss -1.559245], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 96 / 176], [train main loss -1.540643], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 97 / 176], [train main loss -1.571268], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 98 / 176], [train main loss -1.582693], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 99 / 176], [train main loss -1.584029], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 100 / 176], [train main loss -1.592825], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 101 / 176], [train main loss -1.590555], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 102 / 176], [train main loss -1.574230], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 103 / 176], [train main loss -1.587946], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 104 / 176], [train main loss -1.632069], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 105 / 176], [train main loss -1.629039], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 106 / 176], [train main loss -1.644790], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 107 / 176], [train main loss -1.623785], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 108 / 176], [train main loss -1.611799], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 109 / 176], [train main loss -1.608138], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 110 / 176], [train main loss -1.622358], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 111 / 176], [train main loss -1.601803], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 112 / 176], [train main loss -1.613012], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 113 / 176], [train main loss -1.600806], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 114 / 176], [train main loss -1.609006], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 115 / 176], [train main loss -1.597642], [lr 0.008000] [batchtime 0.411]
[epoch 35], [iter 116 / 176], [train main loss -1.606676], [lr 0.008000] [batchtime 0.411]
[epoch 35], [iter 117 / 176], [train main loss -1.619164], [lr 0.008000] [batchtime 0.411]
[epoch 35], [iter 118 / 176], [train main loss -1.634354], [lr 0.008000] [batchtime 0.411]
[epoch 35], [iter 119 / 176], [train main loss -1.636570], [lr 0.008000] [batchtime 0.411]
[epoch 35], [iter 120 / 176], [train main loss -1.621979], [lr 0.008000] [batchtime 0.411]
[epoch 35], [iter 121 / 176], [train main loss -1.601476], [lr 0.008000] [batchtime 0.41]
[epoch 35], [iter 122 / 176], [train main loss -1.593653], [lr 0.008000] [batchtime 0.41]
[epoch 35], [iter 123 / 176], [train main loss -1.584451], [lr 0.008000] [batchtime 0.41]
[epoch 35], [iter 124 / 176], [train main loss -1.574020], [lr 0.008000] [batchtime 0.41]
[epoch 35], [iter 125 / 176], [train main loss -1.564734], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 126 / 176], [train main loss -1.564898], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 127 / 176], [train main loss -1.546419], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 128 / 176], [train main loss -1.533119], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 129 / 176], [train main loss -1.529615], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 130 / 176], [train main loss -1.538111], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 131 / 176], [train main loss -1.536903], [lr 0.008000] [batchtime 0.417]
[epoch 35], [iter 132 / 176], [train main loss -1.544274], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 133 / 176], [train main loss -1.542223], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 134 / 176], [train main loss -1.527642], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 135 / 176], [train main loss -1.541885], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 136 / 176], [train main loss -1.534500], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 137 / 176], [train main loss -1.521693], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 138 / 176], [train main loss -1.511440], [lr 0.008000] [batchtime 0.416]
[epoch 35], [iter 139 / 176], [train main loss -1.509644], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 140 / 176], [train main loss -1.520052], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 141 / 176], [train main loss -1.529499], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 142 / 176], [train main loss -1.540314], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 143 / 176], [train main loss -1.543991], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 144 / 176], [train main loss -1.561206], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 145 / 176], [train main loss -1.551815], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 146 / 176], [train main loss -1.542243], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 147 / 176], [train main loss -1.532798], [lr 0.008000] [batchtime 0.415]
[epoch 35], [iter 148 / 176], [train main loss -1.524603], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 149 / 176], [train main loss -1.548921], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 150 / 176], [train main loss -1.547941], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 151 / 176], [train main loss -1.538686], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 152 / 176], [train main loss -1.525602], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 153 / 176], [train main loss -1.519141], [lr 0.008000] [batchtime 0.414]
[epoch 35], [iter 154 / 176], [train main loss -1.510160], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 155 / 176], [train main loss -1.498184], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 156 / 176], [train main loss -1.498786], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 157 / 176], [train main loss -1.489926], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 158 / 176], [train main loss -1.477311], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 159 / 176], [train main loss -1.492324], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 160 / 176], [train main loss -1.482936], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 161 / 176], [train main loss -1.494994], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 162 / 176], [train main loss -1.487220], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 163 / 176], [train main loss -1.487057], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 164 / 176], [train main loss -1.490511], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 165 / 176], [train main loss -1.505177], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 166 / 176], [train main loss -1.503300], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 167 / 176], [train main loss -1.508346], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 168 / 176], [train main loss -1.496684], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 169 / 176], [train main loss -1.493679], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 170 / 176], [train main loss -1.501441], [lr 0.008000] [batchtime 0.413]
[epoch 35], [iter 171 / 176], [train main loss -1.501367], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 172 / 176], [train main loss -1.489097], [lr 0.008000] [batchtime 0.412]
[epoch 35], [iter 173 / 176], [train main loss -1.490852], [lr 0.008000] [batchtime 0.418]
[epoch 35], [iter 174 / 176], [train main loss -1.477671], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 175 / 176], [train main loss -1.475855], [lr 0.008000] [batchtime 0.419]
[epoch 35], [iter 176 / 176], [train main loss -1.472788], [lr 0.008000] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP    FN    Precision    Recall
----  -------------  --------  -----  ---------  ----  -----------  --------
   0  road              91.80  34.95       0.04  0.05         0.96      0.95
   1  sidewalk          57.54   4.95       0.33  0.41         0.75      0.71
   2  building          80.01  24.12       0.10  0.15         0.91      0.87
   3  wall               6.00   0.04      12.87  2.81         0.07      0.26
   4  fence              2.22   0.03      42.91  1.06         0.02      0.49
   5  pole              23.07   0.30       2.75  0.59         0.27      0.63
   6  traffic light      0.75   0.00     131.80  0.48         0.01      0.67
   7  traffic sign       3.92   0.02      23.92  0.58         0.04      0.63
   8  vegetation        75.84  11.59       0.07  0.25         0.94      0.80
   9  terrain           27.21   0.26       1.87  0.81         0.35      0.55
  10  sky               91.10   3.74       0.04  0.06         0.97      0.94
  11  person            28.57   0.56       1.74  0.76         0.37      0.57
  12  rider              0.15   0.00     660.21  9.82         0.00      0.09
  13  car               76.91   6.28       0.13  0.17         0.89      0.85
  14  truck              0.10   0.00    1034.15  0.35         0.00      0.74
  15  bus                0.06   0.00    1753.57  8.20         0.00      0.11
  16  train              0.01   0.00    7532.41  0.94         0.00      0.52
  17  motorcycle         0.00   0.00  133264.30  1.70         0.00      0.37
  18  bicycle           21.13   0.18       1.11  2.62         0.47      0.28
Mean: 30.86
-----------------------------------------------------------------------------------------------------------
this : [epoch 35], [val loss 0.42822], [acc 0.87019], [acc_cls 0.36900], [mean_iu 0.30862], [fwavacc 0.77852]
best : [epoch 34], [val loss 0.43587], [acc 0.87565], [acc_cls 0.36960], [mean_iu 0.31436], [fwavacc 0.78557]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 36], [iter 1 / 176], [train main loss -2.283600], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 2 / 176], [train main loss -2.294934], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 3 / 176], [train main loss -2.261405], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 4 / 176], [train main loss -2.029080], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 5 / 176], [train main loss -2.484885], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 6 / 176], [train main loss -2.695371], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 7 / 176], [train main loss -2.349661], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 8 / 176], [train main loss -1.915503], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 9 / 176], [train main loss -1.926210], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 10 / 176], [train main loss -1.933447], [lr 0.007943] [batchtime 0]
[epoch 36], [iter 11 / 176], [train main loss -1.840594], [lr 0.007943] [batchtime 0.384]
[epoch 36], [iter 12 / 176], [train main loss -1.943097], [lr 0.007943] [batchtime 0.395]
[epoch 36], [iter 13 / 176], [train main loss -1.947305], [lr 0.007943] [batchtime 0.395]
[epoch 36], [iter 14 / 176], [train main loss -1.955623], [lr 0.007943] [batchtime 0.398]
[epoch 36], [iter 15 / 176], [train main loss -2.059111], [lr 0.007943] [batchtime 0.399]
[epoch 36], [iter 16 / 176], [train main loss -1.976836], [lr 0.007943] [batchtime 0.399]
[epoch 36], [iter 17 / 176], [train main loss -1.919091], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 18 / 176], [train main loss -2.032143], [lr 0.007943] [batchtime 0.403]
[epoch 36], [iter 19 / 176], [train main loss -2.147412], [lr 0.007943] [batchtime 0.402]
[epoch 36], [iter 20 / 176], [train main loss -2.343156], [lr 0.007943] [batchtime 0.402]
[epoch 36], [iter 21 / 176], [train main loss -2.337520], [lr 0.007943] [batchtime 0.402]
[epoch 36], [iter 22 / 176], [train main loss -2.306087], [lr 0.007943] [batchtime 0.401]
[epoch 36], [iter 23 / 176], [train main loss -2.272542], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 24 / 176], [train main loss -2.232431], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 25 / 176], [train main loss -2.338066], [lr 0.007943] [batchtime 0.399]
[epoch 36], [iter 26 / 176], [train main loss -2.280477], [lr 0.007943] [batchtime 0.399]
[epoch 36], [iter 27 / 176], [train main loss -2.221358], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 28 / 176], [train main loss -2.294638], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 29 / 176], [train main loss -2.292214], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 30 / 176], [train main loss -2.285065], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 31 / 176], [train main loss -2.259494], [lr 0.007943] [batchtime 0.4]
[epoch 36], [iter 32 / 176], [train main loss -2.242114], [lr 0.007943] [batchtime 0.449]
[epoch 36], [iter 33 / 176], [train main loss -2.246909], [lr 0.007943] [batchtime 0.453]
[epoch 36], [iter 34 / 176], [train main loss -2.264290], [lr 0.007943] [batchtime 0.451]
[epoch 36], [iter 35 / 176], [train main loss -2.317478], [lr 0.007943] [batchtime 0.448]
[epoch 36], [iter 36 / 176], [train main loss -2.286110], [lr 0.007943] [batchtime 0.447]
[epoch 36], [iter 37 / 176], [train main loss -2.313943], [lr 0.007943] [batchtime 0.444]
[epoch 36], [iter 38 / 176], [train main loss -2.306150], [lr 0.007943] [batchtime 0.443]
[epoch 36], [iter 39 / 176], [train main loss -2.286192], [lr 0.007943] [batchtime 0.441]
[epoch 36], [iter 40 / 176], [train main loss -2.351899], [lr 0.007943] [batchtime 0.44]
[epoch 36], [iter 41 / 176], [train main loss -2.337060], [lr 0.007943] [batchtime 0.439]
[epoch 36], [iter 42 / 176], [train main loss -2.321822], [lr 0.007943] [batchtime 0.438]
[epoch 36], [iter 43 / 176], [train main loss -2.350813], [lr 0.007943] [batchtime 0.437]
[epoch 36], [iter 44 / 176], [train main loss -2.309277], [lr 0.007943] [batchtime 0.436]
[epoch 36], [iter 45 / 176], [train main loss -2.297932], [lr 0.007943] [batchtime 0.435]
[epoch 36], [iter 46 / 176], [train main loss -2.283216], [lr 0.007943] [batchtime 0.434]
[epoch 36], [iter 47 / 176], [train main loss -2.309141], [lr 0.007943] [batchtime 0.433]
[epoch 36], [iter 48 / 176], [train main loss -2.300698], [lr 0.007943] [batchtime 0.432]
[epoch 36], [iter 49 / 176], [train main loss -2.280751], [lr 0.007943] [batchtime 0.431]
[epoch 36], [iter 50 / 176], [train main loss -2.234960], [lr 0.007943] [batchtime 0.431]
[epoch 36], [iter 51 / 176], [train main loss -2.275990], [lr 0.007943] [batchtime 0.43]
[epoch 36], [iter 52 / 176], [train main loss -2.232984], [lr 0.007943] [batchtime 0.429]
[epoch 36], [iter 53 / 176], [train main loss -2.203426], [lr 0.007943] [batchtime 0.429]
[epoch 36], [iter 54 / 176], [train main loss -2.185013], [lr 0.007943] [batchtime 0.428]
[epoch 36], [iter 55 / 176], [train main loss -2.201605], [lr 0.007943] [batchtime 0.428]
[epoch 36], [iter 56 / 176], [train main loss -2.189353], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 57 / 176], [train main loss -2.147577], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 58 / 176], [train main loss -2.122191], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 59 / 176], [train main loss -2.091579], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 60 / 176], [train main loss -2.130925], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 61 / 176], [train main loss -2.112991], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 62 / 176], [train main loss -2.065564], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 63 / 176], [train main loss -2.049391], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 64 / 176], [train main loss -2.023511], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 65 / 176], [train main loss -2.022806], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 66 / 176], [train main loss -2.014180], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 67 / 176], [train main loss -2.029342], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 68 / 176], [train main loss -2.033204], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 69 / 176], [train main loss -2.048670], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 70 / 176], [train main loss -2.031652], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 71 / 176], [train main loss -2.053422], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 72 / 176], [train main loss -2.069061], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 73 / 176], [train main loss -2.049901], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 74 / 176], [train main loss -2.049817], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 75 / 176], [train main loss -2.055592], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 76 / 176], [train main loss -2.024236], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 77 / 176], [train main loss -1.991488], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 78 / 176], [train main loss -2.002275], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 79 / 176], [train main loss -1.983471], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 80 / 176], [train main loss -1.945568], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 81 / 176], [train main loss -1.970743], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 82 / 176], [train main loss -1.960713], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 83 / 176], [train main loss -1.955140], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 84 / 176], [train main loss -1.995554], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 85 / 176], [train main loss -2.005982], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 86 / 176], [train main loss -2.001119], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 87 / 176], [train main loss -2.001905], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 88 / 176], [train main loss -2.024260], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 89 / 176], [train main loss -2.030141], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 90 / 176], [train main loss -2.007288], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 91 / 176], [train main loss -1.977324], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 92 / 176], [train main loss -1.936207], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 93 / 176], [train main loss -1.951187], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 94 / 176], [train main loss -1.953825], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 95 / 176], [train main loss -1.941964], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 96 / 176], [train main loss -1.954043], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 97 / 176], [train main loss -1.969128], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 98 / 176], [train main loss -1.956451], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 99 / 176], [train main loss -1.967906], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 100 / 176], [train main loss -1.991316], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 101 / 176], [train main loss -1.983949], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 102 / 176], [train main loss -1.998050], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 103 / 176], [train main loss -2.015324], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 104 / 176], [train main loss -1.999134], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 105 / 176], [train main loss -1.999100], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 106 / 176], [train main loss -1.994081], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 107 / 176], [train main loss -1.990655], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 108 / 176], [train main loss -1.981519], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 109 / 176], [train main loss -1.966593], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 110 / 176], [train main loss -1.952758], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 111 / 176], [train main loss -1.940983], [lr 0.007943] [batchtime 0.417]
[epoch 36], [iter 112 / 176], [train main loss -1.924249], [lr 0.007943] [batchtime 0.417]
[epoch 36], [iter 113 / 176], [train main loss -1.913779], [lr 0.007943] [batchtime 0.417]
[epoch 36], [iter 114 / 176], [train main loss -1.915374], [lr 0.007943] [batchtime 0.417]
[epoch 36], [iter 115 / 176], [train main loss -1.913199], [lr 0.007943] [batchtime 0.417]
[epoch 36], [iter 116 / 176], [train main loss -1.889122], [lr 0.007943] [batchtime 0.417]
[epoch 36], [iter 117 / 176], [train main loss -1.899196], [lr 0.007943] [batchtime 0.416]
[epoch 36], [iter 118 / 176], [train main loss -1.885468], [lr 0.007943] [batchtime 0.416]
[epoch 36], [iter 119 / 176], [train main loss -1.870926], [lr 0.007943] [batchtime 0.416]
[epoch 36], [iter 120 / 176], [train main loss -1.862996], [lr 0.007943] [batchtime 0.416]
[epoch 36], [iter 121 / 176], [train main loss -1.850803], [lr 0.007943] [batchtime 0.416]
[epoch 36], [iter 122 / 176], [train main loss -1.868028], [lr 0.007943] [batchtime 0.416]
[epoch 36], [iter 123 / 176], [train main loss -1.868380], [lr 0.007943] [batchtime 0.415]
[epoch 36], [iter 124 / 176], [train main loss -1.869119], [lr 0.007943] [batchtime 0.415]
[epoch 36], [iter 125 / 176], [train main loss -1.874918], [lr 0.007943] [batchtime 0.415]
[epoch 36], [iter 126 / 176], [train main loss -1.865453], [lr 0.007943] [batchtime 0.415]
[epoch 36], [iter 127 / 176], [train main loss -1.886189], [lr 0.007943] [batchtime 0.415]
[epoch 36], [iter 128 / 176], [train main loss -1.891657], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 129 / 176], [train main loss -1.881506], [lr 0.007943] [batchtime 0.428]
[epoch 36], [iter 130 / 176], [train main loss -1.893105], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 131 / 176], [train main loss -1.902617], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 132 / 176], [train main loss -1.889611], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 133 / 176], [train main loss -1.880442], [lr 0.007943] [batchtime 0.427]
[epoch 36], [iter 134 / 176], [train main loss -1.904778], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 135 / 176], [train main loss -1.888679], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 136 / 176], [train main loss -1.880418], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 137 / 176], [train main loss -1.891668], [lr 0.007943] [batchtime 0.426]
[epoch 36], [iter 138 / 176], [train main loss -1.893096], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 139 / 176], [train main loss -1.900097], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 140 / 176], [train main loss -1.917055], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 141 / 176], [train main loss -1.907243], [lr 0.007943] [batchtime 0.425]
[epoch 36], [iter 142 / 176], [train main loss -1.905189], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 143 / 176], [train main loss -1.905046], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 144 / 176], [train main loss -1.919151], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 145 / 176], [train main loss -1.924495], [lr 0.007943] [batchtime 0.424]
[epoch 36], [iter 146 / 176], [train main loss -1.920233], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 147 / 176], [train main loss -1.933817], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 148 / 176], [train main loss -1.931546], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 149 / 176], [train main loss -1.929303], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 150 / 176], [train main loss -1.934837], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 151 / 176], [train main loss -1.939940], [lr 0.007943] [batchtime 0.423]
[epoch 36], [iter 152 / 176], [train main loss -1.928534], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 153 / 176], [train main loss -1.898072], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 154 / 176], [train main loss -1.894737], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 155 / 176], [train main loss -1.882157], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 156 / 176], [train main loss -1.870724], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 157 / 176], [train main loss -1.881056], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 158 / 176], [train main loss -1.883165], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 159 / 176], [train main loss -1.873057], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 160 / 176], [train main loss -1.876589], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 161 / 176], [train main loss -1.872221], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 162 / 176], [train main loss -1.870498], [lr 0.007943] [batchtime 0.421]
[epoch 36], [iter 163 / 176], [train main loss -1.853641], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 164 / 176], [train main loss -1.847544], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 165 / 176], [train main loss -1.832993], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 166 / 176], [train main loss -1.828611], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 167 / 176], [train main loss -1.829733], [lr 0.007943] [batchtime 0.42]
[epoch 36], [iter 168 / 176], [train main loss -1.824468], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 169 / 176], [train main loss -1.835983], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 170 / 176], [train main loss -1.837881], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 171 / 176], [train main loss -1.841994], [lr 0.007943] [batchtime 0.419]
[epoch 36], [iter 172 / 176], [train main loss -1.844089], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 173 / 176], [train main loss -1.845857], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 174 / 176], [train main loss -1.841839], [lr 0.007943] [batchtime 0.418]
[epoch 36], [iter 175 / 176], [train main loss -1.833522], [lr 0.007943] [batchtime 0.422]
[epoch 36], [iter 176 / 176], [train main loss -1.833373], [lr 0.007943] [batchtime 0.423]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP      FN    Precision    Recall
----  -------------  --------  -----  ---------  ------  -----------  --------
   0  road              91.10  34.20       0.06    0.03         0.94      0.97
   1  sidewalk          57.61   5.29       0.25    0.49         0.80      0.67
   2  building          80.71  24.20       0.10    0.14         0.91      0.88
   3  wall               7.75   0.06       9.34    2.56         0.10      0.28
   4  fence              2.13   0.03      44.99    0.91         0.02      0.52
   5  pole              24.24   0.32       2.52    0.60         0.28      0.62
   6  traffic light      1.03   0.00      95.63    0.70         0.01      0.59
   7  traffic sign       4.80   0.03      19.27    0.57         0.05      0.64
   8  vegetation        76.78  11.47       0.08    0.22         0.93      0.82
   9  terrain           29.14   0.28       1.59    0.84         0.39      0.54
  10  sky               91.35   3.76       0.03    0.07         0.97      0.94
  11  person            33.43   0.68       1.26    0.74         0.44      0.58
  12  rider              0.02   0.00    5348.49   14.28         0.00      0.07
  13  car               75.26   6.60       0.07    0.26         0.93      0.80
  14  truck              0.00   0.00  547887.69  239.00         0.00      0.00
  15  bus                0.13   0.00     731.54   10.31         0.00      0.09
  16  train              0.03   0.00    3986.44    0.49         0.00      0.67
  17  motorcycle         0.00   0.00  222107.83    0.17         0.00      0.86
  18  bicycle           20.12   0.11       2.63    1.34         0.28      0.43
Mean: 31.35
-----------------------------------------------------------------------------------------------------------
this : [epoch 36], [val loss 0.43526], [acc 0.87032], [acc_cls 0.37129], [mean_iu 0.31348], [fwavacc 0.77908]
best : [epoch 34], [val loss 0.43587], [acc 0.87565], [acc_cls 0.36960], [mean_iu 0.31436], [fwavacc 0.78557]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 37], [iter 1 / 176], [train main loss -2.465054], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 2 / 176], [train main loss -3.540313], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 3 / 176], [train main loss -3.416908], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 4 / 176], [train main loss -2.758968], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 5 / 176], [train main loss -2.368812], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 6 / 176], [train main loss -2.369359], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 7 / 176], [train main loss -2.144022], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 8 / 176], [train main loss -2.241633], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 9 / 176], [train main loss -2.116171], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 10 / 176], [train main loss -1.964392], [lr 0.007886] [batchtime 0]
[epoch 37], [iter 11 / 176], [train main loss -1.993049], [lr 0.007886] [batchtime 0.36]
[epoch 37], [iter 12 / 176], [train main loss -1.698441], [lr 0.007886] [batchtime 0.375]
[epoch 37], [iter 13 / 176], [train main loss -1.815746], [lr 0.007886] [batchtime 0.396]
[epoch 37], [iter 14 / 176], [train main loss -1.805162], [lr 0.007886] [batchtime 0.398]
[epoch 37], [iter 15 / 176], [train main loss -1.761125], [lr 0.007886] [batchtime 0.398]
[epoch 37], [iter 16 / 176], [train main loss -1.689286], [lr 0.007886] [batchtime 0.397]
[epoch 37], [iter 17 / 176], [train main loss -1.601371], [lr 0.007886] [batchtime 0.398]
[epoch 37], [iter 18 / 176], [train main loss -1.698149], [lr 0.007886] [batchtime 0.398]
[epoch 37], [iter 19 / 176], [train main loss -1.997431], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 20 / 176], [train main loss -2.031128], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 21 / 176], [train main loss -2.025769], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 22 / 176], [train main loss -2.047317], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 23 / 176], [train main loss -2.116061], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 24 / 176], [train main loss -2.046967], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 25 / 176], [train main loss -2.047030], [lr 0.007886] [batchtime 0.399]
[epoch 37], [iter 26 / 176], [train main loss -2.100745], [lr 0.007886] [batchtime 0.4]
[epoch 37], [iter 27 / 176], [train main loss -2.050004], [lr 0.007886] [batchtime 0.4]
[epoch 37], [iter 28 / 176], [train main loss -2.121882], [lr 0.007886] [batchtime 0.4]
[epoch 37], [iter 29 / 176], [train main loss -2.106520], [lr 0.007886] [batchtime 0.401]
[epoch 37], [iter 30 / 176], [train main loss -2.231693], [lr 0.007886] [batchtime 0.4]
[epoch 37], [iter 31 / 176], [train main loss -2.223365], [lr 0.007886] [batchtime 0.4]
[epoch 37], [iter 32 / 176], [train main loss -2.300611], [lr 0.007886] [batchtime 0.4]
[epoch 37], [iter 33 / 176], [train main loss -2.280194], [lr 0.007886] [batchtime 0.407]
[epoch 37], [iter 34 / 176], [train main loss -2.234536], [lr 0.007886] [batchtime 0.464]
[epoch 37], [iter 35 / 176], [train main loss -2.199295], [lr 0.007886] [batchtime 0.461]
[epoch 37], [iter 36 / 176], [train main loss -2.234216], [lr 0.007886] [batchtime 0.458]
[epoch 37], [iter 37 / 176], [train main loss -2.243906], [lr 0.007886] [batchtime 0.456]
[epoch 37], [iter 38 / 176], [train main loss -2.264448], [lr 0.007886] [batchtime 0.453]
[epoch 37], [iter 39 / 176], [train main loss -2.323293], [lr 0.007886] [batchtime 0.451]
[epoch 37], [iter 40 / 176], [train main loss -2.336198], [lr 0.007886] [batchtime 0.45]
[epoch 37], [iter 41 / 176], [train main loss -2.327009], [lr 0.007886] [batchtime 0.448]
[epoch 37], [iter 42 / 176], [train main loss -2.341560], [lr 0.007886] [batchtime 0.447]
[epoch 37], [iter 43 / 176], [train main loss -2.286952], [lr 0.007886] [batchtime 0.445]
[epoch 37], [iter 44 / 176], [train main loss -2.245514], [lr 0.007886] [batchtime 0.444]
[epoch 37], [iter 45 / 176], [train main loss -2.152092], [lr 0.007886] [batchtime 0.443]
[epoch 37], [iter 46 / 176], [train main loss -2.118157], [lr 0.007886] [batchtime 0.441]
[epoch 37], [iter 47 / 176], [train main loss -2.118568], [lr 0.007886] [batchtime 0.44]
[epoch 37], [iter 48 / 176], [train main loss -2.130407], [lr 0.007886] [batchtime 0.439]
[epoch 37], [iter 49 / 176], [train main loss -2.085794], [lr 0.007886] [batchtime 0.438]
[epoch 37], [iter 50 / 176], [train main loss -2.084009], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 51 / 176], [train main loss -2.066062], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 52 / 176], [train main loss -2.058335], [lr 0.007886] [batchtime 0.436]
[epoch 37], [iter 53 / 176], [train main loss -1.980531], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 54 / 176], [train main loss -1.980770], [lr 0.007886] [batchtime 0.434]
[epoch 37], [iter 55 / 176], [train main loss -2.012511], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 56 / 176], [train main loss -1.977648], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 57 / 176], [train main loss -1.930524], [lr 0.007886] [batchtime 0.432]
[epoch 37], [iter 58 / 176], [train main loss -1.899726], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 59 / 176], [train main loss -1.925620], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 60 / 176], [train main loss -1.943559], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 61 / 176], [train main loss -1.954400], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 62 / 176], [train main loss -1.978638], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 63 / 176], [train main loss -2.000640], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 64 / 176], [train main loss -1.979670], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 65 / 176], [train main loss -1.965961], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 66 / 176], [train main loss -1.977716], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 67 / 176], [train main loss -2.024225], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 68 / 176], [train main loss -1.994155], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 69 / 176], [train main loss -1.927342], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 70 / 176], [train main loss -1.940316], [lr 0.007886] [batchtime 0.424]
[epoch 37], [iter 71 / 176], [train main loss -1.918759], [lr 0.007886] [batchtime 0.424]
[epoch 37], [iter 72 / 176], [train main loss -1.918668], [lr 0.007886] [batchtime 0.423]
[epoch 37], [iter 73 / 176], [train main loss -1.920907], [lr 0.007886] [batchtime 0.423]
[epoch 37], [iter 74 / 176], [train main loss -1.931434], [lr 0.007886] [batchtime 0.422]
[epoch 37], [iter 75 / 176], [train main loss -1.881760], [lr 0.007886] [batchtime 0.422]
[epoch 37], [iter 76 / 176], [train main loss -1.877816], [lr 0.007886] [batchtime 0.424]
[epoch 37], [iter 77 / 176], [train main loss -1.859702], [lr 0.007886] [batchtime 0.423]
[epoch 37], [iter 78 / 176], [train main loss -1.865022], [lr 0.007886] [batchtime 0.423]
[epoch 37], [iter 79 / 176], [train main loss -1.849387], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 80 / 176], [train main loss -1.858079], [lr 0.007886] [batchtime 0.443]
[epoch 37], [iter 81 / 176], [train main loss -1.844324], [lr 0.007886] [batchtime 0.442]
[epoch 37], [iter 82 / 176], [train main loss -1.846597], [lr 0.007886] [batchtime 0.442]
[epoch 37], [iter 83 / 176], [train main loss -1.856955], [lr 0.007886] [batchtime 0.441]
[epoch 37], [iter 84 / 176], [train main loss -1.877940], [lr 0.007886] [batchtime 0.44]
[epoch 37], [iter 85 / 176], [train main loss -1.894312], [lr 0.007886] [batchtime 0.44]
[epoch 37], [iter 86 / 176], [train main loss -1.914935], [lr 0.007886] [batchtime 0.439]
[epoch 37], [iter 87 / 176], [train main loss -1.900455], [lr 0.007886] [batchtime 0.439]
[epoch 37], [iter 88 / 176], [train main loss -1.896487], [lr 0.007886] [batchtime 0.438]
[epoch 37], [iter 89 / 176], [train main loss -1.877857], [lr 0.007886] [batchtime 0.438]
[epoch 37], [iter 90 / 176], [train main loss -1.848696], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 91 / 176], [train main loss -1.877353], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 92 / 176], [train main loss -1.878231], [lr 0.007886] [batchtime 0.436]
[epoch 37], [iter 93 / 176], [train main loss -1.875943], [lr 0.007886] [batchtime 0.436]
[epoch 37], [iter 94 / 176], [train main loss -1.857373], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 95 / 176], [train main loss -1.858436], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 96 / 176], [train main loss -1.881313], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 97 / 176], [train main loss -1.883410], [lr 0.007886] [batchtime 0.434]
[epoch 37], [iter 98 / 176], [train main loss -1.871949], [lr 0.007886] [batchtime 0.434]
[epoch 37], [iter 99 / 176], [train main loss -1.879352], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 100 / 176], [train main loss -1.864097], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 101 / 176], [train main loss -1.845219], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 102 / 176], [train main loss -1.841901], [lr 0.007886] [batchtime 0.432]
[epoch 37], [iter 103 / 176], [train main loss -1.843273], [lr 0.007886] [batchtime 0.432]
[epoch 37], [iter 104 / 176], [train main loss -1.834571], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 105 / 176], [train main loss -1.846305], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 106 / 176], [train main loss -1.848570], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 107 / 176], [train main loss -1.849989], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 108 / 176], [train main loss -1.857284], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 109 / 176], [train main loss -1.852612], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 110 / 176], [train main loss -1.847495], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 111 / 176], [train main loss -1.836697], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 112 / 176], [train main loss -1.844530], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 113 / 176], [train main loss -1.819464], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 114 / 176], [train main loss -1.830975], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 115 / 176], [train main loss -1.841691], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 116 / 176], [train main loss -1.846207], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 117 / 176], [train main loss -1.856262], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 118 / 176], [train main loss -1.872880], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 119 / 176], [train main loss -1.861401], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 120 / 176], [train main loss -1.876109], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 121 / 176], [train main loss -1.883603], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 122 / 176], [train main loss -1.886171], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 123 / 176], [train main loss -1.870824], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 124 / 176], [train main loss -1.865742], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 125 / 176], [train main loss -1.893498], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 126 / 176], [train main loss -1.904481], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 127 / 176], [train main loss -1.886158], [lr 0.007886] [batchtime 0.438]
[epoch 37], [iter 128 / 176], [train main loss -1.907917], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 129 / 176], [train main loss -1.889831], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 130 / 176], [train main loss -1.901520], [lr 0.007886] [batchtime 0.437]
[epoch 37], [iter 131 / 176], [train main loss -1.911916], [lr 0.007886] [batchtime 0.436]
[epoch 37], [iter 132 / 176], [train main loss -1.918323], [lr 0.007886] [batchtime 0.436]
[epoch 37], [iter 133 / 176], [train main loss -1.918172], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 134 / 176], [train main loss -1.907333], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 135 / 176], [train main loss -1.925743], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 136 / 176], [train main loss -1.911452], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 137 / 176], [train main loss -1.907281], [lr 0.007886] [batchtime 0.434]
[epoch 37], [iter 138 / 176], [train main loss -1.904944], [lr 0.007886] [batchtime 0.434]
[epoch 37], [iter 139 / 176], [train main loss -1.903560], [lr 0.007886] [batchtime 0.434]
[epoch 37], [iter 140 / 176], [train main loss -1.883705], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 141 / 176], [train main loss -1.912266], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 142 / 176], [train main loss -1.903097], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 143 / 176], [train main loss -1.902994], [lr 0.007886] [batchtime 0.433]
[epoch 37], [iter 144 / 176], [train main loss -1.891077], [lr 0.007886] [batchtime 0.432]
[epoch 37], [iter 145 / 176], [train main loss -1.887696], [lr 0.007886] [batchtime 0.432]
[epoch 37], [iter 146 / 176], [train main loss -1.870866], [lr 0.007886] [batchtime 0.432]
[epoch 37], [iter 147 / 176], [train main loss -1.868561], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 148 / 176], [train main loss -1.874923], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 149 / 176], [train main loss -1.857770], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 150 / 176], [train main loss -1.861262], [lr 0.007886] [batchtime 0.431]
[epoch 37], [iter 151 / 176], [train main loss -1.864492], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 152 / 176], [train main loss -1.864405], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 153 / 176], [train main loss -1.854566], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 154 / 176], [train main loss -1.861946], [lr 0.007886] [batchtime 0.43]
[epoch 37], [iter 155 / 176], [train main loss -1.850303], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 156 / 176], [train main loss -1.849973], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 157 / 176], [train main loss -1.849674], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 158 / 176], [train main loss -1.845277], [lr 0.007886] [batchtime 0.429]
[epoch 37], [iter 159 / 176], [train main loss -1.841634], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 160 / 176], [train main loss -1.828809], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 161 / 176], [train main loss -1.834360], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 162 / 176], [train main loss -1.832849], [lr 0.007886] [batchtime 0.428]
[epoch 37], [iter 163 / 176], [train main loss -1.842373], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 164 / 176], [train main loss -1.845082], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 165 / 176], [train main loss -1.852376], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 166 / 176], [train main loss -1.841651], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 167 / 176], [train main loss -1.835188], [lr 0.007886] [batchtime 0.427]
[epoch 37], [iter 168 / 176], [train main loss -1.824967], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 169 / 176], [train main loss -1.828576], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 170 / 176], [train main loss -1.832526], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 171 / 176], [train main loss -1.827003], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 172 / 176], [train main loss -1.818180], [lr 0.007886] [batchtime 0.425]
[epoch 37], [iter 173 / 176], [train main loss -1.807318], [lr 0.007886] [batchtime 0.426]
[epoch 37], [iter 174 / 176], [train main loss -1.806964], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 175 / 176], [train main loss -1.783109], [lr 0.007886] [batchtime 0.435]
[epoch 37], [iter 176 / 176], [train main loss -1.783772], [lr 0.007886] [batchtime 0.435]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP     FN    Precision    Recall
----  -------------  --------  -----  ---------  -----  -----------  --------
   0  road              92.47  35.04       0.04   0.04         0.96      0.96
   1  sidewalk          59.80   5.04       0.31   0.37         0.77      0.73
   2  building          80.97  24.04       0.11   0.13         0.90      0.89
   3  wall               4.54   0.03      18.22   2.82         0.05      0.26
   4  fence              4.27   0.06      21.57   0.86         0.04      0.54
   5  pole              27.07   0.40       1.87   0.83         0.35      0.55
   6  traffic light      1.27   0.00      77.14   0.78         0.01      0.56
   7  traffic sign       6.21   0.04      14.46   0.63         0.06      0.61
   8  vegetation        76.00  11.62       0.06   0.25         0.94      0.80
   9  terrain           30.56   0.29       1.57   0.71         0.39      0.59
  10  sky               92.22   3.74       0.04   0.05         0.97      0.95
  11  person            33.49   0.68       1.27   0.72         0.44      0.58
  12  rider              0.06   0.00    1611.95  10.76         0.00      0.09
  13  car               77.70   6.49       0.09   0.20         0.92      0.83
  14  truck              0.00   0.00  767043.19   9.00         0.00      0.10
  15  bus                1.17   0.00      81.41   3.26         0.01      0.23
  16  train              0.03   0.00    3229.25   0.32         0.00      0.76
  17  motorcycle         0.00   0.00   21493.40   2.56         0.00      0.28
  18  bicycle           23.79   0.16       1.42   1.79         0.41      0.36
Mean: 32.19
-----------------------------------------------------------------------------------------------------------
this : [epoch 37], [val loss 0.41754], [acc 0.87637], [acc_cls 0.38100], [mean_iu 0.32191], [fwavacc 0.78807]
best : [epoch 37], [val loss 0.41754], [acc 0.87637], [acc_cls 0.38100], [mean_iu 0.32191], [fwavacc 0.78807]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 38], [iter 1 / 176], [train main loss -2.579655], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 2 / 176], [train main loss -2.518955], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 3 / 176], [train main loss -1.492290], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 4 / 176], [train main loss -1.683421], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 5 / 176], [train main loss -1.703427], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 6 / 176], [train main loss -1.815995], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 7 / 176], [train main loss -1.613107], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 8 / 176], [train main loss -1.514082], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 9 / 176], [train main loss -1.416401], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 10 / 176], [train main loss -1.386966], [lr 0.007829] [batchtime 0]
[epoch 38], [iter 11 / 176], [train main loss -1.303547], [lr 0.007829] [batchtime 0.365]
[epoch 38], [iter 12 / 176], [train main loss -1.502255], [lr 0.007829] [batchtime 0.384]
[epoch 38], [iter 13 / 176], [train main loss -1.675610], [lr 0.007829] [batchtime 0.387]
[epoch 38], [iter 14 / 176], [train main loss -1.524887], [lr 0.007829] [batchtime 0.39]
[epoch 38], [iter 15 / 176], [train main loss -1.595435], [lr 0.007829] [batchtime 0.391]
[epoch 38], [iter 16 / 176], [train main loss -1.570299], [lr 0.007829] [batchtime 0.393]
[epoch 38], [iter 17 / 176], [train main loss -1.537527], [lr 0.007829] [batchtime 0.393]
[epoch 38], [iter 18 / 176], [train main loss -1.556025], [lr 0.007829] [batchtime 0.394]
[epoch 38], [iter 19 / 176], [train main loss -1.522114], [lr 0.007829] [batchtime 0.395]
[epoch 38], [iter 20 / 176], [train main loss -1.427135], [lr 0.007829] [batchtime 0.395]
[epoch 38], [iter 21 / 176], [train main loss -1.336146], [lr 0.007829] [batchtime 0.396]
[epoch 38], [iter 22 / 176], [train main loss -1.285102], [lr 0.007829] [batchtime 0.396]
[epoch 38], [iter 23 / 176], [train main loss -1.338074], [lr 0.007829] [batchtime 0.396]
[epoch 38], [iter 24 / 176], [train main loss -1.312855], [lr 0.007829] [batchtime 0.402]
[epoch 38], [iter 25 / 176], [train main loss -1.318130], [lr 0.007829] [batchtime 0.413]
[epoch 38], [iter 26 / 176], [train main loss -1.276104], [lr 0.007829] [batchtime 0.412]
[epoch 38], [iter 27 / 176], [train main loss -1.298616], [lr 0.007829] [batchtime 0.411]
[epoch 38], [iter 28 / 176], [train main loss -1.321498], [lr 0.007829] [batchtime 0.41]
[epoch 38], [iter 29 / 176], [train main loss -1.258450], [lr 0.007829] [batchtime 0.409]
[epoch 38], [iter 30 / 176], [train main loss -1.259188], [lr 0.007829] [batchtime 0.409]
[epoch 38], [iter 31 / 176], [train main loss -1.331589], [lr 0.007829] [batchtime 0.409]
[epoch 38], [iter 32 / 176], [train main loss -1.368122], [lr 0.007829] [batchtime 0.408]
[epoch 38], [iter 33 / 176], [train main loss -1.402050], [lr 0.007829] [batchtime 0.407]
[epoch 38], [iter 34 / 176], [train main loss -1.470328], [lr 0.007829] [batchtime 0.407]
[epoch 38], [iter 35 / 176], [train main loss -1.456935], [lr 0.007829] [batchtime 0.406]
[epoch 38], [iter 36 / 176], [train main loss -1.419306], [lr 0.007829] [batchtime 0.406]
[epoch 38], [iter 37 / 176], [train main loss -1.480153], [lr 0.007829] [batchtime 0.406]
[epoch 38], [iter 38 / 176], [train main loss -1.457164], [lr 0.007829] [batchtime 0.406]
[epoch 38], [iter 39 / 176], [train main loss -1.472891], [lr 0.007829] [batchtime 0.405]
[epoch 38], [iter 40 / 176], [train main loss -1.607918], [lr 0.007829] [batchtime 0.405]
[epoch 38], [iter 41 / 176], [train main loss -1.525534], [lr 0.007829] [batchtime 0.405]
[epoch 38], [iter 42 / 176], [train main loss -1.588810], [lr 0.007829] [batchtime 0.405]
[epoch 38], [iter 43 / 176], [train main loss -1.570874], [lr 0.007829] [batchtime 0.404]
[epoch 38], [iter 44 / 176], [train main loss -1.500961], [lr 0.007829] [batchtime 0.404]
[epoch 38], [iter 45 / 176], [train main loss -1.531952], [lr 0.007829] [batchtime 0.404]
[epoch 38], [iter 46 / 176], [train main loss -1.510956], [lr 0.007829] [batchtime 0.404]
[epoch 38], [iter 47 / 176], [train main loss -1.496527], [lr 0.007829] [batchtime 0.404]
[epoch 38], [iter 48 / 176], [train main loss -1.433065], [lr 0.007829] [batchtime 0.409]
[epoch 38], [iter 49 / 176], [train main loss -1.447725], [lr 0.007829] [batchtime 0.443]
[epoch 38], [iter 50 / 176], [train main loss -1.466066], [lr 0.007829] [batchtime 0.441]
[epoch 38], [iter 51 / 176], [train main loss -1.440620], [lr 0.007829] [batchtime 0.44]
[epoch 38], [iter 52 / 176], [train main loss -1.415787], [lr 0.007829] [batchtime 0.439]
[epoch 38], [iter 53 / 176], [train main loss -1.424687], [lr 0.007829] [batchtime 0.438]
[epoch 38], [iter 54 / 176], [train main loss -1.442778], [lr 0.007829] [batchtime 0.437]
[epoch 38], [iter 55 / 176], [train main loss -1.464206], [lr 0.007829] [batchtime 0.436]
[epoch 38], [iter 56 / 176], [train main loss -1.464243], [lr 0.007829] [batchtime 0.435]
[epoch 38], [iter 57 / 176], [train main loss -1.454149], [lr 0.007829] [batchtime 0.434]
[epoch 38], [iter 58 / 176], [train main loss -1.420872], [lr 0.007829] [batchtime 0.434]
[epoch 38], [iter 59 / 176], [train main loss -1.421664], [lr 0.007829] [batchtime 0.433]
[epoch 38], [iter 60 / 176], [train main loss -1.399007], [lr 0.007829] [batchtime 0.432]
[epoch 38], [iter 61 / 176], [train main loss -1.466695], [lr 0.007829] [batchtime 0.431]
[epoch 38], [iter 62 / 176], [train main loss -1.476808], [lr 0.007829] [batchtime 0.431]
[epoch 38], [iter 63 / 176], [train main loss -1.500851], [lr 0.007829] [batchtime 0.43]
[epoch 38], [iter 64 / 176], [train main loss -1.493341], [lr 0.007829] [batchtime 0.43]
[epoch 38], [iter 65 / 176], [train main loss -1.474066], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 66 / 176], [train main loss -1.451746], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 67 / 176], [train main loss -1.421717], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 68 / 176], [train main loss -1.431012], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 69 / 176], [train main loss -1.407246], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 70 / 176], [train main loss -1.388882], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 71 / 176], [train main loss -1.365650], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 72 / 176], [train main loss -1.323857], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 73 / 176], [train main loss -1.368349], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 74 / 176], [train main loss -1.377444], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 75 / 176], [train main loss -1.437738], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 76 / 176], [train main loss -1.483161], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 77 / 176], [train main loss -1.467909], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 78 / 176], [train main loss -1.475453], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 79 / 176], [train main loss -1.416214], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 80 / 176], [train main loss -1.440673], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 81 / 176], [train main loss -1.479345], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 82 / 176], [train main loss -1.463823], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 83 / 176], [train main loss -1.484697], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 84 / 176], [train main loss -1.503869], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 85 / 176], [train main loss -1.497708], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 86 / 176], [train main loss -1.479857], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 87 / 176], [train main loss -1.497081], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 88 / 176], [train main loss -1.520650], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 89 / 176], [train main loss -1.556019], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 90 / 176], [train main loss -1.543322], [lr 0.007829] [batchtime 0.421]
[epoch 38], [iter 91 / 176], [train main loss -1.563118], [lr 0.007829] [batchtime 0.421]
[epoch 38], [iter 92 / 176], [train main loss -1.537302], [lr 0.007829] [batchtime 0.421]
[epoch 38], [iter 93 / 176], [train main loss -1.544038], [lr 0.007829] [batchtime 0.42]
[epoch 38], [iter 94 / 176], [train main loss -1.545411], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 95 / 176], [train main loss -1.541962], [lr 0.007829] [batchtime 0.434]
[epoch 38], [iter 96 / 176], [train main loss -1.547266], [lr 0.007829] [batchtime 0.434]
[epoch 38], [iter 97 / 176], [train main loss -1.566708], [lr 0.007829] [batchtime 0.433]
[epoch 38], [iter 98 / 176], [train main loss -1.584223], [lr 0.007829] [batchtime 0.433]
[epoch 38], [iter 99 / 176], [train main loss -1.570045], [lr 0.007829] [batchtime 0.432]
[epoch 38], [iter 100 / 176], [train main loss -1.546414], [lr 0.007829] [batchtime 0.432]
[epoch 38], [iter 101 / 176], [train main loss -1.552716], [lr 0.007829] [batchtime 0.432]
[epoch 38], [iter 102 / 176], [train main loss -1.544375], [lr 0.007829] [batchtime 0.431]
[epoch 38], [iter 103 / 176], [train main loss -1.520482], [lr 0.007829] [batchtime 0.431]
[epoch 38], [iter 104 / 176], [train main loss -1.522795], [lr 0.007829] [batchtime 0.431]
[epoch 38], [iter 105 / 176], [train main loss -1.510985], [lr 0.007829] [batchtime 0.43]
[epoch 38], [iter 106 / 176], [train main loss -1.505395], [lr 0.007829] [batchtime 0.43]
[epoch 38], [iter 107 / 176], [train main loss -1.515771], [lr 0.007829] [batchtime 0.43]
[epoch 38], [iter 108 / 176], [train main loss -1.515846], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 109 / 176], [train main loss -1.544498], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 110 / 176], [train main loss -1.546438], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 111 / 176], [train main loss -1.567259], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 112 / 176], [train main loss -1.579483], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 113 / 176], [train main loss -1.580996], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 114 / 176], [train main loss -1.601339], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 115 / 176], [train main loss -1.589391], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 116 / 176], [train main loss -1.585612], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 117 / 176], [train main loss -1.583415], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 118 / 176], [train main loss -1.584808], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 119 / 176], [train main loss -1.602224], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 120 / 176], [train main loss -1.612170], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 121 / 176], [train main loss -1.588823], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 122 / 176], [train main loss -1.581565], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 123 / 176], [train main loss -1.577051], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 124 / 176], [train main loss -1.560807], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 125 / 176], [train main loss -1.559995], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 126 / 176], [train main loss -1.566851], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 127 / 176], [train main loss -1.565556], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 128 / 176], [train main loss -1.562860], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 129 / 176], [train main loss -1.559425], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 130 / 176], [train main loss -1.559319], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 131 / 176], [train main loss -1.537552], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 132 / 176], [train main loss -1.544141], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 133 / 176], [train main loss -1.528539], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 134 / 176], [train main loss -1.513066], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 135 / 176], [train main loss -1.501190], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 136 / 176], [train main loss -1.497904], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 137 / 176], [train main loss -1.510793], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 138 / 176], [train main loss -1.516815], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 139 / 176], [train main loss -1.513846], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 140 / 176], [train main loss -1.530029], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 141 / 176], [train main loss -1.552814], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 142 / 176], [train main loss -1.565306], [lr 0.007829] [batchtime 0.426]
[epoch 38], [iter 143 / 176], [train main loss -1.557939], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 144 / 176], [train main loss -1.548612], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 145 / 176], [train main loss -1.543500], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 146 / 176], [train main loss -1.547546], [lr 0.007829] [batchtime 0.425]
[epoch 38], [iter 147 / 176], [train main loss -1.553964], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 148 / 176], [train main loss -1.542032], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 149 / 176], [train main loss -1.543967], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 150 / 176], [train main loss -1.544385], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 151 / 176], [train main loss -1.531671], [lr 0.007829] [batchtime 0.424]
[epoch 38], [iter 152 / 176], [train main loss -1.505925], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 153 / 176], [train main loss -1.501672], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 154 / 176], [train main loss -1.491246], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 155 / 176], [train main loss -1.503021], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 156 / 176], [train main loss -1.507113], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 157 / 176], [train main loss -1.522484], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 158 / 176], [train main loss -1.528112], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 159 / 176], [train main loss -1.501590], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 160 / 176], [train main loss -1.520698], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 161 / 176], [train main loss -1.524188], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 162 / 176], [train main loss -1.536329], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 163 / 176], [train main loss -1.535481], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 164 / 176], [train main loss -1.522301], [lr 0.007829] [batchtime 0.422]
[epoch 38], [iter 165 / 176], [train main loss -1.536413], [lr 0.007829] [batchtime 0.423]
[epoch 38], [iter 166 / 176], [train main loss -1.530934], [lr 0.007829] [batchtime 0.43]
[epoch 38], [iter 167 / 176], [train main loss -1.526894], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 168 / 176], [train main loss -1.526652], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 169 / 176], [train main loss -1.528736], [lr 0.007829] [batchtime 0.429]
[epoch 38], [iter 170 / 176], [train main loss -1.522769], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 171 / 176], [train main loss -1.529956], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 172 / 176], [train main loss -1.545943], [lr 0.007829] [batchtime 0.428]
[epoch 38], [iter 173 / 176], [train main loss -1.544880], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 174 / 176], [train main loss -1.547379], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 175 / 176], [train main loss -1.545651], [lr 0.007829] [batchtime 0.427]
[epoch 38], [iter 176 / 176], [train main loss -1.545840], [lr 0.007829] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              92.33  35.28      0.03    0.05         0.97      0.95
   1  sidewalk          57.38   4.81      0.37    0.37         0.73      0.73
   2  building          80.66  24.59      0.08    0.16         0.93      0.86
   3  wall               6.75   0.05     11.48    2.35         0.08      0.30
   4  fence              3.69   0.05     25.16    0.96         0.04      0.51
   5  pole              25.60   0.36      2.12    0.79         0.32      0.56
   6  traffic light      1.12   0.00     87.58    0.54         0.01      0.65
   7  traffic sign       3.92   0.02     23.90    0.61         0.04      0.62
   8  vegetation        77.72  11.32      0.09    0.19         0.92      0.84
   9  terrain           31.26   0.31      1.37    0.82         0.42      0.55
  10  sky               91.41   3.73      0.04    0.06         0.96      0.95
  11  person            30.06   0.56      1.74    0.58         0.36      0.63
  12  rider              0.41   0.00    240.23    2.44         0.00      0.29
  13  car               78.53   6.40      0.11    0.17         0.90      0.86
  14  truck              0.00   0.00    inf     nan            0.00    nan
  15  bus                0.95   0.00    101.96    2.56         0.01      0.28
  16  train              0.29   0.00    338.89    0.05         0.00      0.95
  17  motorcycle         0.00   0.00  95188.50    9.86         0.00      0.09
  18  bicycle           23.44   0.16      1.50    1.77         0.40      0.36
Mean: 31.87
-----------------------------------------------------------------------------------------------------------
this : [epoch 38], [val loss 0.42246], [acc 0.87643], [acc_cls 0.37381], [mean_iu 0.31870], [fwavacc 0.78680]
best : [epoch 37], [val loss 0.41754], [acc 0.87637], [acc_cls 0.38100], [mean_iu 0.32191], [fwavacc 0.78807]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 39], [iter 1 / 176], [train main loss -1.694553], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 2 / 176], [train main loss -1.943532], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 3 / 176], [train main loss -2.157755], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 4 / 176], [train main loss -1.851380], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 5 / 176], [train main loss -1.859133], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 6 / 176], [train main loss -1.928338], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 7 / 176], [train main loss -1.510842], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 8 / 176], [train main loss -1.587376], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 9 / 176], [train main loss -1.594653], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 10 / 176], [train main loss -1.718479], [lr 0.007771] [batchtime 0]
[epoch 39], [iter 11 / 176], [train main loss -1.686095], [lr 0.007771] [batchtime 0.362]
[epoch 39], [iter 12 / 176], [train main loss -1.936892], [lr 0.007771] [batchtime 0.384]
[epoch 39], [iter 13 / 176], [train main loss -2.002125], [lr 0.007771] [batchtime 0.395]
[epoch 39], [iter 14 / 176], [train main loss -1.910256], [lr 0.007771] [batchtime 0.397]
[epoch 39], [iter 15 / 176], [train main loss -1.910343], [lr 0.007771] [batchtime 0.398]
[epoch 39], [iter 16 / 176], [train main loss -1.896431], [lr 0.007771] [batchtime 0.399]
[epoch 39], [iter 17 / 176], [train main loss -2.001927], [lr 0.007771] [batchtime 0.402]
[epoch 39], [iter 18 / 176], [train main loss -2.024692], [lr 0.007771] [batchtime 0.401]
[epoch 39], [iter 19 / 176], [train main loss -1.991237], [lr 0.007771] [batchtime 0.4]
[epoch 39], [iter 20 / 176], [train main loss -1.956683], [lr 0.007771] [batchtime 0.402]
[epoch 39], [iter 21 / 176], [train main loss -1.903954], [lr 0.007771] [batchtime 0.402]
[epoch 39], [iter 22 / 176], [train main loss -1.967020], [lr 0.007771] [batchtime 0.408]
[epoch 39], [iter 23 / 176], [train main loss -1.895994], [lr 0.007771] [batchtime 0.419]
[epoch 39], [iter 24 / 176], [train main loss -1.849711], [lr 0.007771] [batchtime 0.418]
[epoch 39], [iter 25 / 176], [train main loss -1.850169], [lr 0.007771] [batchtime 0.416]
[epoch 39], [iter 26 / 176], [train main loss -1.894359], [lr 0.007771] [batchtime 0.415]
[epoch 39], [iter 27 / 176], [train main loss -1.873509], [lr 0.007771] [batchtime 0.414]
[epoch 39], [iter 28 / 176], [train main loss -1.831964], [lr 0.007771] [batchtime 0.414]
[epoch 39], [iter 29 / 176], [train main loss -1.827503], [lr 0.007771] [batchtime 0.414]
[epoch 39], [iter 30 / 176], [train main loss -1.892306], [lr 0.007771] [batchtime 0.413]
[epoch 39], [iter 31 / 176], [train main loss -1.887607], [lr 0.007771] [batchtime 0.412]
[epoch 39], [iter 32 / 176], [train main loss -1.941349], [lr 0.007771] [batchtime 0.412]
[epoch 39], [iter 33 / 176], [train main loss -1.831789], [lr 0.007771] [batchtime 0.411]
[epoch 39], [iter 34 / 176], [train main loss -1.817294], [lr 0.007771] [batchtime 0.411]
[epoch 39], [iter 35 / 176], [train main loss -1.874246], [lr 0.007771] [batchtime 0.41]
[epoch 39], [iter 36 / 176], [train main loss -1.840900], [lr 0.007771] [batchtime 0.41]
[epoch 39], [iter 37 / 176], [train main loss -1.856413], [lr 0.007771] [batchtime 0.41]
[epoch 39], [iter 38 / 176], [train main loss -1.837977], [lr 0.007771] [batchtime 0.409]
[epoch 39], [iter 39 / 176], [train main loss -1.823340], [lr 0.007771] [batchtime 0.409]
[epoch 39], [iter 40 / 176], [train main loss -1.847376], [lr 0.007771] [batchtime 0.408]
[epoch 39], [iter 41 / 176], [train main loss -1.906134], [lr 0.007771] [batchtime 0.408]
[epoch 39], [iter 42 / 176], [train main loss -1.963535], [lr 0.007771] [batchtime 0.408]
[epoch 39], [iter 43 / 176], [train main loss -1.950550], [lr 0.007771] [batchtime 0.408]
[epoch 39], [iter 44 / 176], [train main loss -1.926537], [lr 0.007771] [batchtime 0.407]
[epoch 39], [iter 45 / 176], [train main loss -1.911489], [lr 0.007771] [batchtime 0.407]
[epoch 39], [iter 46 / 176], [train main loss -1.904059], [lr 0.007771] [batchtime 0.41]
[epoch 39], [iter 47 / 176], [train main loss -1.847666], [lr 0.007771] [batchtime 0.442]
[epoch 39], [iter 48 / 176], [train main loss -1.883062], [lr 0.007771] [batchtime 0.441]
[epoch 39], [iter 49 / 176], [train main loss -1.830467], [lr 0.007771] [batchtime 0.439]
[epoch 39], [iter 50 / 176], [train main loss -1.831113], [lr 0.007771] [batchtime 0.438]
[epoch 39], [iter 51 / 176], [train main loss -1.839953], [lr 0.007771] [batchtime 0.437]
[epoch 39], [iter 52 / 176], [train main loss -1.797959], [lr 0.007771] [batchtime 0.436]
[epoch 39], [iter 53 / 176], [train main loss -1.798188], [lr 0.007771] [batchtime 0.435]
[epoch 39], [iter 54 / 176], [train main loss -1.825309], [lr 0.007771] [batchtime 0.434]
[epoch 39], [iter 55 / 176], [train main loss -1.816342], [lr 0.007771] [batchtime 0.433]
[epoch 39], [iter 56 / 176], [train main loss -1.823911], [lr 0.007771] [batchtime 0.433]
[epoch 39], [iter 57 / 176], [train main loss -1.765035], [lr 0.007771] [batchtime 0.432]
[epoch 39], [iter 58 / 176], [train main loss -1.830496], [lr 0.007771] [batchtime 0.431]
[epoch 39], [iter 59 / 176], [train main loss -1.889481], [lr 0.007771] [batchtime 0.431]
[epoch 39], [iter 60 / 176], [train main loss -1.887703], [lr 0.007771] [batchtime 0.43]
[epoch 39], [iter 61 / 176], [train main loss -1.887958], [lr 0.007771] [batchtime 0.43]
[epoch 39], [iter 62 / 176], [train main loss -1.887151], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 63 / 176], [train main loss -1.891928], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 64 / 176], [train main loss -1.877389], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 65 / 176], [train main loss -1.865965], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 66 / 176], [train main loss -1.852981], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 67 / 176], [train main loss -1.845575], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 68 / 176], [train main loss -1.866118], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 69 / 176], [train main loss -1.857342], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 70 / 176], [train main loss -1.863548], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 71 / 176], [train main loss -1.854454], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 72 / 176], [train main loss -1.865420], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 73 / 176], [train main loss -1.853443], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 74 / 176], [train main loss -1.850744], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 75 / 176], [train main loss -1.861609], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 76 / 176], [train main loss -1.896318], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 77 / 176], [train main loss -1.951261], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 78 / 176], [train main loss -1.956856], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 79 / 176], [train main loss -1.955948], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 80 / 176], [train main loss -1.964288], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 81 / 176], [train main loss -1.968914], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 82 / 176], [train main loss -1.975934], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 83 / 176], [train main loss -1.981340], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 84 / 176], [train main loss -1.976360], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 85 / 176], [train main loss -1.961425], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 86 / 176], [train main loss -1.969589], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 87 / 176], [train main loss -1.950432], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 88 / 176], [train main loss -1.956562], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 89 / 176], [train main loss -1.975321], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 90 / 176], [train main loss -1.989524], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 91 / 176], [train main loss -1.972909], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 92 / 176], [train main loss -1.955636], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 93 / 176], [train main loss -1.926699], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 94 / 176], [train main loss -1.913431], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 95 / 176], [train main loss -1.910250], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 96 / 176], [train main loss -1.916411], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 97 / 176], [train main loss -1.894157], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 98 / 176], [train main loss -1.907325], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 99 / 176], [train main loss -1.910790], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 100 / 176], [train main loss -1.893974], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 101 / 176], [train main loss -1.891836], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 102 / 176], [train main loss -1.897533], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 103 / 176], [train main loss -1.907516], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 104 / 176], [train main loss -1.907643], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 105 / 176], [train main loss -1.939037], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 106 / 176], [train main loss -1.971389], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 107 / 176], [train main loss -1.941329], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 108 / 176], [train main loss -1.947684], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 109 / 176], [train main loss -1.936163], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 110 / 176], [train main loss -1.948256], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 111 / 176], [train main loss -1.949396], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 112 / 176], [train main loss -1.933654], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 113 / 176], [train main loss -1.943085], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 114 / 176], [train main loss -1.938138], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 115 / 176], [train main loss -1.937668], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 116 / 176], [train main loss -1.902058], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 117 / 176], [train main loss -1.901848], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 118 / 176], [train main loss -1.906179], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 119 / 176], [train main loss -1.887811], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 120 / 176], [train main loss -1.892663], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 121 / 176], [train main loss -1.903928], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 122 / 176], [train main loss -1.906416], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 123 / 176], [train main loss -1.911856], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 124 / 176], [train main loss -1.916706], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 125 / 176], [train main loss -1.936799], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 126 / 176], [train main loss -1.924699], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 127 / 176], [train main loss -1.912135], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 128 / 176], [train main loss -1.914953], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 129 / 176], [train main loss -1.910746], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 130 / 176], [train main loss -1.893055], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 131 / 176], [train main loss -1.902400], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 132 / 176], [train main loss -1.903086], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 133 / 176], [train main loss -1.925803], [lr 0.007771] [batchtime 0.422]
[epoch 39], [iter 134 / 176], [train main loss -1.926358], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 135 / 176], [train main loss -1.933557], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 136 / 176], [train main loss -1.958790], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 137 / 176], [train main loss -1.937882], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 138 / 176], [train main loss -1.950651], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 139 / 176], [train main loss -1.949183], [lr 0.007771] [batchtime 0.42]
[epoch 39], [iter 140 / 176], [train main loss -1.947005], [lr 0.007771] [batchtime 0.421]
[epoch 39], [iter 141 / 176], [train main loss -1.938852], [lr 0.007771] [batchtime 0.43]
[epoch 39], [iter 142 / 176], [train main loss -1.920628], [lr 0.007771] [batchtime 0.43]
[epoch 39], [iter 143 / 176], [train main loss -1.929282], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 144 / 176], [train main loss -1.903202], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 145 / 176], [train main loss -1.880828], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 146 / 176], [train main loss -1.889864], [lr 0.007771] [batchtime 0.429]
[epoch 39], [iter 147 / 176], [train main loss -1.867020], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 148 / 176], [train main loss -1.861338], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 149 / 176], [train main loss -1.856532], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 150 / 176], [train main loss -1.848118], [lr 0.007771] [batchtime 0.428]
[epoch 39], [iter 151 / 176], [train main loss -1.846665], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 152 / 176], [train main loss -1.853760], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 153 / 176], [train main loss -1.838876], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 154 / 176], [train main loss -1.832124], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 155 / 176], [train main loss -1.822630], [lr 0.007771] [batchtime 0.427]
[epoch 39], [iter 156 / 176], [train main loss -1.836476], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 157 / 176], [train main loss -1.834616], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 158 / 176], [train main loss -1.822659], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 159 / 176], [train main loss -1.837940], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 160 / 176], [train main loss -1.823576], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 161 / 176], [train main loss -1.815996], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 162 / 176], [train main loss -1.814894], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 163 / 176], [train main loss -1.812360], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 164 / 176], [train main loss -1.816133], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 165 / 176], [train main loss -1.822826], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 166 / 176], [train main loss -1.824620], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 167 / 176], [train main loss -1.825417], [lr 0.007771] [batchtime 0.426]
[epoch 39], [iter 168 / 176], [train main loss -1.816856], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 169 / 176], [train main loss -1.800807], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 170 / 176], [train main loss -1.802633], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 171 / 176], [train main loss -1.801218], [lr 0.007771] [batchtime 0.425]
[epoch 39], [iter 172 / 176], [train main loss -1.794934], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 173 / 176], [train main loss -1.792066], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 174 / 176], [train main loss -1.799755], [lr 0.007771] [batchtime 0.424]
[epoch 39], [iter 175 / 176], [train main loss -1.801929], [lr 0.007771] [batchtime 0.423]
[epoch 39], [iter 176 / 176], [train main loss -1.795972], [lr 0.007771] [batchtime 0.423]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP         FP    FN    Precision    Recall
----  -------------  --------  -----  ---------  ----  -----------  --------
   0  road              92.74  35.00       0.04  0.04         0.96      0.96
   1  sidewalk          60.98   4.96       0.33  0.31         0.75      0.76
   2  building          80.94  24.86       0.07  0.17         0.94      0.86
   3  wall               6.53   0.05      11.77  2.54         0.08      0.28
   4  fence              2.58   0.03      36.70  1.04         0.03      0.49
   5  pole              24.45   0.32       2.51  0.58         0.28      0.63
   6  traffic light      0.72   0.00     137.04  0.56         0.01      0.64
   7  traffic sign       5.65   0.03      16.10  0.59         0.06      0.63
   8  vegetation        78.42  11.37       0.09  0.19         0.92      0.84
   9  terrain           33.09   0.39       0.87  1.15         0.53      0.47
  10  sky               92.36   3.74       0.04  0.05         0.96      0.96
  11  person            28.97   0.52       1.93  0.52         0.34      0.66
  12  rider              0.11   0.00     908.87  2.14         0.00      0.32
  13  car               76.61   6.52       0.09  0.22         0.92      0.82
  14  truck              0.00   0.00  239700.31  2.50         0.00      0.29
  15  bus                1.11   0.00      86.41  2.43         0.01      0.29
  16  train              0.23   0.00     438.91  0.04         0.00      0.97
  17  motorcycle         0.00   0.00  666325.50  0.00         0.00      1.00
  18  bicycle           24.01   0.14       1.77  1.40         0.36      0.42
Mean: 32.08
-----------------------------------------------------------------------------------------------------------
this : [epoch 39], [val loss 0.41803], [acc 0.87929], [acc_cls 0.37697], [mean_iu 0.32079], [fwavacc 0.79108]
best : [epoch 37], [val loss 0.41754], [acc 0.87637], [acc_cls 0.38100], [mean_iu 0.32191], [fwavacc 0.78807]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 40], [iter 1 / 176], [train main loss -3.896425], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 2 / 176], [train main loss -2.779900], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 3 / 176], [train main loss -3.853454], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 4 / 176], [train main loss -3.126137], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 5 / 176], [train main loss -3.086059], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 6 / 176], [train main loss -2.647098], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 7 / 176], [train main loss -2.582504], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 8 / 176], [train main loss -2.681749], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 9 / 176], [train main loss -2.494004], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 10 / 176], [train main loss -2.381661], [lr 0.007714] [batchtime 0]
[epoch 40], [iter 11 / 176], [train main loss -2.235568], [lr 0.007714] [batchtime 0.377]
[epoch 40], [iter 12 / 176], [train main loss -2.349796], [lr 0.007714] [batchtime 0.391]
[epoch 40], [iter 13 / 176], [train main loss -2.616076], [lr 0.007714] [batchtime 0.392]
[epoch 40], [iter 14 / 176], [train main loss -2.637208], [lr 0.007714] [batchtime 0.395]
[epoch 40], [iter 15 / 176], [train main loss -2.561170], [lr 0.007714] [batchtime 0.395]
[epoch 40], [iter 16 / 176], [train main loss -2.622994], [lr 0.007714] [batchtime 0.398]
[epoch 40], [iter 17 / 176], [train main loss -2.460411], [lr 0.007714] [batchtime 0.397]
[epoch 40], [iter 18 / 176], [train main loss -2.464460], [lr 0.007714] [batchtime 0.397]
[epoch 40], [iter 19 / 176], [train main loss -2.409634], [lr 0.007714] [batchtime 0.397]
[epoch 40], [iter 20 / 176], [train main loss -2.475891], [lr 0.007714] [batchtime 0.397]
[epoch 40], [iter 21 / 176], [train main loss -2.544199], [lr 0.007714] [batchtime 0.397]
[epoch 40], [iter 22 / 176], [train main loss -2.390978], [lr 0.007714] [batchtime 0.396]
[epoch 40], [iter 23 / 176], [train main loss -2.356493], [lr 0.007714] [batchtime 0.404]
[epoch 40], [iter 24 / 176], [train main loss -2.299423], [lr 0.007714] [batchtime 0.415]
[epoch 40], [iter 25 / 176], [train main loss -2.249328], [lr 0.007714] [batchtime 0.413]
[epoch 40], [iter 26 / 176], [train main loss -2.163308], [lr 0.007714] [batchtime 0.411]
[epoch 40], [iter 27 / 176], [train main loss -2.205264], [lr 0.007714] [batchtime 0.41]
[epoch 40], [iter 28 / 176], [train main loss -2.191288], [lr 0.007714] [batchtime 0.41]
[epoch 40], [iter 29 / 176], [train main loss -2.163490], [lr 0.007714] [batchtime 0.409]
[epoch 40], [iter 30 / 176], [train main loss -2.113432], [lr 0.007714] [batchtime 0.408]
[epoch 40], [iter 31 / 176], [train main loss -2.159095], [lr 0.007714] [batchtime 0.408]
[epoch 40], [iter 32 / 176], [train main loss -2.143815], [lr 0.007714] [batchtime 0.407]
[epoch 40], [iter 33 / 176], [train main loss -2.135242], [lr 0.007714] [batchtime 0.407]
[epoch 40], [iter 34 / 176], [train main loss -2.028787], [lr 0.007714] [batchtime 0.407]
[epoch 40], [iter 35 / 176], [train main loss -1.966753], [lr 0.007714] [batchtime 0.407]
[epoch 40], [iter 36 / 176], [train main loss -1.975019], [lr 0.007714] [batchtime 0.407]
[epoch 40], [iter 37 / 176], [train main loss -1.920202], [lr 0.007714] [batchtime 0.406]
[epoch 40], [iter 38 / 176], [train main loss -1.879409], [lr 0.007714] [batchtime 0.406]
[epoch 40], [iter 39 / 176], [train main loss -1.898995], [lr 0.007714] [batchtime 0.406]
[epoch 40], [iter 40 / 176], [train main loss -1.866864], [lr 0.007714] [batchtime 0.406]
[epoch 40], [iter 41 / 176], [train main loss -1.884024], [lr 0.007714] [batchtime 0.405]
[epoch 40], [iter 42 / 176], [train main loss -1.847205], [lr 0.007714] [batchtime 0.405]
[epoch 40], [iter 43 / 176], [train main loss -1.777822], [lr 0.007714] [batchtime 0.405]
[epoch 40], [iter 44 / 176], [train main loss -1.745626], [lr 0.007714] [batchtime 0.405]
[epoch 40], [iter 45 / 176], [train main loss -1.768131], [lr 0.007714] [batchtime 0.405]
[epoch 40], [iter 46 / 176], [train main loss -1.718182], [lr 0.007714] [batchtime 0.405]
[epoch 40], [iter 47 / 176], [train main loss -1.730609], [lr 0.007714] [batchtime 0.408]
[epoch 40], [iter 48 / 176], [train main loss -1.701562], [lr 0.007714] [batchtime 0.439]
[epoch 40], [iter 49 / 176], [train main loss -1.682292], [lr 0.007714] [batchtime 0.438]
[epoch 40], [iter 50 / 176], [train main loss -1.709228], [lr 0.007714] [batchtime 0.437]
[epoch 40], [iter 51 / 176], [train main loss -1.689423], [lr 0.007714] [batchtime 0.436]
[epoch 40], [iter 52 / 176], [train main loss -1.708226], [lr 0.007714] [batchtime 0.435]
[epoch 40], [iter 53 / 176], [train main loss -1.698079], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 54 / 176], [train main loss -1.703516], [lr 0.007714] [batchtime 0.433]
[epoch 40], [iter 55 / 176], [train main loss -1.733095], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 56 / 176], [train main loss -1.755213], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 57 / 176], [train main loss -1.769454], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 58 / 176], [train main loss -1.729801], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 59 / 176], [train main loss -1.702390], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 60 / 176], [train main loss -1.684397], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 61 / 176], [train main loss -1.676700], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 62 / 176], [train main loss -1.678616], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 63 / 176], [train main loss -1.766513], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 64 / 176], [train main loss -1.756152], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 65 / 176], [train main loss -1.779516], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 66 / 176], [train main loss -1.774263], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 67 / 176], [train main loss -1.747036], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 68 / 176], [train main loss -1.771529], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 69 / 176], [train main loss -1.799753], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 70 / 176], [train main loss -1.792893], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 71 / 176], [train main loss -1.780890], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 72 / 176], [train main loss -1.787947], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 73 / 176], [train main loss -1.787481], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 74 / 176], [train main loss -1.791695], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 75 / 176], [train main loss -1.760026], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 76 / 176], [train main loss -1.773352], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 77 / 176], [train main loss -1.740261], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 78 / 176], [train main loss -1.735298], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 79 / 176], [train main loss -1.708720], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 80 / 176], [train main loss -1.722669], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 81 / 176], [train main loss -1.763977], [lr 0.007714] [batchtime 0.423]
[epoch 40], [iter 82 / 176], [train main loss -1.752202], [lr 0.007714] [batchtime 0.423]
[epoch 40], [iter 83 / 176], [train main loss -1.758987], [lr 0.007714] [batchtime 0.423]
[epoch 40], [iter 84 / 176], [train main loss -1.741200], [lr 0.007714] [batchtime 0.423]
[epoch 40], [iter 85 / 176], [train main loss -1.749342], [lr 0.007714] [batchtime 0.422]
[epoch 40], [iter 86 / 176], [train main loss -1.733065], [lr 0.007714] [batchtime 0.422]
[epoch 40], [iter 87 / 176], [train main loss -1.725517], [lr 0.007714] [batchtime 0.422]
[epoch 40], [iter 88 / 176], [train main loss -1.726485], [lr 0.007714] [batchtime 0.422]
[epoch 40], [iter 89 / 176], [train main loss -1.740641], [lr 0.007714] [batchtime 0.421]
[epoch 40], [iter 90 / 176], [train main loss -1.784182], [lr 0.007714] [batchtime 0.421]
[epoch 40], [iter 91 / 176], [train main loss -1.781801], [lr 0.007714] [batchtime 0.421]
[epoch 40], [iter 92 / 176], [train main loss -1.768176], [lr 0.007714] [batchtime 0.421]
[epoch 40], [iter 93 / 176], [train main loss -1.784181], [lr 0.007714] [batchtime 0.42]
[epoch 40], [iter 94 / 176], [train main loss -1.786364], [lr 0.007714] [batchtime 0.437]
[epoch 40], [iter 95 / 176], [train main loss -1.773201], [lr 0.007714] [batchtime 0.436]
[epoch 40], [iter 96 / 176], [train main loss -1.769989], [lr 0.007714] [batchtime 0.435]
[epoch 40], [iter 97 / 176], [train main loss -1.758025], [lr 0.007714] [batchtime 0.435]
[epoch 40], [iter 98 / 176], [train main loss -1.734189], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 99 / 176], [train main loss -1.733185], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 100 / 176], [train main loss -1.734033], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 101 / 176], [train main loss -1.735784], [lr 0.007714] [batchtime 0.433]
[epoch 40], [iter 102 / 176], [train main loss -1.728799], [lr 0.007714] [batchtime 0.433]
[epoch 40], [iter 103 / 176], [train main loss -1.721508], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 104 / 176], [train main loss -1.702681], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 105 / 176], [train main loss -1.707409], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 106 / 176], [train main loss -1.715422], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 107 / 176], [train main loss -1.712710], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 108 / 176], [train main loss -1.715130], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 109 / 176], [train main loss -1.706255], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 110 / 176], [train main loss -1.697621], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 111 / 176], [train main loss -1.686711], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 112 / 176], [train main loss -1.700828], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 113 / 176], [train main loss -1.692444], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 114 / 176], [train main loss -1.701255], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 115 / 176], [train main loss -1.716777], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 116 / 176], [train main loss -1.701348], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 117 / 176], [train main loss -1.697368], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 118 / 176], [train main loss -1.685034], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 119 / 176], [train main loss -1.702591], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 120 / 176], [train main loss -1.713795], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 121 / 176], [train main loss -1.695935], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 122 / 176], [train main loss -1.689600], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 123 / 176], [train main loss -1.698271], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 124 / 176], [train main loss -1.706434], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 125 / 176], [train main loss -1.713632], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 126 / 176], [train main loss -1.711663], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 127 / 176], [train main loss -1.709346], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 128 / 176], [train main loss -1.704537], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 129 / 176], [train main loss -1.698947], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 130 / 176], [train main loss -1.701729], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 131 / 176], [train main loss -1.676333], [lr 0.007714] [batchtime 0.426]
[epoch 40], [iter 132 / 176], [train main loss -1.681093], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 133 / 176], [train main loss -1.687745], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 134 / 176], [train main loss -1.693639], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 135 / 176], [train main loss -1.678861], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 136 / 176], [train main loss -1.669413], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 137 / 176], [train main loss -1.648149], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 138 / 176], [train main loss -1.659444], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 139 / 176], [train main loss -1.647088], [lr 0.007714] [batchtime 0.424]
[epoch 40], [iter 140 / 176], [train main loss -1.638744], [lr 0.007714] [batchtime 0.425]
[epoch 40], [iter 141 / 176], [train main loss -1.626376], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 142 / 176], [train main loss -1.630867], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 143 / 176], [train main loss -1.637558], [lr 0.007714] [batchtime 0.434]
[epoch 40], [iter 144 / 176], [train main loss -1.647946], [lr 0.007714] [batchtime 0.433]
[epoch 40], [iter 145 / 176], [train main loss -1.650765], [lr 0.007714] [batchtime 0.433]
[epoch 40], [iter 146 / 176], [train main loss -1.638622], [lr 0.007714] [batchtime 0.433]
[epoch 40], [iter 147 / 176], [train main loss -1.660684], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 148 / 176], [train main loss -1.668312], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 149 / 176], [train main loss -1.676416], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 150 / 176], [train main loss -1.663174], [lr 0.007714] [batchtime 0.432]
[epoch 40], [iter 151 / 176], [train main loss -1.670648], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 152 / 176], [train main loss -1.677410], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 153 / 176], [train main loss -1.669206], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 154 / 176], [train main loss -1.647471], [lr 0.007714] [batchtime 0.431]
[epoch 40], [iter 155 / 176], [train main loss -1.653782], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 156 / 176], [train main loss -1.652087], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 157 / 176], [train main loss -1.657139], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 158 / 176], [train main loss -1.644020], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 159 / 176], [train main loss -1.640766], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 160 / 176], [train main loss -1.644467], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 161 / 176], [train main loss -1.652934], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 162 / 176], [train main loss -1.659517], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 163 / 176], [train main loss -1.677064], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 164 / 176], [train main loss -1.679021], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 165 / 176], [train main loss -1.701194], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 166 / 176], [train main loss -1.694953], [lr 0.007714] [batchtime 0.43]
[epoch 40], [iter 167 / 176], [train main loss -1.710702], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 168 / 176], [train main loss -1.708285], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 169 / 176], [train main loss -1.700186], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 170 / 176], [train main loss -1.712411], [lr 0.007714] [batchtime 0.429]
[epoch 40], [iter 171 / 176], [train main loss -1.705419], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 172 / 176], [train main loss -1.698714], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 173 / 176], [train main loss -1.691923], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 174 / 176], [train main loss -1.690899], [lr 0.007714] [batchtime 0.428]
[epoch 40], [iter 175 / 176], [train main loss -1.697836], [lr 0.007714] [batchtime 0.427]
[epoch 40], [iter 176 / 176], [train main loss -1.710416], [lr 0.007714] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP      FN    Precision    Recall
----  -------------  --------  -----  --------  ------  -----------  --------
   0  road              92.52  34.98      0.04    0.04         0.96      0.96
   1  sidewalk          60.17   5.15      0.28    0.38         0.78      0.72
   2  building          81.74  24.46      0.09    0.14         0.92      0.88
   3  wall               7.82   0.06      8.94    2.85         0.10      0.26
   4  fence              3.77   0.05     24.80    0.74         0.04      0.57
   5  pole              26.55   0.37      2.11    0.66         0.32      0.60
   6  traffic light      0.98   0.00    100.77    0.52         0.01      0.66
   7  traffic sign       3.69   0.02     25.68    0.45         0.04      0.69
   8  vegetation        78.35  11.44      0.08    0.20         0.93      0.84
   9  terrain           30.55   0.27      1.68    0.59         0.37      0.63
  10  sky               91.44   3.76      0.03    0.06         0.97      0.94
  11  person            33.33   0.64      1.39    0.61         0.42      0.62
  12  rider              0.16   0.00    607.66    4.57         0.00      0.18
  13  car               76.74   6.57      0.08    0.23         0.93      0.82
  14  truck              0.00   0.00    inf     inf            0.00      0.00
  15  bus                0.45   0.00    217.66    3.77         0.00      0.21
  16  train              0.00   0.00  81128.04    1.27         0.00      0.44
  17  motorcycle         0.00   0.00  49356.52    6.26         0.00      0.14
  18  bicycle           22.73   0.16      1.44    1.95         0.41      0.34
Mean: 32.16
-----------------------------------------------------------------------------------------------------------
this : [epoch 40], [val loss 0.40614], [acc 0.87940], [acc_cls 0.37919], [mean_iu 0.32157], [fwavacc 0.79230]
best : [epoch 37], [val loss 0.41754], [acc 0.87637], [acc_cls 0.38100], [mean_iu 0.32191], [fwavacc 0.78807]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 41], [iter 1 / 176], [train main loss -2.674171], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 2 / 176], [train main loss -2.851171], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 3 / 176], [train main loss -1.606609], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 4 / 176], [train main loss -1.773968], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 5 / 176], [train main loss -1.654243], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 6 / 176], [train main loss -1.815881], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 7 / 176], [train main loss -1.778364], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 8 / 176], [train main loss -1.657521], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 9 / 176], [train main loss -1.523070], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 10 / 176], [train main loss -1.594095], [lr 0.007657] [batchtime 0]
[epoch 41], [iter 11 / 176], [train main loss -1.804755], [lr 0.007657] [batchtime 0.374]
[epoch 41], [iter 12 / 176], [train main loss -1.844355], [lr 0.007657] [batchtime 0.385]
[epoch 41], [iter 13 / 176], [train main loss -1.906841], [lr 0.007657] [batchtime 0.389]
[epoch 41], [iter 14 / 176], [train main loss -1.960557], [lr 0.007657] [batchtime 0.392]
[epoch 41], [iter 15 / 176], [train main loss -1.931728], [lr 0.007657] [batchtime 0.393]
[epoch 41], [iter 16 / 176], [train main loss -1.906518], [lr 0.007657] [batchtime 0.394]
[epoch 41], [iter 17 / 176], [train main loss -1.926924], [lr 0.007657] [batchtime 0.394]
[epoch 41], [iter 18 / 176], [train main loss -2.036904], [lr 0.007657] [batchtime 0.396]
[epoch 41], [iter 19 / 176], [train main loss -2.004112], [lr 0.007657] [batchtime 0.396]
[epoch 41], [iter 20 / 176], [train main loss -1.919648], [lr 0.007657] [batchtime 0.395]
[epoch 41], [iter 21 / 176], [train main loss -1.901081], [lr 0.007657] [batchtime 0.402]
[epoch 41], [iter 22 / 176], [train main loss -1.939665], [lr 0.007657] [batchtime 0.414]
[epoch 41], [iter 23 / 176], [train main loss -2.162396], [lr 0.007657] [batchtime 0.413]
[epoch 41], [iter 24 / 176], [train main loss -2.121215], [lr 0.007657] [batchtime 0.412]
[epoch 41], [iter 25 / 176], [train main loss -2.175859], [lr 0.007657] [batchtime 0.411]
[epoch 41], [iter 26 / 176], [train main loss -2.092676], [lr 0.007657] [batchtime 0.41]
[epoch 41], [iter 27 / 176], [train main loss -2.087670], [lr 0.007657] [batchtime 0.41]
[epoch 41], [iter 28 / 176], [train main loss -2.117921], [lr 0.007657] [batchtime 0.409]
[epoch 41], [iter 29 / 176], [train main loss -2.122062], [lr 0.007657] [batchtime 0.408]
[epoch 41], [iter 30 / 176], [train main loss -2.028394], [lr 0.007657] [batchtime 0.408]
[epoch 41], [iter 31 / 176], [train main loss -2.037626], [lr 0.007657] [batchtime 0.407]
[epoch 41], [iter 32 / 176], [train main loss -2.031035], [lr 0.007657] [batchtime 0.407]
[epoch 41], [iter 33 / 176], [train main loss -1.970177], [lr 0.007657] [batchtime 0.406]
[epoch 41], [iter 34 / 176], [train main loss -1.979338], [lr 0.007657] [batchtime 0.406]
[epoch 41], [iter 35 / 176], [train main loss -2.004767], [lr 0.007657] [batchtime 0.405]
[epoch 41], [iter 36 / 176], [train main loss -2.038788], [lr 0.007657] [batchtime 0.405]
[epoch 41], [iter 37 / 176], [train main loss -2.059116], [lr 0.007657] [batchtime 0.405]
[epoch 41], [iter 38 / 176], [train main loss -2.048735], [lr 0.007657] [batchtime 0.404]
[epoch 41], [iter 39 / 176], [train main loss -2.053998], [lr 0.007657] [batchtime 0.404]
[epoch 41], [iter 40 / 176], [train main loss -2.040491], [lr 0.007657] [batchtime 0.404]
[epoch 41], [iter 41 / 176], [train main loss -1.998876], [lr 0.007657] [batchtime 0.403]
[epoch 41], [iter 42 / 176], [train main loss -1.963488], [lr 0.007657] [batchtime 0.403]
[epoch 41], [iter 43 / 176], [train main loss -1.962339], [lr 0.007657] [batchtime 0.403]
[epoch 41], [iter 44 / 176], [train main loss -1.989935], [lr 0.007657] [batchtime 0.403]
[epoch 41], [iter 45 / 176], [train main loss -2.025735], [lr 0.007657] [batchtime 0.403]
[epoch 41], [iter 46 / 176], [train main loss -1.978150], [lr 0.007657] [batchtime 0.438]
[epoch 41], [iter 47 / 176], [train main loss -1.908824], [lr 0.007657] [batchtime 0.445]
[epoch 41], [iter 48 / 176], [train main loss -1.869590], [lr 0.007657] [batchtime 0.444]
[epoch 41], [iter 49 / 176], [train main loss -1.825029], [lr 0.007657] [batchtime 0.442]
[epoch 41], [iter 50 / 176], [train main loss -1.858459], [lr 0.007657] [batchtime 0.441]
[epoch 41], [iter 51 / 176], [train main loss -1.849867], [lr 0.007657] [batchtime 0.44]
[epoch 41], [iter 52 / 176], [train main loss -1.848906], [lr 0.007657] [batchtime 0.439]
[epoch 41], [iter 53 / 176], [train main loss -1.833649], [lr 0.007657] [batchtime 0.438]
[epoch 41], [iter 54 / 176], [train main loss -1.784801], [lr 0.007657] [batchtime 0.437]
[epoch 41], [iter 55 / 176], [train main loss -1.756009], [lr 0.007657] [batchtime 0.436]
[epoch 41], [iter 56 / 176], [train main loss -1.783456], [lr 0.007657] [batchtime 0.435]
[epoch 41], [iter 57 / 176], [train main loss -1.791967], [lr 0.007657] [batchtime 0.434]
[epoch 41], [iter 58 / 176], [train main loss -1.794777], [lr 0.007657] [batchtime 0.433]
[epoch 41], [iter 59 / 176], [train main loss -1.841716], [lr 0.007657] [batchtime 0.432]
[epoch 41], [iter 60 / 176], [train main loss -1.884940], [lr 0.007657] [batchtime 0.432]
[epoch 41], [iter 61 / 176], [train main loss -1.873222], [lr 0.007657] [batchtime 0.431]
[epoch 41], [iter 62 / 176], [train main loss -1.870357], [lr 0.007657] [batchtime 0.43]
[epoch 41], [iter 63 / 176], [train main loss -1.948095], [lr 0.007657] [batchtime 0.43]
[epoch 41], [iter 64 / 176], [train main loss -1.932839], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 65 / 176], [train main loss -1.953090], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 66 / 176], [train main loss -1.975886], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 67 / 176], [train main loss -1.954668], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 68 / 176], [train main loss -1.965352], [lr 0.007657] [batchtime 0.431]
[epoch 41], [iter 69 / 176], [train main loss -1.977851], [lr 0.007657] [batchtime 0.43]
[epoch 41], [iter 70 / 176], [train main loss -1.972997], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 71 / 176], [train main loss -1.918732], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 72 / 176], [train main loss -1.931475], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 73 / 176], [train main loss -1.918712], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 74 / 176], [train main loss -1.925083], [lr 0.007657] [batchtime 0.427]
[epoch 41], [iter 75 / 176], [train main loss -1.928015], [lr 0.007657] [batchtime 0.427]
[epoch 41], [iter 76 / 176], [train main loss -1.937949], [lr 0.007657] [batchtime 0.427]
[epoch 41], [iter 77 / 176], [train main loss -1.926058], [lr 0.007657] [batchtime 0.426]
[epoch 41], [iter 78 / 176], [train main loss -1.921696], [lr 0.007657] [batchtime 0.426]
[epoch 41], [iter 79 / 176], [train main loss -1.977875], [lr 0.007657] [batchtime 0.425]
[epoch 41], [iter 80 / 176], [train main loss -1.947544], [lr 0.007657] [batchtime 0.425]
[epoch 41], [iter 81 / 176], [train main loss -1.953647], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 82 / 176], [train main loss -1.942982], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 83 / 176], [train main loss -1.939902], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 84 / 176], [train main loss -1.962419], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 85 / 176], [train main loss -1.945929], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 86 / 176], [train main loss -1.943146], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 87 / 176], [train main loss -1.937380], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 88 / 176], [train main loss -1.930387], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 89 / 176], [train main loss -1.940290], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 90 / 176], [train main loss -1.958756], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 91 / 176], [train main loss -1.986097], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 92 / 176], [train main loss -1.989367], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 93 / 176], [train main loss -1.988909], [lr 0.007657] [batchtime 0.436]
[epoch 41], [iter 94 / 176], [train main loss -2.007869], [lr 0.007657] [batchtime 0.435]
[epoch 41], [iter 95 / 176], [train main loss -1.986745], [lr 0.007657] [batchtime 0.435]
[epoch 41], [iter 96 / 176], [train main loss -1.995927], [lr 0.007657] [batchtime 0.434]
[epoch 41], [iter 97 / 176], [train main loss -1.982873], [lr 0.007657] [batchtime 0.434]
[epoch 41], [iter 98 / 176], [train main loss -1.964418], [lr 0.007657] [batchtime 0.433]
[epoch 41], [iter 99 / 176], [train main loss -1.977410], [lr 0.007657] [batchtime 0.433]
[epoch 41], [iter 100 / 176], [train main loss -2.002669], [lr 0.007657] [batchtime 0.432]
[epoch 41], [iter 101 / 176], [train main loss -2.014736], [lr 0.007657] [batchtime 0.432]
[epoch 41], [iter 102 / 176], [train main loss -2.005067], [lr 0.007657] [batchtime 0.432]
[epoch 41], [iter 103 / 176], [train main loss -1.993205], [lr 0.007657] [batchtime 0.431]
[epoch 41], [iter 104 / 176], [train main loss -1.991587], [lr 0.007657] [batchtime 0.431]
[epoch 41], [iter 105 / 176], [train main loss -1.987099], [lr 0.007657] [batchtime 0.431]
[epoch 41], [iter 106 / 176], [train main loss -1.999409], [lr 0.007657] [batchtime 0.43]
[epoch 41], [iter 107 / 176], [train main loss -2.016149], [lr 0.007657] [batchtime 0.43]
[epoch 41], [iter 108 / 176], [train main loss -2.022030], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 109 / 176], [train main loss -2.006117], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 110 / 176], [train main loss -1.970053], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 111 / 176], [train main loss -1.963562], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 112 / 176], [train main loss -1.959011], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 113 / 176], [train main loss -1.930591], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 114 / 176], [train main loss -1.925377], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 115 / 176], [train main loss -1.908802], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 116 / 176], [train main loss -1.929651], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 117 / 176], [train main loss -1.923356], [lr 0.007657] [batchtime 0.429]
[epoch 41], [iter 118 / 176], [train main loss -1.914224], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 119 / 176], [train main loss -1.917705], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 120 / 176], [train main loss -1.886548], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 121 / 176], [train main loss -1.897418], [lr 0.007657] [batchtime 0.428]
[epoch 41], [iter 122 / 176], [train main loss -1.873833], [lr 0.007657] [batchtime 0.427]
[epoch 41], [iter 123 / 176], [train main loss -1.852875], [lr 0.007657] [batchtime 0.427]
[epoch 41], [iter 124 / 176], [train main loss -1.850957], [lr 0.007657] [batchtime 0.427]
[epoch 41], [iter 125 / 176], [train main loss -1.835830], [lr 0.007657] [batchtime 0.426]
[epoch 41], [iter 126 / 176], [train main loss -1.834423], [lr 0.007657] [batchtime 0.426]
[epoch 41], [iter 127 / 176], [train main loss -1.825588], [lr 0.007657] [batchtime 0.426]
[epoch 41], [iter 128 / 176], [train main loss -1.803421], [lr 0.007657] [batchtime 0.426]
[epoch 41], [iter 129 / 176], [train main loss -1.789616], [lr 0.007657] [batchtime 0.425]
[epoch 41], [iter 130 / 176], [train main loss -1.781579], [lr 0.007657] [batchtime 0.425]
[epoch 41], [iter 131 / 176], [train main loss -1.770089], [lr 0.007657] [batchtime 0.425]
[epoch 41], [iter 132 / 176], [train main loss -1.755531], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 133 / 176], [train main loss -1.744762], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 134 / 176], [train main loss -1.717011], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 135 / 176], [train main loss -1.721088], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 136 / 176], [train main loss -1.718915], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 137 / 176], [train main loss -1.731725], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 138 / 176], [train main loss -1.723788], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 139 / 176], [train main loss -1.732830], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 140 / 176], [train main loss -1.732758], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 141 / 176], [train main loss -1.751569], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 142 / 176], [train main loss -1.740718], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 143 / 176], [train main loss -1.738583], [lr 0.007657] [batchtime 0.424]
[epoch 41], [iter 144 / 176], [train main loss -1.743888], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 145 / 176], [train main loss -1.733998], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 146 / 176], [train main loss -1.729352], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 147 / 176], [train main loss -1.722358], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 148 / 176], [train main loss -1.719709], [lr 0.007657] [batchtime 0.423]
[epoch 41], [iter 149 / 176], [train main loss -1.707290], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 150 / 176], [train main loss -1.719161], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 151 / 176], [train main loss -1.705306], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 152 / 176], [train main loss -1.702878], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 153 / 176], [train main loss -1.686468], [lr 0.007657] [batchtime 0.422]
[epoch 41], [iter 154 / 176], [train main loss -1.689268], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 155 / 176], [train main loss -1.684856], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 156 / 176], [train main loss -1.688439], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 157 / 176], [train main loss -1.681302], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 158 / 176], [train main loss -1.713032], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 159 / 176], [train main loss -1.713930], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 160 / 176], [train main loss -1.699842], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 161 / 176], [train main loss -1.694720], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 162 / 176], [train main loss -1.716565], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 163 / 176], [train main loss -1.747340], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 164 / 176], [train main loss -1.755959], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 165 / 176], [train main loss -1.750749], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 166 / 176], [train main loss -1.751640], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 167 / 176], [train main loss -1.757466], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 168 / 176], [train main loss -1.731052], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 169 / 176], [train main loss -1.743966], [lr 0.007657] [batchtime 0.421]
[epoch 41], [iter 170 / 176], [train main loss -1.740792], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 171 / 176], [train main loss -1.732307], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 172 / 176], [train main loss -1.748610], [lr 0.007657] [batchtime 0.42]
[epoch 41], [iter 173 / 176], [train main loss -1.739748], [lr 0.007657] [batchtime 0.419]
[epoch 41], [iter 174 / 176], [train main loss -1.744347], [lr 0.007657] [batchtime 0.419]
[epoch 41], [iter 175 / 176], [train main loss -1.753707], [lr 0.007657] [batchtime 0.419]
[epoch 41], [iter 176 / 176], [train main loss -1.757331], [lr 0.007657] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP    FN    Precision    Recall
----  -------------  --------  -----  --------  ----  -----------  --------
   0  road              92.31  34.69      0.05  0.04         0.95      0.97
   1  sidewalk          60.52   5.33      0.24  0.42         0.81      0.71
   2  building          80.95  24.56      0.08  0.15         0.92      0.87
   3  wall               7.13   0.05     10.95  2.08         0.08      0.33
   4  fence              3.39   0.04     27.73  0.74         0.03      0.57
   5  pole              25.58   0.35      2.25  0.66         0.31      0.60
   6  traffic light      1.21   0.00     81.09  0.45         0.01      0.69
   7  traffic sign       5.10   0.03     18.13  0.49         0.05      0.67
   8  vegetation        79.25  11.23      0.10  0.16         0.91      0.86
   9  terrain           33.45   0.34      1.19  0.80         0.46      0.55
  10  sky               91.51   3.77      0.03  0.07         0.97      0.94
  11  person            35.79   0.77      0.98  0.81         0.50      0.55
  12  rider              0.15   0.00    675.33  2.80         0.00      0.26
  13  car               77.73   6.49      0.09  0.20         0.92      0.84
  14  truck              0.00   0.00  24903.03  2.66         0.00      0.27
  15  bus                0.61   0.00    158.18  5.97         0.01      0.14
  16  train              1.69   0.00     58.14  0.20         0.02      0.83
  17  motorcycle         0.01   0.00  18007.82  1.45         0.00      0.41
  18  bicycle           24.43   0.18      1.18  1.91         0.46      0.34
Mean: 32.67
-----------------------------------------------------------------------------------------------------------
this : [epoch 41], [val loss 0.40427], [acc 0.87841], [acc_cls 0.39072], [mean_iu 0.32674], [fwavacc 0.79209]
best : [epoch 41], [val loss 0.40427], [acc 0.87841], [acc_cls 0.39072], [mean_iu 0.32674], [fwavacc 0.79209]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 42], [iter 1 / 176], [train main loss -2.506767], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 2 / 176], [train main loss -1.358679], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 3 / 176], [train main loss -0.876095], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 4 / 176], [train main loss -1.457317], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 5 / 176], [train main loss -1.001267], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 6 / 176], [train main loss -1.313827], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 7 / 176], [train main loss -1.279377], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 8 / 176], [train main loss -1.524622], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 9 / 176], [train main loss -1.590336], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 10 / 176], [train main loss -1.591204], [lr 0.007600] [batchtime 0]
[epoch 42], [iter 11 / 176], [train main loss -1.601450], [lr 0.007600] [batchtime 0.378]
[epoch 42], [iter 12 / 176], [train main loss -1.511023], [lr 0.007600] [batchtime 0.384]
[epoch 42], [iter 13 / 176], [train main loss -1.409599], [lr 0.007600] [batchtime 0.386]
[epoch 42], [iter 14 / 176], [train main loss -1.441938], [lr 0.007600] [batchtime 0.389]
[epoch 42], [iter 15 / 176], [train main loss -1.477798], [lr 0.007600] [batchtime 0.403]
[epoch 42], [iter 16 / 176], [train main loss -1.504516], [lr 0.007600] [batchtime 0.405]
[epoch 42], [iter 17 / 176], [train main loss -1.524053], [lr 0.007600] [batchtime 0.405]
[epoch 42], [iter 18 / 176], [train main loss -1.515433], [lr 0.007600] [batchtime 0.404]
[epoch 42], [iter 19 / 176], [train main loss -1.515658], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 20 / 176], [train main loss -1.696437], [lr 0.007600] [batchtime 0.401]
[epoch 42], [iter 21 / 176], [train main loss -1.707889], [lr 0.007600] [batchtime 0.401]
[epoch 42], [iter 22 / 176], [train main loss -1.808454], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 23 / 176], [train main loss -1.732920], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 24 / 176], [train main loss -1.781853], [lr 0.007600] [batchtime 0.403]
[epoch 42], [iter 25 / 176], [train main loss -1.703449], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 26 / 176], [train main loss -1.829970], [lr 0.007600] [batchtime 0.403]
[epoch 42], [iter 27 / 176], [train main loss -1.881351], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 28 / 176], [train main loss -1.918295], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 29 / 176], [train main loss -1.804879], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 30 / 176], [train main loss -1.796642], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 31 / 176], [train main loss -1.791444], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 32 / 176], [train main loss -1.880641], [lr 0.007600] [batchtime 0.402]
[epoch 42], [iter 33 / 176], [train main loss -1.808824], [lr 0.007600] [batchtime 0.401]
[epoch 42], [iter 34 / 176], [train main loss -1.812363], [lr 0.007600] [batchtime 0.401]
[epoch 42], [iter 35 / 176], [train main loss -1.883381], [lr 0.007600] [batchtime 0.401]
[epoch 42], [iter 36 / 176], [train main loss -1.949056], [lr 0.007600] [batchtime 0.401]
[epoch 42], [iter 37 / 176], [train main loss -1.944994], [lr 0.007600] [batchtime 0.4]
[epoch 42], [iter 38 / 176], [train main loss -1.916077], [lr 0.007600] [batchtime 0.4]
[epoch 42], [iter 39 / 176], [train main loss -1.932411], [lr 0.007600] [batchtime 0.4]
[epoch 42], [iter 40 / 176], [train main loss -1.989068], [lr 0.007600] [batchtime 0.405]
[epoch 42], [iter 41 / 176], [train main loss -1.977542], [lr 0.007600] [batchtime 0.448]
[epoch 42], [iter 42 / 176], [train main loss -1.957631], [lr 0.007600] [batchtime 0.446]
[epoch 42], [iter 43 / 176], [train main loss -1.941566], [lr 0.007600] [batchtime 0.444]
[epoch 42], [iter 44 / 176], [train main loss -1.900065], [lr 0.007600] [batchtime 0.442]
[epoch 42], [iter 45 / 176], [train main loss -1.921402], [lr 0.007600] [batchtime 0.441]
[epoch 42], [iter 46 / 176], [train main loss -1.984753], [lr 0.007600] [batchtime 0.44]
[epoch 42], [iter 47 / 176], [train main loss -1.936040], [lr 0.007600] [batchtime 0.439]
[epoch 42], [iter 48 / 176], [train main loss -1.908338], [lr 0.007600] [batchtime 0.438]
[epoch 42], [iter 49 / 176], [train main loss -1.829524], [lr 0.007600] [batchtime 0.437]
[epoch 42], [iter 50 / 176], [train main loss -1.801473], [lr 0.007600] [batchtime 0.436]
[epoch 42], [iter 51 / 176], [train main loss -1.839888], [lr 0.007600] [batchtime 0.435]
[epoch 42], [iter 52 / 176], [train main loss -1.810200], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 53 / 176], [train main loss -1.781664], [lr 0.007600] [batchtime 0.433]
[epoch 42], [iter 54 / 176], [train main loss -1.769773], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 55 / 176], [train main loss -1.796774], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 56 / 176], [train main loss -1.816015], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 57 / 176], [train main loss -1.827481], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 58 / 176], [train main loss -1.799354], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 59 / 176], [train main loss -1.786593], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 60 / 176], [train main loss -1.781203], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 61 / 176], [train main loss -1.775793], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 62 / 176], [train main loss -1.762057], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 63 / 176], [train main loss -1.826731], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 64 / 176], [train main loss -1.832604], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 65 / 176], [train main loss -1.880356], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 66 / 176], [train main loss -1.858882], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 67 / 176], [train main loss -1.867090], [lr 0.007600] [batchtime 0.424]
[epoch 42], [iter 68 / 176], [train main loss -1.849811], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 69 / 176], [train main loss -1.844871], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 70 / 176], [train main loss -1.826571], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 71 / 176], [train main loss -1.853175], [lr 0.007600] [batchtime 0.422]
[epoch 42], [iter 72 / 176], [train main loss -1.825058], [lr 0.007600] [batchtime 0.422]
[epoch 42], [iter 73 / 176], [train main loss -1.849428], [lr 0.007600] [batchtime 0.421]
[epoch 42], [iter 74 / 176], [train main loss -1.872228], [lr 0.007600] [batchtime 0.421]
[epoch 42], [iter 75 / 176], [train main loss -1.884826], [lr 0.007600] [batchtime 0.421]
[epoch 42], [iter 76 / 176], [train main loss -1.899868], [lr 0.007600] [batchtime 0.42]
[epoch 42], [iter 77 / 176], [train main loss -1.857465], [lr 0.007600] [batchtime 0.42]
[epoch 42], [iter 78 / 176], [train main loss -1.879493], [lr 0.007600] [batchtime 0.419]
[epoch 42], [iter 79 / 176], [train main loss -1.875815], [lr 0.007600] [batchtime 0.419]
[epoch 42], [iter 80 / 176], [train main loss -1.904062], [lr 0.007600] [batchtime 0.419]
[epoch 42], [iter 81 / 176], [train main loss -1.879931], [lr 0.007600] [batchtime 0.419]
[epoch 42], [iter 82 / 176], [train main loss -1.878925], [lr 0.007600] [batchtime 0.418]
[epoch 42], [iter 83 / 176], [train main loss -1.867852], [lr 0.007600] [batchtime 0.418]
[epoch 42], [iter 84 / 176], [train main loss -1.859881], [lr 0.007600] [batchtime 0.418]
[epoch 42], [iter 85 / 176], [train main loss -1.863146], [lr 0.007600] [batchtime 0.418]
[epoch 42], [iter 86 / 176], [train main loss -1.874279], [lr 0.007600] [batchtime 0.417]
[epoch 42], [iter 87 / 176], [train main loss -1.858315], [lr 0.007600] [batchtime 0.419]
[epoch 42], [iter 88 / 176], [train main loss -1.847819], [lr 0.007600] [batchtime 0.437]
[epoch 42], [iter 89 / 176], [train main loss -1.851539], [lr 0.007600] [batchtime 0.436]
[epoch 42], [iter 90 / 176], [train main loss -1.826392], [lr 0.007600] [batchtime 0.436]
[epoch 42], [iter 91 / 176], [train main loss -1.854432], [lr 0.007600] [batchtime 0.435]
[epoch 42], [iter 92 / 176], [train main loss -1.851870], [lr 0.007600] [batchtime 0.435]
[epoch 42], [iter 93 / 176], [train main loss -1.880124], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 94 / 176], [train main loss -1.859232], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 95 / 176], [train main loss -1.860036], [lr 0.007600] [batchtime 0.433]
[epoch 42], [iter 96 / 176], [train main loss -1.862638], [lr 0.007600] [batchtime 0.433]
[epoch 42], [iter 97 / 176], [train main loss -1.860172], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 98 / 176], [train main loss -1.870360], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 99 / 176], [train main loss -1.851463], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 100 / 176], [train main loss -1.841300], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 101 / 176], [train main loss -1.824176], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 102 / 176], [train main loss -1.832150], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 103 / 176], [train main loss -1.827297], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 104 / 176], [train main loss -1.833794], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 105 / 176], [train main loss -1.819082], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 106 / 176], [train main loss -1.837364], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 107 / 176], [train main loss -1.827018], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 108 / 176], [train main loss -1.856884], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 109 / 176], [train main loss -1.863545], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 110 / 176], [train main loss -1.847947], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 111 / 176], [train main loss -1.819535], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 112 / 176], [train main loss -1.799146], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 113 / 176], [train main loss -1.819325], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 114 / 176], [train main loss -1.816562], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 115 / 176], [train main loss -1.809390], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 116 / 176], [train main loss -1.780517], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 117 / 176], [train main loss -1.784363], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 118 / 176], [train main loss -1.796981], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 119 / 176], [train main loss -1.783298], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 120 / 176], [train main loss -1.789011], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 121 / 176], [train main loss -1.777056], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 122 / 176], [train main loss -1.786798], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 123 / 176], [train main loss -1.767077], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 124 / 176], [train main loss -1.801567], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 125 / 176], [train main loss -1.818153], [lr 0.007600] [batchtime 0.424]
[epoch 42], [iter 126 / 176], [train main loss -1.798353], [lr 0.007600] [batchtime 0.424]
[epoch 42], [iter 127 / 176], [train main loss -1.781214], [lr 0.007600] [batchtime 0.424]
[epoch 42], [iter 128 / 176], [train main loss -1.787003], [lr 0.007600] [batchtime 0.424]
[epoch 42], [iter 129 / 176], [train main loss -1.769733], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 130 / 176], [train main loss -1.762279], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 131 / 176], [train main loss -1.764347], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 132 / 176], [train main loss -1.758738], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 133 / 176], [train main loss -1.734883], [lr 0.007600] [batchtime 0.423]
[epoch 42], [iter 134 / 176], [train main loss -1.730160], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 135 / 176], [train main loss -1.711934], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 136 / 176], [train main loss -1.691374], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 137 / 176], [train main loss -1.682883], [lr 0.007600] [batchtime 0.434]
[epoch 42], [iter 138 / 176], [train main loss -1.682433], [lr 0.007600] [batchtime 0.433]
[epoch 42], [iter 139 / 176], [train main loss -1.687823], [lr 0.007600] [batchtime 0.433]
[epoch 42], [iter 140 / 176], [train main loss -1.677948], [lr 0.007600] [batchtime 0.433]
[epoch 42], [iter 141 / 176], [train main loss -1.674341], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 142 / 176], [train main loss -1.686138], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 143 / 176], [train main loss -1.692465], [lr 0.007600] [batchtime 0.432]
[epoch 42], [iter 144 / 176], [train main loss -1.689451], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 145 / 176], [train main loss -1.693951], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 146 / 176], [train main loss -1.687884], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 147 / 176], [train main loss -1.685315], [lr 0.007600] [batchtime 0.431]
[epoch 42], [iter 148 / 176], [train main loss -1.681534], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 149 / 176], [train main loss -1.687256], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 150 / 176], [train main loss -1.671156], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 151 / 176], [train main loss -1.669376], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 152 / 176], [train main loss -1.679119], [lr 0.007600] [batchtime 0.43]
[epoch 42], [iter 153 / 176], [train main loss -1.678156], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 154 / 176], [train main loss -1.684654], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 155 / 176], [train main loss -1.677984], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 156 / 176], [train main loss -1.669675], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 157 / 176], [train main loss -1.658913], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 158 / 176], [train main loss -1.641274], [lr 0.007600] [batchtime 0.429]
[epoch 42], [iter 159 / 176], [train main loss -1.642608], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 160 / 176], [train main loss -1.629911], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 161 / 176], [train main loss -1.631510], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 162 / 176], [train main loss -1.618361], [lr 0.007600] [batchtime 0.428]
[epoch 42], [iter 163 / 176], [train main loss -1.607858], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 164 / 176], [train main loss -1.621427], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 165 / 176], [train main loss -1.625782], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 166 / 176], [train main loss -1.626313], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 167 / 176], [train main loss -1.641280], [lr 0.007600] [batchtime 0.427]
[epoch 42], [iter 168 / 176], [train main loss -1.636657], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 169 / 176], [train main loss -1.640612], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 170 / 176], [train main loss -1.639344], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 171 / 176], [train main loss -1.626049], [lr 0.007600] [batchtime 0.426]
[epoch 42], [iter 172 / 176], [train main loss -1.622043], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 173 / 176], [train main loss -1.629996], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 174 / 176], [train main loss -1.641913], [lr 0.007600] [batchtime 0.425]
[epoch 42], [iter 175 / 176], [train main loss -1.650236], [lr 0.007600] [batchtime 0.424]
[epoch 42], [iter 176 / 176], [train main loss -1.653250], [lr 0.007600] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP    FN    Precision    Recall
----  -------------  --------  -----  --------  ----  -----------  --------
   0  road              92.07  35.15      0.03  0.05         0.97      0.95
   1  sidewalk          57.37   4.57      0.44  0.30         0.69      0.77
   2  building          81.15  24.69      0.08  0.16         0.93      0.87
   3  wall               9.70   0.08      6.70  2.60         0.13      0.28
   4  fence              1.93   0.02     50.26  0.68         0.02      0.59
   5  pole              26.82   0.36      2.13  0.60         0.32      0.62
   6  traffic light      2.15   0.00     44.76  0.72         0.02      0.58
   7  traffic sign       6.41   0.04     14.12  0.47         0.07      0.68
   8  vegetation        78.26  11.20      0.10  0.17         0.91      0.85
   9  terrain           33.11   0.35      1.10  0.92         0.48      0.52
  10  sky               91.93   3.73      0.04  0.05         0.96      0.95
  11  person            36.66   0.74      1.06  0.66         0.48      0.60
  12  rider              0.37   0.00    261.33  4.40         0.00      0.19
  13  car               76.39   6.65      0.06  0.24         0.94      0.80
  14  truck              0.00   0.00  49168.50  0.42         0.00      0.70
  15  bus                1.33   0.00     68.96  5.34         0.01      0.16
  16  train              0.93   0.00    106.86  0.07         0.01      0.93
  17  motorcycle         0.01   0.00   8709.15  1.42         0.00      0.41
  18  bicycle           24.43   0.14      1.83  1.26         0.35      0.44
Mean: 32.69
-----------------------------------------------------------------------------------------------------------
this : [epoch 42], [val loss 0.42927], [acc 0.87737], [acc_cls 0.38400], [mean_iu 0.32686], [fwavacc 0.78797]
best : [epoch 42], [val loss 0.42927], [acc 0.87737], [acc_cls 0.38400], [mean_iu 0.32686], [fwavacc 0.78797]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 43], [iter 1 / 176], [train main loss -1.141699], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 2 / 176], [train main loss -3.388176], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 3 / 176], [train main loss -3.038073], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 4 / 176], [train main loss -2.698155], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 5 / 176], [train main loss -2.621412], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 6 / 176], [train main loss -2.459278], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 7 / 176], [train main loss -2.384087], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 8 / 176], [train main loss -2.268417], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 9 / 176], [train main loss -1.981234], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 10 / 176], [train main loss -1.952811], [lr 0.007543] [batchtime 0]
[epoch 43], [iter 11 / 176], [train main loss -2.130377], [lr 0.007543] [batchtime 0.376]
[epoch 43], [iter 12 / 176], [train main loss -1.997656], [lr 0.007543] [batchtime 0.391]
[epoch 43], [iter 13 / 176], [train main loss -1.833537], [lr 0.007543] [batchtime 0.4]
[epoch 43], [iter 14 / 176], [train main loss -1.844857], [lr 0.007543] [batchtime 0.402]
[epoch 43], [iter 15 / 176], [train main loss -1.823074], [lr 0.007543] [batchtime 0.401]
[epoch 43], [iter 16 / 176], [train main loss -1.851355], [lr 0.007543] [batchtime 0.558]
[epoch 43], [iter 17 / 176], [train main loss -1.890513], [lr 0.007543] [batchtime 0.532]
[epoch 43], [iter 18 / 176], [train main loss -1.823165], [lr 0.007543] [batchtime 0.515]
[epoch 43], [iter 19 / 176], [train main loss -1.949858], [lr 0.007543] [batchtime 0.502]
[epoch 43], [iter 20 / 176], [train main loss -2.046526], [lr 0.007543] [batchtime 0.491]
[epoch 43], [iter 21 / 176], [train main loss -2.106154], [lr 0.007543] [batchtime 0.484]
[epoch 43], [iter 22 / 176], [train main loss -2.068884], [lr 0.007543] [batchtime 0.477]
[epoch 43], [iter 23 / 176], [train main loss -2.009911], [lr 0.007543] [batchtime 0.47]
[epoch 43], [iter 24 / 176], [train main loss -2.028825], [lr 0.007543] [batchtime 0.465]
[epoch 43], [iter 25 / 176], [train main loss -2.076681], [lr 0.007543] [batchtime 0.461]
[epoch 43], [iter 26 / 176], [train main loss -2.090059], [lr 0.007543] [batchtime 0.458]
[epoch 43], [iter 27 / 176], [train main loss -2.096496], [lr 0.007543] [batchtime 0.455]
[epoch 43], [iter 28 / 176], [train main loss -1.964039], [lr 0.007543] [batchtime 0.452]
[epoch 43], [iter 29 / 176], [train main loss -1.945291], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 30 / 176], [train main loss -1.867521], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 31 / 176], [train main loss -1.839792], [lr 0.007543] [batchtime 0.454]
[epoch 43], [iter 32 / 176], [train main loss -1.853269], [lr 0.007543] [batchtime 0.511]
[epoch 43], [iter 33 / 176], [train main loss -1.846016], [lr 0.007543] [batchtime 0.506]
[epoch 43], [iter 34 / 176], [train main loss -1.828323], [lr 0.007543] [batchtime 0.502]
[epoch 43], [iter 35 / 176], [train main loss -1.867230], [lr 0.007543] [batchtime 0.498]
[epoch 43], [iter 36 / 176], [train main loss -1.861409], [lr 0.007543] [batchtime 0.494]
[epoch 43], [iter 37 / 176], [train main loss -1.914240], [lr 0.007543] [batchtime 0.49]
[epoch 43], [iter 38 / 176], [train main loss -1.885839], [lr 0.007543] [batchtime 0.487]
[epoch 43], [iter 39 / 176], [train main loss -1.807379], [lr 0.007543] [batchtime 0.484]
[epoch 43], [iter 40 / 176], [train main loss -1.890905], [lr 0.007543] [batchtime 0.481]
[epoch 43], [iter 41 / 176], [train main loss -1.845354], [lr 0.007543] [batchtime 0.479]
[epoch 43], [iter 42 / 176], [train main loss -1.863764], [lr 0.007543] [batchtime 0.477]
[epoch 43], [iter 43 / 176], [train main loss -1.913988], [lr 0.007543] [batchtime 0.474]
[epoch 43], [iter 44 / 176], [train main loss -1.913214], [lr 0.007543] [batchtime 0.472]
[epoch 43], [iter 45 / 176], [train main loss -1.934049], [lr 0.007543] [batchtime 0.47]
[epoch 43], [iter 46 / 176], [train main loss -1.898929], [lr 0.007543] [batchtime 0.469]
[epoch 43], [iter 47 / 176], [train main loss -1.860956], [lr 0.007543] [batchtime 0.467]
[epoch 43], [iter 48 / 176], [train main loss -1.808218], [lr 0.007543] [batchtime 0.465]
[epoch 43], [iter 49 / 176], [train main loss -1.857115], [lr 0.007543] [batchtime 0.463]
[epoch 43], [iter 50 / 176], [train main loss -1.899976], [lr 0.007543] [batchtime 0.462]
[epoch 43], [iter 51 / 176], [train main loss -1.872312], [lr 0.007543] [batchtime 0.46]
[epoch 43], [iter 52 / 176], [train main loss -1.824328], [lr 0.007543] [batchtime 0.459]
[epoch 43], [iter 53 / 176], [train main loss -1.851081], [lr 0.007543] [batchtime 0.457]
[epoch 43], [iter 54 / 176], [train main loss -1.817790], [lr 0.007543] [batchtime 0.46]
[epoch 43], [iter 55 / 176], [train main loss -1.779588], [lr 0.007543] [batchtime 0.458]
[epoch 43], [iter 56 / 176], [train main loss -1.790743], [lr 0.007543] [batchtime 0.457]
[epoch 43], [iter 57 / 176], [train main loss -1.761927], [lr 0.007543] [batchtime 0.456]
[epoch 43], [iter 58 / 176], [train main loss -1.771489], [lr 0.007543] [batchtime 0.454]
[epoch 43], [iter 59 / 176], [train main loss -1.755167], [lr 0.007543] [batchtime 0.454]
[epoch 43], [iter 60 / 176], [train main loss -1.734288], [lr 0.007543] [batchtime 0.452]
[epoch 43], [iter 61 / 176], [train main loss -1.718782], [lr 0.007543] [batchtime 0.451]
[epoch 43], [iter 62 / 176], [train main loss -1.691401], [lr 0.007543] [batchtime 0.45]
[epoch 43], [iter 63 / 176], [train main loss -1.721128], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 64 / 176], [train main loss -1.713498], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 65 / 176], [train main loss -1.677664], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 66 / 176], [train main loss -1.644075], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 67 / 176], [train main loss -1.657482], [lr 0.007543] [batchtime 0.446]
[epoch 43], [iter 68 / 176], [train main loss -1.639836], [lr 0.007543] [batchtime 0.445]
[epoch 43], [iter 69 / 176], [train main loss -1.606966], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 70 / 176], [train main loss -1.595072], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 71 / 176], [train main loss -1.578115], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 72 / 176], [train main loss -1.572958], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 73 / 176], [train main loss -1.553966], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 74 / 176], [train main loss -1.568156], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 75 / 176], [train main loss -1.603575], [lr 0.007543] [batchtime 0.462]
[epoch 43], [iter 76 / 176], [train main loss -1.617350], [lr 0.007543] [batchtime 0.463]
[epoch 43], [iter 77 / 176], [train main loss -1.647433], [lr 0.007543] [batchtime 0.461]
[epoch 43], [iter 78 / 176], [train main loss -1.670529], [lr 0.007543] [batchtime 0.461]
[epoch 43], [iter 79 / 176], [train main loss -1.668523], [lr 0.007543] [batchtime 0.459]
[epoch 43], [iter 80 / 176], [train main loss -1.690337], [lr 0.007543] [batchtime 0.458]
[epoch 43], [iter 81 / 176], [train main loss -1.682876], [lr 0.007543] [batchtime 0.458]
[epoch 43], [iter 82 / 176], [train main loss -1.671951], [lr 0.007543] [batchtime 0.457]
[epoch 43], [iter 83 / 176], [train main loss -1.676485], [lr 0.007543] [batchtime 0.456]
[epoch 43], [iter 84 / 176], [train main loss -1.624941], [lr 0.007543] [batchtime 0.455]
[epoch 43], [iter 85 / 176], [train main loss -1.627664], [lr 0.007543] [batchtime 0.455]
[epoch 43], [iter 86 / 176], [train main loss -1.623262], [lr 0.007543] [batchtime 0.454]
[epoch 43], [iter 87 / 176], [train main loss -1.588451], [lr 0.007543] [batchtime 0.453]
[epoch 43], [iter 88 / 176], [train main loss -1.605222], [lr 0.007543] [batchtime 0.452]
[epoch 43], [iter 89 / 176], [train main loss -1.606307], [lr 0.007543] [batchtime 0.452]
[epoch 43], [iter 90 / 176], [train main loss -1.641809], [lr 0.007543] [batchtime 0.451]
[epoch 43], [iter 91 / 176], [train main loss -1.638920], [lr 0.007543] [batchtime 0.45]
[epoch 43], [iter 92 / 176], [train main loss -1.635717], [lr 0.007543] [batchtime 0.45]
[epoch 43], [iter 93 / 176], [train main loss -1.658940], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 94 / 176], [train main loss -1.652860], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 95 / 176], [train main loss -1.640601], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 96 / 176], [train main loss -1.647635], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 97 / 176], [train main loss -1.638172], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 98 / 176], [train main loss -1.660495], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 99 / 176], [train main loss -1.644361], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 100 / 176], [train main loss -1.647925], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 101 / 176], [train main loss -1.641449], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 102 / 176], [train main loss -1.656335], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 103 / 176], [train main loss -1.631331], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 104 / 176], [train main loss -1.646679], [lr 0.007543] [batchtime 0.446]
[epoch 43], [iter 105 / 176], [train main loss -1.646703], [lr 0.007543] [batchtime 0.446]
[epoch 43], [iter 106 / 176], [train main loss -1.616863], [lr 0.007543] [batchtime 0.445]
[epoch 43], [iter 107 / 176], [train main loss -1.599415], [lr 0.007543] [batchtime 0.445]
[epoch 43], [iter 108 / 176], [train main loss -1.614934], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 109 / 176], [train main loss -1.611181], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 110 / 176], [train main loss -1.606601], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 111 / 176], [train main loss -1.607943], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 112 / 176], [train main loss -1.636801], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 113 / 176], [train main loss -1.647483], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 114 / 176], [train main loss -1.644245], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 115 / 176], [train main loss -1.646934], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 116 / 176], [train main loss -1.652377], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 117 / 176], [train main loss -1.652349], [lr 0.007543] [batchtime 0.44]
[epoch 43], [iter 118 / 176], [train main loss -1.647107], [lr 0.007543] [batchtime 0.44]
[epoch 43], [iter 119 / 176], [train main loss -1.637339], [lr 0.007543] [batchtime 0.44]
[epoch 43], [iter 120 / 176], [train main loss -1.624873], [lr 0.007543] [batchtime 0.439]
[epoch 43], [iter 121 / 176], [train main loss -1.633032], [lr 0.007543] [batchtime 0.439]
[epoch 43], [iter 122 / 176], [train main loss -1.625644], [lr 0.007543] [batchtime 0.438]
[epoch 43], [iter 123 / 176], [train main loss -1.641516], [lr 0.007543] [batchtime 0.439]
[epoch 43], [iter 124 / 176], [train main loss -1.629613], [lr 0.007543] [batchtime 0.45]
[epoch 43], [iter 125 / 176], [train main loss -1.637587], [lr 0.007543] [batchtime 0.45]
[epoch 43], [iter 126 / 176], [train main loss -1.626339], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 127 / 176], [train main loss -1.620502], [lr 0.007543] [batchtime 0.449]
[epoch 43], [iter 128 / 176], [train main loss -1.608178], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 129 / 176], [train main loss -1.604910], [lr 0.007543] [batchtime 0.448]
[epoch 43], [iter 130 / 176], [train main loss -1.616509], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 131 / 176], [train main loss -1.622073], [lr 0.007543] [batchtime 0.447]
[epoch 43], [iter 132 / 176], [train main loss -1.611716], [lr 0.007543] [batchtime 0.446]
[epoch 43], [iter 133 / 176], [train main loss -1.619906], [lr 0.007543] [batchtime 0.446]
[epoch 43], [iter 134 / 176], [train main loss -1.618254], [lr 0.007543] [batchtime 0.446]
[epoch 43], [iter 135 / 176], [train main loss -1.622512], [lr 0.007543] [batchtime 0.445]
[epoch 43], [iter 136 / 176], [train main loss -1.639447], [lr 0.007543] [batchtime 0.445]
[epoch 43], [iter 137 / 176], [train main loss -1.635435], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 138 / 176], [train main loss -1.612526], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 139 / 176], [train main loss -1.621846], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 140 / 176], [train main loss -1.631034], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 141 / 176], [train main loss -1.639968], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 142 / 176], [train main loss -1.639050], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 143 / 176], [train main loss -1.637277], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 144 / 176], [train main loss -1.616798], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 145 / 176], [train main loss -1.645925], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 146 / 176], [train main loss -1.670329], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 147 / 176], [train main loss -1.663251], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 148 / 176], [train main loss -1.675277], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 149 / 176], [train main loss -1.658724], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 150 / 176], [train main loss -1.650203], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 151 / 176], [train main loss -1.649742], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 152 / 176], [train main loss -1.641825], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 153 / 176], [train main loss -1.636919], [lr 0.007543] [batchtime 0.442]
[epoch 43], [iter 154 / 176], [train main loss -1.639375], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 155 / 176], [train main loss -1.657004], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 156 / 176], [train main loss -1.659962], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 157 / 176], [train main loss -1.660523], [lr 0.007543] [batchtime 0.441]
[epoch 43], [iter 158 / 176], [train main loss -1.672657], [lr 0.007543] [batchtime 0.44]
[epoch 43], [iter 159 / 176], [train main loss -1.698786], [lr 0.007543] [batchtime 0.44]
[epoch 43], [iter 160 / 176], [train main loss -1.716679], [lr 0.007543] [batchtime 0.44]
[epoch 43], [iter 161 / 176], [train main loss -1.713694], [lr 0.007543] [batchtime 0.439]
[epoch 43], [iter 162 / 176], [train main loss -1.720966], [lr 0.007543] [batchtime 0.439]
[epoch 43], [iter 163 / 176], [train main loss -1.727940], [lr 0.007543] [batchtime 0.439]
[epoch 43], [iter 164 / 176], [train main loss -1.719403], [lr 0.007543] [batchtime 0.438]
[epoch 43], [iter 165 / 176], [train main loss -1.726904], [lr 0.007543] [batchtime 0.438]
[epoch 43], [iter 166 / 176], [train main loss -1.736803], [lr 0.007543] [batchtime 0.438]
[epoch 43], [iter 167 / 176], [train main loss -1.737384], [lr 0.007543] [batchtime 0.438]
[epoch 43], [iter 168 / 176], [train main loss -1.748217], [lr 0.007543] [batchtime 0.437]
[epoch 43], [iter 169 / 176], [train main loss -1.738127], [lr 0.007543] [batchtime 0.438]
[epoch 43], [iter 170 / 176], [train main loss -1.725841], [lr 0.007543] [batchtime 0.445]
[epoch 43], [iter 171 / 176], [train main loss -1.708388], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 172 / 176], [train main loss -1.703813], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 173 / 176], [train main loss -1.712599], [lr 0.007543] [batchtime 0.444]
[epoch 43], [iter 174 / 176], [train main loss -1.723316], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 175 / 176], [train main loss -1.723492], [lr 0.007543] [batchtime 0.443]
[epoch 43], [iter 176 / 176], [train main loss -1.705740], [lr 0.007543] [batchtime 0.442]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP    FN    Precision    Recall
----  -------------  --------  -----  -------  ----  -----------  --------
   0  road              92.44  35.20     0.03  0.05         0.97      0.95
   1  sidewalk          59.81   5.03     0.31  0.36         0.76      0.73
   2  building          81.64  24.54     0.08  0.14         0.92      0.88
   3  wall               7.55   0.05     9.76  2.48         0.09      0.29
   4  fence              4.61   0.06    19.93  0.75         0.05      0.57
   5  pole              28.14   0.41     1.77  0.79         0.36      0.56
   6  traffic light      1.77   0.00    54.87  0.67         0.02      0.60
   7  traffic sign       6.06   0.03    15.06  0.44         0.06      0.69
   8  vegetation        78.86  11.39     0.09  0.18         0.92      0.85
   9  terrain           32.74   0.32     1.28  0.77         0.44      0.56
  10  sky               92.36   3.71     0.04  0.04         0.96      0.96
  11  person            33.43   0.62     1.49  0.50         0.40      0.67
  12  rider              0.38   0.00   258.01  3.30         0.00      0.23
  13  car               78.57   6.54     0.08  0.19         0.92      0.84
  14  truck              0.02   0.00  4172.25  3.95         0.00      0.20
  15  bus                0.77   0.00   126.85  2.70         0.01      0.27
  16  train              0.88   0.00   111.93  0.20         0.01      0.83
  17  motorcycle         0.09   0.00  1158.84  1.18         0.00      0.46
  18  bicycle           24.60   0.18     1.22  1.84         0.45      0.35
Mean: 32.88
-----------------------------------------------------------------------------------------------------------
this : [epoch 43], [val loss 0.40398], [acc 0.88095], [acc_cls 0.38705], [mean_iu 0.32881], [fwavacc 0.79449]
best : [epoch 43], [val loss 0.40398], [acc 0.88095], [acc_cls 0.38705], [mean_iu 0.32881], [fwavacc 0.79449]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 44], [iter 1 / 176], [train main loss 0.410233], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 2 / 176], [train main loss -1.149308], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 3 / 176], [train main loss -1.193146], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 4 / 176], [train main loss -1.167366], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 5 / 176], [train main loss -1.382415], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 6 / 176], [train main loss -1.114481], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 7 / 176], [train main loss -0.894089], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 8 / 176], [train main loss -0.935038], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 9 / 176], [train main loss -0.916457], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 10 / 176], [train main loss -1.221006], [lr 0.007486] [batchtime 0]
[epoch 44], [iter 11 / 176], [train main loss -1.193959], [lr 0.007486] [batchtime 0.364]
[epoch 44], [iter 12 / 176], [train main loss -1.142700], [lr 0.007486] [batchtime 0.381]
[epoch 44], [iter 13 / 176], [train main loss -1.308158], [lr 0.007486] [batchtime 0.385]
[epoch 44], [iter 14 / 176], [train main loss -1.383508], [lr 0.007486] [batchtime 0.387]
[epoch 44], [iter 15 / 176], [train main loss -1.431918], [lr 0.007486] [batchtime 0.387]
[epoch 44], [iter 16 / 176], [train main loss -1.603060], [lr 0.007486] [batchtime 0.387]
[epoch 44], [iter 17 / 176], [train main loss -1.554095], [lr 0.007486] [batchtime 0.387]
[epoch 44], [iter 18 / 176], [train main loss -1.565521], [lr 0.007486] [batchtime 0.388]
[epoch 44], [iter 19 / 176], [train main loss -1.584239], [lr 0.007486] [batchtime 0.388]
[epoch 44], [iter 20 / 176], [train main loss -1.670029], [lr 0.007486] [batchtime 0.396]
[epoch 44], [iter 21 / 176], [train main loss -1.611290], [lr 0.007486] [batchtime 0.412]
[epoch 44], [iter 22 / 176], [train main loss -1.477579], [lr 0.007486] [batchtime 0.41]
[epoch 44], [iter 23 / 176], [train main loss -1.551930], [lr 0.007486] [batchtime 0.408]
[epoch 44], [iter 24 / 176], [train main loss -1.433834], [lr 0.007486] [batchtime 0.408]
[epoch 44], [iter 25 / 176], [train main loss -1.526458], [lr 0.007486] [batchtime 0.407]
[epoch 44], [iter 26 / 176], [train main loss -1.533008], [lr 0.007486] [batchtime 0.406]
[epoch 44], [iter 27 / 176], [train main loss -1.525095], [lr 0.007486] [batchtime 0.405]
[epoch 44], [iter 28 / 176], [train main loss -1.515513], [lr 0.007486] [batchtime 0.404]
[epoch 44], [iter 29 / 176], [train main loss -1.626172], [lr 0.007486] [batchtime 0.404]
[epoch 44], [iter 30 / 176], [train main loss -1.560659], [lr 0.007486] [batchtime 0.404]
[epoch 44], [iter 31 / 176], [train main loss -1.423315], [lr 0.007486] [batchtime 0.403]
[epoch 44], [iter 32 / 176], [train main loss -1.415402], [lr 0.007486] [batchtime 0.403]
[epoch 44], [iter 33 / 176], [train main loss -1.432873], [lr 0.007486] [batchtime 0.403]
[epoch 44], [iter 34 / 176], [train main loss -1.361711], [lr 0.007486] [batchtime 0.402]
[epoch 44], [iter 35 / 176], [train main loss -1.407121], [lr 0.007486] [batchtime 0.402]
[epoch 44], [iter 36 / 176], [train main loss -1.368690], [lr 0.007486] [batchtime 0.402]
[epoch 44], [iter 37 / 176], [train main loss -1.286445], [lr 0.007486] [batchtime 0.402]
[epoch 44], [iter 38 / 176], [train main loss -1.290690], [lr 0.007486] [batchtime 0.402]
[epoch 44], [iter 39 / 176], [train main loss -1.388345], [lr 0.007486] [batchtime 0.402]
[epoch 44], [iter 40 / 176], [train main loss -1.383364], [lr 0.007486] [batchtime 0.401]
[epoch 44], [iter 41 / 176], [train main loss -1.382437], [lr 0.007486] [batchtime 0.401]
[epoch 44], [iter 42 / 176], [train main loss -1.427807], [lr 0.007486] [batchtime 0.401]
[epoch 44], [iter 43 / 176], [train main loss -1.414491], [lr 0.007486] [batchtime 0.401]
[epoch 44], [iter 44 / 176], [train main loss -1.427390], [lr 0.007486] [batchtime 0.401]
[epoch 44], [iter 45 / 176], [train main loss -1.420366], [lr 0.007486] [batchtime 0.434]
[epoch 44], [iter 46 / 176], [train main loss -1.391785], [lr 0.007486] [batchtime 0.438]
[epoch 44], [iter 47 / 176], [train main loss -1.387553], [lr 0.007486] [batchtime 0.437]
[epoch 44], [iter 48 / 176], [train main loss -1.361142], [lr 0.007486] [batchtime 0.435]
[epoch 44], [iter 49 / 176], [train main loss -1.349450], [lr 0.007486] [batchtime 0.434]
[epoch 44], [iter 50 / 176], [train main loss -1.370845], [lr 0.007486] [batchtime 0.433]
[epoch 44], [iter 51 / 176], [train main loss -1.340953], [lr 0.007486] [batchtime 0.432]
[epoch 44], [iter 52 / 176], [train main loss -1.365110], [lr 0.007486] [batchtime 0.431]
[epoch 44], [iter 53 / 176], [train main loss -1.337038], [lr 0.007486] [batchtime 0.431]
[epoch 44], [iter 54 / 176], [train main loss -1.336359], [lr 0.007486] [batchtime 0.43]
[epoch 44], [iter 55 / 176], [train main loss -1.387954], [lr 0.007486] [batchtime 0.429]
[epoch 44], [iter 56 / 176], [train main loss -1.410977], [lr 0.007486] [batchtime 0.429]
[epoch 44], [iter 57 / 176], [train main loss -1.423150], [lr 0.007486] [batchtime 0.428]
[epoch 44], [iter 58 / 176], [train main loss -1.476374], [lr 0.007486] [batchtime 0.427]
[epoch 44], [iter 59 / 176], [train main loss -1.482523], [lr 0.007486] [batchtime 0.426]
[epoch 44], [iter 60 / 176], [train main loss -1.504611], [lr 0.007486] [batchtime 0.426]
[epoch 44], [iter 61 / 176], [train main loss -1.553295], [lr 0.007486] [batchtime 0.425]
[epoch 44], [iter 62 / 176], [train main loss -1.540358], [lr 0.007486] [batchtime 0.425]
[epoch 44], [iter 63 / 176], [train main loss -1.469133], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 64 / 176], [train main loss -1.494274], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 65 / 176], [train main loss -1.462671], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 66 / 176], [train main loss -1.457752], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 67 / 176], [train main loss -1.434249], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 68 / 176], [train main loss -1.422203], [lr 0.007486] [batchtime 0.426]
[epoch 44], [iter 69 / 176], [train main loss -1.424466], [lr 0.007486] [batchtime 0.425]
[epoch 44], [iter 70 / 176], [train main loss -1.410153], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 71 / 176], [train main loss -1.401144], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 72 / 176], [train main loss -1.423592], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 73 / 176], [train main loss -1.455767], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 74 / 176], [train main loss -1.445897], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 75 / 176], [train main loss -1.468422], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 76 / 176], [train main loss -1.468460], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 77 / 176], [train main loss -1.492414], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 78 / 176], [train main loss -1.499630], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 79 / 176], [train main loss -1.536282], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 80 / 176], [train main loss -1.535075], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 81 / 176], [train main loss -1.575203], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 82 / 176], [train main loss -1.559595], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 83 / 176], [train main loss -1.578084], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 84 / 176], [train main loss -1.574952], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 85 / 176], [train main loss -1.602616], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 86 / 176], [train main loss -1.634691], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 87 / 176], [train main loss -1.613747], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 88 / 176], [train main loss -1.635043], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 89 / 176], [train main loss -1.646832], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 90 / 176], [train main loss -1.645684], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 91 / 176], [train main loss -1.655677], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 92 / 176], [train main loss -1.636420], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 93 / 176], [train main loss -1.625752], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 94 / 176], [train main loss -1.638578], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 95 / 176], [train main loss -1.659429], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 96 / 176], [train main loss -1.680776], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 97 / 176], [train main loss -1.688799], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 98 / 176], [train main loss -1.684839], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 99 / 176], [train main loss -1.679847], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 100 / 176], [train main loss -1.695513], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 101 / 176], [train main loss -1.674497], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 102 / 176], [train main loss -1.686710], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 103 / 176], [train main loss -1.676499], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 104 / 176], [train main loss -1.696861], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 105 / 176], [train main loss -1.692911], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 106 / 176], [train main loss -1.720535], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 107 / 176], [train main loss -1.717449], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 108 / 176], [train main loss -1.702326], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 109 / 176], [train main loss -1.706371], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 110 / 176], [train main loss -1.701748], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 111 / 176], [train main loss -1.702644], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 112 / 176], [train main loss -1.724259], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 113 / 176], [train main loss -1.710862], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 114 / 176], [train main loss -1.713163], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 115 / 176], [train main loss -1.718886], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 116 / 176], [train main loss -1.721081], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 117 / 176], [train main loss -1.743747], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 118 / 176], [train main loss -1.736550], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 119 / 176], [train main loss -1.737164], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 120 / 176], [train main loss -1.735106], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 121 / 176], [train main loss -1.733142], [lr 0.007486] [batchtime 0.418]
[epoch 44], [iter 122 / 176], [train main loss -1.701396], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 123 / 176], [train main loss -1.685063], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 124 / 176], [train main loss -1.689680], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 125 / 176], [train main loss -1.679563], [lr 0.007486] [batchtime 0.417]
[epoch 44], [iter 126 / 176], [train main loss -1.674972], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 127 / 176], [train main loss -1.661731], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 128 / 176], [train main loss -1.677085], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 129 / 176], [train main loss -1.679833], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 130 / 176], [train main loss -1.676322], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 131 / 176], [train main loss -1.695368], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 132 / 176], [train main loss -1.682217], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 133 / 176], [train main loss -1.664074], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 134 / 176], [train main loss -1.665882], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 135 / 176], [train main loss -1.666711], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 136 / 176], [train main loss -1.673078], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 137 / 176], [train main loss -1.693435], [lr 0.007486] [batchtime 0.415]
[epoch 44], [iter 138 / 176], [train main loss -1.684342], [lr 0.007486] [batchtime 0.414]
[epoch 44], [iter 139 / 176], [train main loss -1.682784], [lr 0.007486] [batchtime 0.414]
[epoch 44], [iter 140 / 176], [train main loss -1.687818], [lr 0.007486] [batchtime 0.416]
[epoch 44], [iter 141 / 176], [train main loss -1.682836], [lr 0.007486] [batchtime 0.426]
[epoch 44], [iter 142 / 176], [train main loss -1.709990], [lr 0.007486] [batchtime 0.426]
[epoch 44], [iter 143 / 176], [train main loss -1.703739], [lr 0.007486] [batchtime 0.426]
[epoch 44], [iter 144 / 176], [train main loss -1.730017], [lr 0.007486] [batchtime 0.425]
[epoch 44], [iter 145 / 176], [train main loss -1.725127], [lr 0.007486] [batchtime 0.425]
[epoch 44], [iter 146 / 176], [train main loss -1.732776], [lr 0.007486] [batchtime 0.425]
[epoch 44], [iter 147 / 176], [train main loss -1.730495], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 148 / 176], [train main loss -1.728112], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 149 / 176], [train main loss -1.715727], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 150 / 176], [train main loss -1.716105], [lr 0.007486] [batchtime 0.424]
[epoch 44], [iter 151 / 176], [train main loss -1.709432], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 152 / 176], [train main loss -1.715521], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 153 / 176], [train main loss -1.699231], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 154 / 176], [train main loss -1.681929], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 155 / 176], [train main loss -1.700947], [lr 0.007486] [batchtime 0.423]
[epoch 44], [iter 156 / 176], [train main loss -1.714314], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 157 / 176], [train main loss -1.704385], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 158 / 176], [train main loss -1.705210], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 159 / 176], [train main loss -1.697442], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 160 / 176], [train main loss -1.715149], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 161 / 176], [train main loss -1.703613], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 162 / 176], [train main loss -1.697876], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 163 / 176], [train main loss -1.691558], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 164 / 176], [train main loss -1.688142], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 165 / 176], [train main loss -1.687541], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 166 / 176], [train main loss -1.682362], [lr 0.007486] [batchtime 0.422]
[epoch 44], [iter 167 / 176], [train main loss -1.677433], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 168 / 176], [train main loss -1.673955], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 169 / 176], [train main loss -1.680455], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 170 / 176], [train main loss -1.687435], [lr 0.007486] [batchtime 0.421]
[epoch 44], [iter 171 / 176], [train main loss -1.684431], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 172 / 176], [train main loss -1.667342], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 173 / 176], [train main loss -1.666923], [lr 0.007486] [batchtime 0.42]
[epoch 44], [iter 174 / 176], [train main loss -1.664991], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 175 / 176], [train main loss -1.671289], [lr 0.007486] [batchtime 0.419]
[epoch 44], [iter 176 / 176], [train main loss -1.684716], [lr 0.007486] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP    FN    Precision    Recall
----  -------------  --------  -----  -------  ----  -----------  --------
   0  road              92.58  35.15     0.03  0.05         0.97      0.96
   1  sidewalk          59.81   4.99     0.32  0.35         0.76      0.74
   2  building          81.85  24.80     0.07  0.15         0.93      0.87
   3  wall               6.58   0.05    11.84  2.36         0.08      0.30
   4  fence              3.73   0.05    25.12  0.66         0.04      0.60
   5  pole              26.47   0.35     2.23  0.55         0.31      0.64
   6  traffic light      0.92   0.00   107.58  0.38         0.01      0.73
   7  traffic sign       3.78   0.02    25.23  0.23         0.04      0.81
   8  vegetation        79.31  11.47     0.08  0.18         0.93      0.85
   9  terrain           30.62   0.29     1.57  0.69         0.39      0.59
  10  sky               92.15   3.70     0.05  0.04         0.96      0.96
  11  person            32.05   0.57     1.67  0.45         0.37      0.69
  12  rider              0.19   0.00   525.48  3.80         0.00      0.21
  13  car               77.98   6.57     0.08  0.21         0.93      0.83
  14  truck              0.02   0.00  4564.74  1.10         0.00      0.48
  15  bus                0.43   0.00   225.72  8.55         0.00      0.10
  16  train              0.47   0.00   213.89  0.09         0.00      0.92
  17  motorcycle         0.05   0.00  2061.93  0.91         0.00      0.52
  18  bicycle           24.42   0.18     1.15  1.95         0.47      0.34
Mean: 32.28
-----------------------------------------------------------------------------------------------------------
this : [epoch 44], [val loss 0.40821], [acc 0.88185], [acc_cls 0.37800], [mean_iu 0.32284], [fwavacc 0.79473]
best : [epoch 43], [val loss 0.40398], [acc 0.88095], [acc_cls 0.38705], [mean_iu 0.32881], [fwavacc 0.79449]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 45], [iter 1 / 176], [train main loss -0.856983], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 2 / 176], [train main loss -0.751503], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 3 / 176], [train main loss -0.992443], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 4 / 176], [train main loss -1.193340], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 5 / 176], [train main loss -1.424121], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 6 / 176], [train main loss -1.464619], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 7 / 176], [train main loss -1.666830], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 8 / 176], [train main loss -1.803348], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 9 / 176], [train main loss -1.993908], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 10 / 176], [train main loss -1.992538], [lr 0.007429] [batchtime 0]
[epoch 45], [iter 11 / 176], [train main loss -2.009295], [lr 0.007429] [batchtime 0.384]
[epoch 45], [iter 12 / 176], [train main loss -1.785596], [lr 0.007429] [batchtime 0.392]
[epoch 45], [iter 13 / 176], [train main loss -1.875408], [lr 0.007429] [batchtime 0.393]
[epoch 45], [iter 14 / 176], [train main loss -1.958738], [lr 0.007429] [batchtime 0.394]
[epoch 45], [iter 15 / 176], [train main loss -1.759718], [lr 0.007429] [batchtime 0.395]
[epoch 45], [iter 16 / 176], [train main loss -1.650462], [lr 0.007429] [batchtime 0.394]
[epoch 45], [iter 17 / 176], [train main loss -1.722868], [lr 0.007429] [batchtime 0.394]
[epoch 45], [iter 18 / 176], [train main loss -1.876918], [lr 0.007429] [batchtime 0.395]
[epoch 45], [iter 19 / 176], [train main loss -1.896835], [lr 0.007429] [batchtime 0.394]
[epoch 45], [iter 20 / 176], [train main loss -1.934900], [lr 0.007429] [batchtime 0.394]
[epoch 45], [iter 21 / 176], [train main loss -1.949160], [lr 0.007429] [batchtime 0.395]
[epoch 45], [iter 22 / 176], [train main loss -1.949090], [lr 0.007429] [batchtime 0.396]
[epoch 45], [iter 23 / 176], [train main loss -1.908641], [lr 0.007429] [batchtime 0.403]
[epoch 45], [iter 24 / 176], [train main loss -1.860999], [lr 0.007429] [batchtime 0.416]
[epoch 45], [iter 25 / 176], [train main loss -1.836290], [lr 0.007429] [batchtime 0.414]
[epoch 45], [iter 26 / 176], [train main loss -1.814498], [lr 0.007429] [batchtime 0.412]
[epoch 45], [iter 27 / 176], [train main loss -1.859228], [lr 0.007429] [batchtime 0.411]
[epoch 45], [iter 28 / 176], [train main loss -1.851947], [lr 0.007429] [batchtime 0.411]
[epoch 45], [iter 29 / 176], [train main loss -1.820822], [lr 0.007429] [batchtime 0.411]
[epoch 45], [iter 30 / 176], [train main loss -1.763764], [lr 0.007429] [batchtime 0.41]
[epoch 45], [iter 31 / 176], [train main loss -1.703785], [lr 0.007429] [batchtime 0.409]
[epoch 45], [iter 32 / 176], [train main loss -1.700916], [lr 0.007429] [batchtime 0.409]
[epoch 45], [iter 33 / 176], [train main loss -1.626788], [lr 0.007429] [batchtime 0.408]
[epoch 45], [iter 34 / 176], [train main loss -1.613232], [lr 0.007429] [batchtime 0.408]
[epoch 45], [iter 35 / 176], [train main loss -1.578670], [lr 0.007429] [batchtime 0.407]
[epoch 45], [iter 36 / 176], [train main loss -1.505054], [lr 0.007429] [batchtime 0.408]
[epoch 45], [iter 37 / 176], [train main loss -1.459968], [lr 0.007429] [batchtime 0.407]
[epoch 45], [iter 38 / 176], [train main loss -1.548312], [lr 0.007429] [batchtime 0.407]
[epoch 45], [iter 39 / 176], [train main loss -1.541144], [lr 0.007429] [batchtime 0.407]
[epoch 45], [iter 40 / 176], [train main loss -1.573521], [lr 0.007429] [batchtime 0.406]
[epoch 45], [iter 41 / 176], [train main loss -1.555605], [lr 0.007429] [batchtime 0.406]
[epoch 45], [iter 42 / 176], [train main loss -1.545841], [lr 0.007429] [batchtime 0.405]
[epoch 45], [iter 43 / 176], [train main loss -1.577091], [lr 0.007429] [batchtime 0.405]
[epoch 45], [iter 44 / 176], [train main loss -1.604240], [lr 0.007429] [batchtime 0.405]
[epoch 45], [iter 45 / 176], [train main loss -1.614610], [lr 0.007429] [batchtime 0.405]
[epoch 45], [iter 46 / 176], [train main loss -1.577832], [lr 0.007429] [batchtime 0.405]
[epoch 45], [iter 47 / 176], [train main loss -1.569542], [lr 0.007429] [batchtime 0.41]
[epoch 45], [iter 48 / 176], [train main loss -1.538772], [lr 0.007429] [batchtime 0.442]
[epoch 45], [iter 49 / 176], [train main loss -1.520727], [lr 0.007429] [batchtime 0.442]
[epoch 45], [iter 50 / 176], [train main loss -1.491653], [lr 0.007429] [batchtime 0.441]
[epoch 45], [iter 51 / 176], [train main loss -1.535814], [lr 0.007429] [batchtime 0.44]
[epoch 45], [iter 52 / 176], [train main loss -1.542068], [lr 0.007429] [batchtime 0.439]
[epoch 45], [iter 53 / 176], [train main loss -1.513860], [lr 0.007429] [batchtime 0.438]
[epoch 45], [iter 54 / 176], [train main loss -1.496105], [lr 0.007429] [batchtime 0.437]
[epoch 45], [iter 55 / 176], [train main loss -1.459886], [lr 0.007429] [batchtime 0.436]
[epoch 45], [iter 56 / 176], [train main loss -1.446891], [lr 0.007429] [batchtime 0.435]
[epoch 45], [iter 57 / 176], [train main loss -1.460014], [lr 0.007429] [batchtime 0.434]
[epoch 45], [iter 58 / 176], [train main loss -1.430538], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 59 / 176], [train main loss -1.390360], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 60 / 176], [train main loss -1.378492], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 61 / 176], [train main loss -1.396801], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 62 / 176], [train main loss -1.359610], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 63 / 176], [train main loss -1.391722], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 64 / 176], [train main loss -1.413101], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 65 / 176], [train main loss -1.416532], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 66 / 176], [train main loss -1.429908], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 67 / 176], [train main loss -1.430597], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 68 / 176], [train main loss -1.424457], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 69 / 176], [train main loss -1.400080], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 70 / 176], [train main loss -1.406904], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 71 / 176], [train main loss -1.469195], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 72 / 176], [train main loss -1.475264], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 73 / 176], [train main loss -1.438132], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 74 / 176], [train main loss -1.443479], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 75 / 176], [train main loss -1.472129], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 76 / 176], [train main loss -1.519920], [lr 0.007429] [batchtime 0.425]
[epoch 45], [iter 77 / 176], [train main loss -1.528874], [lr 0.007429] [batchtime 0.425]
[epoch 45], [iter 78 / 176], [train main loss -1.530110], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 79 / 176], [train main loss -1.518017], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 80 / 176], [train main loss -1.507741], [lr 0.007429] [batchtime 0.423]
[epoch 45], [iter 81 / 176], [train main loss -1.507236], [lr 0.007429] [batchtime 0.423]
[epoch 45], [iter 82 / 176], [train main loss -1.497982], [lr 0.007429] [batchtime 0.422]
[epoch 45], [iter 83 / 176], [train main loss -1.494511], [lr 0.007429] [batchtime 0.422]
[epoch 45], [iter 84 / 176], [train main loss -1.499661], [lr 0.007429] [batchtime 0.421]
[epoch 45], [iter 85 / 176], [train main loss -1.501101], [lr 0.007429] [batchtime 0.421]
[epoch 45], [iter 86 / 176], [train main loss -1.518097], [lr 0.007429] [batchtime 0.421]
[epoch 45], [iter 87 / 176], [train main loss -1.513999], [lr 0.007429] [batchtime 0.421]
[epoch 45], [iter 88 / 176], [train main loss -1.532558], [lr 0.007429] [batchtime 0.42]
[epoch 45], [iter 89 / 176], [train main loss -1.538039], [lr 0.007429] [batchtime 0.42]
[epoch 45], [iter 90 / 176], [train main loss -1.541046], [lr 0.007429] [batchtime 0.42]
[epoch 45], [iter 91 / 176], [train main loss -1.543333], [lr 0.007429] [batchtime 0.42]
[epoch 45], [iter 92 / 176], [train main loss -1.540710], [lr 0.007429] [batchtime 0.419]
[epoch 45], [iter 93 / 176], [train main loss -1.534822], [lr 0.007429] [batchtime 0.419]
[epoch 45], [iter 94 / 176], [train main loss -1.546695], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 95 / 176], [train main loss -1.554352], [lr 0.007429] [batchtime 0.437]
[epoch 45], [iter 96 / 176], [train main loss -1.542007], [lr 0.007429] [batchtime 0.436]
[epoch 45], [iter 97 / 176], [train main loss -1.561302], [lr 0.007429] [batchtime 0.435]
[epoch 45], [iter 98 / 176], [train main loss -1.566063], [lr 0.007429] [batchtime 0.435]
[epoch 45], [iter 99 / 176], [train main loss -1.592219], [lr 0.007429] [batchtime 0.434]
[epoch 45], [iter 100 / 176], [train main loss -1.601344], [lr 0.007429] [batchtime 0.434]
[epoch 45], [iter 101 / 176], [train main loss -1.606241], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 102 / 176], [train main loss -1.598878], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 103 / 176], [train main loss -1.580209], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 104 / 176], [train main loss -1.585568], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 105 / 176], [train main loss -1.589738], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 106 / 176], [train main loss -1.577057], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 107 / 176], [train main loss -1.578083], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 108 / 176], [train main loss -1.574423], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 109 / 176], [train main loss -1.554936], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 110 / 176], [train main loss -1.568485], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 111 / 176], [train main loss -1.574254], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 112 / 176], [train main loss -1.573268], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 113 / 176], [train main loss -1.594414], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 114 / 176], [train main loss -1.597349], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 115 / 176], [train main loss -1.590235], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 116 / 176], [train main loss -1.586338], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 117 / 176], [train main loss -1.602595], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 118 / 176], [train main loss -1.614660], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 119 / 176], [train main loss -1.600214], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 120 / 176], [train main loss -1.588187], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 121 / 176], [train main loss -1.593331], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 122 / 176], [train main loss -1.567292], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 123 / 176], [train main loss -1.571445], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 124 / 176], [train main loss -1.570869], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 125 / 176], [train main loss -1.564428], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 126 / 176], [train main loss -1.566752], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 127 / 176], [train main loss -1.558773], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 128 / 176], [train main loss -1.597667], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 129 / 176], [train main loss -1.588941], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 130 / 176], [train main loss -1.593196], [lr 0.007429] [batchtime 0.426]
[epoch 45], [iter 131 / 176], [train main loss -1.593443], [lr 0.007429] [batchtime 0.425]
[epoch 45], [iter 132 / 176], [train main loss -1.608004], [lr 0.007429] [batchtime 0.425]
[epoch 45], [iter 133 / 176], [train main loss -1.620021], [lr 0.007429] [batchtime 0.425]
[epoch 45], [iter 134 / 176], [train main loss -1.646364], [lr 0.007429] [batchtime 0.425]
[epoch 45], [iter 135 / 176], [train main loss -1.660646], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 136 / 176], [train main loss -1.654212], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 137 / 176], [train main loss -1.649116], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 138 / 176], [train main loss -1.668113], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 139 / 176], [train main loss -1.657112], [lr 0.007429] [batchtime 0.423]
[epoch 45], [iter 140 / 176], [train main loss -1.654105], [lr 0.007429] [batchtime 0.424]
[epoch 45], [iter 141 / 176], [train main loss -1.654328], [lr 0.007429] [batchtime 0.434]
[epoch 45], [iter 142 / 176], [train main loss -1.666271], [lr 0.007429] [batchtime 0.434]
[epoch 45], [iter 143 / 176], [train main loss -1.660227], [lr 0.007429] [batchtime 0.434]
[epoch 45], [iter 144 / 176], [train main loss -1.668303], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 145 / 176], [train main loss -1.665810], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 146 / 176], [train main loss -1.677599], [lr 0.007429] [batchtime 0.433]
[epoch 45], [iter 147 / 176], [train main loss -1.686361], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 148 / 176], [train main loss -1.708643], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 149 / 176], [train main loss -1.712207], [lr 0.007429] [batchtime 0.432]
[epoch 45], [iter 150 / 176], [train main loss -1.718323], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 151 / 176], [train main loss -1.709844], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 152 / 176], [train main loss -1.685909], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 153 / 176], [train main loss -1.649873], [lr 0.007429] [batchtime 0.431]
[epoch 45], [iter 154 / 176], [train main loss -1.640909], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 155 / 176], [train main loss -1.663697], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 156 / 176], [train main loss -1.673268], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 157 / 176], [train main loss -1.680106], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 158 / 176], [train main loss -1.675891], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 159 / 176], [train main loss -1.687897], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 160 / 176], [train main loss -1.673691], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 161 / 176], [train main loss -1.673803], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 162 / 176], [train main loss -1.681053], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 163 / 176], [train main loss -1.692554], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 164 / 176], [train main loss -1.695926], [lr 0.007429] [batchtime 0.43]
[epoch 45], [iter 165 / 176], [train main loss -1.692916], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 166 / 176], [train main loss -1.695312], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 167 / 176], [train main loss -1.688745], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 168 / 176], [train main loss -1.675164], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 169 / 176], [train main loss -1.659543], [lr 0.007429] [batchtime 0.429]
[epoch 45], [iter 170 / 176], [train main loss -1.674011], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 171 / 176], [train main loss -1.680991], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 172 / 176], [train main loss -1.659187], [lr 0.007429] [batchtime 0.428]
[epoch 45], [iter 173 / 176], [train main loss -1.667690], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 174 / 176], [train main loss -1.666742], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 175 / 176], [train main loss -1.652042], [lr 0.007429] [batchtime 0.427]
[epoch 45], [iter 176 / 176], [train main loss -1.666894], [lr 0.007429] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP    FN    Precision    Recall
----  -------------  --------  -----  --------  ----  -----------  --------
   0  road              92.45  35.37      0.03  0.05         0.97      0.95
   1  sidewalk          59.73   4.83      0.36  0.31         0.73      0.76
   2  building          81.28  23.96      0.11  0.12         0.90      0.89
   3  wall               8.12   0.06      8.88  2.43         0.10      0.29
   4  fence              7.20   0.10     12.06  0.83         0.08      0.55
   5  pole              26.82   0.36      2.15  0.58         0.32      0.63
   6  traffic light      2.63   0.00     36.20  0.78         0.03      0.56
   7  traffic sign       6.06   0.03     15.14  0.36         0.06      0.73
   8  vegetation        76.19  11.63      0.06  0.25         0.94      0.80
   9  terrain           32.15   0.32      1.33  0.78         0.43      0.56
  10  sky               92.29   3.74      0.04  0.05         0.97      0.95
  11  person            33.90   0.66      1.31  0.64         0.43      0.61
  12  rider              0.52   0.00    187.12  3.17         0.01      0.24
  13  car               78.88   6.53      0.08  0.19         0.92      0.84
  14  truck              0.00   0.00  78268.81  4.67         0.00      0.18
  15  bus                2.53   0.00     35.26  3.30         0.03      0.23
  16  train              1.56   0.00     62.98  0.02         0.02      0.98
  17  motorcycle         0.10   0.00   1036.89  1.47         0.00      0.40
  18  bicycle           23.40   0.20      0.94  2.34         0.52      0.30
Mean: 32.94
-----------------------------------------------------------------------------------------------------------
this : [epoch 45], [val loss 0.40752], [acc 0.87809], [acc_cls 0.39214], [mean_iu 0.32938], [fwavacc 0.79064]
best : [epoch 45], [val loss 0.40752], [acc 0.87809], [acc_cls 0.39214], [mean_iu 0.32938], [fwavacc 0.79064]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 46], [iter 1 / 176], [train main loss -0.248611], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 2 / 176], [train main loss -0.780659], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 3 / 176], [train main loss -0.902259], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 4 / 176], [train main loss -1.507043], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 5 / 176], [train main loss -1.894405], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 6 / 176], [train main loss -2.219064], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 7 / 176], [train main loss -1.998586], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 8 / 176], [train main loss -1.766789], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 9 / 176], [train main loss -1.484199], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 10 / 176], [train main loss -1.332570], [lr 0.007371] [batchtime 0]
[epoch 46], [iter 11 / 176], [train main loss -1.429167], [lr 0.007371] [batchtime 0.382]
[epoch 46], [iter 12 / 176], [train main loss -1.418633], [lr 0.007371] [batchtime 0.388]
[epoch 46], [iter 13 / 176], [train main loss -1.633850], [lr 0.007371] [batchtime 0.392]
[epoch 46], [iter 14 / 176], [train main loss -1.643903], [lr 0.007371] [batchtime 0.395]
[epoch 46], [iter 15 / 176], [train main loss -1.642251], [lr 0.007371] [batchtime 0.405]
[epoch 46], [iter 16 / 176], [train main loss -1.673467], [lr 0.007371] [batchtime 0.43]
[epoch 46], [iter 17 / 176], [train main loss -1.699462], [lr 0.007371] [batchtime 0.425]
[epoch 46], [iter 18 / 176], [train main loss -1.710280], [lr 0.007371] [batchtime 0.421]
[epoch 46], [iter 19 / 176], [train main loss -1.625130], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 20 / 176], [train main loss -1.583542], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 21 / 176], [train main loss -1.563884], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 22 / 176], [train main loss -1.605466], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 23 / 176], [train main loss -1.728762], [lr 0.007371] [batchtime 0.411]
[epoch 46], [iter 24 / 176], [train main loss -1.564577], [lr 0.007371] [batchtime 0.41]
[epoch 46], [iter 25 / 176], [train main loss -1.584861], [lr 0.007371] [batchtime 0.409]
[epoch 46], [iter 26 / 176], [train main loss -1.554073], [lr 0.007371] [batchtime 0.408]
[epoch 46], [iter 27 / 176], [train main loss -1.591707], [lr 0.007371] [batchtime 0.407]
[epoch 46], [iter 28 / 176], [train main loss -1.680681], [lr 0.007371] [batchtime 0.407]
[epoch 46], [iter 29 / 176], [train main loss -1.732696], [lr 0.007371] [batchtime 0.406]
[epoch 46], [iter 30 / 176], [train main loss -1.716174], [lr 0.007371] [batchtime 0.406]
[epoch 46], [iter 31 / 176], [train main loss -1.768327], [lr 0.007371] [batchtime 0.406]
[epoch 46], [iter 32 / 176], [train main loss -1.815078], [lr 0.007371] [batchtime 0.405]
[epoch 46], [iter 33 / 176], [train main loss -1.807487], [lr 0.007371] [batchtime 0.405]
[epoch 46], [iter 34 / 176], [train main loss -1.800308], [lr 0.007371] [batchtime 0.405]
[epoch 46], [iter 35 / 176], [train main loss -1.764108], [lr 0.007371] [batchtime 0.404]
[epoch 46], [iter 36 / 176], [train main loss -1.723717], [lr 0.007371] [batchtime 0.404]
[epoch 46], [iter 37 / 176], [train main loss -1.798676], [lr 0.007371] [batchtime 0.403]
[epoch 46], [iter 38 / 176], [train main loss -1.739170], [lr 0.007371] [batchtime 0.403]
[epoch 46], [iter 39 / 176], [train main loss -1.718259], [lr 0.007371] [batchtime 0.403]
[epoch 46], [iter 40 / 176], [train main loss -1.695471], [lr 0.007371] [batchtime 0.41]
[epoch 46], [iter 41 / 176], [train main loss -1.666620], [lr 0.007371] [batchtime 0.446]
[epoch 46], [iter 42 / 176], [train main loss -1.659807], [lr 0.007371] [batchtime 0.444]
[epoch 46], [iter 43 / 176], [train main loss -1.733394], [lr 0.007371] [batchtime 0.442]
[epoch 46], [iter 44 / 176], [train main loss -1.739746], [lr 0.007371] [batchtime 0.441]
[epoch 46], [iter 45 / 176], [train main loss -1.795690], [lr 0.007371] [batchtime 0.439]
[epoch 46], [iter 46 / 176], [train main loss -1.760282], [lr 0.007371] [batchtime 0.438]
[epoch 46], [iter 47 / 176], [train main loss -1.757825], [lr 0.007371] [batchtime 0.437]
[epoch 46], [iter 48 / 176], [train main loss -1.719361], [lr 0.007371] [batchtime 0.436]
[epoch 46], [iter 49 / 176], [train main loss -1.705348], [lr 0.007371] [batchtime 0.435]
[epoch 46], [iter 50 / 176], [train main loss -1.693130], [lr 0.007371] [batchtime 0.434]
[epoch 46], [iter 51 / 176], [train main loss -1.725444], [lr 0.007371] [batchtime 0.433]
[epoch 46], [iter 52 / 176], [train main loss -1.714614], [lr 0.007371] [batchtime 0.432]
[epoch 46], [iter 53 / 176], [train main loss -1.756143], [lr 0.007371] [batchtime 0.431]
[epoch 46], [iter 54 / 176], [train main loss -1.755745], [lr 0.007371] [batchtime 0.43]
[epoch 46], [iter 55 / 176], [train main loss -1.769933], [lr 0.007371] [batchtime 0.43]
[epoch 46], [iter 56 / 176], [train main loss -1.806583], [lr 0.007371] [batchtime 0.429]
[epoch 46], [iter 57 / 176], [train main loss -1.825056], [lr 0.007371] [batchtime 0.429]
[epoch 46], [iter 58 / 176], [train main loss -1.794549], [lr 0.007371] [batchtime 0.428]
[epoch 46], [iter 59 / 176], [train main loss -1.761161], [lr 0.007371] [batchtime 0.427]
[epoch 46], [iter 60 / 176], [train main loss -1.780620], [lr 0.007371] [batchtime 0.426]
[epoch 46], [iter 61 / 176], [train main loss -1.770104], [lr 0.007371] [batchtime 0.426]
[epoch 46], [iter 62 / 176], [train main loss -1.732621], [lr 0.007371] [batchtime 0.426]
[epoch 46], [iter 63 / 176], [train main loss -1.741764], [lr 0.007371] [batchtime 0.429]
[epoch 46], [iter 64 / 176], [train main loss -1.749059], [lr 0.007371] [batchtime 0.428]
[epoch 46], [iter 65 / 176], [train main loss -1.742243], [lr 0.007371] [batchtime 0.428]
[epoch 46], [iter 66 / 176], [train main loss -1.748541], [lr 0.007371] [batchtime 0.427]
[epoch 46], [iter 67 / 176], [train main loss -1.755799], [lr 0.007371] [batchtime 0.426]
[epoch 46], [iter 68 / 176], [train main loss -1.742143], [lr 0.007371] [batchtime 0.426]
[epoch 46], [iter 69 / 176], [train main loss -1.743777], [lr 0.007371] [batchtime 0.425]
[epoch 46], [iter 70 / 176], [train main loss -1.743955], [lr 0.007371] [batchtime 0.425]
[epoch 46], [iter 71 / 176], [train main loss -1.732901], [lr 0.007371] [batchtime 0.424]
[epoch 46], [iter 72 / 176], [train main loss -1.738695], [lr 0.007371] [batchtime 0.424]
[epoch 46], [iter 73 / 176], [train main loss -1.739733], [lr 0.007371] [batchtime 0.423]
[epoch 46], [iter 74 / 176], [train main loss -1.746822], [lr 0.007371] [batchtime 0.423]
[epoch 46], [iter 75 / 176], [train main loss -1.763095], [lr 0.007371] [batchtime 0.422]
[epoch 46], [iter 76 / 176], [train main loss -1.736761], [lr 0.007371] [batchtime 0.422]
[epoch 46], [iter 77 / 176], [train main loss -1.734149], [lr 0.007371] [batchtime 0.422]
[epoch 46], [iter 78 / 176], [train main loss -1.756155], [lr 0.007371] [batchtime 0.421]
[epoch 46], [iter 79 / 176], [train main loss -1.736636], [lr 0.007371] [batchtime 0.421]
[epoch 46], [iter 80 / 176], [train main loss -1.724150], [lr 0.007371] [batchtime 0.42]
[epoch 46], [iter 81 / 176], [train main loss -1.727817], [lr 0.007371] [batchtime 0.42]
[epoch 46], [iter 82 / 176], [train main loss -1.714811], [lr 0.007371] [batchtime 0.42]
[epoch 46], [iter 83 / 176], [train main loss -1.722250], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 84 / 176], [train main loss -1.710816], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 85 / 176], [train main loss -1.730579], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 86 / 176], [train main loss -1.718355], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 87 / 176], [train main loss -1.725051], [lr 0.007371] [batchtime 0.424]
[epoch 46], [iter 88 / 176], [train main loss -1.742638], [lr 0.007371] [batchtime 0.424]
[epoch 46], [iter 89 / 176], [train main loss -1.768056], [lr 0.007371] [batchtime 0.424]
[epoch 46], [iter 90 / 176], [train main loss -1.784460], [lr 0.007371] [batchtime 0.423]
[epoch 46], [iter 91 / 176], [train main loss -1.761143], [lr 0.007371] [batchtime 0.423]
[epoch 46], [iter 92 / 176], [train main loss -1.776159], [lr 0.007371] [batchtime 0.423]
[epoch 46], [iter 93 / 176], [train main loss -1.800690], [lr 0.007371] [batchtime 0.422]
[epoch 46], [iter 94 / 176], [train main loss -1.786891], [lr 0.007371] [batchtime 0.422]
[epoch 46], [iter 95 / 176], [train main loss -1.806498], [lr 0.007371] [batchtime 0.422]
[epoch 46], [iter 96 / 176], [train main loss -1.777299], [lr 0.007371] [batchtime 0.421]
[epoch 46], [iter 97 / 176], [train main loss -1.770268], [lr 0.007371] [batchtime 0.421]
[epoch 46], [iter 98 / 176], [train main loss -1.778111], [lr 0.007371] [batchtime 0.421]
[epoch 46], [iter 99 / 176], [train main loss -1.761749], [lr 0.007371] [batchtime 0.42]
[epoch 46], [iter 100 / 176], [train main loss -1.768985], [lr 0.007371] [batchtime 0.42]
[epoch 46], [iter 101 / 176], [train main loss -1.771295], [lr 0.007371] [batchtime 0.42]
[epoch 46], [iter 102 / 176], [train main loss -1.760597], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 103 / 176], [train main loss -1.727924], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 104 / 176], [train main loss -1.728082], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 105 / 176], [train main loss -1.720297], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 106 / 176], [train main loss -1.728371], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 107 / 176], [train main loss -1.741348], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 108 / 176], [train main loss -1.716872], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 109 / 176], [train main loss -1.731895], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 110 / 176], [train main loss -1.722048], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 111 / 176], [train main loss -1.735736], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 112 / 176], [train main loss -1.725864], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 113 / 176], [train main loss -1.716685], [lr 0.007371] [batchtime 0.419]
[epoch 46], [iter 114 / 176], [train main loss -1.723252], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 115 / 176], [train main loss -1.715180], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 116 / 176], [train main loss -1.726856], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 117 / 176], [train main loss -1.740708], [lr 0.007371] [batchtime 0.418]
[epoch 46], [iter 118 / 176], [train main loss -1.746727], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 119 / 176], [train main loss -1.763580], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 120 / 176], [train main loss -1.770638], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 121 / 176], [train main loss -1.794499], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 122 / 176], [train main loss -1.780453], [lr 0.007371] [batchtime 0.417]
[epoch 46], [iter 123 / 176], [train main loss -1.791713], [lr 0.007371] [batchtime 0.416]
[epoch 46], [iter 124 / 176], [train main loss -1.806309], [lr 0.007371] [batchtime 0.416]
[epoch 46], [iter 125 / 176], [train main loss -1.791243], [lr 0.007371] [batchtime 0.416]
[epoch 46], [iter 126 / 176], [train main loss -1.778079], [lr 0.007371] [batchtime 0.416]
[epoch 46], [iter 127 / 176], [train main loss -1.765332], [lr 0.007371] [batchtime 0.416]
[epoch 46], [iter 128 / 176], [train main loss -1.776546], [lr 0.007371] [batchtime 0.416]
[epoch 46], [iter 129 / 176], [train main loss -1.775838], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 130 / 176], [train main loss -1.757138], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 131 / 176], [train main loss -1.763767], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 132 / 176], [train main loss -1.746734], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 133 / 176], [train main loss -1.752553], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 134 / 176], [train main loss -1.731167], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 135 / 176], [train main loss -1.716338], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 136 / 176], [train main loss -1.701275], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 137 / 176], [train main loss -1.674052], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 138 / 176], [train main loss -1.672912], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 139 / 176], [train main loss -1.671857], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 140 / 176], [train main loss -1.666954], [lr 0.007371] [batchtime 0.415]
[epoch 46], [iter 141 / 176], [train main loss -1.665305], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 142 / 176], [train main loss -1.656495], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 143 / 176], [train main loss -1.637896], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 144 / 176], [train main loss -1.673783], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 145 / 176], [train main loss -1.665928], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 146 / 176], [train main loss -1.686484], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 147 / 176], [train main loss -1.684663], [lr 0.007371] [batchtime 0.414]
[epoch 46], [iter 148 / 176], [train main loss -1.678252], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 149 / 176], [train main loss -1.684379], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 150 / 176], [train main loss -1.671692], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 151 / 176], [train main loss -1.663929], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 152 / 176], [train main loss -1.671325], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 153 / 176], [train main loss -1.669939], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 154 / 176], [train main loss -1.672823], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 155 / 176], [train main loss -1.652076], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 156 / 176], [train main loss -1.655470], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 157 / 176], [train main loss -1.653344], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 158 / 176], [train main loss -1.657825], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 159 / 176], [train main loss -1.652981], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 160 / 176], [train main loss -1.652167], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 161 / 176], [train main loss -1.651675], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 162 / 176], [train main loss -1.648334], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 163 / 176], [train main loss -1.648638], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 164 / 176], [train main loss -1.654704], [lr 0.007371] [batchtime 0.413]
[epoch 46], [iter 165 / 176], [train main loss -1.638967], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 166 / 176], [train main loss -1.636275], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 167 / 176], [train main loss -1.639608], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 168 / 176], [train main loss -1.644217], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 169 / 176], [train main loss -1.638289], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 170 / 176], [train main loss -1.652003], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 171 / 176], [train main loss -1.631855], [lr 0.007371] [batchtime 0.412]
[epoch 46], [iter 172 / 176], [train main loss -1.614045], [lr 0.007371] [batchtime 0.411]
[epoch 46], [iter 173 / 176], [train main loss -1.614791], [lr 0.007371] [batchtime 0.411]
[epoch 46], [iter 174 / 176], [train main loss -1.614552], [lr 0.007371] [batchtime 0.411]
[epoch 46], [iter 175 / 176], [train main loss -1.625958], [lr 0.007371] [batchtime 0.411]
[epoch 46], [iter 176 / 176], [train main loss -1.621670], [lr 0.007371] [batchtime 0.41]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP        FP    FN    Precision    Recall
----  -------------  --------  -----  --------  ----  -----------  --------
   0  road              92.50  35.61      0.02  0.06         0.98      0.94
   1  sidewalk          58.15   4.65      0.42  0.30         0.71      0.77
   2  building          81.93  24.63      0.08  0.14         0.93      0.88
   3  wall               5.66   0.04     13.98  2.68         0.07      0.27
   4  fence              6.73   0.09     12.97  0.88         0.07      0.53
   5  pole              28.22   0.39      1.91  0.63         0.34      0.61
   6  traffic light      2.95   0.00     32.08  0.79         0.03      0.56
   7  traffic sign       7.98   0.05     11.10  0.43         0.08      0.70
   8  vegetation        79.74  11.40      0.08  0.17         0.92      0.86
   9  terrain           33.90   0.36      1.02  0.93         0.50      0.52
  10  sky               91.78   3.77      0.03  0.06         0.97      0.94
  11  person            36.84   0.69      1.22  0.50         0.45      0.67
  12  rider              0.28   0.00    353.38  2.20         0.00      0.31
  13  car               79.93   6.47      0.09  0.16         0.91      0.86
  14  truck              0.07   0.00   1358.53  0.82         0.00      0.55
  15  bus                3.26   0.00     21.97  7.71         0.04      0.11
  16  train              1.70   0.00     57.80  0.07         0.02      0.93
  17  motorcycle         0.01   0.00  14643.54  0.71         0.00      0.58
  18  bicycle           25.60   0.17      1.26  1.64         0.44      0.38
Mean: 33.54
-----------------------------------------------------------------------------------------------------------
this : [epoch 46], [val loss 0.39487], [acc 0.88337], [acc_cls 0.39316], [mean_iu 0.33540], [fwavacc 0.79721]
best : [epoch 46], [val loss 0.39487], [acc 0.88337], [acc_cls 0.39316], [mean_iu 0.33540], [fwavacc 0.79721]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 47], [iter 1 / 176], [train main loss -4.099635], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 2 / 176], [train main loss -2.448131], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 3 / 176], [train main loss -2.454412], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 4 / 176], [train main loss -2.723956], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 5 / 176], [train main loss -2.620359], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 6 / 176], [train main loss -2.253924], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 7 / 176], [train main loss -2.021311], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 8 / 176], [train main loss -1.502645], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 9 / 176], [train main loss -1.381945], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 10 / 176], [train main loss -1.238614], [lr 0.007314] [batchtime 0]
[epoch 47], [iter 11 / 176], [train main loss -1.282682], [lr 0.007314] [batchtime 0.376]
[epoch 47], [iter 12 / 176], [train main loss -1.314098], [lr 0.007314] [batchtime 0.382]
[epoch 47], [iter 13 / 176], [train main loss -1.277602], [lr 0.007314] [batchtime 0.388]
[epoch 47], [iter 14 / 176], [train main loss -1.411637], [lr 0.007314] [batchtime 0.391]
[epoch 47], [iter 15 / 176], [train main loss -1.660707], [lr 0.007314] [batchtime 0.393]
[epoch 47], [iter 16 / 176], [train main loss -1.430391], [lr 0.007314] [batchtime 0.398]
[epoch 47], [iter 17 / 176], [train main loss -1.343213], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 18 / 176], [train main loss -1.188731], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 19 / 176], [train main loss -1.249858], [lr 0.007314] [batchtime 0.414]
[epoch 47], [iter 20 / 176], [train main loss -1.314770], [lr 0.007314] [batchtime 0.413]
[epoch 47], [iter 21 / 176], [train main loss -1.307401], [lr 0.007314] [batchtime 0.411]
[epoch 47], [iter 22 / 176], [train main loss -1.365996], [lr 0.007314] [batchtime 0.41]
[epoch 47], [iter 23 / 176], [train main loss -1.269395], [lr 0.007314] [batchtime 0.41]
[epoch 47], [iter 24 / 176], [train main loss -1.273750], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 25 / 176], [train main loss -1.323971], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 26 / 176], [train main loss -1.228458], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 27 / 176], [train main loss -1.267912], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 28 / 176], [train main loss -1.331296], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 29 / 176], [train main loss -1.359753], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 30 / 176], [train main loss -1.359470], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 31 / 176], [train main loss -1.372441], [lr 0.007314] [batchtime 0.404]
[epoch 47], [iter 32 / 176], [train main loss -1.362951], [lr 0.007314] [batchtime 0.404]
[epoch 47], [iter 33 / 176], [train main loss -1.387420], [lr 0.007314] [batchtime 0.404]
[epoch 47], [iter 34 / 176], [train main loss -1.362397], [lr 0.007314] [batchtime 0.404]
[epoch 47], [iter 35 / 176], [train main loss -1.414760], [lr 0.007314] [batchtime 0.404]
[epoch 47], [iter 36 / 176], [train main loss -1.457381], [lr 0.007314] [batchtime 0.403]
[epoch 47], [iter 37 / 176], [train main loss -1.399330], [lr 0.007314] [batchtime 0.403]
[epoch 47], [iter 38 / 176], [train main loss -1.409617], [lr 0.007314] [batchtime 0.403]
[epoch 47], [iter 39 / 176], [train main loss -1.350615], [lr 0.007314] [batchtime 0.403]
[epoch 47], [iter 40 / 176], [train main loss -1.394831], [lr 0.007314] [batchtime 0.402]
[epoch 47], [iter 41 / 176], [train main loss -1.378884], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 42 / 176], [train main loss -1.403409], [lr 0.007314] [batchtime 0.414]
[epoch 47], [iter 43 / 176], [train main loss -1.392781], [lr 0.007314] [batchtime 0.413]
[epoch 47], [iter 44 / 176], [train main loss -1.423365], [lr 0.007314] [batchtime 0.413]
[epoch 47], [iter 45 / 176], [train main loss -1.351496], [lr 0.007314] [batchtime 0.412]
[epoch 47], [iter 46 / 176], [train main loss -1.384406], [lr 0.007314] [batchtime 0.411]
[epoch 47], [iter 47 / 176], [train main loss -1.361961], [lr 0.007314] [batchtime 0.411]
[epoch 47], [iter 48 / 176], [train main loss -1.421010], [lr 0.007314] [batchtime 0.411]
[epoch 47], [iter 49 / 176], [train main loss -1.422178], [lr 0.007314] [batchtime 0.41]
[epoch 47], [iter 50 / 176], [train main loss -1.391607], [lr 0.007314] [batchtime 0.41]
[epoch 47], [iter 51 / 176], [train main loss -1.395481], [lr 0.007314] [batchtime 0.41]
[epoch 47], [iter 52 / 176], [train main loss -1.445861], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 53 / 176], [train main loss -1.488188], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 54 / 176], [train main loss -1.494568], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 55 / 176], [train main loss -1.477466], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 56 / 176], [train main loss -1.500179], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 57 / 176], [train main loss -1.490104], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 58 / 176], [train main loss -1.506459], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 59 / 176], [train main loss -1.526402], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 60 / 176], [train main loss -1.476927], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 61 / 176], [train main loss -1.479534], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 62 / 176], [train main loss -1.501693], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 63 / 176], [train main loss -1.458669], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 64 / 176], [train main loss -1.433364], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 65 / 176], [train main loss -1.492264], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 66 / 176], [train main loss -1.465642], [lr 0.007314] [batchtime 0.41]
[epoch 47], [iter 67 / 176], [train main loss -1.517505], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 68 / 176], [train main loss -1.481053], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 69 / 176], [train main loss -1.497772], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 70 / 176], [train main loss -1.517703], [lr 0.007314] [batchtime 0.409]
[epoch 47], [iter 71 / 176], [train main loss -1.540860], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 72 / 176], [train main loss -1.557566], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 73 / 176], [train main loss -1.569767], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 74 / 176], [train main loss -1.597568], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 75 / 176], [train main loss -1.634648], [lr 0.007314] [batchtime 0.408]
[epoch 47], [iter 76 / 176], [train main loss -1.637567], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 77 / 176], [train main loss -1.641598], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 78 / 176], [train main loss -1.639959], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 79 / 176], [train main loss -1.671761], [lr 0.007314] [batchtime 0.407]
[epoch 47], [iter 80 / 176], [train main loss -1.687510], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 81 / 176], [train main loss -1.681518], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 82 / 176], [train main loss -1.706648], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 83 / 176], [train main loss -1.702635], [lr 0.007314] [batchtime 0.406]
[epoch 47], [iter 84 / 176], [train main loss -1.691729], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 85 / 176], [train main loss -1.749361], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 86 / 176], [train main loss -1.733916], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 87 / 176], [train main loss -1.738290], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 88 / 176], [train main loss -1.724049], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 89 / 176], [train main loss -1.746663], [lr 0.007314] [batchtime 0.405]
[epoch 47], [iter 90 / 176], [train main loss -1.761432], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 91 / 176], [train main loss -1.778792], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 92 / 176], [train main loss -1.757921], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 93 / 176], [train main loss -1.782030], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 94 / 176], [train main loss -1.757896], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 95 / 176], [train main loss -1.764758], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 96 / 176], [train main loss -1.781289], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 97 / 176], [train main loss -1.777210], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 98 / 176], [train main loss -1.778057], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 99 / 176], [train main loss -1.805246], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 100 / 176], [train main loss -1.783336], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 101 / 176], [train main loss -1.812791], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 102 / 176], [train main loss -1.818095], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 103 / 176], [train main loss -1.823792], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 104 / 176], [train main loss -1.824632], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 105 / 176], [train main loss -1.828884], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 106 / 176], [train main loss -1.838448], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 107 / 176], [train main loss -1.845021], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 108 / 176], [train main loss -1.849338], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 109 / 176], [train main loss -1.879379], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 110 / 176], [train main loss -1.919215], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 111 / 176], [train main loss -1.928282], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 112 / 176], [train main loss -1.927646], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 113 / 176], [train main loss -1.930729], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 114 / 176], [train main loss -1.928534], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 115 / 176], [train main loss -1.941026], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 116 / 176], [train main loss -1.962659], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 117 / 176], [train main loss -1.955308], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 118 / 176], [train main loss -1.946651], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 119 / 176], [train main loss -1.940628], [lr 0.007314] [batchtime 0.417]
[epoch 47], [iter 120 / 176], [train main loss -1.940759], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 121 / 176], [train main loss -1.924822], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 122 / 176], [train main loss -1.909806], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 123 / 176], [train main loss -1.890897], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 124 / 176], [train main loss -1.899205], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 125 / 176], [train main loss -1.908438], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 126 / 176], [train main loss -1.925891], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 127 / 176], [train main loss -1.913972], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 128 / 176], [train main loss -1.899866], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 129 / 176], [train main loss -1.915254], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 130 / 176], [train main loss -1.943030], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 131 / 176], [train main loss -1.944307], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 132 / 176], [train main loss -1.932916], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 133 / 176], [train main loss -1.922843], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 134 / 176], [train main loss -1.919202], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 135 / 176], [train main loss -1.912398], [lr 0.007314] [batchtime 0.415]
[epoch 47], [iter 136 / 176], [train main loss -1.905635], [lr 0.007314] [batchtime 0.416]
[epoch 47], [iter 137 / 176], [train main loss -1.904271], [lr 0.007314] [batchtime 0.424]
[epoch 47], [iter 138 / 176], [train main loss -1.885625], [lr 0.007314] [batchtime 0.424]
[epoch 47], [iter 139 / 176], [train main loss -1.867288], [lr 0.007314] [batchtime 0.424]
[epoch 47], [iter 140 / 176], [train main loss -1.861401], [lr 0.007314] [batchtime 0.424]
[epoch 47], [iter 141 / 176], [train main loss -1.864545], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 142 / 176], [train main loss -1.880768], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 143 / 176], [train main loss -1.869725], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 144 / 176], [train main loss -1.874546], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 145 / 176], [train main loss -1.874978], [lr 0.007314] [batchtime 0.423]
[epoch 47], [iter 146 / 176], [train main loss -1.854144], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 147 / 176], [train main loss -1.864902], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 148 / 176], [train main loss -1.876184], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 149 / 176], [train main loss -1.892422], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 150 / 176], [train main loss -1.896739], [lr 0.007314] [batchtime 0.422]
[epoch 47], [iter 151 / 176], [train main loss -1.899379], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 152 / 176], [train main loss -1.887620], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 153 / 176], [train main loss -1.879233], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 154 / 176], [train main loss -1.903015], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 155 / 176], [train main loss -1.910547], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 156 / 176], [train main loss -1.902950], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 157 / 176], [train main loss -1.914668], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 158 / 176], [train main loss -1.943759], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 159 / 176], [train main loss -1.940361], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 160 / 176], [train main loss -1.927769], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 161 / 176], [train main loss -1.923012], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 162 / 176], [train main loss -1.915432], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 163 / 176], [train main loss -1.935275], [lr 0.007314] [batchtime 0.421]
[epoch 47], [iter 164 / 176], [train main loss -1.939222], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 165 / 176], [train main loss -1.940969], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 166 / 176], [train main loss -1.936373], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 167 / 176], [train main loss -1.941543], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 168 / 176], [train main loss -1.935215], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 169 / 176], [train main loss -1.928104], [lr 0.007314] [batchtime 0.42]
[epoch 47], [iter 170 / 176], [train main loss -1.929498], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 171 / 176], [train main loss -1.918059], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 172 / 176], [train main loss -1.920547], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 173 / 176], [train main loss -1.929227], [lr 0.007314] [batchtime 0.419]
[epoch 47], [iter 174 / 176], [train main loss -1.929478], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 175 / 176], [train main loss -1.944732], [lr 0.007314] [batchtime 0.418]
[epoch 47], [iter 176 / 176], [train main loss -1.944235], [lr 0.007314] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP    FN    Precision    Recall
----  -------------  --------  -----  -------  ----  -----------  --------
   0  road              92.46  35.15     0.03  0.05         0.97      0.95
   1  sidewalk          59.50   4.77     0.38  0.30         0.72      0.77
   2  building          81.92  24.56     0.08  0.14         0.92      0.88
   3  wall               9.96   0.08     6.60  2.44         0.13      0.29
   4  fence              7.99   0.11    10.47  1.05         0.09      0.49
   5  pole              28.05   0.39     1.89  0.68         0.35      0.60
   6  traffic light      2.11   0.00    46.00  0.46         0.02      0.69
   7  traffic sign       5.31   0.03    17.52  0.31         0.05      0.76
   8  vegetation        78.15  11.52     0.07  0.21         0.93      0.83
   9  terrain           34.70   0.34     1.19  0.70         0.46      0.59
  10  sky               92.34   3.68     0.05  0.03         0.95      0.97
  11  person            35.81   0.68     1.26  0.53         0.44      0.65
  12  rider              0.18   0.00   539.65  1.75         0.00      0.36
  13  car               77.23   6.58     0.07  0.22         0.93      0.82
  14  truck              0.23   0.00   423.96  0.84         0.00      0.54
  15  bus                2.85   0.00    27.22  6.85         0.04      0.13
  16  train              3.74   0.01    25.65  0.10         0.04      0.91
  17  motorcycle         0.06   0.00  1606.54  0.35         0.00      0.74
  18  bicycle           26.03   0.17     1.28  1.57         0.44      0.39
Mean: 33.61
-----------------------------------------------------------------------------------------------------------
this : [epoch 47], [val loss 0.40992], [acc 0.88088], [acc_cls 0.39399], [mean_iu 0.33612], [fwavacc 0.79443]
best : [epoch 47], [val loss 0.40992], [acc 0.88088], [acc_cls 0.39399], [mean_iu 0.33612], [fwavacc 0.79443]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 48], [iter 1 / 176], [train main loss -2.530962], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 2 / 176], [train main loss -2.157182], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 3 / 176], [train main loss -1.562604], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 4 / 176], [train main loss -1.816121], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 5 / 176], [train main loss -1.502858], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 6 / 176], [train main loss -1.382924], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 7 / 176], [train main loss -1.362252], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 8 / 176], [train main loss -1.455535], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 9 / 176], [train main loss -1.857030], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 10 / 176], [train main loss -1.754598], [lr 0.007257] [batchtime 0]
[epoch 48], [iter 11 / 176], [train main loss -1.377380], [lr 0.007257] [batchtime 0.359]
[epoch 48], [iter 12 / 176], [train main loss -1.294963], [lr 0.007257] [batchtime 0.384]
[epoch 48], [iter 13 / 176], [train main loss -1.165624], [lr 0.007257] [batchtime 0.389]
[epoch 48], [iter 14 / 176], [train main loss -1.329886], [lr 0.007257] [batchtime 0.392]
[epoch 48], [iter 15 / 176], [train main loss -1.363451], [lr 0.007257] [batchtime 0.393]
[epoch 48], [iter 16 / 176], [train main loss -1.370638], [lr 0.007257] [batchtime 0.392]
[epoch 48], [iter 17 / 176], [train main loss -1.484204], [lr 0.007257] [batchtime 0.393]
[epoch 48], [iter 18 / 176], [train main loss -1.546923], [lr 0.007257] [batchtime 0.393]
[epoch 48], [iter 19 / 176], [train main loss -1.585076], [lr 0.007257] [batchtime 0.395]
[epoch 48], [iter 20 / 176], [train main loss -1.686965], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 21 / 176], [train main loss -1.572426], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 22 / 176], [train main loss -1.718026], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 23 / 176], [train main loss -1.673135], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 24 / 176], [train main loss -1.591384], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 25 / 176], [train main loss -1.590813], [lr 0.007257] [batchtime 0.395]
[epoch 48], [iter 26 / 176], [train main loss -1.589146], [lr 0.007257] [batchtime 0.395]
[epoch 48], [iter 27 / 176], [train main loss -1.474634], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 28 / 176], [train main loss -1.469080], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 29 / 176], [train main loss -1.469715], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 30 / 176], [train main loss -1.451470], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 31 / 176], [train main loss -1.438064], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 32 / 176], [train main loss -1.365575], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 33 / 176], [train main loss -1.382447], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 34 / 176], [train main loss -1.448854], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 35 / 176], [train main loss -1.429520], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 36 / 176], [train main loss -1.430575], [lr 0.007257] [batchtime 0.396]
[epoch 48], [iter 37 / 176], [train main loss -1.442644], [lr 0.007257] [batchtime 0.422]
[epoch 48], [iter 38 / 176], [train main loss -1.461201], [lr 0.007257] [batchtime 0.426]
[epoch 48], [iter 39 / 176], [train main loss -1.530731], [lr 0.007257] [batchtime 0.425]
[epoch 48], [iter 40 / 176], [train main loss -1.502909], [lr 0.007257] [batchtime 0.424]
[epoch 48], [iter 41 / 176], [train main loss -1.514884], [lr 0.007257] [batchtime 0.423]
[epoch 48], [iter 42 / 176], [train main loss -1.489906], [lr 0.007257] [batchtime 0.422]
[epoch 48], [iter 43 / 176], [train main loss -1.499381], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 44 / 176], [train main loss -1.490529], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 45 / 176], [train main loss -1.509351], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 46 / 176], [train main loss -1.499422], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 47 / 176], [train main loss -1.501377], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 48 / 176], [train main loss -1.567864], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 49 / 176], [train main loss -1.608703], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 50 / 176], [train main loss -1.567890], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 51 / 176], [train main loss -1.587115], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 52 / 176], [train main loss -1.580922], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 53 / 176], [train main loss -1.569326], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 54 / 176], [train main loss -1.588909], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 55 / 176], [train main loss -1.562746], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 56 / 176], [train main loss -1.557836], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 57 / 176], [train main loss -1.575299], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 58 / 176], [train main loss -1.540928], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 59 / 176], [train main loss -1.552331], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 60 / 176], [train main loss -1.495114], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 61 / 176], [train main loss -1.524838], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 62 / 176], [train main loss -1.487543], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 63 / 176], [train main loss -1.479101], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 64 / 176], [train main loss -1.448549], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 65 / 176], [train main loss -1.417141], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 66 / 176], [train main loss -1.421467], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 67 / 176], [train main loss -1.472305], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 68 / 176], [train main loss -1.457397], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 69 / 176], [train main loss -1.447326], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 70 / 176], [train main loss -1.422008], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 71 / 176], [train main loss -1.460219], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 72 / 176], [train main loss -1.469431], [lr 0.007257] [batchtime 0.409]
[epoch 48], [iter 73 / 176], [train main loss -1.493804], [lr 0.007257] [batchtime 0.409]
[epoch 48], [iter 74 / 176], [train main loss -1.501030], [lr 0.007257] [batchtime 0.409]
[epoch 48], [iter 75 / 176], [train main loss -1.515832], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 76 / 176], [train main loss -1.513766], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 77 / 176], [train main loss -1.545788], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 78 / 176], [train main loss -1.559037], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 79 / 176], [train main loss -1.551560], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 80 / 176], [train main loss -1.552528], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 81 / 176], [train main loss -1.551433], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 82 / 176], [train main loss -1.552900], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 83 / 176], [train main loss -1.593762], [lr 0.007257] [batchtime 0.41]
[epoch 48], [iter 84 / 176], [train main loss -1.630403], [lr 0.007257] [batchtime 0.409]
[epoch 48], [iter 85 / 176], [train main loss -1.616983], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 86 / 176], [train main loss -1.604496], [lr 0.007257] [batchtime 0.422]
[epoch 48], [iter 87 / 176], [train main loss -1.600148], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 88 / 176], [train main loss -1.588640], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 89 / 176], [train main loss -1.596928], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 90 / 176], [train main loss -1.606782], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 91 / 176], [train main loss -1.612282], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 92 / 176], [train main loss -1.671075], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 93 / 176], [train main loss -1.679739], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 94 / 176], [train main loss -1.704888], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 95 / 176], [train main loss -1.712566], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 96 / 176], [train main loss -1.690183], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 97 / 176], [train main loss -1.707215], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 98 / 176], [train main loss -1.679941], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 99 / 176], [train main loss -1.682779], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 100 / 176], [train main loss -1.717117], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 101 / 176], [train main loss -1.725162], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 102 / 176], [train main loss -1.722630], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 103 / 176], [train main loss -1.735552], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 104 / 176], [train main loss -1.732595], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 105 / 176], [train main loss -1.750362], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 106 / 176], [train main loss -1.728021], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 107 / 176], [train main loss -1.763206], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 108 / 176], [train main loss -1.793253], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 109 / 176], [train main loss -1.780512], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 110 / 176], [train main loss -1.791864], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 111 / 176], [train main loss -1.813233], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 112 / 176], [train main loss -1.813801], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 113 / 176], [train main loss -1.813746], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 114 / 176], [train main loss -1.813874], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 115 / 176], [train main loss -1.821737], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 116 / 176], [train main loss -1.831815], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 117 / 176], [train main loss -1.845723], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 118 / 176], [train main loss -1.838294], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 119 / 176], [train main loss -1.831734], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 120 / 176], [train main loss -1.805387], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 121 / 176], [train main loss -1.801343], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 122 / 176], [train main loss -1.808415], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 123 / 176], [train main loss -1.789526], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 124 / 176], [train main loss -1.798540], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 125 / 176], [train main loss -1.789539], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 126 / 176], [train main loss -1.785526], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 127 / 176], [train main loss -1.791578], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 128 / 176], [train main loss -1.807022], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 129 / 176], [train main loss -1.798369], [lr 0.007257] [batchtime 0.412]
[epoch 48], [iter 130 / 176], [train main loss -1.809795], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 131 / 176], [train main loss -1.825049], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 132 / 176], [train main loss -1.825182], [lr 0.007257] [batchtime 0.411]
[epoch 48], [iter 133 / 176], [train main loss -1.845812], [lr 0.007257] [batchtime 0.413]
[epoch 48], [iter 134 / 176], [train main loss -1.854033], [lr 0.007257] [batchtime 0.422]
[epoch 48], [iter 135 / 176], [train main loss -1.835537], [lr 0.007257] [batchtime 0.422]
[epoch 48], [iter 136 / 176], [train main loss -1.829687], [lr 0.007257] [batchtime 0.422]
[epoch 48], [iter 137 / 176], [train main loss -1.834292], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 138 / 176], [train main loss -1.836696], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 139 / 176], [train main loss -1.842206], [lr 0.007257] [batchtime 0.421]
[epoch 48], [iter 140 / 176], [train main loss -1.852309], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 141 / 176], [train main loss -1.827617], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 142 / 176], [train main loss -1.835326], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 143 / 176], [train main loss -1.852815], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 144 / 176], [train main loss -1.853218], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 145 / 176], [train main loss -1.853756], [lr 0.007257] [batchtime 0.42]
[epoch 48], [iter 146 / 176], [train main loss -1.844752], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 147 / 176], [train main loss -1.837887], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 148 / 176], [train main loss -1.821092], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 149 / 176], [train main loss -1.821708], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 150 / 176], [train main loss -1.834873], [lr 0.007257] [batchtime 0.419]
[epoch 48], [iter 151 / 176], [train main loss -1.863433], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 152 / 176], [train main loss -1.867065], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 153 / 176], [train main loss -1.879145], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 154 / 176], [train main loss -1.879842], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 155 / 176], [train main loss -1.886511], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 156 / 176], [train main loss -1.875241], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 157 / 176], [train main loss -1.874331], [lr 0.007257] [batchtime 0.418]
[epoch 48], [iter 158 / 176], [train main loss -1.876705], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 159 / 176], [train main loss -1.874593], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 160 / 176], [train main loss -1.872816], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 161 / 176], [train main loss -1.869279], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 162 / 176], [train main loss -1.854538], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 163 / 176], [train main loss -1.839500], [lr 0.007257] [batchtime 0.417]
[epoch 48], [iter 164 / 176], [train main loss -1.850833], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 165 / 176], [train main loss -1.851696], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 166 / 176], [train main loss -1.852475], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 167 / 176], [train main loss -1.852971], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 168 / 176], [train main loss -1.859985], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 169 / 176], [train main loss -1.865575], [lr 0.007257] [batchtime 0.416]
[epoch 48], [iter 170 / 176], [train main loss -1.859547], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 171 / 176], [train main loss -1.852110], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 172 / 176], [train main loss -1.849582], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 173 / 176], [train main loss -1.836677], [lr 0.007257] [batchtime 0.415]
[epoch 48], [iter 174 / 176], [train main loss -1.845876], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 175 / 176], [train main loss -1.851308], [lr 0.007257] [batchtime 0.414]
[epoch 48], [iter 176 / 176], [train main loss -1.840442], [lr 0.007257] [batchtime 0.414]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.29  35.48    0.02  0.06         0.98      0.94
   1  sidewalk          58.11   4.53    0.46  0.27         0.69      0.79
   2  building          83.08  24.39    0.09  0.11         0.92      0.90
   3  wall               9.79   0.08    6.49  2.73         0.13      0.27
   4  fence              7.67   0.10   11.17  0.88         0.08      0.53
   5  pole              30.53   0.45    1.52  0.76         0.40      0.57
   6  traffic light      3.83   0.01   24.37  0.71         0.04      0.59
   7  traffic sign       7.74   0.04   11.60  0.33         0.08      0.75
   8  vegetation        80.25  11.49    0.08  0.17         0.93      0.85
   9  terrain           34.20   0.32    1.33  0.60         0.43      0.63
  10  sky               92.23   3.77    0.03  0.06         0.97      0.95
  11  person            38.55   0.80    0.92  0.67         0.52      0.60
  12  rider              0.54   0.00  179.37  4.01         0.01      0.20
  13  car               77.02   6.70    0.06  0.24         0.95      0.80
  14  truck              0.15   0.00  672.32  7.28         0.00      0.12
  15  bus                3.48   0.00   24.27  3.47         0.04      0.22
  16  train             12.13   0.02    6.97  0.27         0.13      0.78
  17  motorcycle         0.14   0.00  702.99  0.60         0.00      0.63
  18  bicycle           25.87   0.19    1.04  1.83         0.49      0.35
Mean: 34.61
-----------------------------------------------------------------------------------------------------------
this : [epoch 48], [val loss 0.38780], [acc 0.88376], [acc_cls 0.40927], [mean_iu 0.34611], [fwavacc 0.79930]
best : [epoch 48], [val loss 0.38780], [acc 0.88376], [acc_cls 0.40927], [mean_iu 0.34611], [fwavacc 0.79930]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 49], [iter 1 / 176], [train main loss -1.173225], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 2 / 176], [train main loss -1.290168], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 3 / 176], [train main loss -1.791368], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 4 / 176], [train main loss -1.322368], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 5 / 176], [train main loss -1.507938], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 6 / 176], [train main loss -1.647494], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 7 / 176], [train main loss -1.696690], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 8 / 176], [train main loss -1.746826], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 9 / 176], [train main loss -1.681132], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 10 / 176], [train main loss -1.709078], [lr 0.007200] [batchtime 0]
[epoch 49], [iter 11 / 176], [train main loss -1.659073], [lr 0.007200] [batchtime 0.373]
[epoch 49], [iter 12 / 176], [train main loss -1.697019], [lr 0.007200] [batchtime 0.386]
[epoch 49], [iter 13 / 176], [train main loss -1.517244], [lr 0.007200] [batchtime 0.393]
[epoch 49], [iter 14 / 176], [train main loss -1.572818], [lr 0.007200] [batchtime 0.395]
[epoch 49], [iter 15 / 176], [train main loss -1.727179], [lr 0.007200] [batchtime 0.396]
[epoch 49], [iter 16 / 176], [train main loss -1.647435], [lr 0.007200] [batchtime 0.396]
[epoch 49], [iter 17 / 176], [train main loss -1.611803], [lr 0.007200] [batchtime 0.396]
[epoch 49], [iter 18 / 176], [train main loss -1.479915], [lr 0.007200] [batchtime 0.397]
[epoch 49], [iter 19 / 176], [train main loss -1.582304], [lr 0.007200] [batchtime 0.398]
[epoch 49], [iter 20 / 176], [train main loss -1.605897], [lr 0.007200] [batchtime 0.398]
[epoch 49], [iter 21 / 176], [train main loss -1.667952], [lr 0.007200] [batchtime 0.4]
[epoch 49], [iter 22 / 176], [train main loss -1.565827], [lr 0.007200] [batchtime 0.4]
[epoch 49], [iter 23 / 176], [train main loss -1.526976], [lr 0.007200] [batchtime 0.4]
[epoch 49], [iter 24 / 176], [train main loss -1.550425], [lr 0.007200] [batchtime 0.405]
[epoch 49], [iter 25 / 176], [train main loss -1.457082], [lr 0.007200] [batchtime 0.404]
[epoch 49], [iter 26 / 176], [train main loss -1.428127], [lr 0.007200] [batchtime 0.404]
[epoch 49], [iter 27 / 176], [train main loss -1.376067], [lr 0.007200] [batchtime 0.403]
[epoch 49], [iter 28 / 176], [train main loss -1.420934], [lr 0.007200] [batchtime 0.403]
[epoch 49], [iter 29 / 176], [train main loss -1.377665], [lr 0.007200] [batchtime 0.404]
[epoch 49], [iter 30 / 176], [train main loss -1.296266], [lr 0.007200] [batchtime 0.404]
[epoch 49], [iter 31 / 176], [train main loss -1.343863], [lr 0.007200] [batchtime 0.403]
[epoch 49], [iter 32 / 176], [train main loss -1.322133], [lr 0.007200] [batchtime 0.403]
[epoch 49], [iter 33 / 176], [train main loss -1.376910], [lr 0.007200] [batchtime 0.402]
[epoch 49], [iter 34 / 176], [train main loss -1.457651], [lr 0.007200] [batchtime 0.409]
[epoch 49], [iter 35 / 176], [train main loss -1.454103], [lr 0.007200] [batchtime 0.463]
[epoch 49], [iter 36 / 176], [train main loss -1.432282], [lr 0.007200] [batchtime 0.46]
[epoch 49], [iter 37 / 176], [train main loss -1.415274], [lr 0.007200] [batchtime 0.457]
[epoch 49], [iter 38 / 176], [train main loss -1.458613], [lr 0.007200] [batchtime 0.455]
[epoch 49], [iter 39 / 176], [train main loss -1.515271], [lr 0.007200] [batchtime 0.453]
[epoch 49], [iter 40 / 176], [train main loss -1.493343], [lr 0.007200] [batchtime 0.451]
[epoch 49], [iter 41 / 176], [train main loss -1.541095], [lr 0.007200] [batchtime 0.449]
[epoch 49], [iter 42 / 176], [train main loss -1.565441], [lr 0.007200] [batchtime 0.448]
[epoch 49], [iter 43 / 176], [train main loss -1.551819], [lr 0.007200] [batchtime 0.446]
[epoch 49], [iter 44 / 176], [train main loss -1.543860], [lr 0.007200] [batchtime 0.445]
[epoch 49], [iter 45 / 176], [train main loss -1.573735], [lr 0.007200] [batchtime 0.443]
[epoch 49], [iter 46 / 176], [train main loss -1.552325], [lr 0.007200] [batchtime 0.442]
[epoch 49], [iter 47 / 176], [train main loss -1.600385], [lr 0.007200] [batchtime 0.441]
[epoch 49], [iter 48 / 176], [train main loss -1.634178], [lr 0.007200] [batchtime 0.439]
[epoch 49], [iter 49 / 176], [train main loss -1.607546], [lr 0.007200] [batchtime 0.438]
[epoch 49], [iter 50 / 176], [train main loss -1.615601], [lr 0.007200] [batchtime 0.437]
[epoch 49], [iter 51 / 176], [train main loss -1.662964], [lr 0.007200] [batchtime 0.436]
[epoch 49], [iter 52 / 176], [train main loss -1.654089], [lr 0.007200] [batchtime 0.435]
[epoch 49], [iter 53 / 176], [train main loss -1.660704], [lr 0.007200] [batchtime 0.434]
[epoch 49], [iter 54 / 176], [train main loss -1.624431], [lr 0.007200] [batchtime 0.434]
[epoch 49], [iter 55 / 176], [train main loss -1.591495], [lr 0.007200] [batchtime 0.433]
[epoch 49], [iter 56 / 176], [train main loss -1.594691], [lr 0.007200] [batchtime 0.433]
[epoch 49], [iter 57 / 176], [train main loss -1.580934], [lr 0.007200] [batchtime 0.432]
[epoch 49], [iter 58 / 176], [train main loss -1.549257], [lr 0.007200] [batchtime 0.431]
[epoch 49], [iter 59 / 176], [train main loss -1.511003], [lr 0.007200] [batchtime 0.43]
[epoch 49], [iter 60 / 176], [train main loss -1.539698], [lr 0.007200] [batchtime 0.429]
[epoch 49], [iter 61 / 176], [train main loss -1.549854], [lr 0.007200] [batchtime 0.429]
[epoch 49], [iter 62 / 176], [train main loss -1.536139], [lr 0.007200] [batchtime 0.428]
[epoch 49], [iter 63 / 176], [train main loss -1.500245], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 64 / 176], [train main loss -1.507590], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 65 / 176], [train main loss -1.473629], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 66 / 176], [train main loss -1.478912], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 67 / 176], [train main loss -1.457193], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 68 / 176], [train main loss -1.478950], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 69 / 176], [train main loss -1.518715], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 70 / 176], [train main loss -1.568240], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 71 / 176], [train main loss -1.571287], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 72 / 176], [train main loss -1.583884], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 73 / 176], [train main loss -1.558946], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 74 / 176], [train main loss -1.557051], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 75 / 176], [train main loss -1.577909], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 76 / 176], [train main loss -1.556449], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 77 / 176], [train main loss -1.541106], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 78 / 176], [train main loss -1.554840], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 79 / 176], [train main loss -1.557452], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 80 / 176], [train main loss -1.544916], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 81 / 176], [train main loss -1.564036], [lr 0.007200] [batchtime 0.435]
[epoch 49], [iter 82 / 176], [train main loss -1.562688], [lr 0.007200] [batchtime 0.436]
[epoch 49], [iter 83 / 176], [train main loss -1.544061], [lr 0.007200] [batchtime 0.436]
[epoch 49], [iter 84 / 176], [train main loss -1.545450], [lr 0.007200] [batchtime 0.435]
[epoch 49], [iter 85 / 176], [train main loss -1.537827], [lr 0.007200] [batchtime 0.434]
[epoch 49], [iter 86 / 176], [train main loss -1.511709], [lr 0.007200] [batchtime 0.434]
[epoch 49], [iter 87 / 176], [train main loss -1.526440], [lr 0.007200] [batchtime 0.433]
[epoch 49], [iter 88 / 176], [train main loss -1.506982], [lr 0.007200] [batchtime 0.433]
[epoch 49], [iter 89 / 176], [train main loss -1.495308], [lr 0.007200] [batchtime 0.432]
[epoch 49], [iter 90 / 176], [train main loss -1.509031], [lr 0.007200] [batchtime 0.432]
[epoch 49], [iter 91 / 176], [train main loss -1.505406], [lr 0.007200] [batchtime 0.431]
[epoch 49], [iter 92 / 176], [train main loss -1.526396], [lr 0.007200] [batchtime 0.431]
[epoch 49], [iter 93 / 176], [train main loss -1.523513], [lr 0.007200] [batchtime 0.43]
[epoch 49], [iter 94 / 176], [train main loss -1.535871], [lr 0.007200] [batchtime 0.43]
[epoch 49], [iter 95 / 176], [train main loss -1.523957], [lr 0.007200] [batchtime 0.43]
[epoch 49], [iter 96 / 176], [train main loss -1.514918], [lr 0.007200] [batchtime 0.429]
[epoch 49], [iter 97 / 176], [train main loss -1.511418], [lr 0.007200] [batchtime 0.429]
[epoch 49], [iter 98 / 176], [train main loss -1.508020], [lr 0.007200] [batchtime 0.428]
[epoch 49], [iter 99 / 176], [train main loss -1.516454], [lr 0.007200] [batchtime 0.428]
[epoch 49], [iter 100 / 176], [train main loss -1.510413], [lr 0.007200] [batchtime 0.428]
[epoch 49], [iter 101 / 176], [train main loss -1.505868], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 102 / 176], [train main loss -1.512001], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 103 / 176], [train main loss -1.501410], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 104 / 176], [train main loss -1.501912], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 105 / 176], [train main loss -1.520977], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 106 / 176], [train main loss -1.523957], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 107 / 176], [train main loss -1.524264], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 108 / 176], [train main loss -1.525727], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 109 / 176], [train main loss -1.530421], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 110 / 176], [train main loss -1.553575], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 111 / 176], [train main loss -1.548415], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 112 / 176], [train main loss -1.544933], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 113 / 176], [train main loss -1.558322], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 114 / 176], [train main loss -1.548587], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 115 / 176], [train main loss -1.540611], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 116 / 176], [train main loss -1.506126], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 117 / 176], [train main loss -1.504863], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 118 / 176], [train main loss -1.477506], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 119 / 176], [train main loss -1.482900], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 120 / 176], [train main loss -1.504586], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 121 / 176], [train main loss -1.489007], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 122 / 176], [train main loss -1.483732], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 123 / 176], [train main loss -1.480334], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 124 / 176], [train main loss -1.488565], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 125 / 176], [train main loss -1.484788], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 126 / 176], [train main loss -1.476048], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 127 / 176], [train main loss -1.478888], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 128 / 176], [train main loss -1.478766], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 129 / 176], [train main loss -1.486543], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 130 / 176], [train main loss -1.507507], [lr 0.007200] [batchtime 0.427]
[epoch 49], [iter 131 / 176], [train main loss -1.506878], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 132 / 176], [train main loss -1.514510], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 133 / 176], [train main loss -1.524100], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 134 / 176], [train main loss -1.525464], [lr 0.007200] [batchtime 0.426]
[epoch 49], [iter 135 / 176], [train main loss -1.511229], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 136 / 176], [train main loss -1.502026], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 137 / 176], [train main loss -1.513266], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 138 / 176], [train main loss -1.502009], [lr 0.007200] [batchtime 0.425]
[epoch 49], [iter 139 / 176], [train main loss -1.513945], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 140 / 176], [train main loss -1.537993], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 141 / 176], [train main loss -1.535167], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 142 / 176], [train main loss -1.512131], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 143 / 176], [train main loss -1.511532], [lr 0.007200] [batchtime 0.424]
[epoch 49], [iter 144 / 176], [train main loss -1.522778], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 145 / 176], [train main loss -1.528611], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 146 / 176], [train main loss -1.510670], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 147 / 176], [train main loss -1.526040], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 148 / 176], [train main loss -1.538940], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 149 / 176], [train main loss -1.535702], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 150 / 176], [train main loss -1.551670], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 151 / 176], [train main loss -1.539224], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 152 / 176], [train main loss -1.542998], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 153 / 176], [train main loss -1.538316], [lr 0.007200] [batchtime 0.423]
[epoch 49], [iter 154 / 176], [train main loss -1.546141], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 155 / 176], [train main loss -1.528168], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 156 / 176], [train main loss -1.513269], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 157 / 176], [train main loss -1.509128], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 158 / 176], [train main loss -1.500887], [lr 0.007200] [batchtime 0.422]
[epoch 49], [iter 159 / 176], [train main loss -1.501623], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 160 / 176], [train main loss -1.504117], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 161 / 176], [train main loss -1.507748], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 162 / 176], [train main loss -1.512573], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 163 / 176], [train main loss -1.524528], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 164 / 176], [train main loss -1.508426], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 165 / 176], [train main loss -1.505085], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 166 / 176], [train main loss -1.521319], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 167 / 176], [train main loss -1.530429], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 168 / 176], [train main loss -1.529107], [lr 0.007200] [batchtime 0.421]
[epoch 49], [iter 169 / 176], [train main loss -1.535693], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 170 / 176], [train main loss -1.542883], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 171 / 176], [train main loss -1.545061], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 172 / 176], [train main loss -1.547328], [lr 0.007200] [batchtime 0.42]
[epoch 49], [iter 173 / 176], [train main loss -1.550149], [lr 0.007200] [batchtime 0.419]
[epoch 49], [iter 174 / 176], [train main loss -1.543196], [lr 0.007200] [batchtime 0.419]
[epoch 49], [iter 175 / 176], [train main loss -1.537916], [lr 0.007200] [batchtime 0.419]
[epoch 49], [iter 176 / 176], [train main loss -1.544234], [lr 0.007200] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP    FN    Precision    Recall
----  -------------  --------  -----  -------  ----  -----------  --------
   0  road              93.28  34.87     0.04  0.03         0.96      0.97
   1  sidewalk          63.61   5.46     0.21  0.37         0.83      0.73
   2  building          82.53  24.64     0.08  0.13         0.93      0.88
   3  wall              10.97   0.09     5.53  2.59         0.15      0.28
   4  fence             10.31   0.15     7.73  0.98         0.11      0.51
   5  pole              30.31   0.45     1.50  0.80         0.40      0.55
   6  traffic light      4.81   0.01    18.93  0.84         0.05      0.54
   7  traffic sign       7.70   0.04    11.68  0.30         0.08      0.77
   8  vegetation        79.54  11.47     0.08  0.18         0.93      0.85
   9  terrain           32.15   0.31     1.39  0.72         0.42      0.58
  10  sky               91.99   3.74     0.04  0.05         0.96      0.95
  11  person            37.45   0.72     1.13  0.54         0.47      0.65
  12  rider              0.37   0.00   263.62  2.11         0.00      0.32
  13  car               81.02   6.57     0.08  0.16         0.93      0.86
  14  truck              0.33   0.00   298.39  1.08         0.00      0.48
  15  bus                4.55   0.00    17.19  3.77         0.05      0.21
  16  train              4.28   0.01    22.26  0.09         0.04      0.92
  17  motorcycle         0.08   0.00  1252.67  0.71         0.00      0.59
  18  bicycle           26.20   0.18     1.16  1.66         0.46      0.38
Mean: 34.82
-----------------------------------------------------------------------------------------------------------
this : [epoch 49], [val loss 0.38124], [acc 0.88721], [acc_cls 0.41000], [mean_iu 0.34815], [fwavacc 0.80687]
best : [epoch 49], [val loss 0.38124], [acc 0.88721], [acc_cls 0.41000], [mean_iu 0.34815], [fwavacc 0.80687]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 50], [iter 1 / 176], [train main loss -1.362362], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 2 / 176], [train main loss -2.932577], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 3 / 176], [train main loss -2.623818], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 4 / 176], [train main loss -2.291829], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 5 / 176], [train main loss -2.297537], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 6 / 176], [train main loss -2.071077], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 7 / 176], [train main loss -2.111891], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 8 / 176], [train main loss -2.258017], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 9 / 176], [train main loss -2.254484], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 10 / 176], [train main loss -2.270658], [lr 0.007143] [batchtime 0]
[epoch 50], [iter 11 / 176], [train main loss -2.525114], [lr 0.007143] [batchtime 0.369]
[epoch 50], [iter 12 / 176], [train main loss -2.286801], [lr 0.007143] [batchtime 0.38]
[epoch 50], [iter 13 / 176], [train main loss -2.235959], [lr 0.007143] [batchtime 0.384]
[epoch 50], [iter 14 / 176], [train main loss -2.226894], [lr 0.007143] [batchtime 0.387]
[epoch 50], [iter 15 / 176], [train main loss -2.107868], [lr 0.007143] [batchtime 0.389]
[epoch 50], [iter 16 / 176], [train main loss -2.064587], [lr 0.007143] [batchtime 0.389]
[epoch 50], [iter 17 / 176], [train main loss -2.007927], [lr 0.007143] [batchtime 0.39]
[epoch 50], [iter 18 / 176], [train main loss -1.904359], [lr 0.007143] [batchtime 0.39]
[epoch 50], [iter 19 / 176], [train main loss -1.878412], [lr 0.007143] [batchtime 0.39]
[epoch 50], [iter 20 / 176], [train main loss -2.010113], [lr 0.007143] [batchtime 0.391]
[epoch 50], [iter 21 / 176], [train main loss -1.943614], [lr 0.007143] [batchtime 0.392]
[epoch 50], [iter 22 / 176], [train main loss -2.011541], [lr 0.007143] [batchtime 0.392]
[epoch 50], [iter 23 / 176], [train main loss -1.955243], [lr 0.007143] [batchtime 0.392]
[epoch 50], [iter 24 / 176], [train main loss -2.018930], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 25 / 176], [train main loss -1.939910], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 26 / 176], [train main loss -1.973481], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 27 / 176], [train main loss -1.965620], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 28 / 176], [train main loss -1.894761], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 29 / 176], [train main loss -1.802527], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 30 / 176], [train main loss -1.820937], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 31 / 176], [train main loss -1.812042], [lr 0.007143] [batchtime 0.394]
[epoch 50], [iter 32 / 176], [train main loss -1.838604], [lr 0.007143] [batchtime 0.458]
[epoch 50], [iter 33 / 176], [train main loss -1.788241], [lr 0.007143] [batchtime 0.46]
[epoch 50], [iter 34 / 176], [train main loss -1.798580], [lr 0.007143] [batchtime 0.457]
[epoch 50], [iter 35 / 176], [train main loss -1.751058], [lr 0.007143] [batchtime 0.454]
[epoch 50], [iter 36 / 176], [train main loss -1.681086], [lr 0.007143] [batchtime 0.452]
[epoch 50], [iter 37 / 176], [train main loss -1.675454], [lr 0.007143] [batchtime 0.449]
[epoch 50], [iter 38 / 176], [train main loss -1.667401], [lr 0.007143] [batchtime 0.447]
[epoch 50], [iter 39 / 176], [train main loss -1.651862], [lr 0.007143] [batchtime 0.445]
[epoch 50], [iter 40 / 176], [train main loss -1.618818], [lr 0.007143] [batchtime 0.444]
[epoch 50], [iter 41 / 176], [train main loss -1.593877], [lr 0.007143] [batchtime 0.443]
[epoch 50], [iter 42 / 176], [train main loss -1.586204], [lr 0.007143] [batchtime 0.442]
[epoch 50], [iter 43 / 176], [train main loss -1.581970], [lr 0.007143] [batchtime 0.44]
[epoch 50], [iter 44 / 176], [train main loss -1.532064], [lr 0.007143] [batchtime 0.439]
[epoch 50], [iter 45 / 176], [train main loss -1.564871], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 46 / 176], [train main loss -1.577613], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 47 / 176], [train main loss -1.629238], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 48 / 176], [train main loss -1.594329], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 49 / 176], [train main loss -1.595753], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 50 / 176], [train main loss -1.525557], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 51 / 176], [train main loss -1.534215], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 52 / 176], [train main loss -1.568518], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 53 / 176], [train main loss -1.600103], [lr 0.007143] [batchtime 0.43]
[epoch 50], [iter 54 / 176], [train main loss -1.651805], [lr 0.007143] [batchtime 0.429]
[epoch 50], [iter 55 / 176], [train main loss -1.676063], [lr 0.007143] [batchtime 0.429]
[epoch 50], [iter 56 / 176], [train main loss -1.686422], [lr 0.007143] [batchtime 0.428]
[epoch 50], [iter 57 / 176], [train main loss -1.693228], [lr 0.007143] [batchtime 0.427]
[epoch 50], [iter 58 / 176], [train main loss -1.645173], [lr 0.007143] [batchtime 0.426]
[epoch 50], [iter 59 / 176], [train main loss -1.631100], [lr 0.007143] [batchtime 0.426]
[epoch 50], [iter 60 / 176], [train main loss -1.651904], [lr 0.007143] [batchtime 0.425]
[epoch 50], [iter 61 / 176], [train main loss -1.639257], [lr 0.007143] [batchtime 0.425]
[epoch 50], [iter 62 / 176], [train main loss -1.601138], [lr 0.007143] [batchtime 0.424]
[epoch 50], [iter 63 / 176], [train main loss -1.599713], [lr 0.007143] [batchtime 0.423]
[epoch 50], [iter 64 / 176], [train main loss -1.594036], [lr 0.007143] [batchtime 0.423]
[epoch 50], [iter 65 / 176], [train main loss -1.574426], [lr 0.007143] [batchtime 0.422]
[epoch 50], [iter 66 / 176], [train main loss -1.576971], [lr 0.007143] [batchtime 0.422]
[epoch 50], [iter 67 / 176], [train main loss -1.575672], [lr 0.007143] [batchtime 0.421]
[epoch 50], [iter 68 / 176], [train main loss -1.592023], [lr 0.007143] [batchtime 0.421]
[epoch 50], [iter 69 / 176], [train main loss -1.617724], [lr 0.007143] [batchtime 0.42]
[epoch 50], [iter 70 / 176], [train main loss -1.651788], [lr 0.007143] [batchtime 0.42]
[epoch 50], [iter 71 / 176], [train main loss -1.668762], [lr 0.007143] [batchtime 0.419]
[epoch 50], [iter 72 / 176], [train main loss -1.681376], [lr 0.007143] [batchtime 0.419]
[epoch 50], [iter 73 / 176], [train main loss -1.665558], [lr 0.007143] [batchtime 0.419]
[epoch 50], [iter 74 / 176], [train main loss -1.663010], [lr 0.007143] [batchtime 0.418]
[epoch 50], [iter 75 / 176], [train main loss -1.659783], [lr 0.007143] [batchtime 0.418]
[epoch 50], [iter 76 / 176], [train main loss -1.660188], [lr 0.007143] [batchtime 0.418]
[epoch 50], [iter 77 / 176], [train main loss -1.634250], [lr 0.007143] [batchtime 0.417]
[epoch 50], [iter 78 / 176], [train main loss -1.639595], [lr 0.007143] [batchtime 0.421]
[epoch 50], [iter 79 / 176], [train main loss -1.660168], [lr 0.007143] [batchtime 0.438]
[epoch 50], [iter 80 / 176], [train main loss -1.655449], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 81 / 176], [train main loss -1.617611], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 82 / 176], [train main loss -1.603545], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 83 / 176], [train main loss -1.635579], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 84 / 176], [train main loss -1.620247], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 85 / 176], [train main loss -1.616666], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 86 / 176], [train main loss -1.602935], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 87 / 176], [train main loss -1.604567], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 88 / 176], [train main loss -1.583366], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 89 / 176], [train main loss -1.575562], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 90 / 176], [train main loss -1.583162], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 91 / 176], [train main loss -1.593941], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 92 / 176], [train main loss -1.604737], [lr 0.007143] [batchtime 0.43]
[epoch 50], [iter 93 / 176], [train main loss -1.602543], [lr 0.007143] [batchtime 0.43]
[epoch 50], [iter 94 / 176], [train main loss -1.589535], [lr 0.007143] [batchtime 0.429]
[epoch 50], [iter 95 / 176], [train main loss -1.579988], [lr 0.007143] [batchtime 0.429]
[epoch 50], [iter 96 / 176], [train main loss -1.588629], [lr 0.007143] [batchtime 0.429]
[epoch 50], [iter 97 / 176], [train main loss -1.593518], [lr 0.007143] [batchtime 0.428]
[epoch 50], [iter 98 / 176], [train main loss -1.597603], [lr 0.007143] [batchtime 0.428]
[epoch 50], [iter 99 / 176], [train main loss -1.577727], [lr 0.007143] [batchtime 0.428]
[epoch 50], [iter 100 / 176], [train main loss -1.609798], [lr 0.007143] [batchtime 0.427]
[epoch 50], [iter 101 / 176], [train main loss -1.613887], [lr 0.007143] [batchtime 0.427]
[epoch 50], [iter 102 / 176], [train main loss -1.622157], [lr 0.007143] [batchtime 0.426]
[epoch 50], [iter 103 / 176], [train main loss -1.624709], [lr 0.007143] [batchtime 0.426]
[epoch 50], [iter 104 / 176], [train main loss -1.643239], [lr 0.007143] [batchtime 0.426]
[epoch 50], [iter 105 / 176], [train main loss -1.618498], [lr 0.007143] [batchtime 0.425]
[epoch 50], [iter 106 / 176], [train main loss -1.596219], [lr 0.007143] [batchtime 0.425]
[epoch 50], [iter 107 / 176], [train main loss -1.600564], [lr 0.007143] [batchtime 0.425]
[epoch 50], [iter 108 / 176], [train main loss -1.611011], [lr 0.007143] [batchtime 0.424]
[epoch 50], [iter 109 / 176], [train main loss -1.619143], [lr 0.007143] [batchtime 0.424]
[epoch 50], [iter 110 / 176], [train main loss -1.629741], [lr 0.007143] [batchtime 0.424]
[epoch 50], [iter 111 / 176], [train main loss -1.633676], [lr 0.007143] [batchtime 0.423]
[epoch 50], [iter 112 / 176], [train main loss -1.612140], [lr 0.007143] [batchtime 0.423]
[epoch 50], [iter 113 / 176], [train main loss -1.602742], [lr 0.007143] [batchtime 0.423]
[epoch 50], [iter 114 / 176], [train main loss -1.590414], [lr 0.007143] [batchtime 0.423]
[epoch 50], [iter 115 / 176], [train main loss -1.567883], [lr 0.007143] [batchtime 0.422]
[epoch 50], [iter 116 / 176], [train main loss -1.580645], [lr 0.007143] [batchtime 0.422]
[epoch 50], [iter 117 / 176], [train main loss -1.550594], [lr 0.007143] [batchtime 0.422]
[epoch 50], [iter 118 / 176], [train main loss -1.545456], [lr 0.007143] [batchtime 0.421]
[epoch 50], [iter 119 / 176], [train main loss -1.537837], [lr 0.007143] [batchtime 0.421]
[epoch 50], [iter 120 / 176], [train main loss -1.536954], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 121 / 176], [train main loss -1.544616], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 122 / 176], [train main loss -1.538911], [lr 0.007143] [batchtime 0.438]
[epoch 50], [iter 123 / 176], [train main loss -1.515742], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 124 / 176], [train main loss -1.502037], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 125 / 176], [train main loss -1.489722], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 126 / 176], [train main loss -1.490697], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 127 / 176], [train main loss -1.520742], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 128 / 176], [train main loss -1.531695], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 129 / 176], [train main loss -1.529329], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 130 / 176], [train main loss -1.531875], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 131 / 176], [train main loss -1.556562], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 132 / 176], [train main loss -1.555585], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 133 / 176], [train main loss -1.553398], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 134 / 176], [train main loss -1.578699], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 135 / 176], [train main loss -1.591418], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 136 / 176], [train main loss -1.590580], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 137 / 176], [train main loss -1.626639], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 138 / 176], [train main loss -1.625959], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 139 / 176], [train main loss -1.612705], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 140 / 176], [train main loss -1.579322], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 141 / 176], [train main loss -1.577877], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 142 / 176], [train main loss -1.606913], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 143 / 176], [train main loss -1.613329], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 144 / 176], [train main loss -1.622171], [lr 0.007143] [batchtime 0.43]
[epoch 50], [iter 145 / 176], [train main loss -1.626455], [lr 0.007143] [batchtime 0.43]
[epoch 50], [iter 146 / 176], [train main loss -1.628162], [lr 0.007143] [batchtime 0.431]
[epoch 50], [iter 147 / 176], [train main loss -1.645985], [lr 0.007143] [batchtime 0.438]
[epoch 50], [iter 148 / 176], [train main loss -1.642072], [lr 0.007143] [batchtime 0.438]
[epoch 50], [iter 149 / 176], [train main loss -1.640993], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 150 / 176], [train main loss -1.638947], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 151 / 176], [train main loss -1.645895], [lr 0.007143] [batchtime 0.437]
[epoch 50], [iter 152 / 176], [train main loss -1.646228], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 153 / 176], [train main loss -1.632434], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 154 / 176], [train main loss -1.620116], [lr 0.007143] [batchtime 0.436]
[epoch 50], [iter 155 / 176], [train main loss -1.620397], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 156 / 176], [train main loss -1.652752], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 157 / 176], [train main loss -1.648443], [lr 0.007143] [batchtime 0.435]
[epoch 50], [iter 158 / 176], [train main loss -1.653734], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 159 / 176], [train main loss -1.640093], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 160 / 176], [train main loss -1.643341], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 161 / 176], [train main loss -1.644692], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 162 / 176], [train main loss -1.652407], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 163 / 176], [train main loss -1.658163], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 164 / 176], [train main loss -1.654838], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 165 / 176], [train main loss -1.648493], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 166 / 176], [train main loss -1.638193], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 167 / 176], [train main loss -1.638906], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 168 / 176], [train main loss -1.644394], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 169 / 176], [train main loss -1.644369], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 170 / 176], [train main loss -1.664202], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 171 / 176], [train main loss -1.669696], [lr 0.007143] [batchtime 0.434]
[epoch 50], [iter 172 / 176], [train main loss -1.659980], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 173 / 176], [train main loss -1.657426], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 174 / 176], [train main loss -1.674595], [lr 0.007143] [batchtime 0.433]
[epoch 50], [iter 175 / 176], [train main loss -1.678196], [lr 0.007143] [batchtime 0.432]
[epoch 50], [iter 176 / 176], [train main loss -1.697961], [lr 0.007143] [batchtime 0.432]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP     FN    Precision    Recall
----  -------------  --------  -----  ------  -----  -----------  --------
   0  road              93.31  35.28    0.03   0.04         0.97      0.96
   1  sidewalk          62.98   5.21    0.26   0.32         0.79      0.76
   2  building          82.44  24.50    0.08   0.13         0.92      0.89
   3  wall               8.82   0.07    7.39   2.95         0.12      0.25
   4  fence              7.55   0.10   11.52   0.72         0.08      0.58
   5  pole              30.38   0.44    1.61   0.69         0.38      0.59
   6  traffic light      3.10   0.00   30.44   0.77         0.03      0.56
   7  traffic sign       8.51   0.05   10.36   0.39         0.09      0.72
   8  vegetation        79.47  11.50    0.07   0.18         0.93      0.84
   9  terrain           34.93   0.33    1.25   0.61         0.44      0.62
  10  sky               92.58   3.74    0.03   0.05         0.97      0.96
  11  person            39.30   0.77    0.98   0.56         0.50      0.64
  12  rider              0.87   0.00  111.60   1.94         0.01      0.34
  13  car               79.96   6.55    0.08   0.17         0.93      0.85
  14  truck              0.10   0.00  945.50  10.89         0.00      0.08
  15  bus                4.38   0.01   15.23   6.62         0.06      0.13
  16  train              3.85   0.01   24.72   0.22         0.04      0.82
  17  motorcycle         0.24   0.00  408.67   0.41         0.00      0.71
  18  bicycle           26.99   0.19    1.06   1.64         0.49      0.38
Mean: 34.72
-----------------------------------------------------------------------------------------------------------
this : [epoch 50], [val loss 0.37733], [acc 0.88745], [acc_cls 0.40810], [mean_iu 0.34724], [fwavacc 0.80579]
best : [epoch 49], [val loss 0.38124], [acc 0.88721], [acc_cls 0.41000], [mean_iu 0.34815], [fwavacc 0.80687]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 51], [iter 1 / 176], [train main loss 0.978645], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 2 / 176], [train main loss 0.467089], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 3 / 176], [train main loss -0.440649], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 4 / 176], [train main loss -0.731022], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 5 / 176], [train main loss -1.368312], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 6 / 176], [train main loss -2.008048], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 7 / 176], [train main loss -1.944075], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 8 / 176], [train main loss -1.849890], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 9 / 176], [train main loss -1.862974], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 10 / 176], [train main loss -1.872831], [lr 0.007086] [batchtime 0]
[epoch 51], [iter 11 / 176], [train main loss -1.945299], [lr 0.007086] [batchtime 0.362]
[epoch 51], [iter 12 / 176], [train main loss -2.193383], [lr 0.007086] [batchtime 0.378]
[epoch 51], [iter 13 / 176], [train main loss -2.195896], [lr 0.007086] [batchtime 0.386]
[epoch 51], [iter 14 / 176], [train main loss -2.089313], [lr 0.007086] [batchtime 0.391]
[epoch 51], [iter 15 / 176], [train main loss -2.152705], [lr 0.007086] [batchtime 0.393]
[epoch 51], [iter 16 / 176], [train main loss -1.967391], [lr 0.007086] [batchtime 0.393]
[epoch 51], [iter 17 / 176], [train main loss -1.926432], [lr 0.007086] [batchtime 0.393]
[epoch 51], [iter 18 / 176], [train main loss -1.971781], [lr 0.007086] [batchtime 0.394]
[epoch 51], [iter 19 / 176], [train main loss -1.955000], [lr 0.007086] [batchtime 0.395]
[epoch 51], [iter 20 / 176], [train main loss -1.881011], [lr 0.007086] [batchtime 0.395]
[epoch 51], [iter 21 / 176], [train main loss -1.927630], [lr 0.007086] [batchtime 0.396]
[epoch 51], [iter 22 / 176], [train main loss -1.757830], [lr 0.007086] [batchtime 0.396]
[epoch 51], [iter 23 / 176], [train main loss -1.807655], [lr 0.007086] [batchtime 0.396]
[epoch 51], [iter 24 / 176], [train main loss -1.942996], [lr 0.007086] [batchtime 0.397]
[epoch 51], [iter 25 / 176], [train main loss -2.128579], [lr 0.007086] [batchtime 0.397]
[epoch 51], [iter 26 / 176], [train main loss -1.999681], [lr 0.007086] [batchtime 0.397]
[epoch 51], [iter 27 / 176], [train main loss -2.004213], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 28 / 176], [train main loss -2.081201], [lr 0.007086] [batchtime 0.425]
[epoch 51], [iter 29 / 176], [train main loss -2.050828], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 30 / 176], [train main loss -2.086379], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 31 / 176], [train main loss -2.085328], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 32 / 176], [train main loss -2.007262], [lr 0.007086] [batchtime 0.418]
[epoch 51], [iter 33 / 176], [train main loss -2.047712], [lr 0.007086] [batchtime 0.417]
[epoch 51], [iter 34 / 176], [train main loss -2.019693], [lr 0.007086] [batchtime 0.417]
[epoch 51], [iter 35 / 176], [train main loss -2.138063], [lr 0.007086] [batchtime 0.416]
[epoch 51], [iter 36 / 176], [train main loss -2.112592], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 37 / 176], [train main loss -2.025749], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 38 / 176], [train main loss -1.980322], [lr 0.007086] [batchtime 0.414]
[epoch 51], [iter 39 / 176], [train main loss -2.047842], [lr 0.007086] [batchtime 0.413]
[epoch 51], [iter 40 / 176], [train main loss -2.052463], [lr 0.007086] [batchtime 0.413]
[epoch 51], [iter 41 / 176], [train main loss -2.081538], [lr 0.007086] [batchtime 0.413]
[epoch 51], [iter 42 / 176], [train main loss -2.053975], [lr 0.007086] [batchtime 0.412]
[epoch 51], [iter 43 / 176], [train main loss -2.032490], [lr 0.007086] [batchtime 0.412]
[epoch 51], [iter 44 / 176], [train main loss -2.045028], [lr 0.007086] [batchtime 0.411]
[epoch 51], [iter 45 / 176], [train main loss -2.033061], [lr 0.007086] [batchtime 0.411]
[epoch 51], [iter 46 / 176], [train main loss -1.967817], [lr 0.007086] [batchtime 0.41]
[epoch 51], [iter 47 / 176], [train main loss -1.941696], [lr 0.007086] [batchtime 0.41]
[epoch 51], [iter 48 / 176], [train main loss -1.974189], [lr 0.007086] [batchtime 0.41]
[epoch 51], [iter 49 / 176], [train main loss -1.990922], [lr 0.007086] [batchtime 0.41]
[epoch 51], [iter 50 / 176], [train main loss -1.989554], [lr 0.007086] [batchtime 0.409]
[epoch 51], [iter 51 / 176], [train main loss -1.993435], [lr 0.007086] [batchtime 0.409]
[epoch 51], [iter 52 / 176], [train main loss -1.930693], [lr 0.007086] [batchtime 0.409]
[epoch 51], [iter 53 / 176], [train main loss -1.938139], [lr 0.007086] [batchtime 0.408]
[epoch 51], [iter 54 / 176], [train main loss -1.925908], [lr 0.007086] [batchtime 0.408]
[epoch 51], [iter 55 / 176], [train main loss -1.875586], [lr 0.007086] [batchtime 0.408]
[epoch 51], [iter 56 / 176], [train main loss -1.873905], [lr 0.007086] [batchtime 0.408]
[epoch 51], [iter 57 / 176], [train main loss -1.876722], [lr 0.007086] [batchtime 0.407]
[epoch 51], [iter 58 / 176], [train main loss -1.894644], [lr 0.007086] [batchtime 0.407]
[epoch 51], [iter 59 / 176], [train main loss -1.929866], [lr 0.007086] [batchtime 0.407]
[epoch 51], [iter 60 / 176], [train main loss -1.916640], [lr 0.007086] [batchtime 0.407]
[epoch 51], [iter 61 / 176], [train main loss -1.900505], [lr 0.007086] [batchtime 0.407]
[epoch 51], [iter 62 / 176], [train main loss -1.900133], [lr 0.007086] [batchtime 0.406]
[epoch 51], [iter 63 / 176], [train main loss -1.909575], [lr 0.007086] [batchtime 0.406]
[epoch 51], [iter 64 / 176], [train main loss -1.885231], [lr 0.007086] [batchtime 0.406]
[epoch 51], [iter 65 / 176], [train main loss -1.888241], [lr 0.007086] [batchtime 0.406]
[epoch 51], [iter 66 / 176], [train main loss -1.916787], [lr 0.007086] [batchtime 0.406]
[epoch 51], [iter 67 / 176], [train main loss -1.908970], [lr 0.007086] [batchtime 0.406]
[epoch 51], [iter 68 / 176], [train main loss -1.896430], [lr 0.007086] [batchtime 0.405]
[epoch 51], [iter 69 / 176], [train main loss -1.903526], [lr 0.007086] [batchtime 0.405]
[epoch 51], [iter 70 / 176], [train main loss -1.926038], [lr 0.007086] [batchtime 0.405]
[epoch 51], [iter 71 / 176], [train main loss -1.911633], [lr 0.007086] [batchtime 0.405]
[epoch 51], [iter 72 / 176], [train main loss -1.920788], [lr 0.007086] [batchtime 0.405]
[epoch 51], [iter 73 / 176], [train main loss -1.923656], [lr 0.007086] [batchtime 0.405]
[epoch 51], [iter 74 / 176], [train main loss -1.951285], [lr 0.007086] [batchtime 0.404]
[epoch 51], [iter 75 / 176], [train main loss -1.931431], [lr 0.007086] [batchtime 0.404]
[epoch 51], [iter 76 / 176], [train main loss -1.930352], [lr 0.007086] [batchtime 0.407]
[epoch 51], [iter 77 / 176], [train main loss -1.903801], [lr 0.007086] [batchtime 0.426]
[epoch 51], [iter 78 / 176], [train main loss -1.893760], [lr 0.007086] [batchtime 0.426]
[epoch 51], [iter 79 / 176], [train main loss -1.871814], [lr 0.007086] [batchtime 0.425]
[epoch 51], [iter 80 / 176], [train main loss -1.868439], [lr 0.007086] [batchtime 0.424]
[epoch 51], [iter 81 / 176], [train main loss -1.853220], [lr 0.007086] [batchtime 0.424]
[epoch 51], [iter 82 / 176], [train main loss -1.837968], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 83 / 176], [train main loss -1.851567], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 84 / 176], [train main loss -1.871329], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 85 / 176], [train main loss -1.852049], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 86 / 176], [train main loss -1.895302], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 87 / 176], [train main loss -1.886864], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 88 / 176], [train main loss -1.858358], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 89 / 176], [train main loss -1.836079], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 90 / 176], [train main loss -1.824923], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 91 / 176], [train main loss -1.834050], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 92 / 176], [train main loss -1.854499], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 93 / 176], [train main loss -1.877313], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 94 / 176], [train main loss -1.863093], [lr 0.007086] [batchtime 0.419]
[epoch 51], [iter 95 / 176], [train main loss -1.853709], [lr 0.007086] [batchtime 0.419]
[epoch 51], [iter 96 / 176], [train main loss -1.898442], [lr 0.007086] [batchtime 0.419]
[epoch 51], [iter 97 / 176], [train main loss -1.908354], [lr 0.007086] [batchtime 0.418]
[epoch 51], [iter 98 / 176], [train main loss -1.894811], [lr 0.007086] [batchtime 0.418]
[epoch 51], [iter 99 / 176], [train main loss -1.855017], [lr 0.007086] [batchtime 0.418]
[epoch 51], [iter 100 / 176], [train main loss -1.852031], [lr 0.007086] [batchtime 0.418]
[epoch 51], [iter 101 / 176], [train main loss -1.863050], [lr 0.007086] [batchtime 0.417]
[epoch 51], [iter 102 / 176], [train main loss -1.841091], [lr 0.007086] [batchtime 0.417]
[epoch 51], [iter 103 / 176], [train main loss -1.848856], [lr 0.007086] [batchtime 0.417]
[epoch 51], [iter 104 / 176], [train main loss -1.847783], [lr 0.007086] [batchtime 0.417]
[epoch 51], [iter 105 / 176], [train main loss -1.867681], [lr 0.007086] [batchtime 0.416]
[epoch 51], [iter 106 / 176], [train main loss -1.900933], [lr 0.007086] [batchtime 0.416]
[epoch 51], [iter 107 / 176], [train main loss -1.883729], [lr 0.007086] [batchtime 0.416]
[epoch 51], [iter 108 / 176], [train main loss -1.884120], [lr 0.007086] [batchtime 0.416]
[epoch 51], [iter 109 / 176], [train main loss -1.871005], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 110 / 176], [train main loss -1.875832], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 111 / 176], [train main loss -1.887378], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 112 / 176], [train main loss -1.876378], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 113 / 176], [train main loss -1.884068], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 114 / 176], [train main loss -1.868244], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 115 / 176], [train main loss -1.860373], [lr 0.007086] [batchtime 0.414]
[epoch 51], [iter 116 / 176], [train main loss -1.865360], [lr 0.007086] [batchtime 0.414]
[epoch 51], [iter 117 / 176], [train main loss -1.864498], [lr 0.007086] [batchtime 0.414]
[epoch 51], [iter 118 / 176], [train main loss -1.874570], [lr 0.007086] [batchtime 0.414]
[epoch 51], [iter 119 / 176], [train main loss -1.857508], [lr 0.007086] [batchtime 0.414]
[epoch 51], [iter 120 / 176], [train main loss -1.859236], [lr 0.007086] [batchtime 0.413]
[epoch 51], [iter 121 / 176], [train main loss -1.854487], [lr 0.007086] [batchtime 0.413]
[epoch 51], [iter 122 / 176], [train main loss -1.853119], [lr 0.007086] [batchtime 0.413]
[epoch 51], [iter 123 / 176], [train main loss -1.842258], [lr 0.007086] [batchtime 0.415]
[epoch 51], [iter 124 / 176], [train main loss -1.829716], [lr 0.007086] [batchtime 0.427]
[epoch 51], [iter 125 / 176], [train main loss -1.829227], [lr 0.007086] [batchtime 0.427]
[epoch 51], [iter 126 / 176], [train main loss -1.828246], [lr 0.007086] [batchtime 0.426]
[epoch 51], [iter 127 / 176], [train main loss -1.823110], [lr 0.007086] [batchtime 0.426]
[epoch 51], [iter 128 / 176], [train main loss -1.814202], [lr 0.007086] [batchtime 0.426]
[epoch 51], [iter 129 / 176], [train main loss -1.814321], [lr 0.007086] [batchtime 0.425]
[epoch 51], [iter 130 / 176], [train main loss -1.803367], [lr 0.007086] [batchtime 0.425]
[epoch 51], [iter 131 / 176], [train main loss -1.805325], [lr 0.007086] [batchtime 0.425]
[epoch 51], [iter 132 / 176], [train main loss -1.804764], [lr 0.007086] [batchtime 0.425]
[epoch 51], [iter 133 / 176], [train main loss -1.819499], [lr 0.007086] [batchtime 0.424]
[epoch 51], [iter 134 / 176], [train main loss -1.809026], [lr 0.007086] [batchtime 0.424]
[epoch 51], [iter 135 / 176], [train main loss -1.810431], [lr 0.007086] [batchtime 0.424]
[epoch 51], [iter 136 / 176], [train main loss -1.789541], [lr 0.007086] [batchtime 0.424]
[epoch 51], [iter 137 / 176], [train main loss -1.774187], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 138 / 176], [train main loss -1.778635], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 139 / 176], [train main loss -1.794881], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 140 / 176], [train main loss -1.789929], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 141 / 176], [train main loss -1.775412], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 142 / 176], [train main loss -1.751849], [lr 0.007086] [batchtime 0.423]
[epoch 51], [iter 143 / 176], [train main loss -1.744875], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 144 / 176], [train main loss -1.734694], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 145 / 176], [train main loss -1.734041], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 146 / 176], [train main loss -1.733492], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 147 / 176], [train main loss -1.740135], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 148 / 176], [train main loss -1.740226], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 149 / 176], [train main loss -1.747624], [lr 0.007086] [batchtime 0.422]
[epoch 51], [iter 150 / 176], [train main loss -1.761106], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 151 / 176], [train main loss -1.761406], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 152 / 176], [train main loss -1.788669], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 153 / 176], [train main loss -1.773335], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 154 / 176], [train main loss -1.772060], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 155 / 176], [train main loss -1.749942], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 156 / 176], [train main loss -1.752530], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 157 / 176], [train main loss -1.771872], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 158 / 176], [train main loss -1.795488], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 159 / 176], [train main loss -1.799500], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 160 / 176], [train main loss -1.817693], [lr 0.007086] [batchtime 0.42]
[epoch 51], [iter 161 / 176], [train main loss -1.813782], [lr 0.007086] [batchtime 0.421]
[epoch 51], [iter 162 / 176], [train main loss -1.800773], [lr 0.007086] [batchtime 0.429]
[epoch 51], [iter 163 / 176], [train main loss -1.808530], [lr 0.007086] [batchtime 0.429]
[epoch 51], [iter 164 / 176], [train main loss -1.812072], [lr 0.007086] [batchtime 0.428]
[epoch 51], [iter 165 / 176], [train main loss -1.811501], [lr 0.007086] [batchtime 0.428]
[epoch 51], [iter 166 / 176], [train main loss -1.820782], [lr 0.007086] [batchtime 0.428]
[epoch 51], [iter 167 / 176], [train main loss -1.799830], [lr 0.007086] [batchtime 0.43]
[epoch 51], [iter 168 / 176], [train main loss -1.810491], [lr 0.007086] [batchtime 0.429]
[epoch 51], [iter 169 / 176], [train main loss -1.824487], [lr 0.007086] [batchtime 0.429]
[epoch 51], [iter 170 / 176], [train main loss -1.824077], [lr 0.007086] [batchtime 0.429]
[epoch 51], [iter 171 / 176], [train main loss -1.825516], [lr 0.007086] [batchtime 0.428]
[epoch 51], [iter 172 / 176], [train main loss -1.829675], [lr 0.007086] [batchtime 0.428]
[epoch 51], [iter 173 / 176], [train main loss -1.823620], [lr 0.007086] [batchtime 0.428]
[epoch 51], [iter 174 / 176], [train main loss -1.821202], [lr 0.007086] [batchtime 0.427]
[epoch 51], [iter 175 / 176], [train main loss -1.811106], [lr 0.007086] [batchtime 0.427]
[epoch 51], [iter 176 / 176], [train main loss -1.809372], [lr 0.007086] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.39  35.21    0.03  0.04         0.97      0.96
   1  sidewalk          64.03   5.10    0.29  0.27         0.77      0.79
   2  building          83.41  24.74    0.07  0.12         0.93      0.89
   3  wall              12.93   0.11    4.17  2.56         0.19      0.28
   4  fence             13.36   0.20    5.44  1.04         0.16      0.49
   5  pole              31.33   0.46    1.46  0.73         0.41      0.58
   6  traffic light      3.61   0.01   26.17  0.53         0.04      0.65
   7  traffic sign       8.29   0.05   10.68  0.39         0.09      0.72
   8  vegetation        80.37  11.49    0.08  0.17         0.93      0.86
   9  terrain           37.53   0.35    1.09  0.58         0.48      0.63
  10  sky               92.61   3.76    0.03  0.05         0.97      0.95
  11  person            39.62   0.80    0.92  0.60         0.52      0.63
  12  rider              0.58   0.00  170.92  1.85         0.01      0.35
  13  car               81.00   6.57    0.08  0.16         0.93      0.86
  14  truck              0.23   0.00  433.09  2.97         0.00      0.25
  15  bus                7.40   0.01    5.85  6.65         0.15      0.13
  16  train              3.79   0.01   25.27  0.13         0.04      0.88
  17  motorcycle         0.19   0.00  530.78  0.66         0.00      0.60
  18  bicycle           26.44   0.20    0.97  1.81         0.51      0.36
Mean: 35.79
-----------------------------------------------------------------------------------------------------------
this : [epoch 51], [val loss 0.36888], [acc 0.89064], [acc_cls 0.42510], [mean_iu 0.35794], [fwavacc 0.81255]
best : [epoch 51], [val loss 0.36888], [acc 0.89064], [acc_cls 0.42510], [mean_iu 0.35794], [fwavacc 0.81255]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 52], [iter 1 / 176], [train main loss -0.518448], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 2 / 176], [train main loss 0.617892], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 3 / 176], [train main loss 1.257734], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 4 / 176], [train main loss 0.743922], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 5 / 176], [train main loss 0.026160], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 6 / 176], [train main loss 0.193470], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 7 / 176], [train main loss 0.101200], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 8 / 176], [train main loss 0.612008], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 9 / 176], [train main loss 0.585992], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 10 / 176], [train main loss 0.355825], [lr 0.007029] [batchtime 0]
[epoch 52], [iter 11 / 176], [train main loss 0.145884], [lr 0.007029] [batchtime 0.372]
[epoch 52], [iter 12 / 176], [train main loss 0.040408], [lr 0.007029] [batchtime 0.376]
[epoch 52], [iter 13 / 176], [train main loss -0.427822], [lr 0.007029] [batchtime 0.382]
[epoch 52], [iter 14 / 176], [train main loss -0.376598], [lr 0.007029] [batchtime 0.385]
[epoch 52], [iter 15 / 176], [train main loss -0.470965], [lr 0.007029] [batchtime 0.386]
[epoch 52], [iter 16 / 176], [train main loss -0.549012], [lr 0.007029] [batchtime 0.387]
[epoch 52], [iter 17 / 176], [train main loss -0.622278], [lr 0.007029] [batchtime 0.389]
[epoch 52], [iter 18 / 176], [train main loss -0.843108], [lr 0.007029] [batchtime 0.389]
[epoch 52], [iter 19 / 176], [train main loss -1.014860], [lr 0.007029] [batchtime 0.389]
[epoch 52], [iter 20 / 176], [train main loss -1.052159], [lr 0.007029] [batchtime 0.39]
[epoch 52], [iter 21 / 176], [train main loss -1.038282], [lr 0.007029] [batchtime 0.39]
[epoch 52], [iter 22 / 176], [train main loss -1.063532], [lr 0.007029] [batchtime 0.391]
[epoch 52], [iter 23 / 176], [train main loss -1.187258], [lr 0.007029] [batchtime 0.391]
[epoch 52], [iter 24 / 176], [train main loss -1.267630], [lr 0.007029] [batchtime 0.398]
[epoch 52], [iter 25 / 176], [train main loss -1.237787], [lr 0.007029] [batchtime 0.4]
[epoch 52], [iter 26 / 176], [train main loss -1.354568], [lr 0.007029] [batchtime 0.4]
[epoch 52], [iter 27 / 176], [train main loss -1.344047], [lr 0.007029] [batchtime 0.4]
[epoch 52], [iter 28 / 176], [train main loss -1.343235], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 29 / 176], [train main loss -1.350016], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 30 / 176], [train main loss -1.410862], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 31 / 176], [train main loss -1.380920], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 32 / 176], [train main loss -1.402920], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 33 / 176], [train main loss -1.477972], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 34 / 176], [train main loss -1.468898], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 35 / 176], [train main loss -1.465845], [lr 0.007029] [batchtime 0.399]
[epoch 52], [iter 36 / 176], [train main loss -1.516032], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 37 / 176], [train main loss -1.525974], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 38 / 176], [train main loss -1.554163], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 39 / 176], [train main loss -1.532604], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 40 / 176], [train main loss -1.526839], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 41 / 176], [train main loss -1.578300], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 42 / 176], [train main loss -1.573969], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 43 / 176], [train main loss -1.596230], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 44 / 176], [train main loss -1.574541], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 45 / 176], [train main loss -1.521195], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 46 / 176], [train main loss -1.525108], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 47 / 176], [train main loss -1.492715], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 48 / 176], [train main loss -1.503537], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 49 / 176], [train main loss -1.440486], [lr 0.007029] [batchtime 0.415]
[epoch 52], [iter 50 / 176], [train main loss -1.493473], [lr 0.007029] [batchtime 0.414]
[epoch 52], [iter 51 / 176], [train main loss -1.520693], [lr 0.007029] [batchtime 0.413]
[epoch 52], [iter 52 / 176], [train main loss -1.537630], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 53 / 176], [train main loss -1.540289], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 54 / 176], [train main loss -1.505666], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 55 / 176], [train main loss -1.514111], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 56 / 176], [train main loss -1.516035], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 57 / 176], [train main loss -1.559808], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 58 / 176], [train main loss -1.549588], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 59 / 176], [train main loss -1.560825], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 60 / 176], [train main loss -1.538048], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 61 / 176], [train main loss -1.575633], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 62 / 176], [train main loss -1.567992], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 63 / 176], [train main loss -1.583132], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 64 / 176], [train main loss -1.570458], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 65 / 176], [train main loss -1.531202], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 66 / 176], [train main loss -1.537026], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 67 / 176], [train main loss -1.573048], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 68 / 176], [train main loss -1.571490], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 69 / 176], [train main loss -1.563734], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 70 / 176], [train main loss -1.550037], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 71 / 176], [train main loss -1.573340], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 72 / 176], [train main loss -1.579697], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 73 / 176], [train main loss -1.601638], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 74 / 176], [train main loss -1.634523], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 75 / 176], [train main loss -1.654714], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 76 / 176], [train main loss -1.644826], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 77 / 176], [train main loss -1.625497], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 78 / 176], [train main loss -1.628887], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 79 / 176], [train main loss -1.616915], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 80 / 176], [train main loss -1.629412], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 81 / 176], [train main loss -1.604901], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 82 / 176], [train main loss -1.628267], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 83 / 176], [train main loss -1.623190], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 84 / 176], [train main loss -1.580145], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 85 / 176], [train main loss -1.576855], [lr 0.007029] [batchtime 0.406]
[epoch 52], [iter 86 / 176], [train main loss -1.603884], [lr 0.007029] [batchtime 0.405]
[epoch 52], [iter 87 / 176], [train main loss -1.590511], [lr 0.007029] [batchtime 0.405]
[epoch 52], [iter 88 / 176], [train main loss -1.604166], [lr 0.007029] [batchtime 0.405]
[epoch 52], [iter 89 / 176], [train main loss -1.587606], [lr 0.007029] [batchtime 0.405]
[epoch 52], [iter 90 / 176], [train main loss -1.555190], [lr 0.007029] [batchtime 0.405]
[epoch 52], [iter 91 / 176], [train main loss -1.561956], [lr 0.007029] [batchtime 0.405]
[epoch 52], [iter 92 / 176], [train main loss -1.526216], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 93 / 176], [train main loss -1.527864], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 94 / 176], [train main loss -1.516459], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 95 / 176], [train main loss -1.500713], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 96 / 176], [train main loss -1.511746], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 97 / 176], [train main loss -1.519968], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 98 / 176], [train main loss -1.530086], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 99 / 176], [train main loss -1.524172], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 100 / 176], [train main loss -1.562828], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 101 / 176], [train main loss -1.594684], [lr 0.007029] [batchtime 0.412]
[epoch 52], [iter 102 / 176], [train main loss -1.599591], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 103 / 176], [train main loss -1.632579], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 104 / 176], [train main loss -1.634486], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 105 / 176], [train main loss -1.656843], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 106 / 176], [train main loss -1.639787], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 107 / 176], [train main loss -1.646672], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 108 / 176], [train main loss -1.655567], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 109 / 176], [train main loss -1.652332], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 110 / 176], [train main loss -1.650520], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 111 / 176], [train main loss -1.680446], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 112 / 176], [train main loss -1.671963], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 113 / 176], [train main loss -1.650548], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 114 / 176], [train main loss -1.654113], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 115 / 176], [train main loss -1.661739], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 116 / 176], [train main loss -1.657467], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 117 / 176], [train main loss -1.657289], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 118 / 176], [train main loss -1.668502], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 119 / 176], [train main loss -1.682528], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 120 / 176], [train main loss -1.678651], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 121 / 176], [train main loss -1.672916], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 122 / 176], [train main loss -1.699705], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 123 / 176], [train main loss -1.704205], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 124 / 176], [train main loss -1.705405], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 125 / 176], [train main loss -1.714231], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 126 / 176], [train main loss -1.735206], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 127 / 176], [train main loss -1.750304], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 128 / 176], [train main loss -1.753877], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 129 / 176], [train main loss -1.758548], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 130 / 176], [train main loss -1.748985], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 131 / 176], [train main loss -1.752023], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 132 / 176], [train main loss -1.739697], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 133 / 176], [train main loss -1.727254], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 134 / 176], [train main loss -1.730444], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 135 / 176], [train main loss -1.737101], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 136 / 176], [train main loss -1.724016], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 137 / 176], [train main loss -1.722007], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 138 / 176], [train main loss -1.733462], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 139 / 176], [train main loss -1.732490], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 140 / 176], [train main loss -1.728186], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 141 / 176], [train main loss -1.748877], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 142 / 176], [train main loss -1.747745], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 143 / 176], [train main loss -1.759784], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 144 / 176], [train main loss -1.756641], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 145 / 176], [train main loss -1.760865], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 146 / 176], [train main loss -1.762761], [lr 0.007029] [batchtime 0.407]
[epoch 52], [iter 147 / 176], [train main loss -1.767470], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 148 / 176], [train main loss -1.770054], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 149 / 176], [train main loss -1.786430], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 150 / 176], [train main loss -1.773486], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 151 / 176], [train main loss -1.776097], [lr 0.007029] [batchtime 0.411]
[epoch 52], [iter 152 / 176], [train main loss -1.773876], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 153 / 176], [train main loss -1.762653], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 154 / 176], [train main loss -1.745789], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 155 / 176], [train main loss -1.748028], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 156 / 176], [train main loss -1.757769], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 157 / 176], [train main loss -1.743925], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 158 / 176], [train main loss -1.743660], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 159 / 176], [train main loss -1.736923], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 160 / 176], [train main loss -1.730028], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 161 / 176], [train main loss -1.723665], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 162 / 176], [train main loss -1.730012], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 163 / 176], [train main loss -1.730825], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 164 / 176], [train main loss -1.727283], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 165 / 176], [train main loss -1.724632], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 166 / 176], [train main loss -1.719948], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 167 / 176], [train main loss -1.713751], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 168 / 176], [train main loss -1.706171], [lr 0.007029] [batchtime 0.41]
[epoch 52], [iter 169 / 176], [train main loss -1.687589], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 170 / 176], [train main loss -1.671651], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 171 / 176], [train main loss -1.665159], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 172 / 176], [train main loss -1.665560], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 173 / 176], [train main loss -1.641819], [lr 0.007029] [batchtime 0.409]
[epoch 52], [iter 174 / 176], [train main loss -1.647266], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 175 / 176], [train main loss -1.642122], [lr 0.007029] [batchtime 0.408]
[epoch 52], [iter 176 / 176], [train main loss -1.644572], [lr 0.007029] [batchtime 0.408]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP    FN    Precision    Recall
----  -------------  --------  -----  -------  ----  -----------  --------
   0  road              92.39  35.66     0.02  0.06         0.98      0.94
   1  sidewalk          57.64   4.56     0.44  0.29         0.69      0.77
   2  building          82.67  24.85     0.07  0.14         0.94      0.88
   3  wall              10.05   0.08     6.61  2.34         0.13      0.30
   4  fence             13.17   0.19     5.77  0.82         0.15      0.55
   5  pole              30.35   0.43     1.67  0.63         0.37      0.61
   6  traffic light      3.58   0.01    26.34  0.60         0.04      0.62
   7  traffic sign       9.74   0.06     8.90  0.37         0.10      0.73
   8  vegetation        80.52  11.24     0.10  0.14         0.91      0.88
   9  terrain           34.10   0.32     1.27  0.66         0.44      0.60
  10  sky               92.44   3.74     0.03  0.05         0.97      0.95
  11  person            41.21   0.85     0.80  0.63         0.56      0.61
  12  rider              0.86   0.00   113.79  1.51         0.01      0.40
  13  car               81.02   6.48     0.09  0.14         0.92      0.87
  14  truck              0.04   0.00  2391.53  0.46         0.00      0.68
  15  bus                9.52   0.02     4.05  5.45         0.20      0.16
  16  train              8.80   0.02    10.19  0.18         0.09      0.85
  17  motorcycle         0.13   0.00   795.56  1.35         0.00      0.43
  18  bicycle           26.04   0.13     1.90  0.94         0.34      0.52
Mean: 35.49
-----------------------------------------------------------------------------------------------------------
this : [epoch 52], [val loss 0.38842], [acc 0.88647], [acc_cls 0.41218], [mean_iu 0.35488], [fwavacc 0.80274]
best : [epoch 51], [val loss 0.36888], [acc 0.89064], [acc_cls 0.42510], [mean_iu 0.35794], [fwavacc 0.81255]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 53], [iter 1 / 176], [train main loss -3.455852], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 2 / 176], [train main loss -1.907074], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 3 / 176], [train main loss -1.920226], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 4 / 176], [train main loss -2.248067], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 5 / 176], [train main loss -2.107694], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 6 / 176], [train main loss -1.792310], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 7 / 176], [train main loss -1.616190], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 8 / 176], [train main loss -1.689614], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 9 / 176], [train main loss -1.580313], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 10 / 176], [train main loss -1.564718], [lr 0.006971] [batchtime 0]
[epoch 53], [iter 11 / 176], [train main loss -1.720012], [lr 0.006971] [batchtime 0.368]
[epoch 53], [iter 12 / 176], [train main loss -1.875841], [lr 0.006971] [batchtime 0.382]
[epoch 53], [iter 13 / 176], [train main loss -1.750668], [lr 0.006971] [batchtime 0.386]
[epoch 53], [iter 14 / 176], [train main loss -1.506260], [lr 0.006971] [batchtime 0.387]
[epoch 53], [iter 15 / 176], [train main loss -1.458417], [lr 0.006971] [batchtime 0.39]
[epoch 53], [iter 16 / 176], [train main loss -1.599887], [lr 0.006971] [batchtime 0.392]
[epoch 53], [iter 17 / 176], [train main loss -1.704417], [lr 0.006971] [batchtime 0.392]
[epoch 53], [iter 18 / 176], [train main loss -1.818265], [lr 0.006971] [batchtime 0.392]
[epoch 53], [iter 19 / 176], [train main loss -1.730314], [lr 0.006971] [batchtime 0.392]
[epoch 53], [iter 20 / 176], [train main loss -1.756572], [lr 0.006971] [batchtime 0.393]
[epoch 53], [iter 21 / 176], [train main loss -1.732559], [lr 0.006971] [batchtime 0.394]
[epoch 53], [iter 22 / 176], [train main loss -1.630887], [lr 0.006971] [batchtime 0.394]
[epoch 53], [iter 23 / 176], [train main loss -1.700485], [lr 0.006971] [batchtime 0.395]
[epoch 53], [iter 24 / 176], [train main loss -1.729153], [lr 0.006971] [batchtime 0.396]
[epoch 53], [iter 25 / 176], [train main loss -1.706085], [lr 0.006971] [batchtime 0.396]
[epoch 53], [iter 26 / 176], [train main loss -1.657009], [lr 0.006971] [batchtime 0.396]
[epoch 53], [iter 27 / 176], [train main loss -1.577043], [lr 0.006971] [batchtime 0.396]
[epoch 53], [iter 28 / 176], [train main loss -1.540090], [lr 0.006971] [batchtime 0.397]
[epoch 53], [iter 29 / 176], [train main loss -1.512746], [lr 0.006971] [batchtime 0.397]
[epoch 53], [iter 30 / 176], [train main loss -1.545546], [lr 0.006971] [batchtime 0.405]
[epoch 53], [iter 31 / 176], [train main loss -1.583473], [lr 0.006971] [batchtime 0.473]
[epoch 53], [iter 32 / 176], [train main loss -1.602410], [lr 0.006971] [batchtime 0.468]
[epoch 53], [iter 33 / 176], [train main loss -1.643121], [lr 0.006971] [batchtime 0.464]
[epoch 53], [iter 34 / 176], [train main loss -1.560510], [lr 0.006971] [batchtime 0.461]
[epoch 53], [iter 35 / 176], [train main loss -1.633705], [lr 0.006971] [batchtime 0.459]
[epoch 53], [iter 36 / 176], [train main loss -1.601958], [lr 0.006971] [batchtime 0.456]
[epoch 53], [iter 37 / 176], [train main loss -1.576387], [lr 0.006971] [batchtime 0.454]
[epoch 53], [iter 38 / 176], [train main loss -1.604898], [lr 0.006971] [batchtime 0.452]
[epoch 53], [iter 39 / 176], [train main loss -1.580763], [lr 0.006971] [batchtime 0.45]
[epoch 53], [iter 40 / 176], [train main loss -1.609170], [lr 0.006971] [batchtime 0.448]
[epoch 53], [iter 41 / 176], [train main loss -1.607210], [lr 0.006971] [batchtime 0.447]
[epoch 53], [iter 42 / 176], [train main loss -1.617756], [lr 0.006971] [batchtime 0.446]
[epoch 53], [iter 43 / 176], [train main loss -1.638389], [lr 0.006971] [batchtime 0.444]
[epoch 53], [iter 44 / 176], [train main loss -1.694311], [lr 0.006971] [batchtime 0.443]
[epoch 53], [iter 45 / 176], [train main loss -1.695156], [lr 0.006971] [batchtime 0.441]
[epoch 53], [iter 46 / 176], [train main loss -1.677284], [lr 0.006971] [batchtime 0.44]
[epoch 53], [iter 47 / 176], [train main loss -1.713017], [lr 0.006971] [batchtime 0.439]
[epoch 53], [iter 48 / 176], [train main loss -1.677704], [lr 0.006971] [batchtime 0.438]
[epoch 53], [iter 49 / 176], [train main loss -1.730654], [lr 0.006971] [batchtime 0.437]
[epoch 53], [iter 50 / 176], [train main loss -1.767247], [lr 0.006971] [batchtime 0.436]
[epoch 53], [iter 51 / 176], [train main loss -1.779593], [lr 0.006971] [batchtime 0.435]
[epoch 53], [iter 52 / 176], [train main loss -1.836145], [lr 0.006971] [batchtime 0.434]
[epoch 53], [iter 53 / 176], [train main loss -1.869210], [lr 0.006971] [batchtime 0.433]
[epoch 53], [iter 54 / 176], [train main loss -1.848421], [lr 0.006971] [batchtime 0.432]
[epoch 53], [iter 55 / 176], [train main loss -1.805422], [lr 0.006971] [batchtime 0.431]
[epoch 53], [iter 56 / 176], [train main loss -1.836797], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 57 / 176], [train main loss -1.854045], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 58 / 176], [train main loss -1.810181], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 59 / 176], [train main loss -1.790044], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 60 / 176], [train main loss -1.772005], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 61 / 176], [train main loss -1.775783], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 62 / 176], [train main loss -1.775217], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 63 / 176], [train main loss -1.779503], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 64 / 176], [train main loss -1.792014], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 65 / 176], [train main loss -1.811129], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 66 / 176], [train main loss -1.836322], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 67 / 176], [train main loss -1.802303], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 68 / 176], [train main loss -1.778545], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 69 / 176], [train main loss -1.784068], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 70 / 176], [train main loss -1.810184], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 71 / 176], [train main loss -1.809522], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 72 / 176], [train main loss -1.804945], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 73 / 176], [train main loss -1.797615], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 74 / 176], [train main loss -1.792698], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 75 / 176], [train main loss -1.796064], [lr 0.006971] [batchtime 0.42]
[epoch 53], [iter 76 / 176], [train main loss -1.794993], [lr 0.006971] [batchtime 0.42]
[epoch 53], [iter 77 / 176], [train main loss -1.811886], [lr 0.006971] [batchtime 0.437]
[epoch 53], [iter 78 / 176], [train main loss -1.810661], [lr 0.006971] [batchtime 0.439]
[epoch 53], [iter 79 / 176], [train main loss -1.777120], [lr 0.006971] [batchtime 0.438]
[epoch 53], [iter 80 / 176], [train main loss -1.768890], [lr 0.006971] [batchtime 0.438]
[epoch 53], [iter 81 / 176], [train main loss -1.741861], [lr 0.006971] [batchtime 0.437]
[epoch 53], [iter 82 / 176], [train main loss -1.746706], [lr 0.006971] [batchtime 0.436]
[epoch 53], [iter 83 / 176], [train main loss -1.744780], [lr 0.006971] [batchtime 0.436]
[epoch 53], [iter 84 / 176], [train main loss -1.743870], [lr 0.006971] [batchtime 0.435]
[epoch 53], [iter 85 / 176], [train main loss -1.749806], [lr 0.006971] [batchtime 0.435]
[epoch 53], [iter 86 / 176], [train main loss -1.743136], [lr 0.006971] [batchtime 0.434]
[epoch 53], [iter 87 / 176], [train main loss -1.739368], [lr 0.006971] [batchtime 0.434]
[epoch 53], [iter 88 / 176], [train main loss -1.738873], [lr 0.006971] [batchtime 0.433]
[epoch 53], [iter 89 / 176], [train main loss -1.726710], [lr 0.006971] [batchtime 0.433]
[epoch 53], [iter 90 / 176], [train main loss -1.733843], [lr 0.006971] [batchtime 0.432]
[epoch 53], [iter 91 / 176], [train main loss -1.728983], [lr 0.006971] [batchtime 0.432]
[epoch 53], [iter 92 / 176], [train main loss -1.735643], [lr 0.006971] [batchtime 0.431]
[epoch 53], [iter 93 / 176], [train main loss -1.744257], [lr 0.006971] [batchtime 0.431]
[epoch 53], [iter 94 / 176], [train main loss -1.733549], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 95 / 176], [train main loss -1.736083], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 96 / 176], [train main loss -1.728251], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 97 / 176], [train main loss -1.752824], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 98 / 176], [train main loss -1.778725], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 99 / 176], [train main loss -1.790115], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 100 / 176], [train main loss -1.810924], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 101 / 176], [train main loss -1.808776], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 102 / 176], [train main loss -1.767872], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 103 / 176], [train main loss -1.782095], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 104 / 176], [train main loss -1.772651], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 105 / 176], [train main loss -1.793445], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 106 / 176], [train main loss -1.801082], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 107 / 176], [train main loss -1.795092], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 108 / 176], [train main loss -1.800284], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 109 / 176], [train main loss -1.804266], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 110 / 176], [train main loss -1.792288], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 111 / 176], [train main loss -1.797127], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 112 / 176], [train main loss -1.779595], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 113 / 176], [train main loss -1.781738], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 114 / 176], [train main loss -1.782703], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 115 / 176], [train main loss -1.792406], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 116 / 176], [train main loss -1.822695], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 117 / 176], [train main loss -1.826063], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 118 / 176], [train main loss -1.826717], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 119 / 176], [train main loss -1.841262], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 120 / 176], [train main loss -1.812101], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 121 / 176], [train main loss -1.798301], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 122 / 176], [train main loss -1.786089], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 123 / 176], [train main loss -1.779083], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 124 / 176], [train main loss -1.779613], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 125 / 176], [train main loss -1.777717], [lr 0.006971] [batchtime 0.433]
[epoch 53], [iter 126 / 176], [train main loss -1.793908], [lr 0.006971] [batchtime 0.433]
[epoch 53], [iter 127 / 176], [train main loss -1.802209], [lr 0.006971] [batchtime 0.432]
[epoch 53], [iter 128 / 176], [train main loss -1.809248], [lr 0.006971] [batchtime 0.432]
[epoch 53], [iter 129 / 176], [train main loss -1.790031], [lr 0.006971] [batchtime 0.432]
[epoch 53], [iter 130 / 176], [train main loss -1.809116], [lr 0.006971] [batchtime 0.431]
[epoch 53], [iter 131 / 176], [train main loss -1.818198], [lr 0.006971] [batchtime 0.431]
[epoch 53], [iter 132 / 176], [train main loss -1.829034], [lr 0.006971] [batchtime 0.431]
[epoch 53], [iter 133 / 176], [train main loss -1.831662], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 134 / 176], [train main loss -1.822360], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 135 / 176], [train main loss -1.814406], [lr 0.006971] [batchtime 0.43]
[epoch 53], [iter 136 / 176], [train main loss -1.812007], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 137 / 176], [train main loss -1.819295], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 138 / 176], [train main loss -1.827575], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 139 / 176], [train main loss -1.828641], [lr 0.006971] [batchtime 0.429]
[epoch 53], [iter 140 / 176], [train main loss -1.826767], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 141 / 176], [train main loss -1.820162], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 142 / 176], [train main loss -1.824797], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 143 / 176], [train main loss -1.797468], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 144 / 176], [train main loss -1.800980], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 145 / 176], [train main loss -1.805193], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 146 / 176], [train main loss -1.794669], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 147 / 176], [train main loss -1.794125], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 148 / 176], [train main loss -1.816799], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 149 / 176], [train main loss -1.809763], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 150 / 176], [train main loss -1.804176], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 151 / 176], [train main loss -1.798578], [lr 0.006971] [batchtime 0.426]
[epoch 53], [iter 152 / 176], [train main loss -1.803306], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 153 / 176], [train main loss -1.794472], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 154 / 176], [train main loss -1.791724], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 155 / 176], [train main loss -1.808241], [lr 0.006971] [batchtime 0.425]
[epoch 53], [iter 156 / 176], [train main loss -1.824436], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 157 / 176], [train main loss -1.841799], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 158 / 176], [train main loss -1.839466], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 159 / 176], [train main loss -1.840375], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 160 / 176], [train main loss -1.820750], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 161 / 176], [train main loss -1.823803], [lr 0.006971] [batchtime 0.424]
[epoch 53], [iter 162 / 176], [train main loss -1.835473], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 163 / 176], [train main loss -1.829976], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 164 / 176], [train main loss -1.818206], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 165 / 176], [train main loss -1.803950], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 166 / 176], [train main loss -1.796786], [lr 0.006971] [batchtime 0.423]
[epoch 53], [iter 167 / 176], [train main loss -1.794311], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 168 / 176], [train main loss -1.791260], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 169 / 176], [train main loss -1.787151], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 170 / 176], [train main loss -1.769799], [lr 0.006971] [batchtime 0.422]
[epoch 53], [iter 171 / 176], [train main loss -1.774261], [lr 0.006971] [batchtime 0.421]
[epoch 53], [iter 172 / 176], [train main loss -1.765985], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 173 / 176], [train main loss -1.758740], [lr 0.006971] [batchtime 0.428]
[epoch 53], [iter 174 / 176], [train main loss -1.758086], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 175 / 176], [train main loss -1.757739], [lr 0.006971] [batchtime 0.427]
[epoch 53], [iter 176 / 176], [train main loss -1.740407], [lr 0.006971] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.03  35.78    0.02  0.07         0.98      0.93
   1  sidewalk          54.88   4.11    0.60  0.22         0.62      0.82
   2  building          82.79  25.07    0.06  0.15         0.94      0.87
   3  wall               9.19   0.07    7.98  1.90         0.11      0.35
   4  fence             11.13   0.15    7.35  0.64         0.12      0.61
   5  pole              29.96   0.42    1.73  0.61         0.37      0.62
   6  traffic light      3.34   0.01   28.32  0.62         0.03      0.62
   7  traffic sign       5.46   0.03   17.08  0.22         0.06      0.82
   8  vegetation        80.93  11.46    0.08  0.16         0.93      0.86
   9  terrain           36.93   0.34    1.16  0.55         0.46      0.65
  10  sky               93.05   3.71    0.04  0.03         0.96      0.97
  11  person            39.32   0.73    1.09  0.46         0.48      0.69
  12  rider              1.58   0.00   60.18  2.09         0.02      0.32
  13  car               81.18   6.52    0.08  0.15         0.92      0.87
  14  truck              0.54   0.00  183.06  0.61         0.01      0.62
  15  bus               10.02   0.02    3.59  5.40         0.22      0.16
  16  train              8.05   0.01   11.20  0.22         0.08      0.82
  17  motorcycle         0.56   0.00  176.31  0.78         0.01      0.56
  18  bicycle           28.18   0.19    1.07  1.48         0.48      0.40
Mean: 35.22
-----------------------------------------------------------------------------------------------------------
this : [epoch 53], [val loss 0.40159], [acc 0.88619], [acc_cls 0.41041], [mean_iu 0.35217], [fwavacc 0.80018]
best : [epoch 51], [val loss 0.36888], [acc 0.89064], [acc_cls 0.42510], [mean_iu 0.35794], [fwavacc 0.81255]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 54], [iter 1 / 176], [train main loss -3.283333], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 2 / 176], [train main loss -3.577798], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 3 / 176], [train main loss -3.624715], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 4 / 176], [train main loss -2.531506], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 5 / 176], [train main loss -2.612020], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 6 / 176], [train main loss -2.206821], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 7 / 176], [train main loss -2.162744], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 8 / 176], [train main loss -2.401967], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 9 / 176], [train main loss -2.577942], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 10 / 176], [train main loss -2.407838], [lr 0.006914] [batchtime 0]
[epoch 54], [iter 11 / 176], [train main loss -2.583820], [lr 0.006914] [batchtime 0.377]
[epoch 54], [iter 12 / 176], [train main loss -2.741281], [lr 0.006914] [batchtime 0.387]
[epoch 54], [iter 13 / 176], [train main loss -2.806619], [lr 0.006914] [batchtime 0.387]
[epoch 54], [iter 14 / 176], [train main loss -2.804497], [lr 0.006914] [batchtime 0.388]
[epoch 54], [iter 15 / 176], [train main loss -2.586919], [lr 0.006914] [batchtime 0.391]
[epoch 54], [iter 16 / 176], [train main loss -2.496145], [lr 0.006914] [batchtime 0.391]
[epoch 54], [iter 17 / 176], [train main loss -2.501461], [lr 0.006914] [batchtime 0.391]
[epoch 54], [iter 18 / 176], [train main loss -2.440162], [lr 0.006914] [batchtime 0.391]
[epoch 54], [iter 19 / 176], [train main loss -2.365535], [lr 0.006914] [batchtime 0.391]
[epoch 54], [iter 20 / 176], [train main loss -2.280060], [lr 0.006914] [batchtime 0.392]
[epoch 54], [iter 21 / 176], [train main loss -2.111514], [lr 0.006914] [batchtime 0.391]
[epoch 54], [iter 22 / 176], [train main loss -1.995477], [lr 0.006914] [batchtime 0.392]
[epoch 54], [iter 23 / 176], [train main loss -2.118079], [lr 0.006914] [batchtime 0.393]
[epoch 54], [iter 24 / 176], [train main loss -2.165015], [lr 0.006914] [batchtime 0.393]
[epoch 54], [iter 25 / 176], [train main loss -2.112643], [lr 0.006914] [batchtime 0.393]
[epoch 54], [iter 26 / 176], [train main loss -2.137457], [lr 0.006914] [batchtime 0.393]
[epoch 54], [iter 27 / 176], [train main loss -2.231153], [lr 0.006914] [batchtime 0.394]
[epoch 54], [iter 28 / 176], [train main loss -2.229689], [lr 0.006914] [batchtime 0.394]
[epoch 54], [iter 29 / 176], [train main loss -2.251621], [lr 0.006914] [batchtime 0.395]
[epoch 54], [iter 30 / 176], [train main loss -2.250059], [lr 0.006914] [batchtime 0.395]
[epoch 54], [iter 31 / 176], [train main loss -2.209734], [lr 0.006914] [batchtime 0.395]
[epoch 54], [iter 32 / 176], [train main loss -2.225188], [lr 0.006914] [batchtime 0.395]
[epoch 54], [iter 33 / 176], [train main loss -2.269347], [lr 0.006914] [batchtime 0.452]
[epoch 54], [iter 34 / 176], [train main loss -2.281152], [lr 0.006914] [batchtime 0.459]
[epoch 54], [iter 35 / 176], [train main loss -2.305756], [lr 0.006914] [batchtime 0.456]
[epoch 54], [iter 36 / 176], [train main loss -2.238699], [lr 0.006914] [batchtime 0.454]
[epoch 54], [iter 37 / 176], [train main loss -2.199062], [lr 0.006914] [batchtime 0.451]
[epoch 54], [iter 38 / 176], [train main loss -2.138643], [lr 0.006914] [batchtime 0.45]
[epoch 54], [iter 39 / 176], [train main loss -2.125670], [lr 0.006914] [batchtime 0.448]
[epoch 54], [iter 40 / 176], [train main loss -2.119896], [lr 0.006914] [batchtime 0.446]
[epoch 54], [iter 41 / 176], [train main loss -2.082330], [lr 0.006914] [batchtime 0.444]
[epoch 54], [iter 42 / 176], [train main loss -1.971617], [lr 0.006914] [batchtime 0.443]
[epoch 54], [iter 43 / 176], [train main loss -1.963531], [lr 0.006914] [batchtime 0.441]
[epoch 54], [iter 44 / 176], [train main loss -1.981731], [lr 0.006914] [batchtime 0.44]
[epoch 54], [iter 45 / 176], [train main loss -1.924712], [lr 0.006914] [batchtime 0.439]
[epoch 54], [iter 46 / 176], [train main loss -1.893264], [lr 0.006914] [batchtime 0.438]
[epoch 54], [iter 47 / 176], [train main loss -1.900700], [lr 0.006914] [batchtime 0.437]
[epoch 54], [iter 48 / 176], [train main loss -1.922559], [lr 0.006914] [batchtime 0.436]
[epoch 54], [iter 49 / 176], [train main loss -1.948577], [lr 0.006914] [batchtime 0.435]
[epoch 54], [iter 50 / 176], [train main loss -1.880879], [lr 0.006914] [batchtime 0.434]
[epoch 54], [iter 51 / 176], [train main loss -1.879125], [lr 0.006914] [batchtime 0.433]
[epoch 54], [iter 52 / 176], [train main loss -1.892147], [lr 0.006914] [batchtime 0.432]
[epoch 54], [iter 53 / 176], [train main loss -1.852418], [lr 0.006914] [batchtime 0.431]
[epoch 54], [iter 54 / 176], [train main loss -1.877729], [lr 0.006914] [batchtime 0.431]
[epoch 54], [iter 55 / 176], [train main loss -1.875175], [lr 0.006914] [batchtime 0.43]
[epoch 54], [iter 56 / 176], [train main loss -1.850255], [lr 0.006914] [batchtime 0.429]
[epoch 54], [iter 57 / 176], [train main loss -1.855800], [lr 0.006914] [batchtime 0.429]
[epoch 54], [iter 58 / 176], [train main loss -1.860157], [lr 0.006914] [batchtime 0.428]
[epoch 54], [iter 59 / 176], [train main loss -1.828758], [lr 0.006914] [batchtime 0.427]
[epoch 54], [iter 60 / 176], [train main loss -1.868266], [lr 0.006914] [batchtime 0.427]
[epoch 54], [iter 61 / 176], [train main loss -1.899112], [lr 0.006914] [batchtime 0.426]
[epoch 54], [iter 62 / 176], [train main loss -1.926009], [lr 0.006914] [batchtime 0.425]
[epoch 54], [iter 63 / 176], [train main loss -1.955745], [lr 0.006914] [batchtime 0.425]
[epoch 54], [iter 64 / 176], [train main loss -1.962680], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 65 / 176], [train main loss -1.995248], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 66 / 176], [train main loss -1.960634], [lr 0.006914] [batchtime 0.426]
[epoch 54], [iter 67 / 176], [train main loss -1.975444], [lr 0.006914] [batchtime 0.425]
[epoch 54], [iter 68 / 176], [train main loss -1.995954], [lr 0.006914] [batchtime 0.425]
[epoch 54], [iter 69 / 176], [train main loss -1.953954], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 70 / 176], [train main loss -1.954833], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 71 / 176], [train main loss -1.983799], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 72 / 176], [train main loss -1.968287], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 73 / 176], [train main loss -1.937622], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 74 / 176], [train main loss -1.936262], [lr 0.006914] [batchtime 0.422]
[epoch 54], [iter 75 / 176], [train main loss -1.930051], [lr 0.006914] [batchtime 0.422]
[epoch 54], [iter 76 / 176], [train main loss -1.926005], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 77 / 176], [train main loss -1.952753], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 78 / 176], [train main loss -1.941662], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 79 / 176], [train main loss -1.923717], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 80 / 176], [train main loss -1.918346], [lr 0.006914] [batchtime 0.426]
[epoch 54], [iter 81 / 176], [train main loss -1.875651], [lr 0.006914] [batchtime 0.425]
[epoch 54], [iter 82 / 176], [train main loss -1.895991], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 83 / 176], [train main loss -1.927194], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 84 / 176], [train main loss -1.931943], [lr 0.006914] [batchtime 0.424]
[epoch 54], [iter 85 / 176], [train main loss -1.935844], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 86 / 176], [train main loss -1.935262], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 87 / 176], [train main loss -1.904942], [lr 0.006914] [batchtime 0.423]
[epoch 54], [iter 88 / 176], [train main loss -1.919568], [lr 0.006914] [batchtime 0.422]
[epoch 54], [iter 89 / 176], [train main loss -1.940329], [lr 0.006914] [batchtime 0.422]
[epoch 54], [iter 90 / 176], [train main loss -1.907596], [lr 0.006914] [batchtime 0.422]
[epoch 54], [iter 91 / 176], [train main loss -1.907751], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 92 / 176], [train main loss -1.908613], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 93 / 176], [train main loss -1.917091], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 94 / 176], [train main loss -1.922646], [lr 0.006914] [batchtime 0.421]
[epoch 54], [iter 95 / 176], [train main loss -1.926330], [lr 0.006914] [batchtime 0.42]
[epoch 54], [iter 96 / 176], [train main loss -1.924065], [lr 0.006914] [batchtime 0.42]
[epoch 54], [iter 97 / 176], [train main loss -1.916738], [lr 0.006914] [batchtime 0.42]
[epoch 54], [iter 98 / 176], [train main loss -1.932117], [lr 0.006914] [batchtime 0.419]
[epoch 54], [iter 99 / 176], [train main loss -1.941518], [lr 0.006914] [batchtime 0.419]
[epoch 54], [iter 100 / 176], [train main loss -1.946983], [lr 0.006914] [batchtime 0.419]
[epoch 54], [iter 101 / 176], [train main loss -1.963831], [lr 0.006914] [batchtime 0.418]
[epoch 54], [iter 102 / 176], [train main loss -1.980914], [lr 0.006914] [batchtime 0.418]
[epoch 54], [iter 103 / 176], [train main loss -1.989649], [lr 0.006914] [batchtime 0.418]
[epoch 54], [iter 104 / 176], [train main loss -1.977140], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 105 / 176], [train main loss -1.939257], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 106 / 176], [train main loss -1.920856], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 107 / 176], [train main loss -1.914743], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 108 / 176], [train main loss -1.902705], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 109 / 176], [train main loss -1.891019], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 110 / 176], [train main loss -1.891945], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 111 / 176], [train main loss -1.880533], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 112 / 176], [train main loss -1.881789], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 113 / 176], [train main loss -1.884789], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 114 / 176], [train main loss -1.883321], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 115 / 176], [train main loss -1.888819], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 116 / 176], [train main loss -1.891475], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 117 / 176], [train main loss -1.874677], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 118 / 176], [train main loss -1.881391], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 119 / 176], [train main loss -1.871695], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 120 / 176], [train main loss -1.885511], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 121 / 176], [train main loss -1.873898], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 122 / 176], [train main loss -1.863715], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 123 / 176], [train main loss -1.857189], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 124 / 176], [train main loss -1.876141], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 125 / 176], [train main loss -1.896922], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 126 / 176], [train main loss -1.908223], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 127 / 176], [train main loss -1.902155], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 128 / 176], [train main loss -1.909137], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 129 / 176], [train main loss -1.890942], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 130 / 176], [train main loss -1.879008], [lr 0.006914] [batchtime 0.418]
[epoch 54], [iter 131 / 176], [train main loss -1.869193], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 132 / 176], [train main loss -1.878524], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 133 / 176], [train main loss -1.875252], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 134 / 176], [train main loss -1.869675], [lr 0.006914] [batchtime 0.417]
[epoch 54], [iter 135 / 176], [train main loss -1.874477], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 136 / 176], [train main loss -1.884880], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 137 / 176], [train main loss -1.868514], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 138 / 176], [train main loss -1.863014], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 139 / 176], [train main loss -1.879363], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 140 / 176], [train main loss -1.879252], [lr 0.006914] [batchtime 0.416]
[epoch 54], [iter 141 / 176], [train main loss -1.868456], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 142 / 176], [train main loss -1.849999], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 143 / 176], [train main loss -1.846446], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 144 / 176], [train main loss -1.837638], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 145 / 176], [train main loss -1.839845], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 146 / 176], [train main loss -1.823891], [lr 0.006914] [batchtime 0.415]
[epoch 54], [iter 147 / 176], [train main loss -1.794326], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 148 / 176], [train main loss -1.784384], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 149 / 176], [train main loss -1.790584], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 150 / 176], [train main loss -1.776202], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 151 / 176], [train main loss -1.777930], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 152 / 176], [train main loss -1.778061], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 153 / 176], [train main loss -1.773595], [lr 0.006914] [batchtime 0.414]
[epoch 54], [iter 154 / 176], [train main loss -1.789180], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 155 / 176], [train main loss -1.803698], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 156 / 176], [train main loss -1.794569], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 157 / 176], [train main loss -1.806256], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 158 / 176], [train main loss -1.822441], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 159 / 176], [train main loss -1.807064], [lr 0.006914] [batchtime 0.413]
[epoch 54], [iter 160 / 176], [train main loss -1.811744], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 161 / 176], [train main loss -1.817764], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 162 / 176], [train main loss -1.828720], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 163 / 176], [train main loss -1.824110], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 164 / 176], [train main loss -1.839106], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 165 / 176], [train main loss -1.819669], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 166 / 176], [train main loss -1.816224], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 167 / 176], [train main loss -1.828368], [lr 0.006914] [batchtime 0.412]
[epoch 54], [iter 168 / 176], [train main loss -1.830244], [lr 0.006914] [batchtime 0.411]
[epoch 54], [iter 169 / 176], [train main loss -1.829678], [lr 0.006914] [batchtime 0.411]
[epoch 54], [iter 170 / 176], [train main loss -1.833998], [lr 0.006914] [batchtime 0.411]
[epoch 54], [iter 171 / 176], [train main loss -1.833488], [lr 0.006914] [batchtime 0.411]
[epoch 54], [iter 172 / 176], [train main loss -1.823367], [lr 0.006914] [batchtime 0.411]
[epoch 54], [iter 173 / 176], [train main loss -1.816435], [lr 0.006914] [batchtime 0.41]
[epoch 54], [iter 174 / 176], [train main loss -1.807897], [lr 0.006914] [batchtime 0.41]
[epoch 54], [iter 175 / 176], [train main loss -1.807980], [lr 0.006914] [batchtime 0.41]
[epoch 54], [iter 176 / 176], [train main loss -1.810838], [lr 0.006914] [batchtime 0.41]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP       FP    FN    Precision    Recall
----  -------------  --------  -----  -------  ----  -----------  --------
   0  road              93.05  35.48     0.02  0.05         0.98      0.95
   1  sidewalk          60.90   4.72     0.39  0.25         0.72      0.80
   2  building          83.45  24.62     0.08  0.12         0.93      0.89
   3  wall              13.02   0.11     4.34  2.35         0.19      0.30
   4  fence             15.59   0.24     4.35  1.07         0.19      0.48
   5  pole              31.14   0.44     1.58  0.64         0.39      0.61
   6  traffic light      3.57   0.01    26.44  0.57         0.04      0.64
   7  traffic sign       8.86   0.05    10.02  0.27         0.09      0.79
   8  vegetation        79.92  11.56     0.07  0.18         0.93      0.85
   9  terrain           37.06   0.37     0.97  0.73         0.51      0.58
  10  sky               92.95   3.70     0.05  0.03         0.96      0.97
  11  person            41.02   0.80     0.91  0.53         0.52      0.65
  12  rider              0.69   0.00   141.41  2.03         0.01      0.33
  13  car               81.54   6.61     0.07  0.16         0.93      0.86
  14  truck              0.03   0.00  2902.27  0.22         0.00      0.82
  15  bus               12.30   0.02     2.94  4.19         0.25      0.19
  16  train             14.23   0.03     5.83  0.20         0.15      0.84
  17  motorcycle         0.43   0.00   231.29  0.41         0.00      0.71
  18  bicycle           28.33   0.20     0.93  1.60         0.52      0.38
Mean: 36.74
-----------------------------------------------------------------------------------------------------------
this : [epoch 54], [val loss 0.37078], [acc 0.88969], [acc_cls 0.43663], [mean_iu 0.36741], [fwavacc 0.81009]
best : [epoch 54], [val loss 0.37078], [acc 0.88969], [acc_cls 0.43663], [mean_iu 0.36741], [fwavacc 0.81009]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 55], [iter 1 / 176], [train main loss -1.658782], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 2 / 176], [train main loss -2.770801], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 3 / 176], [train main loss -2.665769], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 4 / 176], [train main loss -2.520128], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 5 / 176], [train main loss -2.593473], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 6 / 176], [train main loss -2.495220], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 7 / 176], [train main loss -2.266152], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 8 / 176], [train main loss -2.010921], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 9 / 176], [train main loss -1.849701], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 10 / 176], [train main loss -1.880112], [lr 0.006857] [batchtime 0]
[epoch 55], [iter 11 / 176], [train main loss -2.101764], [lr 0.006857] [batchtime 0.361]
[epoch 55], [iter 12 / 176], [train main loss -2.228317], [lr 0.006857] [batchtime 0.382]
[epoch 55], [iter 13 / 176], [train main loss -2.139271], [lr 0.006857] [batchtime 0.386]
[epoch 55], [iter 14 / 176], [train main loss -2.127427], [lr 0.006857] [batchtime 0.391]
[epoch 55], [iter 15 / 176], [train main loss -2.097390], [lr 0.006857] [batchtime 0.392]
[epoch 55], [iter 16 / 176], [train main loss -2.051136], [lr 0.006857] [batchtime 0.394]
[epoch 55], [iter 17 / 176], [train main loss -2.209421], [lr 0.006857] [batchtime 0.394]
[epoch 55], [iter 18 / 176], [train main loss -2.047484], [lr 0.006857] [batchtime 0.396]
[epoch 55], [iter 19 / 176], [train main loss -2.116119], [lr 0.006857] [batchtime 0.396]
[epoch 55], [iter 20 / 176], [train main loss -2.093754], [lr 0.006857] [batchtime 0.396]
[epoch 55], [iter 21 / 176], [train main loss -2.106825], [lr 0.006857] [batchtime 0.396]
[epoch 55], [iter 22 / 176], [train main loss -2.188638], [lr 0.006857] [batchtime 0.397]
[epoch 55], [iter 23 / 176], [train main loss -2.217417], [lr 0.006857] [batchtime 0.398]
[epoch 55], [iter 24 / 176], [train main loss -2.284485], [lr 0.006857] [batchtime 0.399]
[epoch 55], [iter 25 / 176], [train main loss -2.263243], [lr 0.006857] [batchtime 0.399]
[epoch 55], [iter 26 / 176], [train main loss -2.283435], [lr 0.006857] [batchtime 0.399]
[epoch 55], [iter 27 / 176], [train main loss -2.220389], [lr 0.006857] [batchtime 0.399]
[epoch 55], [iter 28 / 176], [train main loss -2.250735], [lr 0.006857] [batchtime 0.399]
[epoch 55], [iter 29 / 176], [train main loss -2.223920], [lr 0.006857] [batchtime 0.398]
[epoch 55], [iter 30 / 176], [train main loss -2.201280], [lr 0.006857] [batchtime 0.398]
[epoch 55], [iter 31 / 176], [train main loss -2.119859], [lr 0.006857] [batchtime 0.398]
[epoch 55], [iter 32 / 176], [train main loss -2.144016], [lr 0.006857] [batchtime 0.406]
[epoch 55], [iter 33 / 176], [train main loss -2.076622], [lr 0.006857] [batchtime 0.462]
[epoch 55], [iter 34 / 176], [train main loss -2.074374], [lr 0.006857] [batchtime 0.459]
[epoch 55], [iter 35 / 176], [train main loss -2.116133], [lr 0.006857] [batchtime 0.456]
[epoch 55], [iter 36 / 176], [train main loss -2.134233], [lr 0.006857] [batchtime 0.454]
[epoch 55], [iter 37 / 176], [train main loss -2.124449], [lr 0.006857] [batchtime 0.452]
[epoch 55], [iter 38 / 176], [train main loss -2.096102], [lr 0.006857] [batchtime 0.45]
[epoch 55], [iter 39 / 176], [train main loss -2.070648], [lr 0.006857] [batchtime 0.448]
[epoch 55], [iter 40 / 176], [train main loss -2.021655], [lr 0.006857] [batchtime 0.446]
[epoch 55], [iter 41 / 176], [train main loss -2.035729], [lr 0.006857] [batchtime 0.445]
[epoch 55], [iter 42 / 176], [train main loss -2.121337], [lr 0.006857] [batchtime 0.443]
[epoch 55], [iter 43 / 176], [train main loss -2.101731], [lr 0.006857] [batchtime 0.442]
[epoch 55], [iter 44 / 176], [train main loss -2.023817], [lr 0.006857] [batchtime 0.441]
[epoch 55], [iter 45 / 176], [train main loss -1.934499], [lr 0.006857] [batchtime 0.44]
[epoch 55], [iter 46 / 176], [train main loss -1.992367], [lr 0.006857] [batchtime 0.439]
[epoch 55], [iter 47 / 176], [train main loss -2.015572], [lr 0.006857] [batchtime 0.438]
[epoch 55], [iter 48 / 176], [train main loss -2.029804], [lr 0.006857] [batchtime 0.436]
[epoch 55], [iter 49 / 176], [train main loss -2.037461], [lr 0.006857] [batchtime 0.436]
[epoch 55], [iter 50 / 176], [train main loss -2.030267], [lr 0.006857] [batchtime 0.435]
[epoch 55], [iter 51 / 176], [train main loss -2.038150], [lr 0.006857] [batchtime 0.434]
[epoch 55], [iter 52 / 176], [train main loss -2.003292], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 53 / 176], [train main loss -1.985878], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 54 / 176], [train main loss -1.950914], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 55 / 176], [train main loss -1.913358], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 56 / 176], [train main loss -1.951315], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 57 / 176], [train main loss -1.908135], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 58 / 176], [train main loss -1.908773], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 59 / 176], [train main loss -1.863466], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 60 / 176], [train main loss -1.814196], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 61 / 176], [train main loss -1.792520], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 62 / 176], [train main loss -1.814907], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 63 / 176], [train main loss -1.871505], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 64 / 176], [train main loss -1.852063], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 65 / 176], [train main loss -1.856852], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 66 / 176], [train main loss -1.841004], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 67 / 176], [train main loss -1.865046], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 68 / 176], [train main loss -1.860300], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 69 / 176], [train main loss -1.850227], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 70 / 176], [train main loss -1.806787], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 71 / 176], [train main loss -1.800831], [lr 0.006857] [batchtime 0.423]
[epoch 55], [iter 72 / 176], [train main loss -1.788542], [lr 0.006857] [batchtime 0.423]
[epoch 55], [iter 73 / 176], [train main loss -1.778125], [lr 0.006857] [batchtime 0.422]
[epoch 55], [iter 74 / 176], [train main loss -1.801097], [lr 0.006857] [batchtime 0.422]
[epoch 55], [iter 75 / 176], [train main loss -1.798673], [lr 0.006857] [batchtime 0.421]
[epoch 55], [iter 76 / 176], [train main loss -1.796666], [lr 0.006857] [batchtime 0.421]
[epoch 55], [iter 77 / 176], [train main loss -1.797701], [lr 0.006857] [batchtime 0.421]
[epoch 55], [iter 78 / 176], [train main loss -1.797345], [lr 0.006857] [batchtime 0.42]
[epoch 55], [iter 79 / 176], [train main loss -1.774103], [lr 0.006857] [batchtime 0.438]
[epoch 55], [iter 80 / 176], [train main loss -1.774392], [lr 0.006857] [batchtime 0.441]
[epoch 55], [iter 81 / 176], [train main loss -1.760174], [lr 0.006857] [batchtime 0.44]
[epoch 55], [iter 82 / 176], [train main loss -1.760873], [lr 0.006857] [batchtime 0.439]
[epoch 55], [iter 83 / 176], [train main loss -1.754955], [lr 0.006857] [batchtime 0.439]
[epoch 55], [iter 84 / 176], [train main loss -1.761017], [lr 0.006857] [batchtime 0.438]
[epoch 55], [iter 85 / 176], [train main loss -1.776686], [lr 0.006857] [batchtime 0.438]
[epoch 55], [iter 86 / 176], [train main loss -1.777367], [lr 0.006857] [batchtime 0.437]
[epoch 55], [iter 87 / 176], [train main loss -1.802577], [lr 0.006857] [batchtime 0.437]
[epoch 55], [iter 88 / 176], [train main loss -1.778228], [lr 0.006857] [batchtime 0.436]
[epoch 55], [iter 89 / 176], [train main loss -1.744766], [lr 0.006857] [batchtime 0.435]
[epoch 55], [iter 90 / 176], [train main loss -1.752372], [lr 0.006857] [batchtime 0.435]
[epoch 55], [iter 91 / 176], [train main loss -1.768126], [lr 0.006857] [batchtime 0.435]
[epoch 55], [iter 92 / 176], [train main loss -1.785095], [lr 0.006857] [batchtime 0.434]
[epoch 55], [iter 93 / 176], [train main loss -1.814202], [lr 0.006857] [batchtime 0.434]
[epoch 55], [iter 94 / 176], [train main loss -1.793177], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 95 / 176], [train main loss -1.774709], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 96 / 176], [train main loss -1.761486], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 97 / 176], [train main loss -1.775139], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 98 / 176], [train main loss -1.748494], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 99 / 176], [train main loss -1.746110], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 100 / 176], [train main loss -1.747477], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 101 / 176], [train main loss -1.732073], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 102 / 176], [train main loss -1.740800], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 103 / 176], [train main loss -1.712812], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 104 / 176], [train main loss -1.703873], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 105 / 176], [train main loss -1.715367], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 106 / 176], [train main loss -1.727812], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 107 / 176], [train main loss -1.733948], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 108 / 176], [train main loss -1.743799], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 109 / 176], [train main loss -1.755497], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 110 / 176], [train main loss -1.770599], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 111 / 176], [train main loss -1.759122], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 112 / 176], [train main loss -1.732622], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 113 / 176], [train main loss -1.701888], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 114 / 176], [train main loss -1.694263], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 115 / 176], [train main loss -1.681031], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 116 / 176], [train main loss -1.682951], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 117 / 176], [train main loss -1.667742], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 118 / 176], [train main loss -1.676311], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 119 / 176], [train main loss -1.677955], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 120 / 176], [train main loss -1.675788], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 121 / 176], [train main loss -1.691392], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 122 / 176], [train main loss -1.681205], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 123 / 176], [train main loss -1.675871], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 124 / 176], [train main loss -1.663001], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 125 / 176], [train main loss -1.666135], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 126 / 176], [train main loss -1.674432], [lr 0.006857] [batchtime 0.435]
[epoch 55], [iter 127 / 176], [train main loss -1.672258], [lr 0.006857] [batchtime 0.435]
[epoch 55], [iter 128 / 176], [train main loss -1.676973], [lr 0.006857] [batchtime 0.434]
[epoch 55], [iter 129 / 176], [train main loss -1.681462], [lr 0.006857] [batchtime 0.434]
[epoch 55], [iter 130 / 176], [train main loss -1.691287], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 131 / 176], [train main loss -1.688344], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 132 / 176], [train main loss -1.675773], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 133 / 176], [train main loss -1.677548], [lr 0.006857] [batchtime 0.433]
[epoch 55], [iter 134 / 176], [train main loss -1.673711], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 135 / 176], [train main loss -1.675399], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 136 / 176], [train main loss -1.660805], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 137 / 176], [train main loss -1.677401], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 138 / 176], [train main loss -1.665675], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 139 / 176], [train main loss -1.653737], [lr 0.006857] [batchtime 0.431]
[epoch 55], [iter 140 / 176], [train main loss -1.648246], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 141 / 176], [train main loss -1.629103], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 142 / 176], [train main loss -1.635914], [lr 0.006857] [batchtime 0.43]
[epoch 55], [iter 143 / 176], [train main loss -1.650859], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 144 / 176], [train main loss -1.660623], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 145 / 176], [train main loss -1.641869], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 146 / 176], [train main loss -1.639476], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 147 / 176], [train main loss -1.650269], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 148 / 176], [train main loss -1.666992], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 149 / 176], [train main loss -1.676366], [lr 0.006857] [batchtime 0.429]
[epoch 55], [iter 150 / 176], [train main loss -1.665976], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 151 / 176], [train main loss -1.663873], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 152 / 176], [train main loss -1.658745], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 153 / 176], [train main loss -1.671595], [lr 0.006857] [batchtime 0.428]
[epoch 55], [iter 154 / 176], [train main loss -1.661612], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 155 / 176], [train main loss -1.646820], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 156 / 176], [train main loss -1.653596], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 157 / 176], [train main loss -1.666161], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 158 / 176], [train main loss -1.670104], [lr 0.006857] [batchtime 0.427]
[epoch 55], [iter 159 / 176], [train main loss -1.659793], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 160 / 176], [train main loss -1.665164], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 161 / 176], [train main loss -1.683970], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 162 / 176], [train main loss -1.687000], [lr 0.006857] [batchtime 0.426]
[epoch 55], [iter 163 / 176], [train main loss -1.695350], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 164 / 176], [train main loss -1.685448], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 165 / 176], [train main loss -1.682677], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 166 / 176], [train main loss -1.688742], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 167 / 176], [train main loss -1.700828], [lr 0.006857] [batchtime 0.425]
[epoch 55], [iter 168 / 176], [train main loss -1.716207], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 169 / 176], [train main loss -1.716411], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 170 / 176], [train main loss -1.709879], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 171 / 176], [train main loss -1.709548], [lr 0.006857] [batchtime 0.423]
[epoch 55], [iter 172 / 176], [train main loss -1.707335], [lr 0.006857] [batchtime 0.423]
[epoch 55], [iter 173 / 176], [train main loss -1.708118], [lr 0.006857] [batchtime 0.424]
[epoch 55], [iter 174 / 176], [train main loss -1.704233], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 175 / 176], [train main loss -1.693754], [lr 0.006857] [batchtime 0.432]
[epoch 55], [iter 176 / 176], [train main loss -1.707864], [lr 0.006857] [batchtime 0.432]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.20  34.95    0.04  0.03         0.96      0.97
   1  sidewalk          63.89   5.38    0.22  0.34         0.82      0.75
   2  building          83.02  24.34    0.09  0.11         0.92      0.90
   3  wall              10.95   0.09    5.53  2.60         0.15      0.28
   4  fence             13.71   0.20    5.48  0.82         0.15      0.55
   5  pole              31.39   0.45    1.54  0.65         0.39      0.61
   6  traffic light      4.70   0.01   19.61  0.69         0.05      0.59
   7  traffic sign       8.32   0.05   10.70  0.32         0.09      0.76
   8  vegetation        78.67  11.67    0.06  0.21         0.94      0.83
   9  terrain           31.39   0.27    1.75  0.44         0.36      0.70
  10  sky               92.40   3.73    0.04  0.04         0.96      0.96
  11  person            42.53   0.92    0.67  0.69         0.60      0.59
  12  rider              1.10   0.00   88.04  1.96         0.01      0.34
  13  car               82.07   6.58    0.07  0.14         0.93      0.87
  14  truck              0.41   0.00  241.44  0.71         0.00      0.58
  15  bus                3.45   0.00   21.79  6.17         0.04      0.14
  16  train             24.54   0.05    2.63  0.45         0.28      0.69
  17  motorcycle         0.11   0.00  875.75  1.00         0.00      0.50
  18  bicycle           28.34   0.20    0.98  1.55         0.51      0.39
Mean: 36.54
-----------------------------------------------------------------------------------------------------------
this : [epoch 55], [val loss 0.37703], [acc 0.88891], [acc_cls 0.43019], [mean_iu 0.36536], [fwavacc 0.80967]
best : [epoch 54], [val loss 0.37078], [acc 0.88969], [acc_cls 0.43663], [mean_iu 0.36741], [fwavacc 0.81009]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 56], [iter 1 / 176], [train main loss -3.245947], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 2 / 176], [train main loss -4.603696], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 3 / 176], [train main loss -3.713841], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 4 / 176], [train main loss -3.427397], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 5 / 176], [train main loss -3.136420], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 6 / 176], [train main loss -2.861271], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 7 / 176], [train main loss -2.330783], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 8 / 176], [train main loss -2.076531], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 9 / 176], [train main loss -1.952368], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 10 / 176], [train main loss -1.783683], [lr 0.006800] [batchtime 0]
[epoch 56], [iter 11 / 176], [train main loss -1.573417], [lr 0.006800] [batchtime 0.368]
[epoch 56], [iter 12 / 176], [train main loss -1.602272], [lr 0.006800] [batchtime 0.386]
[epoch 56], [iter 13 / 176], [train main loss -1.496368], [lr 0.006800] [batchtime 0.394]
[epoch 56], [iter 14 / 176], [train main loss -1.527136], [lr 0.006800] [batchtime 0.396]
[epoch 56], [iter 15 / 176], [train main loss -1.620942], [lr 0.006800] [batchtime 0.397]
[epoch 56], [iter 16 / 176], [train main loss -1.641604], [lr 0.006800] [batchtime 0.398]
[epoch 56], [iter 17 / 176], [train main loss -1.787719], [lr 0.006800] [batchtime 0.398]
[epoch 56], [iter 18 / 176], [train main loss -1.753153], [lr 0.006800] [batchtime 0.397]
[epoch 56], [iter 19 / 176], [train main loss -1.672025], [lr 0.006800] [batchtime 0.397]
[epoch 56], [iter 20 / 176], [train main loss -1.736295], [lr 0.006800] [batchtime 0.396]
[epoch 56], [iter 21 / 176], [train main loss -1.778723], [lr 0.006800] [batchtime 0.396]
[epoch 56], [iter 22 / 176], [train main loss -1.829868], [lr 0.006800] [batchtime 0.397]
[epoch 56], [iter 23 / 176], [train main loss -1.817072], [lr 0.006800] [batchtime 0.396]
[epoch 56], [iter 24 / 176], [train main loss -1.694883], [lr 0.006800] [batchtime 0.396]
[epoch 56], [iter 25 / 176], [train main loss -1.769238], [lr 0.006800] [batchtime 0.395]
[epoch 56], [iter 26 / 176], [train main loss -1.805568], [lr 0.006800] [batchtime 0.395]
[epoch 56], [iter 27 / 176], [train main loss -1.825414], [lr 0.006800] [batchtime 0.395]
[epoch 56], [iter 28 / 176], [train main loss -1.826743], [lr 0.006800] [batchtime 0.394]
[epoch 56], [iter 29 / 176], [train main loss -1.701657], [lr 0.006800] [batchtime 0.394]
[epoch 56], [iter 30 / 176], [train main loss -1.738250], [lr 0.006800] [batchtime 0.394]
[epoch 56], [iter 31 / 176], [train main loss -1.591623], [lr 0.006800] [batchtime 0.394]
[epoch 56], [iter 32 / 176], [train main loss -1.650753], [lr 0.006800] [batchtime 0.437]
[epoch 56], [iter 33 / 176], [train main loss -1.626839], [lr 0.006800] [batchtime 0.445]
[epoch 56], [iter 34 / 176], [train main loss -1.636575], [lr 0.006800] [batchtime 0.443]
[epoch 56], [iter 35 / 176], [train main loss -1.640884], [lr 0.006800] [batchtime 0.441]
[epoch 56], [iter 36 / 176], [train main loss -1.608934], [lr 0.006800] [batchtime 0.439]
[epoch 56], [iter 37 / 176], [train main loss -1.712115], [lr 0.006800] [batchtime 0.437]
[epoch 56], [iter 38 / 176], [train main loss -1.705575], [lr 0.006800] [batchtime 0.436]
[epoch 56], [iter 39 / 176], [train main loss -1.702062], [lr 0.006800] [batchtime 0.435]
[epoch 56], [iter 40 / 176], [train main loss -1.647720], [lr 0.006800] [batchtime 0.434]
[epoch 56], [iter 41 / 176], [train main loss -1.649223], [lr 0.006800] [batchtime 0.433]
[epoch 56], [iter 42 / 176], [train main loss -1.670679], [lr 0.006800] [batchtime 0.432]
[epoch 56], [iter 43 / 176], [train main loss -1.633463], [lr 0.006800] [batchtime 0.431]
[epoch 56], [iter 44 / 176], [train main loss -1.662497], [lr 0.006800] [batchtime 0.43]
[epoch 56], [iter 45 / 176], [train main loss -1.733758], [lr 0.006800] [batchtime 0.429]
[epoch 56], [iter 46 / 176], [train main loss -1.718672], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 47 / 176], [train main loss -1.758543], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 48 / 176], [train main loss -1.724971], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 49 / 176], [train main loss -1.749469], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 50 / 176], [train main loss -1.730812], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 51 / 176], [train main loss -1.746334], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 52 / 176], [train main loss -1.740709], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 53 / 176], [train main loss -1.703191], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 54 / 176], [train main loss -1.710530], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 55 / 176], [train main loss -1.764520], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 56 / 176], [train main loss -1.727355], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 57 / 176], [train main loss -1.713243], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 58 / 176], [train main loss -1.722589], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 59 / 176], [train main loss -1.736947], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 60 / 176], [train main loss -1.723053], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 61 / 176], [train main loss -1.753095], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 62 / 176], [train main loss -1.734127], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 63 / 176], [train main loss -1.741917], [lr 0.006800] [batchtime 0.418]
[epoch 56], [iter 64 / 176], [train main loss -1.760776], [lr 0.006800] [batchtime 0.418]
[epoch 56], [iter 65 / 176], [train main loss -1.727444], [lr 0.006800] [batchtime 0.418]
[epoch 56], [iter 66 / 176], [train main loss -1.724987], [lr 0.006800] [batchtime 0.417]
[epoch 56], [iter 67 / 176], [train main loss -1.721365], [lr 0.006800] [batchtime 0.417]
[epoch 56], [iter 68 / 176], [train main loss -1.756351], [lr 0.006800] [batchtime 0.416]
[epoch 56], [iter 69 / 176], [train main loss -1.773708], [lr 0.006800] [batchtime 0.416]
[epoch 56], [iter 70 / 176], [train main loss -1.770512], [lr 0.006800] [batchtime 0.416]
[epoch 56], [iter 71 / 176], [train main loss -1.781740], [lr 0.006800] [batchtime 0.415]
[epoch 56], [iter 72 / 176], [train main loss -1.771853], [lr 0.006800] [batchtime 0.415]
[epoch 56], [iter 73 / 176], [train main loss -1.794681], [lr 0.006800] [batchtime 0.415]
[epoch 56], [iter 74 / 176], [train main loss -1.766843], [lr 0.006800] [batchtime 0.414]
[epoch 56], [iter 75 / 176], [train main loss -1.773198], [lr 0.006800] [batchtime 0.414]
[epoch 56], [iter 76 / 176], [train main loss -1.775266], [lr 0.006800] [batchtime 0.414]
[epoch 56], [iter 77 / 176], [train main loss -1.744649], [lr 0.006800] [batchtime 0.413]
[epoch 56], [iter 78 / 176], [train main loss -1.739630], [lr 0.006800] [batchtime 0.413]
[epoch 56], [iter 79 / 176], [train main loss -1.728143], [lr 0.006800] [batchtime 0.416]
[epoch 56], [iter 80 / 176], [train main loss -1.701390], [lr 0.006800] [batchtime 0.434]
[epoch 56], [iter 81 / 176], [train main loss -1.724545], [lr 0.006800] [batchtime 0.433]
[epoch 56], [iter 82 / 176], [train main loss -1.736090], [lr 0.006800] [batchtime 0.432]
[epoch 56], [iter 83 / 176], [train main loss -1.748837], [lr 0.006800] [batchtime 0.432]
[epoch 56], [iter 84 / 176], [train main loss -1.758816], [lr 0.006800] [batchtime 0.431]
[epoch 56], [iter 85 / 176], [train main loss -1.755975], [lr 0.006800] [batchtime 0.431]
[epoch 56], [iter 86 / 176], [train main loss -1.765990], [lr 0.006800] [batchtime 0.43]
[epoch 56], [iter 87 / 176], [train main loss -1.768297], [lr 0.006800] [batchtime 0.43]
[epoch 56], [iter 88 / 176], [train main loss -1.778152], [lr 0.006800] [batchtime 0.429]
[epoch 56], [iter 89 / 176], [train main loss -1.792949], [lr 0.006800] [batchtime 0.429]
[epoch 56], [iter 90 / 176], [train main loss -1.827074], [lr 0.006800] [batchtime 0.429]
[epoch 56], [iter 91 / 176], [train main loss -1.834629], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 92 / 176], [train main loss -1.832004], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 93 / 176], [train main loss -1.857213], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 94 / 176], [train main loss -1.859136], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 95 / 176], [train main loss -1.833961], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 96 / 176], [train main loss -1.850824], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 97 / 176], [train main loss -1.850331], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 98 / 176], [train main loss -1.852249], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 99 / 176], [train main loss -1.865750], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 100 / 176], [train main loss -1.894584], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 101 / 176], [train main loss -1.891397], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 102 / 176], [train main loss -1.884464], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 103 / 176], [train main loss -1.898689], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 104 / 176], [train main loss -1.887095], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 105 / 176], [train main loss -1.900272], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 106 / 176], [train main loss -1.908375], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 107 / 176], [train main loss -1.909979], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 108 / 176], [train main loss -1.923800], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 109 / 176], [train main loss -1.921141], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 110 / 176], [train main loss -1.912410], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 111 / 176], [train main loss -1.913648], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 112 / 176], [train main loss -1.919372], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 113 / 176], [train main loss -1.929983], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 114 / 176], [train main loss -1.936748], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 115 / 176], [train main loss -1.946270], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 116 / 176], [train main loss -1.911766], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 117 / 176], [train main loss -1.890342], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 118 / 176], [train main loss -1.916767], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 119 / 176], [train main loss -1.910658], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 120 / 176], [train main loss -1.909410], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 121 / 176], [train main loss -1.907014], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 122 / 176], [train main loss -1.920706], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 123 / 176], [train main loss -1.944938], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 124 / 176], [train main loss -1.944801], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 125 / 176], [train main loss -1.951391], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 126 / 176], [train main loss -1.967734], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 127 / 176], [train main loss -1.982136], [lr 0.006800] [batchtime 0.429]
[epoch 56], [iter 128 / 176], [train main loss -1.978863], [lr 0.006800] [batchtime 0.429]
[epoch 56], [iter 129 / 176], [train main loss -1.987763], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 130 / 176], [train main loss -1.970611], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 131 / 176], [train main loss -1.962660], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 132 / 176], [train main loss -1.963113], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 133 / 176], [train main loss -1.955647], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 134 / 176], [train main loss -1.957282], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 135 / 176], [train main loss -1.970291], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 136 / 176], [train main loss -1.993313], [lr 0.006800] [batchtime 0.427]
[epoch 56], [iter 137 / 176], [train main loss -1.968561], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 138 / 176], [train main loss -1.974335], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 139 / 176], [train main loss -1.984451], [lr 0.006800] [batchtime 0.426]
[epoch 56], [iter 140 / 176], [train main loss -1.999721], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 141 / 176], [train main loss -1.982016], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 142 / 176], [train main loss -1.970854], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 143 / 176], [train main loss -1.965153], [lr 0.006800] [batchtime 0.425]
[epoch 56], [iter 144 / 176], [train main loss -1.961639], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 145 / 176], [train main loss -1.984212], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 146 / 176], [train main loss -1.996493], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 147 / 176], [train main loss -1.995720], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 148 / 176], [train main loss -1.991903], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 149 / 176], [train main loss -1.988543], [lr 0.006800] [batchtime 0.424]
[epoch 56], [iter 150 / 176], [train main loss -1.986142], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 151 / 176], [train main loss -1.988079], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 152 / 176], [train main loss -1.986671], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 153 / 176], [train main loss -1.982423], [lr 0.006800] [batchtime 0.423]
[epoch 56], [iter 154 / 176], [train main loss -1.985913], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 155 / 176], [train main loss -1.986447], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 156 / 176], [train main loss -1.984184], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 157 / 176], [train main loss -2.009838], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 158 / 176], [train main loss -2.007965], [lr 0.006800] [batchtime 0.422]
[epoch 56], [iter 159 / 176], [train main loss -1.992713], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 160 / 176], [train main loss -1.989657], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 161 / 176], [train main loss -1.971728], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 162 / 176], [train main loss -1.971017], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 163 / 176], [train main loss -1.969266], [lr 0.006800] [batchtime 0.421]
[epoch 56], [iter 164 / 176], [train main loss -1.969343], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 165 / 176], [train main loss -1.979028], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 166 / 176], [train main loss -1.990836], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 167 / 176], [train main loss -1.991918], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 168 / 176], [train main loss -1.995769], [lr 0.006800] [batchtime 0.42]
[epoch 56], [iter 169 / 176], [train main loss -1.977558], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 170 / 176], [train main loss -1.983433], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 171 / 176], [train main loss -1.992944], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 172 / 176], [train main loss -1.980243], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 173 / 176], [train main loss -1.974404], [lr 0.006800] [batchtime 0.418]
[epoch 56], [iter 174 / 176], [train main loss -1.951696], [lr 0.006800] [batchtime 0.419]
[epoch 56], [iter 175 / 176], [train main loss -1.952691], [lr 0.006800] [batchtime 0.428]
[epoch 56], [iter 176 / 176], [train main loss -1.948471], [lr 0.006800] [batchtime 0.428]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.19  35.30    0.03  0.05         0.97      0.95
   1  sidewalk          57.98   4.61    0.43  0.30         0.70      0.77
   2  building          83.20  24.32    0.09  0.11         0.91      0.90
   3  wall              11.50   0.11    4.61  3.09         0.18      0.24
   4  fence              9.82   0.13    8.52  0.66         0.10      0.60
   5  pole              30.02   0.41    1.79  0.54         0.36      0.65
   6  traffic light      3.68   0.01   25.62  0.55         0.04      0.65
   7  traffic sign      10.26   0.06    8.40  0.35         0.11      0.74
   8  vegetation        79.53  11.57    0.07  0.19         0.94      0.84
   9  terrain           34.43   0.37    1.00  0.90         0.50      0.53
  10  sky               92.46   3.75    0.03  0.05         0.97      0.95
  11  person            41.53   0.84    0.83  0.58         0.55      0.63
  12  rider              1.36   0.00   70.86  1.47         0.01      0.40
  13  car               77.90   6.66    0.06  0.22         0.94      0.82
  14  truck              1.09   0.00   89.10  1.36         0.01      0.42
  15  bus                8.67   0.02    4.77  5.77         0.17      0.15
  16  train             12.87   0.02    6.25  0.53         0.14      0.66
  17  motorcycle         0.43   0.00  230.81  0.57         0.00      0.64
  18  bicycle           27.01   0.19    1.10  1.60         0.48      0.38
Mean: 35.58
-----------------------------------------------------------------------------------------------------------
this : [epoch 56], [val loss 0.39319], [acc 0.88349], [acc_cls 0.42516], [mean_iu 0.35576], [fwavacc 0.80010]
best : [epoch 54], [val loss 0.37078], [acc 0.88969], [acc_cls 0.43663], [mean_iu 0.36741], [fwavacc 0.81009]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 57], [iter 1 / 176], [train main loss -2.397398], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 2 / 176], [train main loss -2.942878], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 3 / 176], [train main loss -3.160720], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 4 / 176], [train main loss -2.453255], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 5 / 176], [train main loss -2.339848], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 6 / 176], [train main loss -1.925000], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 7 / 176], [train main loss -1.766063], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 8 / 176], [train main loss -1.655220], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 9 / 176], [train main loss -1.788373], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 10 / 176], [train main loss -1.960730], [lr 0.006743] [batchtime 0]
[epoch 57], [iter 11 / 176], [train main loss -1.891643], [lr 0.006743] [batchtime 0.372]
[epoch 57], [iter 12 / 176], [train main loss -1.750841], [lr 0.006743] [batchtime 0.385]
[epoch 57], [iter 13 / 176], [train main loss -1.766551], [lr 0.006743] [batchtime 0.39]
[epoch 57], [iter 14 / 176], [train main loss -1.880260], [lr 0.006743] [batchtime 0.391]
[epoch 57], [iter 15 / 176], [train main loss -1.910357], [lr 0.006743] [batchtime 0.392]
[epoch 57], [iter 16 / 176], [train main loss -1.901279], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 17 / 176], [train main loss -1.831460], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 18 / 176], [train main loss -1.805022], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 19 / 176], [train main loss -1.757795], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 20 / 176], [train main loss -1.780120], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 21 / 176], [train main loss -1.789164], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 22 / 176], [train main loss -1.826946], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 23 / 176], [train main loss -1.659443], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 24 / 176], [train main loss -1.733269], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 25 / 176], [train main loss -1.737172], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 26 / 176], [train main loss -1.776437], [lr 0.006743] [batchtime 0.395]
[epoch 57], [iter 27 / 176], [train main loss -1.734611], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 28 / 176], [train main loss -1.761808], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 29 / 176], [train main loss -1.741324], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 30 / 176], [train main loss -1.714034], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 31 / 176], [train main loss -1.860000], [lr 0.006743] [batchtime 0.396]
[epoch 57], [iter 32 / 176], [train main loss -1.960097], [lr 0.006743] [batchtime 0.397]
[epoch 57], [iter 33 / 176], [train main loss -1.863413], [lr 0.006743] [batchtime 0.432]
[epoch 57], [iter 34 / 176], [train main loss -1.868950], [lr 0.006743] [batchtime 0.44]
[epoch 57], [iter 35 / 176], [train main loss -1.897846], [lr 0.006743] [batchtime 0.438]
[epoch 57], [iter 36 / 176], [train main loss -1.932054], [lr 0.006743] [batchtime 0.437]
[epoch 57], [iter 37 / 176], [train main loss -1.948183], [lr 0.006743] [batchtime 0.435]
[epoch 57], [iter 38 / 176], [train main loss -1.974092], [lr 0.006743] [batchtime 0.434]
[epoch 57], [iter 39 / 176], [train main loss -1.909243], [lr 0.006743] [batchtime 0.433]
[epoch 57], [iter 40 / 176], [train main loss -1.962972], [lr 0.006743] [batchtime 0.431]
[epoch 57], [iter 41 / 176], [train main loss -1.989474], [lr 0.006743] [batchtime 0.43]
[epoch 57], [iter 42 / 176], [train main loss -1.975265], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 43 / 176], [train main loss -2.002727], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 44 / 176], [train main loss -1.995149], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 45 / 176], [train main loss -1.908152], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 46 / 176], [train main loss -1.854401], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 47 / 176], [train main loss -1.940100], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 48 / 176], [train main loss -1.894982], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 49 / 176], [train main loss -1.908736], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 50 / 176], [train main loss -1.854384], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 51 / 176], [train main loss -1.919298], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 52 / 176], [train main loss -1.904151], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 53 / 176], [train main loss -1.864852], [lr 0.006743] [batchtime 0.42]
[epoch 57], [iter 54 / 176], [train main loss -1.810048], [lr 0.006743] [batchtime 0.42]
[epoch 57], [iter 55 / 176], [train main loss -1.821379], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 56 / 176], [train main loss -1.803931], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 57 / 176], [train main loss -1.820926], [lr 0.006743] [batchtime 0.418]
[epoch 57], [iter 58 / 176], [train main loss -1.835952], [lr 0.006743] [batchtime 0.418]
[epoch 57], [iter 59 / 176], [train main loss -1.828603], [lr 0.006743] [batchtime 0.417]
[epoch 57], [iter 60 / 176], [train main loss -1.819608], [lr 0.006743] [batchtime 0.417]
[epoch 57], [iter 61 / 176], [train main loss -1.807506], [lr 0.006743] [batchtime 0.416]
[epoch 57], [iter 62 / 176], [train main loss -1.776791], [lr 0.006743] [batchtime 0.416]
[epoch 57], [iter 63 / 176], [train main loss -1.782862], [lr 0.006743] [batchtime 0.416]
[epoch 57], [iter 64 / 176], [train main loss -1.766165], [lr 0.006743] [batchtime 0.415]
[epoch 57], [iter 65 / 176], [train main loss -1.758187], [lr 0.006743] [batchtime 0.415]
[epoch 57], [iter 66 / 176], [train main loss -1.810857], [lr 0.006743] [batchtime 0.416]
[epoch 57], [iter 67 / 176], [train main loss -1.816583], [lr 0.006743] [batchtime 0.416]
[epoch 57], [iter 68 / 176], [train main loss -1.874100], [lr 0.006743] [batchtime 0.416]
[epoch 57], [iter 69 / 176], [train main loss -1.847683], [lr 0.006743] [batchtime 0.415]
[epoch 57], [iter 70 / 176], [train main loss -1.840770], [lr 0.006743] [batchtime 0.415]
[epoch 57], [iter 71 / 176], [train main loss -1.861013], [lr 0.006743] [batchtime 0.414]
[epoch 57], [iter 72 / 176], [train main loss -1.874829], [lr 0.006743] [batchtime 0.414]
[epoch 57], [iter 73 / 176], [train main loss -1.851913], [lr 0.006743] [batchtime 0.414]
[epoch 57], [iter 74 / 176], [train main loss -1.847413], [lr 0.006743] [batchtime 0.413]
[epoch 57], [iter 75 / 176], [train main loss -1.822219], [lr 0.006743] [batchtime 0.413]
[epoch 57], [iter 76 / 176], [train main loss -1.788274], [lr 0.006743] [batchtime 0.413]
[epoch 57], [iter 77 / 176], [train main loss -1.797951], [lr 0.006743] [batchtime 0.412]
[epoch 57], [iter 78 / 176], [train main loss -1.799026], [lr 0.006743] [batchtime 0.412]
[epoch 57], [iter 79 / 176], [train main loss -1.811722], [lr 0.006743] [batchtime 0.412]
[epoch 57], [iter 80 / 176], [train main loss -1.793781], [lr 0.006743] [batchtime 0.411]
[epoch 57], [iter 81 / 176], [train main loss -1.832324], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 82 / 176], [train main loss -1.819975], [lr 0.006743] [batchtime 0.432]
[epoch 57], [iter 83 / 176], [train main loss -1.826644], [lr 0.006743] [batchtime 0.432]
[epoch 57], [iter 84 / 176], [train main loss -1.817509], [lr 0.006743] [batchtime 0.431]
[epoch 57], [iter 85 / 176], [train main loss -1.825670], [lr 0.006743] [batchtime 0.431]
[epoch 57], [iter 86 / 176], [train main loss -1.811077], [lr 0.006743] [batchtime 0.43]
[epoch 57], [iter 87 / 176], [train main loss -1.803129], [lr 0.006743] [batchtime 0.43]
[epoch 57], [iter 88 / 176], [train main loss -1.798896], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 89 / 176], [train main loss -1.821086], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 90 / 176], [train main loss -1.806984], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 91 / 176], [train main loss -1.788429], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 92 / 176], [train main loss -1.774764], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 93 / 176], [train main loss -1.757992], [lr 0.006743] [batchtime 0.427]
[epoch 57], [iter 94 / 176], [train main loss -1.756644], [lr 0.006743] [batchtime 0.427]
[epoch 57], [iter 95 / 176], [train main loss -1.755505], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 96 / 176], [train main loss -1.779014], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 97 / 176], [train main loss -1.792274], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 98 / 176], [train main loss -1.772910], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 99 / 176], [train main loss -1.768622], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 100 / 176], [train main loss -1.753425], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 101 / 176], [train main loss -1.756226], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 102 / 176], [train main loss -1.765375], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 103 / 176], [train main loss -1.787737], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 104 / 176], [train main loss -1.789885], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 105 / 176], [train main loss -1.784549], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 106 / 176], [train main loss -1.786930], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 107 / 176], [train main loss -1.783672], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 108 / 176], [train main loss -1.791776], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 109 / 176], [train main loss -1.797623], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 110 / 176], [train main loss -1.780818], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 111 / 176], [train main loss -1.778290], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 112 / 176], [train main loss -1.768826], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 113 / 176], [train main loss -1.763131], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 114 / 176], [train main loss -1.784480], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 115 / 176], [train main loss -1.798814], [lr 0.006743] [batchtime 0.42]
[epoch 57], [iter 116 / 176], [train main loss -1.818757], [lr 0.006743] [batchtime 0.42]
[epoch 57], [iter 117 / 176], [train main loss -1.843479], [lr 0.006743] [batchtime 0.42]
[epoch 57], [iter 118 / 176], [train main loss -1.850497], [lr 0.006743] [batchtime 0.42]
[epoch 57], [iter 119 / 176], [train main loss -1.845323], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 120 / 176], [train main loss -1.841459], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 121 / 176], [train main loss -1.821200], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 122 / 176], [train main loss -1.813335], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 123 / 176], [train main loss -1.853869], [lr 0.006743] [batchtime 0.419]
[epoch 57], [iter 124 / 176], [train main loss -1.839918], [lr 0.006743] [batchtime 0.418]
[epoch 57], [iter 125 / 176], [train main loss -1.823461], [lr 0.006743] [batchtime 0.418]
[epoch 57], [iter 126 / 176], [train main loss -1.817637], [lr 0.006743] [batchtime 0.418]
[epoch 57], [iter 127 / 176], [train main loss -1.815332], [lr 0.006743] [batchtime 0.418]
[epoch 57], [iter 128 / 176], [train main loss -1.813077], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 129 / 176], [train main loss -1.822454], [lr 0.006743] [batchtime 0.431]
[epoch 57], [iter 130 / 176], [train main loss -1.816386], [lr 0.006743] [batchtime 0.431]
[epoch 57], [iter 131 / 176], [train main loss -1.806475], [lr 0.006743] [batchtime 0.43]
[epoch 57], [iter 132 / 176], [train main loss -1.802652], [lr 0.006743] [batchtime 0.43]
[epoch 57], [iter 133 / 176], [train main loss -1.801129], [lr 0.006743] [batchtime 0.43]
[epoch 57], [iter 134 / 176], [train main loss -1.803110], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 135 / 176], [train main loss -1.801275], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 136 / 176], [train main loss -1.799697], [lr 0.006743] [batchtime 0.429]
[epoch 57], [iter 137 / 176], [train main loss -1.818189], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 138 / 176], [train main loss -1.838855], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 139 / 176], [train main loss -1.817902], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 140 / 176], [train main loss -1.813498], [lr 0.006743] [batchtime 0.428]
[epoch 57], [iter 141 / 176], [train main loss -1.798184], [lr 0.006743] [batchtime 0.427]
[epoch 57], [iter 142 / 176], [train main loss -1.784976], [lr 0.006743] [batchtime 0.427]
[epoch 57], [iter 143 / 176], [train main loss -1.786151], [lr 0.006743] [batchtime 0.427]
[epoch 57], [iter 144 / 176], [train main loss -1.779015], [lr 0.006743] [batchtime 0.427]
[epoch 57], [iter 145 / 176], [train main loss -1.774014], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 146 / 176], [train main loss -1.760269], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 147 / 176], [train main loss -1.765499], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 148 / 176], [train main loss -1.767120], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 149 / 176], [train main loss -1.764374], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 150 / 176], [train main loss -1.759082], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 151 / 176], [train main loss -1.764349], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 152 / 176], [train main loss -1.781241], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 153 / 176], [train main loss -1.793603], [lr 0.006743] [batchtime 0.425]
[epoch 57], [iter 154 / 176], [train main loss -1.796029], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 155 / 176], [train main loss -1.782310], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 156 / 176], [train main loss -1.795423], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 157 / 176], [train main loss -1.785821], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 158 / 176], [train main loss -1.799684], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 159 / 176], [train main loss -1.777895], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 160 / 176], [train main loss -1.785485], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 161 / 176], [train main loss -1.788611], [lr 0.006743] [batchtime 0.424]
[epoch 57], [iter 162 / 176], [train main loss -1.799091], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 163 / 176], [train main loss -1.818653], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 164 / 176], [train main loss -1.809467], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 165 / 176], [train main loss -1.810459], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 166 / 176], [train main loss -1.822015], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 167 / 176], [train main loss -1.829564], [lr 0.006743] [batchtime 0.423]
[epoch 57], [iter 168 / 176], [train main loss -1.824631], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 169 / 176], [train main loss -1.828767], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 170 / 176], [train main loss -1.824924], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 171 / 176], [train main loss -1.839227], [lr 0.006743] [batchtime 0.422]
[epoch 57], [iter 172 / 176], [train main loss -1.832728], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 173 / 176], [train main loss -1.831488], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 174 / 176], [train main loss -1.821305], [lr 0.006743] [batchtime 0.421]
[epoch 57], [iter 175 / 176], [train main loss -1.818550], [lr 0.006743] [batchtime 0.426]
[epoch 57], [iter 176 / 176], [train main loss -1.815035], [lr 0.006743] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.64  35.59    0.02  0.06         0.98      0.95
   1  sidewalk          59.59   4.51    0.46  0.22         0.68      0.82
   2  building          82.67  24.80    0.07  0.14         0.93      0.88
   3  wall              10.87   0.09    5.94  2.26         0.14      0.31
   4  fence             17.70   0.28    3.49  1.16         0.22      0.46
   5  pole              29.64   0.41    1.77  0.61         0.36      0.62
   6  traffic light      3.77   0.01   24.93  0.61         0.04      0.62
   7  traffic sign       8.12   0.05   11.01  0.30         0.08      0.77
   8  vegetation        79.70  11.48    0.08  0.18         0.93      0.85
   9  terrain           38.32   0.37    0.99  0.62         0.50      0.62
  10  sky               92.74   3.74    0.04  0.04         0.96      0.96
  11  person            36.63   0.67    1.28  0.45         0.44      0.69
  12  rider              0.86   0.00  113.70  1.70         0.01      0.37
  13  car               81.39   6.48    0.09  0.14         0.92      0.88
  14  truck              0.45   0.00  220.31  3.18         0.00      0.24
  15  bus                9.35   0.01    5.34  4.36         0.16      0.19
  16  train             20.07   0.04    3.78  0.20         0.21      0.83
  17  motorcycle         0.18   0.00  548.77  0.78         0.00      0.56
  18  bicycle           26.82   0.20    0.92  1.81         0.52      0.36
Mean: 36.40
-----------------------------------------------------------------------------------------------------------
this : [epoch 57], [val loss 0.39352], [acc 0.88717], [acc_cls 0.42615], [mean_iu 0.36395], [fwavacc 0.80460]
best : [epoch 54], [val loss 0.37078], [acc 0.88969], [acc_cls 0.43663], [mean_iu 0.36741], [fwavacc 0.81009]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 58], [iter 1 / 176], [train main loss -1.771814], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 2 / 176], [train main loss -2.154391], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 3 / 176], [train main loss -0.960459], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 4 / 176], [train main loss -1.131692], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 5 / 176], [train main loss -1.410642], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 6 / 176], [train main loss -1.544581], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 7 / 176], [train main loss -1.729206], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 8 / 176], [train main loss -1.442780], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 9 / 176], [train main loss -1.683859], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 10 / 176], [train main loss -1.710710], [lr 0.006686] [batchtime 0]
[epoch 58], [iter 11 / 176], [train main loss -1.656208], [lr 0.006686] [batchtime 0.375]
[epoch 58], [iter 12 / 176], [train main loss -1.796654], [lr 0.006686] [batchtime 0.389]
[epoch 58], [iter 13 / 176], [train main loss -1.619310], [lr 0.006686] [batchtime 0.393]
[epoch 58], [iter 14 / 176], [train main loss -1.611175], [lr 0.006686] [batchtime 0.396]
[epoch 58], [iter 15 / 176], [train main loss -1.696417], [lr 0.006686] [batchtime 0.397]
[epoch 58], [iter 16 / 176], [train main loss -1.631941], [lr 0.006686] [batchtime 0.4]
[epoch 58], [iter 17 / 176], [train main loss -1.639405], [lr 0.006686] [batchtime 0.399]
[epoch 58], [iter 18 / 176], [train main loss -1.731939], [lr 0.006686] [batchtime 0.4]
[epoch 58], [iter 19 / 176], [train main loss -1.693456], [lr 0.006686] [batchtime 0.4]
[epoch 58], [iter 20 / 176], [train main loss -1.693170], [lr 0.006686] [batchtime 0.402]
[epoch 58], [iter 21 / 176], [train main loss -1.708783], [lr 0.006686] [batchtime 0.402]
[epoch 58], [iter 22 / 176], [train main loss -1.667582], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 23 / 176], [train main loss -1.684286], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 24 / 176], [train main loss -1.575348], [lr 0.006686] [batchtime 0.402]
[epoch 58], [iter 25 / 176], [train main loss -1.630553], [lr 0.006686] [batchtime 0.402]
[epoch 58], [iter 26 / 176], [train main loss -1.704477], [lr 0.006686] [batchtime 0.402]
[epoch 58], [iter 27 / 176], [train main loss -1.773714], [lr 0.006686] [batchtime 0.402]
[epoch 58], [iter 28 / 176], [train main loss -1.747966], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 29 / 176], [train main loss -1.699212], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 30 / 176], [train main loss -1.765812], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 31 / 176], [train main loss -1.675417], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 32 / 176], [train main loss -1.785673], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 33 / 176], [train main loss -1.781863], [lr 0.006686] [batchtime 0.4]
[epoch 58], [iter 34 / 176], [train main loss -1.708302], [lr 0.006686] [batchtime 0.4]
[epoch 58], [iter 35 / 176], [train main loss -1.696463], [lr 0.006686] [batchtime 0.401]
[epoch 58], [iter 36 / 176], [train main loss -1.733142], [lr 0.006686] [batchtime 0.4]
[epoch 58], [iter 37 / 176], [train main loss -1.719565], [lr 0.006686] [batchtime 0.453]
[epoch 58], [iter 38 / 176], [train main loss -1.731854], [lr 0.006686] [batchtime 0.459]
[epoch 58], [iter 39 / 176], [train main loss -1.815658], [lr 0.006686] [batchtime 0.457]
[epoch 58], [iter 40 / 176], [train main loss -1.845204], [lr 0.006686] [batchtime 0.455]
[epoch 58], [iter 41 / 176], [train main loss -1.766685], [lr 0.006686] [batchtime 0.453]
[epoch 58], [iter 42 / 176], [train main loss -1.850626], [lr 0.006686] [batchtime 0.452]
[epoch 58], [iter 43 / 176], [train main loss -1.835529], [lr 0.006686] [batchtime 0.45]
[epoch 58], [iter 44 / 176], [train main loss -1.790915], [lr 0.006686] [batchtime 0.448]
[epoch 58], [iter 45 / 176], [train main loss -1.819437], [lr 0.006686] [batchtime 0.447]
[epoch 58], [iter 46 / 176], [train main loss -1.879127], [lr 0.006686] [batchtime 0.445]
[epoch 58], [iter 47 / 176], [train main loss -1.882602], [lr 0.006686] [batchtime 0.444]
[epoch 58], [iter 48 / 176], [train main loss -1.838519], [lr 0.006686] [batchtime 0.443]
[epoch 58], [iter 49 / 176], [train main loss -1.838433], [lr 0.006686] [batchtime 0.442]
[epoch 58], [iter 50 / 176], [train main loss -1.842276], [lr 0.006686] [batchtime 0.44]
[epoch 58], [iter 51 / 176], [train main loss -1.836802], [lr 0.006686] [batchtime 0.439]
[epoch 58], [iter 52 / 176], [train main loss -1.821086], [lr 0.006686] [batchtime 0.438]
[epoch 58], [iter 53 / 176], [train main loss -1.904577], [lr 0.006686] [batchtime 0.438]
[epoch 58], [iter 54 / 176], [train main loss -1.911963], [lr 0.006686] [batchtime 0.437]
[epoch 58], [iter 55 / 176], [train main loss -1.888634], [lr 0.006686] [batchtime 0.436]
[epoch 58], [iter 56 / 176], [train main loss -1.858090], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 57 / 176], [train main loss -1.873748], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 58 / 176], [train main loss -1.850006], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 59 / 176], [train main loss -1.840011], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 60 / 176], [train main loss -1.838568], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 61 / 176], [train main loss -1.780312], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 62 / 176], [train main loss -1.808110], [lr 0.006686] [batchtime 0.431]
[epoch 58], [iter 63 / 176], [train main loss -1.810744], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 64 / 176], [train main loss -1.781554], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 65 / 176], [train main loss -1.795682], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 66 / 176], [train main loss -1.758456], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 67 / 176], [train main loss -1.747865], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 68 / 176], [train main loss -1.705679], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 69 / 176], [train main loss -1.720237], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 70 / 176], [train main loss -1.755273], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 71 / 176], [train main loss -1.746366], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 72 / 176], [train main loss -1.761607], [lr 0.006686] [batchtime 0.426]
[epoch 58], [iter 73 / 176], [train main loss -1.760244], [lr 0.006686] [batchtime 0.426]
[epoch 58], [iter 74 / 176], [train main loss -1.765462], [lr 0.006686] [batchtime 0.425]
[epoch 58], [iter 75 / 176], [train main loss -1.755783], [lr 0.006686] [batchtime 0.425]
[epoch 58], [iter 76 / 176], [train main loss -1.734015], [lr 0.006686] [batchtime 0.424]
[epoch 58], [iter 77 / 176], [train main loss -1.745359], [lr 0.006686] [batchtime 0.424]
[epoch 58], [iter 78 / 176], [train main loss -1.729251], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 79 / 176], [train main loss -1.712337], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 80 / 176], [train main loss -1.725181], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 81 / 176], [train main loss -1.725874], [lr 0.006686] [batchtime 0.422]
[epoch 58], [iter 82 / 176], [train main loss -1.713151], [lr 0.006686] [batchtime 0.422]
[epoch 58], [iter 83 / 176], [train main loss -1.709591], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 84 / 176], [train main loss -1.721610], [lr 0.006686] [batchtime 0.438]
[epoch 58], [iter 85 / 176], [train main loss -1.750404], [lr 0.006686] [batchtime 0.437]
[epoch 58], [iter 86 / 176], [train main loss -1.735876], [lr 0.006686] [batchtime 0.437]
[epoch 58], [iter 87 / 176], [train main loss -1.722779], [lr 0.006686] [batchtime 0.436]
[epoch 58], [iter 88 / 176], [train main loss -1.695437], [lr 0.006686] [batchtime 0.436]
[epoch 58], [iter 89 / 176], [train main loss -1.695982], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 90 / 176], [train main loss -1.709349], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 91 / 176], [train main loss -1.702737], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 92 / 176], [train main loss -1.696389], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 93 / 176], [train main loss -1.680978], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 94 / 176], [train main loss -1.689561], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 95 / 176], [train main loss -1.692052], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 96 / 176], [train main loss -1.716072], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 97 / 176], [train main loss -1.739496], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 98 / 176], [train main loss -1.746828], [lr 0.006686] [batchtime 0.431]
[epoch 58], [iter 99 / 176], [train main loss -1.754593], [lr 0.006686] [batchtime 0.431]
[epoch 58], [iter 100 / 176], [train main loss -1.785293], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 101 / 176], [train main loss -1.777054], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 102 / 176], [train main loss -1.789034], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 103 / 176], [train main loss -1.795204], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 104 / 176], [train main loss -1.832979], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 105 / 176], [train main loss -1.822976], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 106 / 176], [train main loss -1.809922], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 107 / 176], [train main loss -1.805119], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 108 / 176], [train main loss -1.786340], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 109 / 176], [train main loss -1.809178], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 110 / 176], [train main loss -1.817258], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 111 / 176], [train main loss -1.841704], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 112 / 176], [train main loss -1.844997], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 113 / 176], [train main loss -1.842186], [lr 0.006686] [batchtime 0.426]
[epoch 58], [iter 114 / 176], [train main loss -1.845048], [lr 0.006686] [batchtime 0.426]
[epoch 58], [iter 115 / 176], [train main loss -1.850231], [lr 0.006686] [batchtime 0.425]
[epoch 58], [iter 116 / 176], [train main loss -1.860069], [lr 0.006686] [batchtime 0.425]
[epoch 58], [iter 117 / 176], [train main loss -1.860189], [lr 0.006686] [batchtime 0.425]
[epoch 58], [iter 118 / 176], [train main loss -1.860984], [lr 0.006686] [batchtime 0.425]
[epoch 58], [iter 119 / 176], [train main loss -1.889134], [lr 0.006686] [batchtime 0.424]
[epoch 58], [iter 120 / 176], [train main loss -1.866711], [lr 0.006686] [batchtime 0.424]
[epoch 58], [iter 121 / 176], [train main loss -1.851254], [lr 0.006686] [batchtime 0.424]
[epoch 58], [iter 122 / 176], [train main loss -1.863068], [lr 0.006686] [batchtime 0.424]
[epoch 58], [iter 123 / 176], [train main loss -1.858401], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 124 / 176], [train main loss -1.856404], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 125 / 176], [train main loss -1.850512], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 126 / 176], [train main loss -1.867692], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 127 / 176], [train main loss -1.844764], [lr 0.006686] [batchtime 0.422]
[epoch 58], [iter 128 / 176], [train main loss -1.834409], [lr 0.006686] [batchtime 0.422]
[epoch 58], [iter 129 / 176], [train main loss -1.842724], [lr 0.006686] [batchtime 0.422]
[epoch 58], [iter 130 / 176], [train main loss -1.845657], [lr 0.006686] [batchtime 0.423]
[epoch 58], [iter 131 / 176], [train main loss -1.843254], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 132 / 176], [train main loss -1.824671], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 133 / 176], [train main loss -1.834266], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 134 / 176], [train main loss -1.826850], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 135 / 176], [train main loss -1.814029], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 136 / 176], [train main loss -1.819130], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 137 / 176], [train main loss -1.833159], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 138 / 176], [train main loss -1.809785], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 139 / 176], [train main loss -1.827484], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 140 / 176], [train main loss -1.841774], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 141 / 176], [train main loss -1.842657], [lr 0.006686] [batchtime 0.431]
[epoch 58], [iter 142 / 176], [train main loss -1.854550], [lr 0.006686] [batchtime 0.431]
[epoch 58], [iter 143 / 176], [train main loss -1.850758], [lr 0.006686] [batchtime 0.431]
[epoch 58], [iter 144 / 176], [train main loss -1.850472], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 145 / 176], [train main loss -1.864394], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 146 / 176], [train main loss -1.869009], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 147 / 176], [train main loss -1.868048], [lr 0.006686] [batchtime 0.43]
[epoch 58], [iter 148 / 176], [train main loss -1.874112], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 149 / 176], [train main loss -1.858174], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 150 / 176], [train main loss -1.862831], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 151 / 176], [train main loss -1.862652], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 152 / 176], [train main loss -1.849485], [lr 0.006686] [batchtime 0.429]
[epoch 58], [iter 153 / 176], [train main loss -1.838178], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 154 / 176], [train main loss -1.844559], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 155 / 176], [train main loss -1.832061], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 156 / 176], [train main loss -1.823597], [lr 0.006686] [batchtime 0.428]
[epoch 58], [iter 157 / 176], [train main loss -1.818517], [lr 0.006686] [batchtime 0.427]
[epoch 58], [iter 158 / 176], [train main loss -1.831664], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 159 / 176], [train main loss -1.856327], [lr 0.006686] [batchtime 0.436]
[epoch 58], [iter 160 / 176], [train main loss -1.856198], [lr 0.006686] [batchtime 0.436]
[epoch 58], [iter 161 / 176], [train main loss -1.850243], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 162 / 176], [train main loss -1.849262], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 163 / 176], [train main loss -1.849618], [lr 0.006686] [batchtime 0.435]
[epoch 58], [iter 164 / 176], [train main loss -1.835523], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 165 / 176], [train main loss -1.835611], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 166 / 176], [train main loss -1.842899], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 167 / 176], [train main loss -1.835705], [lr 0.006686] [batchtime 0.434]
[epoch 58], [iter 168 / 176], [train main loss -1.816587], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 169 / 176], [train main loss -1.815383], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 170 / 176], [train main loss -1.812405], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 171 / 176], [train main loss -1.817053], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 172 / 176], [train main loss -1.819380], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 173 / 176], [train main loss -1.818769], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 174 / 176], [train main loss -1.833571], [lr 0.006686] [batchtime 0.432]
[epoch 58], [iter 175 / 176], [train main loss -1.829005], [lr 0.006686] [batchtime 0.433]
[epoch 58], [iter 176 / 176], [train main loss -1.844217], [lr 0.006686] [batchtime 0.433]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.33  35.13    0.04  0.04         0.97      0.96
   1  sidewalk          64.09   5.35    0.23  0.33         0.81      0.75
   2  building          83.51  25.20    0.05  0.14         0.95      0.88
   3  wall              11.60   0.09    5.54  2.08         0.15      0.32
   4  fence             14.68   0.21    5.10  0.71         0.16      0.59
   5  pole              31.45   0.44    1.56  0.62         0.39      0.62
   6  traffic light      4.61   0.01   20.05  0.63         0.05      0.61
   7  traffic sign       8.62   0.05   10.37  0.23         0.09      0.82
   8  vegetation        81.67  11.22    0.10  0.12         0.91      0.89
   9  terrain           34.61   0.30    1.42  0.47         0.41      0.68
  10  sky               93.23   3.71    0.04  0.03         0.96      0.97
  11  person            43.52   0.90    0.71  0.59         0.58      0.63
  12  rider              1.06   0.00   91.53  1.40         0.01      0.42
  13  car               82.35   6.50    0.09  0.13         0.92      0.89
  14  truck              0.45   0.00  218.09  1.23         0.00      0.45
  15  bus               11.05   0.02    3.05  5.00         0.25      0.17
  16  train              5.89   0.01   15.72  0.25         0.06      0.80
  17  motorcycle         0.54   0.00  184.48  0.67         0.01      0.60
  18  bicycle           29.45   0.21    0.89  1.50         0.53      0.40
Mean: 36.62
-----------------------------------------------------------------------------------------------------------
this : [epoch 58], [val loss 0.36516], [acc 0.89349], [acc_cls 0.43197], [mean_iu 0.36617], [fwavacc 0.81617]
best : [epoch 54], [val loss 0.37078], [acc 0.88969], [acc_cls 0.43663], [mean_iu 0.36741], [fwavacc 0.81009]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 59], [iter 1 / 176], [train main loss -3.743441], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 2 / 176], [train main loss -2.488190], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 3 / 176], [train main loss -2.491910], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 4 / 176], [train main loss -2.496759], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 5 / 176], [train main loss -2.073121], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 6 / 176], [train main loss -1.911863], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 7 / 176], [train main loss -1.455345], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 8 / 176], [train main loss -1.293870], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 9 / 176], [train main loss -1.267152], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 10 / 176], [train main loss -1.519169], [lr 0.006629] [batchtime 0]
[epoch 59], [iter 11 / 176], [train main loss -1.458635], [lr 0.006629] [batchtime 0.377]
[epoch 59], [iter 12 / 176], [train main loss -1.344755], [lr 0.006629] [batchtime 0.389]
[epoch 59], [iter 13 / 176], [train main loss -1.496755], [lr 0.006629] [batchtime 0.394]
[epoch 59], [iter 14 / 176], [train main loss -1.498643], [lr 0.006629] [batchtime 0.395]
[epoch 59], [iter 15 / 176], [train main loss -1.625116], [lr 0.006629] [batchtime 0.394]
[epoch 59], [iter 16 / 176], [train main loss -1.555115], [lr 0.006629] [batchtime 0.394]
[epoch 59], [iter 17 / 176], [train main loss -1.429082], [lr 0.006629] [batchtime 0.394]
[epoch 59], [iter 18 / 176], [train main loss -1.329289], [lr 0.006629] [batchtime 0.395]
[epoch 59], [iter 19 / 176], [train main loss -1.293042], [lr 0.006629] [batchtime 0.395]
[epoch 59], [iter 20 / 176], [train main loss -1.369452], [lr 0.006629] [batchtime 0.395]
[epoch 59], [iter 21 / 176], [train main loss -1.308456], [lr 0.006629] [batchtime 0.395]
[epoch 59], [iter 22 / 176], [train main loss -1.239978], [lr 0.006629] [batchtime 0.396]
[epoch 59], [iter 23 / 176], [train main loss -1.239196], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 24 / 176], [train main loss -1.212284], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 25 / 176], [train main loss -1.197905], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 26 / 176], [train main loss -1.261755], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 27 / 176], [train main loss -1.184470], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 28 / 176], [train main loss -1.234456], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 29 / 176], [train main loss -1.309201], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 30 / 176], [train main loss -1.292246], [lr 0.006629] [batchtime 0.398]
[epoch 59], [iter 31 / 176], [train main loss -1.392756], [lr 0.006629] [batchtime 0.398]
[epoch 59], [iter 32 / 176], [train main loss -1.357898], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 33 / 176], [train main loss -1.362753], [lr 0.006629] [batchtime 0.398]
[epoch 59], [iter 34 / 176], [train main loss -1.444729], [lr 0.006629] [batchtime 0.397]
[epoch 59], [iter 35 / 176], [train main loss -1.400776], [lr 0.006629] [batchtime 0.398]
[epoch 59], [iter 36 / 176], [train main loss -1.416611], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 37 / 176], [train main loss -1.428950], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 38 / 176], [train main loss -1.438834], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 39 / 176], [train main loss -1.411098], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 40 / 176], [train main loss -1.441148], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 41 / 176], [train main loss -1.421295], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 42 / 176], [train main loss -1.392919], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 43 / 176], [train main loss -1.401547], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 44 / 176], [train main loss -1.339300], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 45 / 176], [train main loss -1.317805], [lr 0.006629] [batchtime 0.417]
[epoch 59], [iter 46 / 176], [train main loss -1.323676], [lr 0.006629] [batchtime 0.416]
[epoch 59], [iter 47 / 176], [train main loss -1.307223], [lr 0.006629] [batchtime 0.416]
[epoch 59], [iter 48 / 176], [train main loss -1.324468], [lr 0.006629] [batchtime 0.416]
[epoch 59], [iter 49 / 176], [train main loss -1.349191], [lr 0.006629] [batchtime 0.415]
[epoch 59], [iter 50 / 176], [train main loss -1.343436], [lr 0.006629] [batchtime 0.415]
[epoch 59], [iter 51 / 176], [train main loss -1.290877], [lr 0.006629] [batchtime 0.414]
[epoch 59], [iter 52 / 176], [train main loss -1.273425], [lr 0.006629] [batchtime 0.414]
[epoch 59], [iter 53 / 176], [train main loss -1.233974], [lr 0.006629] [batchtime 0.414]
[epoch 59], [iter 54 / 176], [train main loss -1.293729], [lr 0.006629] [batchtime 0.414]
[epoch 59], [iter 55 / 176], [train main loss -1.300860], [lr 0.006629] [batchtime 0.413]
[epoch 59], [iter 56 / 176], [train main loss -1.281548], [lr 0.006629] [batchtime 0.413]
[epoch 59], [iter 57 / 176], [train main loss -1.291753], [lr 0.006629] [batchtime 0.413]
[epoch 59], [iter 58 / 176], [train main loss -1.301887], [lr 0.006629] [batchtime 0.413]
[epoch 59], [iter 59 / 176], [train main loss -1.343863], [lr 0.006629] [batchtime 0.412]
[epoch 59], [iter 60 / 176], [train main loss -1.352620], [lr 0.006629] [batchtime 0.412]
[epoch 59], [iter 61 / 176], [train main loss -1.361330], [lr 0.006629] [batchtime 0.412]
[epoch 59], [iter 62 / 176], [train main loss -1.382606], [lr 0.006629] [batchtime 0.412]
[epoch 59], [iter 63 / 176], [train main loss -1.370326], [lr 0.006629] [batchtime 0.411]
[epoch 59], [iter 64 / 176], [train main loss -1.369819], [lr 0.006629] [batchtime 0.411]
[epoch 59], [iter 65 / 176], [train main loss -1.326490], [lr 0.006629] [batchtime 0.411]
[epoch 59], [iter 66 / 176], [train main loss -1.347496], [lr 0.006629] [batchtime 0.411]
[epoch 59], [iter 67 / 176], [train main loss -1.336855], [lr 0.006629] [batchtime 0.41]
[epoch 59], [iter 68 / 176], [train main loss -1.349532], [lr 0.006629] [batchtime 0.41]
[epoch 59], [iter 69 / 176], [train main loss -1.375415], [lr 0.006629] [batchtime 0.41]
[epoch 59], [iter 70 / 176], [train main loss -1.406866], [lr 0.006629] [batchtime 0.41]
[epoch 59], [iter 71 / 176], [train main loss -1.383617], [lr 0.006629] [batchtime 0.41]
[epoch 59], [iter 72 / 176], [train main loss -1.408335], [lr 0.006629] [batchtime 0.409]
[epoch 59], [iter 73 / 176], [train main loss -1.492374], [lr 0.006629] [batchtime 0.409]
[epoch 59], [iter 74 / 176], [train main loss -1.453879], [lr 0.006629] [batchtime 0.409]
[epoch 59], [iter 75 / 176], [train main loss -1.458487], [lr 0.006629] [batchtime 0.409]
[epoch 59], [iter 76 / 176], [train main loss -1.493226], [lr 0.006629] [batchtime 0.409]
[epoch 59], [iter 77 / 176], [train main loss -1.497176], [lr 0.006629] [batchtime 0.408]
[epoch 59], [iter 78 / 176], [train main loss -1.506469], [lr 0.006629] [batchtime 0.408]
[epoch 59], [iter 79 / 176], [train main loss -1.518897], [lr 0.006629] [batchtime 0.408]
[epoch 59], [iter 80 / 176], [train main loss -1.509258], [lr 0.006629] [batchtime 0.408]
[epoch 59], [iter 81 / 176], [train main loss -1.539528], [lr 0.006629] [batchtime 0.408]
[epoch 59], [iter 82 / 176], [train main loss -1.548068], [lr 0.006629] [batchtime 0.408]
[epoch 59], [iter 83 / 176], [train main loss -1.565476], [lr 0.006629] [batchtime 0.407]
[epoch 59], [iter 84 / 176], [train main loss -1.559113], [lr 0.006629] [batchtime 0.41]
[epoch 59], [iter 85 / 176], [train main loss -1.562673], [lr 0.006629] [batchtime 0.428]
[epoch 59], [iter 86 / 176], [train main loss -1.572557], [lr 0.006629] [batchtime 0.427]
[epoch 59], [iter 87 / 176], [train main loss -1.533855], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 88 / 176], [train main loss -1.529852], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 89 / 176], [train main loss -1.529409], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 90 / 176], [train main loss -1.529821], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 91 / 176], [train main loss -1.503990], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 92 / 176], [train main loss -1.524570], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 93 / 176], [train main loss -1.505285], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 94 / 176], [train main loss -1.497791], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 95 / 176], [train main loss -1.508511], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 96 / 176], [train main loss -1.516889], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 97 / 176], [train main loss -1.539274], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 98 / 176], [train main loss -1.534082], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 99 / 176], [train main loss -1.513916], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 100 / 176], [train main loss -1.511173], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 101 / 176], [train main loss -1.517720], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 102 / 176], [train main loss -1.521206], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 103 / 176], [train main loss -1.508862], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 104 / 176], [train main loss -1.504867], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 105 / 176], [train main loss -1.499616], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 106 / 176], [train main loss -1.508767], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 107 / 176], [train main loss -1.528783], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 108 / 176], [train main loss -1.548871], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 109 / 176], [train main loss -1.558015], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 110 / 176], [train main loss -1.574410], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 111 / 176], [train main loss -1.571858], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 112 / 176], [train main loss -1.576691], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 113 / 176], [train main loss -1.566942], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 114 / 176], [train main loss -1.586562], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 115 / 176], [train main loss -1.584742], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 116 / 176], [train main loss -1.593797], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 117 / 176], [train main loss -1.611699], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 118 / 176], [train main loss -1.610556], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 119 / 176], [train main loss -1.620051], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 120 / 176], [train main loss -1.614418], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 121 / 176], [train main loss -1.619571], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 122 / 176], [train main loss -1.615437], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 123 / 176], [train main loss -1.629702], [lr 0.006629] [batchtime 0.418]
[epoch 59], [iter 124 / 176], [train main loss -1.662023], [lr 0.006629] [batchtime 0.417]
[epoch 59], [iter 125 / 176], [train main loss -1.659802], [lr 0.006629] [batchtime 0.417]
[epoch 59], [iter 126 / 176], [train main loss -1.677995], [lr 0.006629] [batchtime 0.417]
[epoch 59], [iter 127 / 176], [train main loss -1.668187], [lr 0.006629] [batchtime 0.417]
[epoch 59], [iter 128 / 176], [train main loss -1.690800], [lr 0.006629] [batchtime 0.417]
[epoch 59], [iter 129 / 176], [train main loss -1.684439], [lr 0.006629] [batchtime 0.416]
[epoch 59], [iter 130 / 176], [train main loss -1.692368], [lr 0.006629] [batchtime 0.416]
[epoch 59], [iter 131 / 176], [train main loss -1.713488], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 132 / 176], [train main loss -1.705318], [lr 0.006629] [batchtime 0.428]
[epoch 59], [iter 133 / 176], [train main loss -1.703953], [lr 0.006629] [batchtime 0.428]
[epoch 59], [iter 134 / 176], [train main loss -1.711349], [lr 0.006629] [batchtime 0.428]
[epoch 59], [iter 135 / 176], [train main loss -1.715420], [lr 0.006629] [batchtime 0.427]
[epoch 59], [iter 136 / 176], [train main loss -1.724023], [lr 0.006629] [batchtime 0.427]
[epoch 59], [iter 137 / 176], [train main loss -1.726477], [lr 0.006629] [batchtime 0.427]
[epoch 59], [iter 138 / 176], [train main loss -1.728598], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 139 / 176], [train main loss -1.735221], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 140 / 176], [train main loss -1.724547], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 141 / 176], [train main loss -1.728910], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 142 / 176], [train main loss -1.739449], [lr 0.006629] [batchtime 0.426]
[epoch 59], [iter 143 / 176], [train main loss -1.737788], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 144 / 176], [train main loss -1.752595], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 145 / 176], [train main loss -1.757998], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 146 / 176], [train main loss -1.782539], [lr 0.006629] [batchtime 0.425]
[epoch 59], [iter 147 / 176], [train main loss -1.787736], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 148 / 176], [train main loss -1.793835], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 149 / 176], [train main loss -1.804205], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 150 / 176], [train main loss -1.792938], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 151 / 176], [train main loss -1.786850], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 152 / 176], [train main loss -1.774223], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 153 / 176], [train main loss -1.790198], [lr 0.006629] [batchtime 0.424]
[epoch 59], [iter 154 / 176], [train main loss -1.785111], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 155 / 176], [train main loss -1.772835], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 156 / 176], [train main loss -1.780412], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 157 / 176], [train main loss -1.781072], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 158 / 176], [train main loss -1.783142], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 159 / 176], [train main loss -1.801878], [lr 0.006629] [batchtime 0.423]
[epoch 59], [iter 160 / 176], [train main loss -1.801682], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 161 / 176], [train main loss -1.789867], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 162 / 176], [train main loss -1.779413], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 163 / 176], [train main loss -1.773796], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 164 / 176], [train main loss -1.789144], [lr 0.006629] [batchtime 0.422]
[epoch 59], [iter 165 / 176], [train main loss -1.783607], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 166 / 176], [train main loss -1.796418], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 167 / 176], [train main loss -1.770646], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 168 / 176], [train main loss -1.776806], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 169 / 176], [train main loss -1.787350], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 170 / 176], [train main loss -1.785810], [lr 0.006629] [batchtime 0.421]
[epoch 59], [iter 171 / 176], [train main loss -1.777535], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 172 / 176], [train main loss -1.775481], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 173 / 176], [train main loss -1.770467], [lr 0.006629] [batchtime 0.42]
[epoch 59], [iter 174 / 176], [train main loss -1.747744], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 175 / 176], [train main loss -1.754056], [lr 0.006629] [batchtime 0.419]
[epoch 59], [iter 176 / 176], [train main loss -1.762802], [lr 0.006629] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.77  35.10    0.04  0.03         0.97      0.97
   1  sidewalk          65.82   5.50    0.20  0.32         0.83      0.76
   2  building          83.77  24.75    0.07  0.12         0.93      0.89
   3  wall              13.98   0.15    3.07  3.08         0.25      0.24
   4  fence             13.87   0.21    5.17  1.05         0.16      0.49
   5  pole              30.37   0.42    1.73  0.57         0.37      0.64
   6  traffic light      3.70   0.01   25.59  0.41         0.04      0.71
   7  traffic sign       9.60   0.06    9.11  0.30         0.10      0.77
   8  vegetation        80.61  11.44    0.08  0.16         0.93      0.86
   9  terrain           37.30   0.37    1.01  0.67         0.50      0.60
  10  sky               93.00   3.75    0.03  0.04         0.97      0.96
  11  person            42.57   0.83    0.85  0.50         0.54      0.67
  12  rider              1.15   0.00   84.03  1.65         0.01      0.38
  13  car               83.32   6.53    0.08  0.12         0.92      0.90
  14  truck              0.46   0.00  217.83  0.79         0.00      0.56
  15  bus               10.74   0.01    5.22  3.09         0.16      0.24
  16  train             27.90   0.06    2.17  0.42         0.32      0.70
  17  motorcycle         0.35   0.00  284.00  0.50         0.00      0.67
  18  bicycle           28.53   0.23    0.72  1.78         0.58      0.36
Mean: 37.94
-----------------------------------------------------------------------------------------------------------
this : [epoch 59], [val loss 0.37427], [acc 0.89394], [acc_cls 0.45134], [mean_iu 0.37937], [fwavacc 0.81923]
best : [epoch 59], [val loss 0.37427], [acc 0.89394], [acc_cls 0.45134], [mean_iu 0.37937], [fwavacc 0.81923]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 60], [iter 1 / 176], [train main loss 0.134080], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 2 / 176], [train main loss -1.561826], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 3 / 176], [train main loss -1.730052], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 4 / 176], [train main loss -2.065346], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 5 / 176], [train main loss -2.376313], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 6 / 176], [train main loss -2.167131], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 7 / 176], [train main loss -2.358839], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 8 / 176], [train main loss -2.594253], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 9 / 176], [train main loss -2.391616], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 10 / 176], [train main loss -2.471616], [lr 0.006571] [batchtime 0]
[epoch 60], [iter 11 / 176], [train main loss -2.523087], [lr 0.006571] [batchtime 0.365]
[epoch 60], [iter 12 / 176], [train main loss -2.420742], [lr 0.006571] [batchtime 0.383]
[epoch 60], [iter 13 / 176], [train main loss -2.492008], [lr 0.006571] [batchtime 0.389]
[epoch 60], [iter 14 / 176], [train main loss -2.380173], [lr 0.006571] [batchtime 0.393]
[epoch 60], [iter 15 / 176], [train main loss -2.350783], [lr 0.006571] [batchtime 0.391]
[epoch 60], [iter 16 / 176], [train main loss -2.270349], [lr 0.006571] [batchtime 0.392]
[epoch 60], [iter 17 / 176], [train main loss -2.183108], [lr 0.006571] [batchtime 0.393]
[epoch 60], [iter 18 / 176], [train main loss -2.051797], [lr 0.006571] [batchtime 0.395]
[epoch 60], [iter 19 / 176], [train main loss -2.184129], [lr 0.006571] [batchtime 0.398]
[epoch 60], [iter 20 / 176], [train main loss -2.095937], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 21 / 176], [train main loss -1.988205], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 22 / 176], [train main loss -1.889528], [lr 0.006571] [batchtime 0.4]
[epoch 60], [iter 23 / 176], [train main loss -1.934540], [lr 0.006571] [batchtime 0.4]
[epoch 60], [iter 24 / 176], [train main loss -1.903972], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 25 / 176], [train main loss -2.021540], [lr 0.006571] [batchtime 0.4]
[epoch 60], [iter 26 / 176], [train main loss -1.954905], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 27 / 176], [train main loss -1.927277], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 28 / 176], [train main loss -1.956757], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 29 / 176], [train main loss -1.990218], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 30 / 176], [train main loss -1.855298], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 31 / 176], [train main loss -1.821629], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 32 / 176], [train main loss -1.883452], [lr 0.006571] [batchtime 0.399]
[epoch 60], [iter 33 / 176], [train main loss -1.881622], [lr 0.006571] [batchtime 0.464]
[epoch 60], [iter 34 / 176], [train main loss -1.838498], [lr 0.006571] [batchtime 0.466]
[epoch 60], [iter 35 / 176], [train main loss -1.888833], [lr 0.006571] [batchtime 0.463]
[epoch 60], [iter 36 / 176], [train main loss -1.841362], [lr 0.006571] [batchtime 0.46]
[epoch 60], [iter 37 / 176], [train main loss -1.815611], [lr 0.006571] [batchtime 0.458]
[epoch 60], [iter 38 / 176], [train main loss -1.832811], [lr 0.006571] [batchtime 0.456]
[epoch 60], [iter 39 / 176], [train main loss -1.800235], [lr 0.006571] [batchtime 0.454]
[epoch 60], [iter 40 / 176], [train main loss -1.778097], [lr 0.006571] [batchtime 0.452]
[epoch 60], [iter 41 / 176], [train main loss -1.760150], [lr 0.006571] [batchtime 0.45]
[epoch 60], [iter 42 / 176], [train main loss -1.781730], [lr 0.006571] [batchtime 0.449]
[epoch 60], [iter 43 / 176], [train main loss -1.814790], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 44 / 176], [train main loss -1.819643], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 45 / 176], [train main loss -1.776656], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 46 / 176], [train main loss -1.754698], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 47 / 176], [train main loss -1.739801], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 48 / 176], [train main loss -1.773147], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 49 / 176], [train main loss -1.785076], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 50 / 176], [train main loss -1.769642], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 51 / 176], [train main loss -1.726884], [lr 0.006571] [batchtime 0.438]
[epoch 60], [iter 52 / 176], [train main loss -1.788336], [lr 0.006571] [batchtime 0.437]
[epoch 60], [iter 53 / 176], [train main loss -1.799551], [lr 0.006571] [batchtime 0.436]
[epoch 60], [iter 54 / 176], [train main loss -1.775842], [lr 0.006571] [batchtime 0.436]
[epoch 60], [iter 55 / 176], [train main loss -1.733220], [lr 0.006571] [batchtime 0.435]
[epoch 60], [iter 56 / 176], [train main loss -1.659643], [lr 0.006571] [batchtime 0.434]
[epoch 60], [iter 57 / 176], [train main loss -1.670114], [lr 0.006571] [batchtime 0.433]
[epoch 60], [iter 58 / 176], [train main loss -1.691639], [lr 0.006571] [batchtime 0.433]
[epoch 60], [iter 59 / 176], [train main loss -1.689210], [lr 0.006571] [batchtime 0.432]
[epoch 60], [iter 60 / 176], [train main loss -1.690919], [lr 0.006571] [batchtime 0.431]
[epoch 60], [iter 61 / 176], [train main loss -1.684444], [lr 0.006571] [batchtime 0.43]
[epoch 60], [iter 62 / 176], [train main loss -1.671531], [lr 0.006571] [batchtime 0.433]
[epoch 60], [iter 63 / 176], [train main loss -1.664185], [lr 0.006571] [batchtime 0.432]
[epoch 60], [iter 64 / 176], [train main loss -1.665845], [lr 0.006571] [batchtime 0.431]
[epoch 60], [iter 65 / 176], [train main loss -1.656692], [lr 0.006571] [batchtime 0.431]
[epoch 60], [iter 66 / 176], [train main loss -1.626082], [lr 0.006571] [batchtime 0.43]
[epoch 60], [iter 67 / 176], [train main loss -1.608326], [lr 0.006571] [batchtime 0.43]
[epoch 60], [iter 68 / 176], [train main loss -1.609706], [lr 0.006571] [batchtime 0.429]
[epoch 60], [iter 69 / 176], [train main loss -1.615530], [lr 0.006571] [batchtime 0.428]
[epoch 60], [iter 70 / 176], [train main loss -1.617460], [lr 0.006571] [batchtime 0.428]
[epoch 60], [iter 71 / 176], [train main loss -1.657021], [lr 0.006571] [batchtime 0.427]
[epoch 60], [iter 72 / 176], [train main loss -1.628834], [lr 0.006571] [batchtime 0.427]
[epoch 60], [iter 73 / 176], [train main loss -1.608417], [lr 0.006571] [batchtime 0.426]
[epoch 60], [iter 74 / 176], [train main loss -1.590955], [lr 0.006571] [batchtime 0.426]
[epoch 60], [iter 75 / 176], [train main loss -1.610160], [lr 0.006571] [batchtime 0.425]
[epoch 60], [iter 76 / 176], [train main loss -1.600280], [lr 0.006571] [batchtime 0.425]
[epoch 60], [iter 77 / 176], [train main loss -1.563428], [lr 0.006571] [batchtime 0.424]
[epoch 60], [iter 78 / 176], [train main loss -1.574038], [lr 0.006571] [batchtime 0.428]
[epoch 60], [iter 79 / 176], [train main loss -1.583367], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 80 / 176], [train main loss -1.547950], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 81 / 176], [train main loss -1.546603], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 82 / 176], [train main loss -1.562648], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 83 / 176], [train main loss -1.551465], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 84 / 176], [train main loss -1.548492], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 85 / 176], [train main loss -1.536105], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 86 / 176], [train main loss -1.497355], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 87 / 176], [train main loss -1.521135], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 88 / 176], [train main loss -1.524038], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 89 / 176], [train main loss -1.522842], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 90 / 176], [train main loss -1.534071], [lr 0.006571] [batchtime 0.438]
[epoch 60], [iter 91 / 176], [train main loss -1.543335], [lr 0.006571] [batchtime 0.438]
[epoch 60], [iter 92 / 176], [train main loss -1.537665], [lr 0.006571] [batchtime 0.437]
[epoch 60], [iter 93 / 176], [train main loss -1.524187], [lr 0.006571] [batchtime 0.437]
[epoch 60], [iter 94 / 176], [train main loss -1.552147], [lr 0.006571] [batchtime 0.436]
[epoch 60], [iter 95 / 176], [train main loss -1.522408], [lr 0.006571] [batchtime 0.436]
[epoch 60], [iter 96 / 176], [train main loss -1.495017], [lr 0.006571] [batchtime 0.435]
[epoch 60], [iter 97 / 176], [train main loss -1.497417], [lr 0.006571] [batchtime 0.435]
[epoch 60], [iter 98 / 176], [train main loss -1.496456], [lr 0.006571] [batchtime 0.435]
[epoch 60], [iter 99 / 176], [train main loss -1.521051], [lr 0.006571] [batchtime 0.434]
[epoch 60], [iter 100 / 176], [train main loss -1.518721], [lr 0.006571] [batchtime 0.434]
[epoch 60], [iter 101 / 176], [train main loss -1.515207], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 102 / 176], [train main loss -1.541815], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 103 / 176], [train main loss -1.563053], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 104 / 176], [train main loss -1.576662], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 105 / 176], [train main loss -1.548455], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 106 / 176], [train main loss -1.552716], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 107 / 176], [train main loss -1.548632], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 108 / 176], [train main loss -1.590183], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 109 / 176], [train main loss -1.603475], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 110 / 176], [train main loss -1.615579], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 111 / 176], [train main loss -1.618963], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 112 / 176], [train main loss -1.618984], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 113 / 176], [train main loss -1.612522], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 114 / 176], [train main loss -1.586773], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 115 / 176], [train main loss -1.584818], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 116 / 176], [train main loss -1.570938], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 117 / 176], [train main loss -1.588502], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 118 / 176], [train main loss -1.578549], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 119 / 176], [train main loss -1.563300], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 120 / 176], [train main loss -1.562319], [lr 0.006571] [batchtime 0.438]
[epoch 60], [iter 121 / 176], [train main loss -1.555150], [lr 0.006571] [batchtime 0.438]
[epoch 60], [iter 122 / 176], [train main loss -1.554320], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 123 / 176], [train main loss -1.552641], [lr 0.006571] [batchtime 0.45]
[epoch 60], [iter 124 / 176], [train main loss -1.543223], [lr 0.006571] [batchtime 0.45]
[epoch 60], [iter 125 / 176], [train main loss -1.538620], [lr 0.006571] [batchtime 0.449]
[epoch 60], [iter 126 / 176], [train main loss -1.537050], [lr 0.006571] [batchtime 0.449]
[epoch 60], [iter 127 / 176], [train main loss -1.545852], [lr 0.006571] [batchtime 0.448]
[epoch 60], [iter 128 / 176], [train main loss -1.542556], [lr 0.006571] [batchtime 0.448]
[epoch 60], [iter 129 / 176], [train main loss -1.538489], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 130 / 176], [train main loss -1.544407], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 131 / 176], [train main loss -1.539469], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 132 / 176], [train main loss -1.530905], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 133 / 176], [train main loss -1.548690], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 134 / 176], [train main loss -1.557654], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 135 / 176], [train main loss -1.567514], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 136 / 176], [train main loss -1.561145], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 137 / 176], [train main loss -1.563411], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 138 / 176], [train main loss -1.559995], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 139 / 176], [train main loss -1.565740], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 140 / 176], [train main loss -1.574045], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 141 / 176], [train main loss -1.574871], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 142 / 176], [train main loss -1.560939], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 143 / 176], [train main loss -1.571588], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 144 / 176], [train main loss -1.563435], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 145 / 176], [train main loss -1.550791], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 146 / 176], [train main loss -1.555426], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 147 / 176], [train main loss -1.556377], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 148 / 176], [train main loss -1.552667], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 149 / 176], [train main loss -1.539309], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 150 / 176], [train main loss -1.533845], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 151 / 176], [train main loss -1.530023], [lr 0.006571] [batchtime 0.443]
[epoch 60], [iter 152 / 176], [train main loss -1.528901], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 153 / 176], [train main loss -1.539319], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 154 / 176], [train main loss -1.542642], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 155 / 176], [train main loss -1.535327], [lr 0.006571] [batchtime 0.442]
[epoch 60], [iter 156 / 176], [train main loss -1.546618], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 157 / 176], [train main loss -1.541491], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 158 / 176], [train main loss -1.543976], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 159 / 176], [train main loss -1.541245], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 160 / 176], [train main loss -1.558243], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 161 / 176], [train main loss -1.568457], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 162 / 176], [train main loss -1.568775], [lr 0.006571] [batchtime 0.44]
[epoch 60], [iter 163 / 176], [train main loss -1.562178], [lr 0.006571] [batchtime 0.439]
[epoch 60], [iter 164 / 176], [train main loss -1.563452], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 165 / 176], [train main loss -1.577368], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 166 / 176], [train main loss -1.545467], [lr 0.006571] [batchtime 0.441]
[epoch 60], [iter 167 / 176], [train main loss -1.544285], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 168 / 176], [train main loss -1.539527], [lr 0.006571] [batchtime 0.447]
[epoch 60], [iter 169 / 176], [train main loss -1.524435], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 170 / 176], [train main loss -1.528555], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 171 / 176], [train main loss -1.514067], [lr 0.006571] [batchtime 0.446]
[epoch 60], [iter 172 / 176], [train main loss -1.524189], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 173 / 176], [train main loss -1.521915], [lr 0.006571] [batchtime 0.445]
[epoch 60], [iter 174 / 176], [train main loss -1.523370], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 175 / 176], [train main loss -1.521467], [lr 0.006571] [batchtime 0.444]
[epoch 60], [iter 176 / 176], [train main loss -1.518098], [lr 0.006571] [batchtime 0.444]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.15  35.66    0.02  0.05         0.98      0.95
   1  sidewalk          61.30   4.68    0.41  0.22         0.71      0.82
   2  building          83.37  24.71    0.08  0.12         0.93      0.89
   3  wall              12.67   0.10    4.92  1.97         0.17      0.34
   4  fence              9.95   0.13    8.45  0.60         0.11      0.63
   5  pole              31.83   0.45    1.54  0.61         0.39      0.62
   6  traffic light      4.17   0.01   22.44  0.55         0.04      0.65
   7  traffic sign      11.25   0.07    7.56  0.34         0.12      0.75
   8  vegetation        79.63  11.60    0.07  0.19         0.94      0.84
   9  terrain           36.06   0.36    1.02  0.75         0.49      0.57
  10  sky               92.72   3.74    0.04  0.04         0.97      0.96
  11  person            42.23   0.79    0.93  0.43         0.52      0.70
  12  rider              0.82   0.00  120.36  1.04         0.01      0.49
  13  car               82.43   6.57    0.08  0.14         0.93      0.88
  14  truck              0.67   0.00  147.69  0.47         0.01      0.68
  15  bus               12.91   0.03    2.43  4.32         0.29      0.19
  16  train             19.00   0.04    3.89  0.38         0.20      0.73
  17  motorcycle         0.15   0.00  676.51  0.32         0.00      0.76
  18  bicycle           28.34   0.19    1.01  1.51         0.50      0.40
Mean: 36.98
-----------------------------------------------------------------------------------------------------------
this : [epoch 60], [val loss 0.37019], [acc 0.89119], [acc_cls 0.43700], [mean_iu 0.36982], [fwavacc 0.81041]
best : [epoch 59], [val loss 0.37427], [acc 0.89394], [acc_cls 0.45134], [mean_iu 0.37937], [fwavacc 0.81923]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 61], [iter 1 / 176], [train main loss -0.092558], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 2 / 176], [train main loss -1.088664], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 3 / 176], [train main loss -0.980412], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 4 / 176], [train main loss -1.692081], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 5 / 176], [train main loss -1.483630], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 6 / 176], [train main loss -1.276986], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 7 / 176], [train main loss -1.507203], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 8 / 176], [train main loss -1.687451], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 9 / 176], [train main loss -1.573837], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 10 / 176], [train main loss -1.480726], [lr 0.006514] [batchtime 0]
[epoch 61], [iter 11 / 176], [train main loss -1.705179], [lr 0.006514] [batchtime 0.373]
[epoch 61], [iter 12 / 176], [train main loss -1.653647], [lr 0.006514] [batchtime 0.383]
[epoch 61], [iter 13 / 176], [train main loss -1.598517], [lr 0.006514] [batchtime 0.387]
[epoch 61], [iter 14 / 176], [train main loss -1.566083], [lr 0.006514] [batchtime 0.391]
[epoch 61], [iter 15 / 176], [train main loss -1.604040], [lr 0.006514] [batchtime 0.392]
[epoch 61], [iter 16 / 176], [train main loss -1.641093], [lr 0.006514] [batchtime 0.392]
[epoch 61], [iter 17 / 176], [train main loss -1.569399], [lr 0.006514] [batchtime 0.395]
[epoch 61], [iter 18 / 176], [train main loss -1.589043], [lr 0.006514] [batchtime 0.396]
[epoch 61], [iter 19 / 176], [train main loss -1.583149], [lr 0.006514] [batchtime 0.397]
[epoch 61], [iter 20 / 176], [train main loss -1.606519], [lr 0.006514] [batchtime 0.396]
[epoch 61], [iter 21 / 176], [train main loss -1.623235], [lr 0.006514] [batchtime 0.396]
[epoch 61], [iter 22 / 176], [train main loss -1.610134], [lr 0.006514] [batchtime 0.407]
[epoch 61], [iter 23 / 176], [train main loss -1.597788], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 24 / 176], [train main loss -1.626517], [lr 0.006514] [batchtime 0.418]
[epoch 61], [iter 25 / 176], [train main loss -1.642073], [lr 0.006514] [batchtime 0.415]
[epoch 61], [iter 26 / 176], [train main loss -1.651283], [lr 0.006514] [batchtime 0.415]
[epoch 61], [iter 27 / 176], [train main loss -1.740078], [lr 0.006514] [batchtime 0.413]
[epoch 61], [iter 28 / 176], [train main loss -1.783255], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 29 / 176], [train main loss -1.792105], [lr 0.006514] [batchtime 0.463]
[epoch 61], [iter 30 / 176], [train main loss -1.796967], [lr 0.006514] [batchtime 0.459]
[epoch 61], [iter 31 / 176], [train main loss -1.771392], [lr 0.006514] [batchtime 0.456]
[epoch 61], [iter 32 / 176], [train main loss -1.822792], [lr 0.006514] [batchtime 0.453]
[epoch 61], [iter 33 / 176], [train main loss -1.722201], [lr 0.006514] [batchtime 0.45]
[epoch 61], [iter 34 / 176], [train main loss -1.830453], [lr 0.006514] [batchtime 0.448]
[epoch 61], [iter 35 / 176], [train main loss -1.809919], [lr 0.006514] [batchtime 0.445]
[epoch 61], [iter 36 / 176], [train main loss -1.765169], [lr 0.006514] [batchtime 0.443]
[epoch 61], [iter 37 / 176], [train main loss -1.795454], [lr 0.006514] [batchtime 0.441]
[epoch 61], [iter 38 / 176], [train main loss -1.800585], [lr 0.006514] [batchtime 0.44]
[epoch 61], [iter 39 / 176], [train main loss -1.860909], [lr 0.006514] [batchtime 0.438]
[epoch 61], [iter 40 / 176], [train main loss -1.821427], [lr 0.006514] [batchtime 0.436]
[epoch 61], [iter 41 / 176], [train main loss -1.838527], [lr 0.006514] [batchtime 0.435]
[epoch 61], [iter 42 / 176], [train main loss -1.823236], [lr 0.006514] [batchtime 0.434]
[epoch 61], [iter 43 / 176], [train main loss -1.797738], [lr 0.006514] [batchtime 0.433]
[epoch 61], [iter 44 / 176], [train main loss -1.794559], [lr 0.006514] [batchtime 0.44]
[epoch 61], [iter 45 / 176], [train main loss -1.860428], [lr 0.006514] [batchtime 0.442]
[epoch 61], [iter 46 / 176], [train main loss -1.942843], [lr 0.006514] [batchtime 0.44]
[epoch 61], [iter 47 / 176], [train main loss -1.907116], [lr 0.006514] [batchtime 0.439]
[epoch 61], [iter 48 / 176], [train main loss -1.909413], [lr 0.006514] [batchtime 0.438]
[epoch 61], [iter 49 / 176], [train main loss -1.948594], [lr 0.006514] [batchtime 0.437]
[epoch 61], [iter 50 / 176], [train main loss -1.972442], [lr 0.006514] [batchtime 0.436]
[epoch 61], [iter 51 / 176], [train main loss -1.996281], [lr 0.006514] [batchtime 0.435]
[epoch 61], [iter 52 / 176], [train main loss -1.976232], [lr 0.006514] [batchtime 0.434]
[epoch 61], [iter 53 / 176], [train main loss -2.002145], [lr 0.006514] [batchtime 0.433]
[epoch 61], [iter 54 / 176], [train main loss -2.022075], [lr 0.006514] [batchtime 0.432]
[epoch 61], [iter 55 / 176], [train main loss -2.006202], [lr 0.006514] [batchtime 0.431]
[epoch 61], [iter 56 / 176], [train main loss -1.990011], [lr 0.006514] [batchtime 0.431]
[epoch 61], [iter 57 / 176], [train main loss -2.024181], [lr 0.006514] [batchtime 0.43]
[epoch 61], [iter 58 / 176], [train main loss -2.023879], [lr 0.006514] [batchtime 0.43]
[epoch 61], [iter 59 / 176], [train main loss -2.065135], [lr 0.006514] [batchtime 0.429]
[epoch 61], [iter 60 / 176], [train main loss -2.059183], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 61 / 176], [train main loss -2.043843], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 62 / 176], [train main loss -2.030622], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 63 / 176], [train main loss -2.018351], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 64 / 176], [train main loss -2.060383], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 65 / 176], [train main loss -2.047953], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 66 / 176], [train main loss -2.067121], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 67 / 176], [train main loss -2.023316], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 68 / 176], [train main loss -1.997444], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 69 / 176], [train main loss -1.978912], [lr 0.006514] [batchtime 0.444]
[epoch 61], [iter 70 / 176], [train main loss -1.938354], [lr 0.006514] [batchtime 0.443]
[epoch 61], [iter 71 / 176], [train main loss -1.952623], [lr 0.006514] [batchtime 0.442]
[epoch 61], [iter 72 / 176], [train main loss -1.950892], [lr 0.006514] [batchtime 0.441]
[epoch 61], [iter 73 / 176], [train main loss -1.980460], [lr 0.006514] [batchtime 0.441]
[epoch 61], [iter 74 / 176], [train main loss -1.947548], [lr 0.006514] [batchtime 0.44]
[epoch 61], [iter 75 / 176], [train main loss -1.954296], [lr 0.006514] [batchtime 0.439]
[epoch 61], [iter 76 / 176], [train main loss -1.953963], [lr 0.006514] [batchtime 0.439]
[epoch 61], [iter 77 / 176], [train main loss -1.967006], [lr 0.006514] [batchtime 0.438]
[epoch 61], [iter 78 / 176], [train main loss -1.968072], [lr 0.006514] [batchtime 0.438]
[epoch 61], [iter 79 / 176], [train main loss -1.972245], [lr 0.006514] [batchtime 0.437]
[epoch 61], [iter 80 / 176], [train main loss -1.979212], [lr 0.006514] [batchtime 0.437]
[epoch 61], [iter 81 / 176], [train main loss -1.996207], [lr 0.006514] [batchtime 0.436]
[epoch 61], [iter 82 / 176], [train main loss -1.996263], [lr 0.006514] [batchtime 0.436]
[epoch 61], [iter 83 / 176], [train main loss -1.977437], [lr 0.006514] [batchtime 0.435]
[epoch 61], [iter 84 / 176], [train main loss -1.986658], [lr 0.006514] [batchtime 0.435]
[epoch 61], [iter 85 / 176], [train main loss -1.962229], [lr 0.006514] [batchtime 0.434]
[epoch 61], [iter 86 / 176], [train main loss -1.961382], [lr 0.006514] [batchtime 0.434]
[epoch 61], [iter 87 / 176], [train main loss -1.957956], [lr 0.006514] [batchtime 0.433]
[epoch 61], [iter 88 / 176], [train main loss -1.974399], [lr 0.006514] [batchtime 0.433]
[epoch 61], [iter 89 / 176], [train main loss -1.973133], [lr 0.006514] [batchtime 0.432]
[epoch 61], [iter 90 / 176], [train main loss -1.974756], [lr 0.006514] [batchtime 0.432]
[epoch 61], [iter 91 / 176], [train main loss -1.975344], [lr 0.006514] [batchtime 0.431]
[epoch 61], [iter 92 / 176], [train main loss -1.962559], [lr 0.006514] [batchtime 0.431]
[epoch 61], [iter 93 / 176], [train main loss -1.945682], [lr 0.006514] [batchtime 0.43]
[epoch 61], [iter 94 / 176], [train main loss -1.953953], [lr 0.006514] [batchtime 0.43]
[epoch 61], [iter 95 / 176], [train main loss -1.949968], [lr 0.006514] [batchtime 0.43]
[epoch 61], [iter 96 / 176], [train main loss -1.954355], [lr 0.006514] [batchtime 0.429]
[epoch 61], [iter 97 / 176], [train main loss -1.952705], [lr 0.006514] [batchtime 0.429]
[epoch 61], [iter 98 / 176], [train main loss -1.943942], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 99 / 176], [train main loss -1.943535], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 100 / 176], [train main loss -1.897143], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 101 / 176], [train main loss -1.878649], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 102 / 176], [train main loss -1.897706], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 103 / 176], [train main loss -1.867961], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 104 / 176], [train main loss -1.851393], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 105 / 176], [train main loss -1.844991], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 106 / 176], [train main loss -1.836592], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 107 / 176], [train main loss -1.845670], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 108 / 176], [train main loss -1.848063], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 109 / 176], [train main loss -1.852638], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 110 / 176], [train main loss -1.829013], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 111 / 176], [train main loss -1.826297], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 112 / 176], [train main loss -1.833138], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 113 / 176], [train main loss -1.818125], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 114 / 176], [train main loss -1.837305], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 115 / 176], [train main loss -1.814183], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 116 / 176], [train main loss -1.824913], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 117 / 176], [train main loss -1.821182], [lr 0.006514] [batchtime 0.429]
[epoch 61], [iter 118 / 176], [train main loss -1.798306], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 119 / 176], [train main loss -1.787027], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 120 / 176], [train main loss -1.789094], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 121 / 176], [train main loss -1.786760], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 122 / 176], [train main loss -1.801973], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 123 / 176], [train main loss -1.821007], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 124 / 176], [train main loss -1.801967], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 125 / 176], [train main loss -1.826330], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 126 / 176], [train main loss -1.812298], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 127 / 176], [train main loss -1.788260], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 128 / 176], [train main loss -1.781549], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 129 / 176], [train main loss -1.772363], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 130 / 176], [train main loss -1.755692], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 131 / 176], [train main loss -1.736078], [lr 0.006514] [batchtime 0.425]
[epoch 61], [iter 132 / 176], [train main loss -1.745182], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 133 / 176], [train main loss -1.731171], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 134 / 176], [train main loss -1.733840], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 135 / 176], [train main loss -1.756947], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 136 / 176], [train main loss -1.747382], [lr 0.006514] [batchtime 0.424]
[epoch 61], [iter 137 / 176], [train main loss -1.747825], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 138 / 176], [train main loss -1.752455], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 139 / 176], [train main loss -1.736833], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 140 / 176], [train main loss -1.739350], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 141 / 176], [train main loss -1.738037], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 142 / 176], [train main loss -1.736380], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 143 / 176], [train main loss -1.734503], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 144 / 176], [train main loss -1.751197], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 145 / 176], [train main loss -1.762727], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 146 / 176], [train main loss -1.759192], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 147 / 176], [train main loss -1.772383], [lr 0.006514] [batchtime 0.423]
[epoch 61], [iter 148 / 176], [train main loss -1.775491], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 149 / 176], [train main loss -1.768206], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 150 / 176], [train main loss -1.770810], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 151 / 176], [train main loss -1.761150], [lr 0.006514] [batchtime 0.422]
[epoch 61], [iter 152 / 176], [train main loss -1.763787], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 153 / 176], [train main loss -1.760613], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 154 / 176], [train main loss -1.764182], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 155 / 176], [train main loss -1.780707], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 156 / 176], [train main loss -1.781292], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 157 / 176], [train main loss -1.776053], [lr 0.006514] [batchtime 0.421]
[epoch 61], [iter 158 / 176], [train main loss -1.773406], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 159 / 176], [train main loss -1.771607], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 160 / 176], [train main loss -1.783418], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 161 / 176], [train main loss -1.793075], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 162 / 176], [train main loss -1.797687], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 163 / 176], [train main loss -1.796799], [lr 0.006514] [batchtime 0.419]
[epoch 61], [iter 164 / 176], [train main loss -1.791084], [lr 0.006514] [batchtime 0.42]
[epoch 61], [iter 165 / 176], [train main loss -1.771688], [lr 0.006514] [batchtime 0.429]
[epoch 61], [iter 166 / 176], [train main loss -1.769443], [lr 0.006514] [batchtime 0.429]
[epoch 61], [iter 167 / 176], [train main loss -1.770252], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 168 / 176], [train main loss -1.772787], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 169 / 176], [train main loss -1.775362], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 170 / 176], [train main loss -1.758438], [lr 0.006514] [batchtime 0.428]
[epoch 61], [iter 171 / 176], [train main loss -1.757619], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 172 / 176], [train main loss -1.762469], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 173 / 176], [train main loss -1.755877], [lr 0.006514] [batchtime 0.427]
[epoch 61], [iter 174 / 176], [train main loss -1.771591], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 175 / 176], [train main loss -1.764883], [lr 0.006514] [batchtime 0.426]
[epoch 61], [iter 176 / 176], [train main loss -1.754203], [lr 0.006514] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.04  34.29    0.06  0.03         0.94      0.97
   1  sidewalk          60.75   5.66    0.16  0.48         0.86      0.67
   2  building          83.92  24.87    0.07  0.12         0.94      0.89
   3  wall              13.32   0.11    4.23  2.28         0.19      0.31
   4  fence             17.93   0.27    3.67  0.91         0.21      0.52
   5  pole              32.77   0.47    1.44  0.61         0.41      0.62
   6  traffic light      4.08   0.01   23.09  0.45         0.04      0.69
   7  traffic sign       8.07   0.05   11.16  0.22         0.08      0.82
   8  vegetation        82.49  11.28    0.10  0.12         0.91      0.90
   9  terrain           34.72   0.33    1.24  0.64         0.45      0.61
  10  sky               92.26   3.78    0.02  0.06         0.98      0.94
  11  person            45.14   0.94    0.63  0.59         0.61      0.63
  12  rider              0.59   0.00  166.38  1.16         0.01      0.46
  13  car               83.26   6.58    0.07  0.13         0.93      0.89
  14  truck              0.68   0.00  144.85  1.95         0.01      0.34
  15  bus               11.36   0.02    3.21  4.59         0.24      0.18
  16  train             13.04   0.02    6.35  0.32         0.14      0.76
  17  motorcycle         0.29   0.00  345.77  0.55         0.00      0.64
  18  bicycle           30.01   0.23    0.72  1.61         0.58      0.38
Mean: 37.20
-----------------------------------------------------------------------------------------------------------
this : [epoch 61], [val loss 0.38360], [acc 0.88914], [acc_cls 0.44874], [mean_iu 0.37196], [fwavacc 0.81267]
best : [epoch 59], [val loss 0.37427], [acc 0.89394], [acc_cls 0.45134], [mean_iu 0.37937], [fwavacc 0.81923]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 62], [iter 1 / 176], [train main loss -2.032761], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 2 / 176], [train main loss -2.269830], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 3 / 176], [train main loss -2.071793], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 4 / 176], [train main loss -1.774775], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 5 / 176], [train main loss -2.007021], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 6 / 176], [train main loss -2.563038], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 7 / 176], [train main loss -2.338817], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 8 / 176], [train main loss -1.957213], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 9 / 176], [train main loss -1.965761], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 10 / 176], [train main loss -2.122561], [lr 0.006457] [batchtime 0]
[epoch 62], [iter 11 / 176], [train main loss -2.210206], [lr 0.006457] [batchtime 0.365]
[epoch 62], [iter 12 / 176], [train main loss -2.041697], [lr 0.006457] [batchtime 0.385]
[epoch 62], [iter 13 / 176], [train main loss -2.211885], [lr 0.006457] [batchtime 0.391]
[epoch 62], [iter 14 / 176], [train main loss -2.254175], [lr 0.006457] [batchtime 0.391]
[epoch 62], [iter 15 / 176], [train main loss -2.454667], [lr 0.006457] [batchtime 0.392]
[epoch 62], [iter 16 / 176], [train main loss -2.420300], [lr 0.006457] [batchtime 0.393]
[epoch 62], [iter 17 / 176], [train main loss -2.395184], [lr 0.006457] [batchtime 0.393]
[epoch 62], [iter 18 / 176], [train main loss -2.408282], [lr 0.006457] [batchtime 0.394]
[epoch 62], [iter 19 / 176], [train main loss -2.335773], [lr 0.006457] [batchtime 0.395]
[epoch 62], [iter 20 / 176], [train main loss -2.398579], [lr 0.006457] [batchtime 0.395]
[epoch 62], [iter 21 / 176], [train main loss -2.383508], [lr 0.006457] [batchtime 0.394]
[epoch 62], [iter 22 / 176], [train main loss -2.371295], [lr 0.006457] [batchtime 0.395]
[epoch 62], [iter 23 / 176], [train main loss -2.405808], [lr 0.006457] [batchtime 0.4]
[epoch 62], [iter 24 / 176], [train main loss -2.388317], [lr 0.006457] [batchtime 0.411]
[epoch 62], [iter 25 / 176], [train main loss -2.334073], [lr 0.006457] [batchtime 0.41]
[epoch 62], [iter 26 / 176], [train main loss -2.253893], [lr 0.006457] [batchtime 0.41]
[epoch 62], [iter 27 / 176], [train main loss -2.070548], [lr 0.006457] [batchtime 0.408]
[epoch 62], [iter 28 / 176], [train main loss -2.061023], [lr 0.006457] [batchtime 0.407]
[epoch 62], [iter 29 / 176], [train main loss -2.019633], [lr 0.006457] [batchtime 0.407]
[epoch 62], [iter 30 / 176], [train main loss -1.978784], [lr 0.006457] [batchtime 0.407]
[epoch 62], [iter 31 / 176], [train main loss -1.918170], [lr 0.006457] [batchtime 0.406]
[epoch 62], [iter 32 / 176], [train main loss -1.927737], [lr 0.006457] [batchtime 0.405]
[epoch 62], [iter 33 / 176], [train main loss -1.907066], [lr 0.006457] [batchtime 0.406]
[epoch 62], [iter 34 / 176], [train main loss -1.895986], [lr 0.006457] [batchtime 0.405]
[epoch 62], [iter 35 / 176], [train main loss -1.869838], [lr 0.006457] [batchtime 0.405]
[epoch 62], [iter 36 / 176], [train main loss -1.871677], [lr 0.006457] [batchtime 0.405]
[epoch 62], [iter 37 / 176], [train main loss -1.936514], [lr 0.006457] [batchtime 0.405]
[epoch 62], [iter 38 / 176], [train main loss -1.989128], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 39 / 176], [train main loss -2.062648], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 40 / 176], [train main loss -1.946185], [lr 0.006457] [batchtime 0.405]
[epoch 62], [iter 41 / 176], [train main loss -1.923500], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 42 / 176], [train main loss -1.881000], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 43 / 176], [train main loss -1.847341], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 44 / 176], [train main loss -1.866753], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 45 / 176], [train main loss -1.870382], [lr 0.006457] [batchtime 0.404]
[epoch 62], [iter 46 / 176], [train main loss -1.873970], [lr 0.006457] [batchtime 0.403]
[epoch 62], [iter 47 / 176], [train main loss -1.855241], [lr 0.006457] [batchtime 0.407]
[epoch 62], [iter 48 / 176], [train main loss -1.835141], [lr 0.006457] [batchtime 0.442]
[epoch 62], [iter 49 / 176], [train main loss -1.823689], [lr 0.006457] [batchtime 0.441]
[epoch 62], [iter 50 / 176], [train main loss -1.798244], [lr 0.006457] [batchtime 0.439]
[epoch 62], [iter 51 / 176], [train main loss -1.810791], [lr 0.006457] [batchtime 0.438]
[epoch 62], [iter 52 / 176], [train main loss -1.808949], [lr 0.006457] [batchtime 0.437]
[epoch 62], [iter 53 / 176], [train main loss -1.816646], [lr 0.006457] [batchtime 0.436]
[epoch 62], [iter 54 / 176], [train main loss -1.865225], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 55 / 176], [train main loss -1.875251], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 56 / 176], [train main loss -1.864642], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 57 / 176], [train main loss -1.832751], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 58 / 176], [train main loss -1.843521], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 59 / 176], [train main loss -1.824831], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 60 / 176], [train main loss -1.779472], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 61 / 176], [train main loss -1.766608], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 62 / 176], [train main loss -1.771383], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 63 / 176], [train main loss -1.741309], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 64 / 176], [train main loss -1.771449], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 65 / 176], [train main loss -1.748631], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 66 / 176], [train main loss -1.767672], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 67 / 176], [train main loss -1.734549], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 68 / 176], [train main loss -1.752885], [lr 0.006457] [batchtime 0.426]
[epoch 62], [iter 69 / 176], [train main loss -1.738702], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 70 / 176], [train main loss -1.693973], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 71 / 176], [train main loss -1.735300], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 72 / 176], [train main loss -1.743105], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 73 / 176], [train main loss -1.754633], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 74 / 176], [train main loss -1.757632], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 75 / 176], [train main loss -1.732969], [lr 0.006457] [batchtime 0.426]
[epoch 62], [iter 76 / 176], [train main loss -1.710250], [lr 0.006457] [batchtime 0.426]
[epoch 62], [iter 77 / 176], [train main loss -1.700761], [lr 0.006457] [batchtime 0.425]
[epoch 62], [iter 78 / 176], [train main loss -1.702766], [lr 0.006457] [batchtime 0.425]
[epoch 62], [iter 79 / 176], [train main loss -1.727591], [lr 0.006457] [batchtime 0.424]
[epoch 62], [iter 80 / 176], [train main loss -1.739648], [lr 0.006457] [batchtime 0.424]
[epoch 62], [iter 81 / 176], [train main loss -1.723379], [lr 0.006457] [batchtime 0.424]
[epoch 62], [iter 82 / 176], [train main loss -1.716507], [lr 0.006457] [batchtime 0.423]
[epoch 62], [iter 83 / 176], [train main loss -1.721301], [lr 0.006457] [batchtime 0.423]
[epoch 62], [iter 84 / 176], [train main loss -1.724767], [lr 0.006457] [batchtime 0.423]
[epoch 62], [iter 85 / 176], [train main loss -1.684158], [lr 0.006457] [batchtime 0.422]
[epoch 62], [iter 86 / 176], [train main loss -1.646767], [lr 0.006457] [batchtime 0.422]
[epoch 62], [iter 87 / 176], [train main loss -1.658414], [lr 0.006457] [batchtime 0.422]
[epoch 62], [iter 88 / 176], [train main loss -1.677999], [lr 0.006457] [batchtime 0.421]
[epoch 62], [iter 89 / 176], [train main loss -1.714340], [lr 0.006457] [batchtime 0.421]
[epoch 62], [iter 90 / 176], [train main loss -1.701998], [lr 0.006457] [batchtime 0.421]
[epoch 62], [iter 91 / 176], [train main loss -1.702125], [lr 0.006457] [batchtime 0.42]
[epoch 62], [iter 92 / 176], [train main loss -1.681456], [lr 0.006457] [batchtime 0.42]
[epoch 62], [iter 93 / 176], [train main loss -1.701454], [lr 0.006457] [batchtime 0.42]
[epoch 62], [iter 94 / 176], [train main loss -1.705489], [lr 0.006457] [batchtime 0.438]
[epoch 62], [iter 95 / 176], [train main loss -1.713876], [lr 0.006457] [batchtime 0.438]
[epoch 62], [iter 96 / 176], [train main loss -1.690234], [lr 0.006457] [batchtime 0.437]
[epoch 62], [iter 97 / 176], [train main loss -1.700039], [lr 0.006457] [batchtime 0.438]
[epoch 62], [iter 98 / 176], [train main loss -1.710740], [lr 0.006457] [batchtime 0.437]
[epoch 62], [iter 99 / 176], [train main loss -1.709998], [lr 0.006457] [batchtime 0.437]
[epoch 62], [iter 100 / 176], [train main loss -1.678546], [lr 0.006457] [batchtime 0.436]
[epoch 62], [iter 101 / 176], [train main loss -1.653249], [lr 0.006457] [batchtime 0.436]
[epoch 62], [iter 102 / 176], [train main loss -1.652117], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 103 / 176], [train main loss -1.642386], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 104 / 176], [train main loss -1.641704], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 105 / 176], [train main loss -1.634037], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 106 / 176], [train main loss -1.624428], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 107 / 176], [train main loss -1.636514], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 108 / 176], [train main loss -1.619132], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 109 / 176], [train main loss -1.621023], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 110 / 176], [train main loss -1.627293], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 111 / 176], [train main loss -1.623863], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 112 / 176], [train main loss -1.612068], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 113 / 176], [train main loss -1.629800], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 114 / 176], [train main loss -1.619529], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 115 / 176], [train main loss -1.617610], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 116 / 176], [train main loss -1.642997], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 117 / 176], [train main loss -1.632607], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 118 / 176], [train main loss -1.614622], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 119 / 176], [train main loss -1.611260], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 120 / 176], [train main loss -1.604340], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 121 / 176], [train main loss -1.587513], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 122 / 176], [train main loss -1.602624], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 123 / 176], [train main loss -1.605130], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 124 / 176], [train main loss -1.613318], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 125 / 176], [train main loss -1.608801], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 126 / 176], [train main loss -1.604955], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 127 / 176], [train main loss -1.606189], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 128 / 176], [train main loss -1.627104], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 129 / 176], [train main loss -1.626781], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 130 / 176], [train main loss -1.601728], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 131 / 176], [train main loss -1.600833], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 132 / 176], [train main loss -1.607977], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 133 / 176], [train main loss -1.613961], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 134 / 176], [train main loss -1.620386], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 135 / 176], [train main loss -1.622718], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 136 / 176], [train main loss -1.619335], [lr 0.006457] [batchtime 0.427]
[epoch 62], [iter 137 / 176], [train main loss -1.621354], [lr 0.006457] [batchtime 0.426]
[epoch 62], [iter 138 / 176], [train main loss -1.611825], [lr 0.006457] [batchtime 0.426]
[epoch 62], [iter 139 / 176], [train main loss -1.603251], [lr 0.006457] [batchtime 0.428]
[epoch 62], [iter 140 / 176], [train main loss -1.603562], [lr 0.006457] [batchtime 0.438]
[epoch 62], [iter 141 / 176], [train main loss -1.624970], [lr 0.006457] [batchtime 0.437]
[epoch 62], [iter 142 / 176], [train main loss -1.616130], [lr 0.006457] [batchtime 0.437]
[epoch 62], [iter 143 / 176], [train main loss -1.633994], [lr 0.006457] [batchtime 0.436]
[epoch 62], [iter 144 / 176], [train main loss -1.633448], [lr 0.006457] [batchtime 0.436]
[epoch 62], [iter 145 / 176], [train main loss -1.653073], [lr 0.006457] [batchtime 0.436]
[epoch 62], [iter 146 / 176], [train main loss -1.648148], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 147 / 176], [train main loss -1.648669], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 148 / 176], [train main loss -1.642549], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 149 / 176], [train main loss -1.626536], [lr 0.006457] [batchtime 0.435]
[epoch 62], [iter 150 / 176], [train main loss -1.642804], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 151 / 176], [train main loss -1.650302], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 152 / 176], [train main loss -1.666295], [lr 0.006457] [batchtime 0.434]
[epoch 62], [iter 153 / 176], [train main loss -1.656879], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 154 / 176], [train main loss -1.661975], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 155 / 176], [train main loss -1.663783], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 156 / 176], [train main loss -1.678963], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 157 / 176], [train main loss -1.684243], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 158 / 176], [train main loss -1.678356], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 159 / 176], [train main loss -1.660367], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 160 / 176], [train main loss -1.656393], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 161 / 176], [train main loss -1.671992], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 162 / 176], [train main loss -1.672212], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 163 / 176], [train main loss -1.681596], [lr 0.006457] [batchtime 0.433]
[epoch 62], [iter 164 / 176], [train main loss -1.688879], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 165 / 176], [train main loss -1.678051], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 166 / 176], [train main loss -1.694080], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 167 / 176], [train main loss -1.690798], [lr 0.006457] [batchtime 0.432]
[epoch 62], [iter 168 / 176], [train main loss -1.695443], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 169 / 176], [train main loss -1.693917], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 170 / 176], [train main loss -1.690231], [lr 0.006457] [batchtime 0.431]
[epoch 62], [iter 171 / 176], [train main loss -1.698408], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 172 / 176], [train main loss -1.697892], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 173 / 176], [train main loss -1.686460], [lr 0.006457] [batchtime 0.43]
[epoch 62], [iter 174 / 176], [train main loss -1.697103], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 175 / 176], [train main loss -1.691164], [lr 0.006457] [batchtime 0.429]
[epoch 62], [iter 176 / 176], [train main loss -1.662394], [lr 0.006457] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.38  35.31    0.03  0.04         0.97      0.96
   1  sidewalk          63.00   4.76    0.39  0.20         0.72      0.83
   2  building          83.68  24.89    0.07  0.13         0.94      0.89
   3  wall              13.90   0.12    3.78  2.41         0.21      0.29
   4  fence             18.10   0.27    3.74  0.79         0.21      0.56
   5  pole              29.89   0.40    1.86  0.49         0.35      0.67
   6  traffic light      4.56   0.01   20.47  0.45         0.05      0.69
   7  traffic sign       9.61   0.06    9.12  0.28         0.10      0.78
   8  vegetation        80.50  11.56    0.07  0.17         0.93      0.85
   9  terrain           38.81   0.37    0.97  0.61         0.51      0.62
  10  sky               92.77   3.73    0.04  0.04         0.96      0.96
  11  person            43.55   0.87    0.76  0.54         0.57      0.65
  12  rider              1.68   0.00   57.01  1.53         0.02      0.39
  13  car               80.05   6.62    0.07  0.18         0.94      0.85
  14  truck              1.17   0.00   83.68  1.06         0.01      0.49
  15  bus               11.30   0.03    2.06  5.78         0.33      0.15
  16  train             15.51   0.03    4.72  0.73         0.17      0.58
  17  motorcycle         0.72   0.00  136.86  1.11         0.01      0.47
  18  bicycle           30.88   0.19    1.04  1.20         0.49      0.46
Mean: 37.53
-----------------------------------------------------------------------------------------------------------
this : [epoch 62], [val loss 0.35869], [acc 0.89230], [acc_cls 0.44654], [mean_iu 0.37529], [fwavacc 0.81383]
best : [epoch 59], [val loss 0.37427], [acc 0.89394], [acc_cls 0.45134], [mean_iu 0.37937], [fwavacc 0.81923]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 63], [iter 1 / 176], [train main loss 1.497218], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 2 / 176], [train main loss 0.097454], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 3 / 176], [train main loss -1.076447], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 4 / 176], [train main loss -1.663020], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 5 / 176], [train main loss -1.459706], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 6 / 176], [train main loss -1.781752], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 7 / 176], [train main loss -1.979216], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 8 / 176], [train main loss -1.726924], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 9 / 176], [train main loss -1.725903], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 10 / 176], [train main loss -1.942613], [lr 0.006400] [batchtime 0]
[epoch 63], [iter 11 / 176], [train main loss -1.900960], [lr 0.006400] [batchtime 0.378]
[epoch 63], [iter 12 / 176], [train main loss -2.124384], [lr 0.006400] [batchtime 0.392]
[epoch 63], [iter 13 / 176], [train main loss -2.122321], [lr 0.006400] [batchtime 0.396]
[epoch 63], [iter 14 / 176], [train main loss -2.242667], [lr 0.006400] [batchtime 0.398]
[epoch 63], [iter 15 / 176], [train main loss -2.080342], [lr 0.006400] [batchtime 0.399]
[epoch 63], [iter 16 / 176], [train main loss -1.945539], [lr 0.006400] [batchtime 0.399]
[epoch 63], [iter 17 / 176], [train main loss -1.874036], [lr 0.006400] [batchtime 0.398]
[epoch 63], [iter 18 / 176], [train main loss -1.806208], [lr 0.006400] [batchtime 0.399]
[epoch 63], [iter 19 / 176], [train main loss -1.754366], [lr 0.006400] [batchtime 0.399]
[epoch 63], [iter 20 / 176], [train main loss -1.759443], [lr 0.006400] [batchtime 0.398]
[epoch 63], [iter 21 / 176], [train main loss -1.768847], [lr 0.006400] [batchtime 0.398]
[epoch 63], [iter 22 / 176], [train main loss -1.790424], [lr 0.006400] [batchtime 0.402]
[epoch 63], [iter 23 / 176], [train main loss -1.840348], [lr 0.006400] [batchtime 0.412]
[epoch 63], [iter 24 / 176], [train main loss -1.829253], [lr 0.006400] [batchtime 0.411]
[epoch 63], [iter 25 / 176], [train main loss -1.875945], [lr 0.006400] [batchtime 0.41]
[epoch 63], [iter 26 / 176], [train main loss -2.013103], [lr 0.006400] [batchtime 0.408]
[epoch 63], [iter 27 / 176], [train main loss -1.973285], [lr 0.006400] [batchtime 0.408]
[epoch 63], [iter 28 / 176], [train main loss -1.886003], [lr 0.006400] [batchtime 0.407]
[epoch 63], [iter 29 / 176], [train main loss -1.909256], [lr 0.006400] [batchtime 0.407]
[epoch 63], [iter 30 / 176], [train main loss -1.872463], [lr 0.006400] [batchtime 0.407]
[epoch 63], [iter 31 / 176], [train main loss -1.948826], [lr 0.006400] [batchtime 0.407]
[epoch 63], [iter 32 / 176], [train main loss -1.890514], [lr 0.006400] [batchtime 0.407]
[epoch 63], [iter 33 / 176], [train main loss -1.881487], [lr 0.006400] [batchtime 0.406]
[epoch 63], [iter 34 / 176], [train main loss -1.919193], [lr 0.006400] [batchtime 0.406]
[epoch 63], [iter 35 / 176], [train main loss -1.879301], [lr 0.006400] [batchtime 0.406]
[epoch 63], [iter 36 / 176], [train main loss -1.820520], [lr 0.006400] [batchtime 0.405]
[epoch 63], [iter 37 / 176], [train main loss -1.865819], [lr 0.006400] [batchtime 0.405]
[epoch 63], [iter 38 / 176], [train main loss -1.854677], [lr 0.006400] [batchtime 0.404]
[epoch 63], [iter 39 / 176], [train main loss -1.910064], [lr 0.006400] [batchtime 0.404]
[epoch 63], [iter 40 / 176], [train main loss -1.940713], [lr 0.006400] [batchtime 0.404]
[epoch 63], [iter 41 / 176], [train main loss -1.945154], [lr 0.006400] [batchtime 0.404]
[epoch 63], [iter 42 / 176], [train main loss -1.934154], [lr 0.006400] [batchtime 0.404]
[epoch 63], [iter 43 / 176], [train main loss -1.885233], [lr 0.006400] [batchtime 0.404]
[epoch 63], [iter 44 / 176], [train main loss -1.861606], [lr 0.006400] [batchtime 0.403]
[epoch 63], [iter 45 / 176], [train main loss -1.857037], [lr 0.006400] [batchtime 0.403]
[epoch 63], [iter 46 / 176], [train main loss -1.886324], [lr 0.006400] [batchtime 0.408]
[epoch 63], [iter 47 / 176], [train main loss -1.830759], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 48 / 176], [train main loss -1.859248], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 49 / 176], [train main loss -1.927100], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 50 / 176], [train main loss -1.945078], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 51 / 176], [train main loss -1.901724], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 52 / 176], [train main loss -1.890948], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 53 / 176], [train main loss -1.889659], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 54 / 176], [train main loss -1.860728], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 55 / 176], [train main loss -1.838051], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 56 / 176], [train main loss -1.848928], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 57 / 176], [train main loss -1.866362], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 58 / 176], [train main loss -1.861890], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 59 / 176], [train main loss -1.875549], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 60 / 176], [train main loss -1.913666], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 61 / 176], [train main loss -1.927946], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 62 / 176], [train main loss -1.925811], [lr 0.006400] [batchtime 0.42]
[epoch 63], [iter 63 / 176], [train main loss -1.943689], [lr 0.006400] [batchtime 0.42]
[epoch 63], [iter 64 / 176], [train main loss -1.923659], [lr 0.006400] [batchtime 0.42]
[epoch 63], [iter 65 / 176], [train main loss -1.894133], [lr 0.006400] [batchtime 0.419]
[epoch 63], [iter 66 / 176], [train main loss -1.852411], [lr 0.006400] [batchtime 0.419]
[epoch 63], [iter 67 / 176], [train main loss -1.830188], [lr 0.006400] [batchtime 0.419]
[epoch 63], [iter 68 / 176], [train main loss -1.820174], [lr 0.006400] [batchtime 0.418]
[epoch 63], [iter 69 / 176], [train main loss -1.790493], [lr 0.006400] [batchtime 0.419]
[epoch 63], [iter 70 / 176], [train main loss -1.775558], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 71 / 176], [train main loss -1.811225], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 72 / 176], [train main loss -1.791079], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 73 / 176], [train main loss -1.782666], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 74 / 176], [train main loss -1.759657], [lr 0.006400] [batchtime 0.42]
[epoch 63], [iter 75 / 176], [train main loss -1.730722], [lr 0.006400] [batchtime 0.42]
[epoch 63], [iter 76 / 176], [train main loss -1.727264], [lr 0.006400] [batchtime 0.419]
[epoch 63], [iter 77 / 176], [train main loss -1.766685], [lr 0.006400] [batchtime 0.419]
[epoch 63], [iter 78 / 176], [train main loss -1.809103], [lr 0.006400] [batchtime 0.418]
[epoch 63], [iter 79 / 176], [train main loss -1.799421], [lr 0.006400] [batchtime 0.418]
[epoch 63], [iter 80 / 176], [train main loss -1.766984], [lr 0.006400] [batchtime 0.418]
[epoch 63], [iter 81 / 176], [train main loss -1.761128], [lr 0.006400] [batchtime 0.417]
[epoch 63], [iter 82 / 176], [train main loss -1.748393], [lr 0.006400] [batchtime 0.417]
[epoch 63], [iter 83 / 176], [train main loss -1.754273], [lr 0.006400] [batchtime 0.417]
[epoch 63], [iter 84 / 176], [train main loss -1.766120], [lr 0.006400] [batchtime 0.417]
[epoch 63], [iter 85 / 176], [train main loss -1.755644], [lr 0.006400] [batchtime 0.416]
[epoch 63], [iter 86 / 176], [train main loss -1.736871], [lr 0.006400] [batchtime 0.416]
[epoch 63], [iter 87 / 176], [train main loss -1.767543], [lr 0.006400] [batchtime 0.416]
[epoch 63], [iter 88 / 176], [train main loss -1.807205], [lr 0.006400] [batchtime 0.415]
[epoch 63], [iter 89 / 176], [train main loss -1.812446], [lr 0.006400] [batchtime 0.415]
[epoch 63], [iter 90 / 176], [train main loss -1.782432], [lr 0.006400] [batchtime 0.415]
[epoch 63], [iter 91 / 176], [train main loss -1.749425], [lr 0.006400] [batchtime 0.415]
[epoch 63], [iter 92 / 176], [train main loss -1.752837], [lr 0.006400] [batchtime 0.415]
[epoch 63], [iter 93 / 176], [train main loss -1.728440], [lr 0.006400] [batchtime 0.415]
[epoch 63], [iter 94 / 176], [train main loss -1.717072], [lr 0.006400] [batchtime 0.431]
[epoch 63], [iter 95 / 176], [train main loss -1.753631], [lr 0.006400] [batchtime 0.432]
[epoch 63], [iter 96 / 176], [train main loss -1.747298], [lr 0.006400] [batchtime 0.432]
[epoch 63], [iter 97 / 176], [train main loss -1.769336], [lr 0.006400] [batchtime 0.431]
[epoch 63], [iter 98 / 176], [train main loss -1.781264], [lr 0.006400] [batchtime 0.431]
[epoch 63], [iter 99 / 176], [train main loss -1.771833], [lr 0.006400] [batchtime 0.43]
[epoch 63], [iter 100 / 176], [train main loss -1.759258], [lr 0.006400] [batchtime 0.43]
[epoch 63], [iter 101 / 176], [train main loss -1.768228], [lr 0.006400] [batchtime 0.429]
[epoch 63], [iter 102 / 176], [train main loss -1.789093], [lr 0.006400] [batchtime 0.429]
[epoch 63], [iter 103 / 176], [train main loss -1.771221], [lr 0.006400] [batchtime 0.429]
[epoch 63], [iter 104 / 176], [train main loss -1.756638], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 105 / 176], [train main loss -1.728815], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 106 / 176], [train main loss -1.734530], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 107 / 176], [train main loss -1.742845], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 108 / 176], [train main loss -1.747838], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 109 / 176], [train main loss -1.746556], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 110 / 176], [train main loss -1.723106], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 111 / 176], [train main loss -1.738822], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 112 / 176], [train main loss -1.748895], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 113 / 176], [train main loss -1.771862], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 114 / 176], [train main loss -1.798348], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 115 / 176], [train main loss -1.776726], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 116 / 176], [train main loss -1.763781], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 117 / 176], [train main loss -1.760886], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 118 / 176], [train main loss -1.727001], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 119 / 176], [train main loss -1.751707], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 120 / 176], [train main loss -1.755093], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 121 / 176], [train main loss -1.761379], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 122 / 176], [train main loss -1.754940], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 123 / 176], [train main loss -1.741678], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 124 / 176], [train main loss -1.729700], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 125 / 176], [train main loss -1.720125], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 126 / 176], [train main loss -1.718625], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 127 / 176], [train main loss -1.726017], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 128 / 176], [train main loss -1.733284], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 129 / 176], [train main loss -1.736478], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 130 / 176], [train main loss -1.750560], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 131 / 176], [train main loss -1.732655], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 132 / 176], [train main loss -1.747926], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 133 / 176], [train main loss -1.768337], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 134 / 176], [train main loss -1.769769], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 135 / 176], [train main loss -1.797408], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 136 / 176], [train main loss -1.796657], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 137 / 176], [train main loss -1.804475], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 138 / 176], [train main loss -1.798509], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 139 / 176], [train main loss -1.811453], [lr 0.006400] [batchtime 0.421]
[epoch 63], [iter 140 / 176], [train main loss -1.840014], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 141 / 176], [train main loss -1.834238], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 142 / 176], [train main loss -1.821850], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 143 / 176], [train main loss -1.817757], [lr 0.006400] [batchtime 0.428]
[epoch 63], [iter 144 / 176], [train main loss -1.815847], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 145 / 176], [train main loss -1.803802], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 146 / 176], [train main loss -1.831936], [lr 0.006400] [batchtime 0.427]
[epoch 63], [iter 147 / 176], [train main loss -1.844562], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 148 / 176], [train main loss -1.826644], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 149 / 176], [train main loss -1.829952], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 150 / 176], [train main loss -1.837040], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 151 / 176], [train main loss -1.830994], [lr 0.006400] [batchtime 0.426]
[epoch 63], [iter 152 / 176], [train main loss -1.842294], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 153 / 176], [train main loss -1.826715], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 154 / 176], [train main loss -1.820593], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 155 / 176], [train main loss -1.831672], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 156 / 176], [train main loss -1.826717], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 157 / 176], [train main loss -1.829178], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 158 / 176], [train main loss -1.828641], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 159 / 176], [train main loss -1.816757], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 160 / 176], [train main loss -1.814395], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 161 / 176], [train main loss -1.824244], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 162 / 176], [train main loss -1.820284], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 163 / 176], [train main loss -1.802089], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 164 / 176], [train main loss -1.787317], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 165 / 176], [train main loss -1.780842], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 166 / 176], [train main loss -1.772765], [lr 0.006400] [batchtime 0.425]
[epoch 63], [iter 167 / 176], [train main loss -1.769063], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 168 / 176], [train main loss -1.764948], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 169 / 176], [train main loss -1.773940], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 170 / 176], [train main loss -1.765529], [lr 0.006400] [batchtime 0.424]
[epoch 63], [iter 171 / 176], [train main loss -1.764679], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 172 / 176], [train main loss -1.779100], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 173 / 176], [train main loss -1.779532], [lr 0.006400] [batchtime 0.423]
[epoch 63], [iter 174 / 176], [train main loss -1.781821], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 175 / 176], [train main loss -1.782237], [lr 0.006400] [batchtime 0.422]
[epoch 63], [iter 176 / 176], [train main loss -1.766558], [lr 0.006400] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.73  35.39    0.03  0.04         0.97      0.96
   1  sidewalk          64.48   5.15    0.28  0.27         0.78      0.79
   2  building          84.28  24.73    0.08  0.11         0.93      0.90
   3  wall              14.50   0.15    2.93  2.96         0.25      0.25
   4  fence             15.93   0.24    4.39  0.89         0.19      0.53
   5  pole              33.05   0.48    1.36  0.67         0.42      0.60
   6  traffic light      4.65   0.01   19.98  0.52         0.05      0.66
   7  traffic sign      10.88   0.06    7.93  0.26         0.11      0.79
   8  vegetation        81.28  11.46    0.08  0.15         0.93      0.87
   9  terrain           37.96   0.37    0.98  0.65         0.50      0.61
  10  sky               92.77   3.71    0.04  0.03         0.96      0.97
  11  person            43.10   0.82    0.87  0.45         0.54      0.69
  12  rider              0.66   0.00  148.68  1.23         0.01      0.45
  13  car               81.91   6.67    0.06  0.16         0.94      0.86
  14  truck              1.42   0.00   69.06  0.55         0.01      0.65
  15  bus               14.00   0.03    1.76  4.38         0.36      0.19
  16  train             25.61   0.05    2.34  0.56         0.30      0.64
  17  motorcycle         0.26   0.00  389.92  0.58         0.00      0.63
  18  bicycle           30.99   0.19    1.01  1.22         0.50      0.45
Mean: 38.50
-----------------------------------------------------------------------------------------------------------
this : [epoch 63], [val loss 0.36725], [acc 0.89511], [acc_cls 0.46099], [mean_iu 0.38498], [fwavacc 0.82022]
best : [epoch 63], [val loss 0.36725], [acc 0.89511], [acc_cls 0.46099], [mean_iu 0.38498], [fwavacc 0.82022]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 64], [iter 1 / 176], [train main loss -2.730437], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 2 / 176], [train main loss -3.581762], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 3 / 176], [train main loss -2.857879], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 4 / 176], [train main loss -2.613939], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 5 / 176], [train main loss -2.626607], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 6 / 176], [train main loss -2.522821], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 7 / 176], [train main loss -2.844799], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 8 / 176], [train main loss -2.636364], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 9 / 176], [train main loss -2.438765], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 10 / 176], [train main loss -2.570097], [lr 0.006343] [batchtime 0]
[epoch 64], [iter 11 / 176], [train main loss -2.419510], [lr 0.006343] [batchtime 0.385]
[epoch 64], [iter 12 / 176], [train main loss -2.358159], [lr 0.006343] [batchtime 0.387]
[epoch 64], [iter 13 / 176], [train main loss -2.275457], [lr 0.006343] [batchtime 0.39]
[epoch 64], [iter 14 / 176], [train main loss -2.268499], [lr 0.006343] [batchtime 0.392]
[epoch 64], [iter 15 / 176], [train main loss -2.421198], [lr 0.006343] [batchtime 0.393]
[epoch 64], [iter 16 / 176], [train main loss -2.271028], [lr 0.006343] [batchtime 0.411]
[epoch 64], [iter 17 / 176], [train main loss -2.239798], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 18 / 176], [train main loss -2.367284], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 19 / 176], [train main loss -2.396782], [lr 0.006343] [batchtime 0.424]
[epoch 64], [iter 20 / 176], [train main loss -2.541760], [lr 0.006343] [batchtime 0.42]
[epoch 64], [iter 21 / 176], [train main loss -2.440182], [lr 0.006343] [batchtime 0.419]
[epoch 64], [iter 22 / 176], [train main loss -2.286013], [lr 0.006343] [batchtime 0.417]
[epoch 64], [iter 23 / 176], [train main loss -2.203449], [lr 0.006343] [batchtime 0.416]
[epoch 64], [iter 24 / 176], [train main loss -2.198535], [lr 0.006343] [batchtime 0.415]
[epoch 64], [iter 25 / 176], [train main loss -2.079311], [lr 0.006343] [batchtime 0.413]
[epoch 64], [iter 26 / 176], [train main loss -2.047832], [lr 0.006343] [batchtime 0.412]
[epoch 64], [iter 27 / 176], [train main loss -2.117732], [lr 0.006343] [batchtime 0.411]
[epoch 64], [iter 28 / 176], [train main loss -2.086028], [lr 0.006343] [batchtime 0.41]
[epoch 64], [iter 29 / 176], [train main loss -2.033910], [lr 0.006343] [batchtime 0.41]
[epoch 64], [iter 30 / 176], [train main loss -2.107797], [lr 0.006343] [batchtime 0.409]
[epoch 64], [iter 31 / 176], [train main loss -2.009874], [lr 0.006343] [batchtime 0.409]
[epoch 64], [iter 32 / 176], [train main loss -2.029334], [lr 0.006343] [batchtime 0.409]
[epoch 64], [iter 33 / 176], [train main loss -1.986397], [lr 0.006343] [batchtime 0.41]
[epoch 64], [iter 34 / 176], [train main loss -2.035905], [lr 0.006343] [batchtime 0.409]
[epoch 64], [iter 35 / 176], [train main loss -2.043631], [lr 0.006343] [batchtime 0.409]
[epoch 64], [iter 36 / 176], [train main loss -2.111965], [lr 0.006343] [batchtime 0.409]
[epoch 64], [iter 37 / 176], [train main loss -2.159237], [lr 0.006343] [batchtime 0.408]
[epoch 64], [iter 38 / 176], [train main loss -2.115730], [lr 0.006343] [batchtime 0.408]
[epoch 64], [iter 39 / 176], [train main loss -2.106359], [lr 0.006343] [batchtime 0.408]
[epoch 64], [iter 40 / 176], [train main loss -2.094785], [lr 0.006343] [batchtime 0.412]
[epoch 64], [iter 41 / 176], [train main loss -2.155638], [lr 0.006343] [batchtime 0.452]
[epoch 64], [iter 42 / 176], [train main loss -2.141972], [lr 0.006343] [batchtime 0.45]
[epoch 64], [iter 43 / 176], [train main loss -2.116300], [lr 0.006343] [batchtime 0.448]
[epoch 64], [iter 44 / 176], [train main loss -2.101650], [lr 0.006343] [batchtime 0.447]
[epoch 64], [iter 45 / 176], [train main loss -2.116431], [lr 0.006343] [batchtime 0.445]
[epoch 64], [iter 46 / 176], [train main loss -2.095605], [lr 0.006343] [batchtime 0.444]
[epoch 64], [iter 47 / 176], [train main loss -2.093500], [lr 0.006343] [batchtime 0.443]
[epoch 64], [iter 48 / 176], [train main loss -2.141138], [lr 0.006343] [batchtime 0.441]
[epoch 64], [iter 49 / 176], [train main loss -2.130442], [lr 0.006343] [batchtime 0.44]
[epoch 64], [iter 50 / 176], [train main loss -2.129178], [lr 0.006343] [batchtime 0.439]
[epoch 64], [iter 51 / 176], [train main loss -2.115104], [lr 0.006343] [batchtime 0.438]
[epoch 64], [iter 52 / 176], [train main loss -2.074549], [lr 0.006343] [batchtime 0.437]
[epoch 64], [iter 53 / 176], [train main loss -2.104923], [lr 0.006343] [batchtime 0.436]
[epoch 64], [iter 54 / 176], [train main loss -2.064218], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 55 / 176], [train main loss -2.047023], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 56 / 176], [train main loss -2.048200], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 57 / 176], [train main loss -2.056847], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 58 / 176], [train main loss -2.061287], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 59 / 176], [train main loss -2.058395], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 60 / 176], [train main loss -2.056529], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 61 / 176], [train main loss -2.050560], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 62 / 176], [train main loss -2.050113], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 63 / 176], [train main loss -2.078443], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 64 / 176], [train main loss -2.086794], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 65 / 176], [train main loss -2.073591], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 66 / 176], [train main loss -2.065744], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 67 / 176], [train main loss -2.071614], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 68 / 176], [train main loss -2.090072], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 69 / 176], [train main loss -2.097333], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 70 / 176], [train main loss -2.079553], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 71 / 176], [train main loss -2.086287], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 72 / 176], [train main loss -2.107845], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 73 / 176], [train main loss -2.121524], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 74 / 176], [train main loss -2.145128], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 75 / 176], [train main loss -2.138119], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 76 / 176], [train main loss -2.123085], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 77 / 176], [train main loss -2.094518], [lr 0.006343] [batchtime 0.425]
[epoch 64], [iter 78 / 176], [train main loss -2.084112], [lr 0.006343] [batchtime 0.425]
[epoch 64], [iter 79 / 176], [train main loss -2.047166], [lr 0.006343] [batchtime 0.424]
[epoch 64], [iter 80 / 176], [train main loss -2.051403], [lr 0.006343] [batchtime 0.424]
[epoch 64], [iter 81 / 176], [train main loss -2.074492], [lr 0.006343] [batchtime 0.423]
[epoch 64], [iter 82 / 176], [train main loss -2.093483], [lr 0.006343] [batchtime 0.423]
[epoch 64], [iter 83 / 176], [train main loss -2.079269], [lr 0.006343] [batchtime 0.422]
[epoch 64], [iter 84 / 176], [train main loss -2.068014], [lr 0.006343] [batchtime 0.422]
[epoch 64], [iter 85 / 176], [train main loss -2.054379], [lr 0.006343] [batchtime 0.422]
[epoch 64], [iter 86 / 176], [train main loss -2.035724], [lr 0.006343] [batchtime 0.421]
[epoch 64], [iter 87 / 176], [train main loss -2.012736], [lr 0.006343] [batchtime 0.439]
[epoch 64], [iter 88 / 176], [train main loss -2.009850], [lr 0.006343] [batchtime 0.44]
[epoch 64], [iter 89 / 176], [train main loss -1.999220], [lr 0.006343] [batchtime 0.44]
[epoch 64], [iter 90 / 176], [train main loss -2.015598], [lr 0.006343] [batchtime 0.439]
[epoch 64], [iter 91 / 176], [train main loss -1.995448], [lr 0.006343] [batchtime 0.438]
[epoch 64], [iter 92 / 176], [train main loss -1.999194], [lr 0.006343] [batchtime 0.438]
[epoch 64], [iter 93 / 176], [train main loss -1.982565], [lr 0.006343] [batchtime 0.437]
[epoch 64], [iter 94 / 176], [train main loss -2.004873], [lr 0.006343] [batchtime 0.437]
[epoch 64], [iter 95 / 176], [train main loss -2.004745], [lr 0.006343] [batchtime 0.436]
[epoch 64], [iter 96 / 176], [train main loss -2.006370], [lr 0.006343] [batchtime 0.436]
[epoch 64], [iter 97 / 176], [train main loss -2.002663], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 98 / 176], [train main loss -1.991433], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 99 / 176], [train main loss -1.975030], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 100 / 176], [train main loss -1.956730], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 101 / 176], [train main loss -1.950975], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 102 / 176], [train main loss -1.930659], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 103 / 176], [train main loss -1.921077], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 104 / 176], [train main loss -1.916039], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 105 / 176], [train main loss -1.925195], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 106 / 176], [train main loss -1.947755], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 107 / 176], [train main loss -1.949900], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 108 / 176], [train main loss -1.936192], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 109 / 176], [train main loss -1.951266], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 110 / 176], [train main loss -1.952113], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 111 / 176], [train main loss -1.963229], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 112 / 176], [train main loss -1.993477], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 113 / 176], [train main loss -2.000147], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 114 / 176], [train main loss -2.002859], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 115 / 176], [train main loss -1.980716], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 116 / 176], [train main loss -1.960629], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 117 / 176], [train main loss -1.960988], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 118 / 176], [train main loss -1.962098], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 119 / 176], [train main loss -1.942543], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 120 / 176], [train main loss -1.931590], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 121 / 176], [train main loss -1.909835], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 122 / 176], [train main loss -1.920322], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 123 / 176], [train main loss -1.925557], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 124 / 176], [train main loss -1.918055], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 125 / 176], [train main loss -1.920947], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 126 / 176], [train main loss -1.916922], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 127 / 176], [train main loss -1.923500], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 128 / 176], [train main loss -1.932510], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 129 / 176], [train main loss -1.944902], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 130 / 176], [train main loss -1.938386], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 131 / 176], [train main loss -1.956468], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 132 / 176], [train main loss -1.955441], [lr 0.006343] [batchtime 0.425]
[epoch 64], [iter 133 / 176], [train main loss -1.953561], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 134 / 176], [train main loss -1.957348], [lr 0.006343] [batchtime 0.436]
[epoch 64], [iter 135 / 176], [train main loss -1.965544], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 136 / 176], [train main loss -1.985549], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 137 / 176], [train main loss -1.976148], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 138 / 176], [train main loss -1.953995], [lr 0.006343] [batchtime 0.435]
[epoch 64], [iter 139 / 176], [train main loss -1.950760], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 140 / 176], [train main loss -1.957094], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 141 / 176], [train main loss -1.946525], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 142 / 176], [train main loss -1.939842], [lr 0.006343] [batchtime 0.434]
[epoch 64], [iter 143 / 176], [train main loss -1.926671], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 144 / 176], [train main loss -1.934997], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 145 / 176], [train main loss -1.931734], [lr 0.006343] [batchtime 0.433]
[epoch 64], [iter 146 / 176], [train main loss -1.945185], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 147 / 176], [train main loss -1.952437], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 148 / 176], [train main loss -1.953658], [lr 0.006343] [batchtime 0.432]
[epoch 64], [iter 149 / 176], [train main loss -1.952524], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 150 / 176], [train main loss -1.954573], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 151 / 176], [train main loss -1.947189], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 152 / 176], [train main loss -1.935169], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 153 / 176], [train main loss -1.915530], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 154 / 176], [train main loss -1.919167], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 155 / 176], [train main loss -1.914558], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 156 / 176], [train main loss -1.908127], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 157 / 176], [train main loss -1.909507], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 158 / 176], [train main loss -1.911409], [lr 0.006343] [batchtime 0.431]
[epoch 64], [iter 159 / 176], [train main loss -1.891070], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 160 / 176], [train main loss -1.905911], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 161 / 176], [train main loss -1.912336], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 162 / 176], [train main loss -1.904971], [lr 0.006343] [batchtime 0.43]
[epoch 64], [iter 163 / 176], [train main loss -1.917171], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 164 / 176], [train main loss -1.903934], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 165 / 176], [train main loss -1.909827], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 166 / 176], [train main loss -1.901763], [lr 0.006343] [batchtime 0.429]
[epoch 64], [iter 167 / 176], [train main loss -1.889001], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 168 / 176], [train main loss -1.886672], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 169 / 176], [train main loss -1.890908], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 170 / 176], [train main loss -1.913784], [lr 0.006343] [batchtime 0.428]
[epoch 64], [iter 171 / 176], [train main loss -1.917540], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 172 / 176], [train main loss -1.911147], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 173 / 176], [train main loss -1.897471], [lr 0.006343] [batchtime 0.427]
[epoch 64], [iter 174 / 176], [train main loss -1.895414], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 175 / 176], [train main loss -1.890296], [lr 0.006343] [batchtime 0.426]
[epoch 64], [iter 176 / 176], [train main loss -1.904819], [lr 0.006343] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.09  35.61    0.02  0.05         0.98      0.95
   1  sidewalk          61.06   4.75    0.39  0.25         0.72      0.80
   2  building          83.61  24.64    0.08  0.12         0.93      0.90
   3  wall              12.69   0.10    4.83  2.05         0.17      0.33
   4  fence             14.33   0.20    5.38  0.60         0.16      0.62
   5  pole              30.73   0.41    1.78  0.47         0.36      0.68
   6  traffic light      5.38   0.01   17.04  0.55         0.06      0.65
   7  traffic sign       9.74   0.06    8.95  0.32         0.10      0.76
   8  vegetation        80.56  11.63    0.06  0.18         0.94      0.85
   9  terrain           34.99   0.32    1.31  0.55         0.43      0.65
  10  sky               91.56   3.77    0.03  0.06         0.97      0.94
  11  person            42.37   0.80    0.91  0.45         0.52      0.69
  12  rider              1.46   0.00   66.33  1.16         0.01      0.46
  13  car               82.64   6.62    0.07  0.14         0.94      0.88
  14  truck              0.52   0.00  189.85  0.51         0.01      0.66
  15  bus               10.01   0.02    3.39  5.60         0.23      0.15
  16  train             16.82   0.04    3.69  1.26         0.21      0.44
  17  motorcycle         0.17   0.00  569.97  0.53         0.00      0.65
  18  bicycle           29.02   0.21    0.84  1.60         0.54      0.38
Mean: 36.88
-----------------------------------------------------------------------------------------------------------
this : [epoch 64], [val loss 0.38488], [acc 0.89190], [acc_cls 0.43598], [mean_iu 0.36882], [fwavacc 0.81180]
best : [epoch 63], [val loss 0.36725], [acc 0.89511], [acc_cls 0.46099], [mean_iu 0.38498], [fwavacc 0.82022]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 65], [iter 1 / 176], [train main loss -2.644059], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 2 / 176], [train main loss -2.538010], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 3 / 176], [train main loss -2.264839], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 4 / 176], [train main loss -1.805001], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 5 / 176], [train main loss -1.919052], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 6 / 176], [train main loss -2.256069], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 7 / 176], [train main loss -1.832506], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 8 / 176], [train main loss -1.938082], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 9 / 176], [train main loss -1.989503], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 10 / 176], [train main loss -1.859784], [lr 0.006286] [batchtime 0]
[epoch 65], [iter 11 / 176], [train main loss -2.037093], [lr 0.006286] [batchtime 0.375]
[epoch 65], [iter 12 / 176], [train main loss -2.063499], [lr 0.006286] [batchtime 0.384]
[epoch 65], [iter 13 / 176], [train main loss -1.894305], [lr 0.006286] [batchtime 0.388]
[epoch 65], [iter 14 / 176], [train main loss -1.997676], [lr 0.006286] [batchtime 0.39]
[epoch 65], [iter 15 / 176], [train main loss -2.104734], [lr 0.006286] [batchtime 0.391]
[epoch 65], [iter 16 / 176], [train main loss -1.951312], [lr 0.006286] [batchtime 0.392]
[epoch 65], [iter 17 / 176], [train main loss -1.962515], [lr 0.006286] [batchtime 0.393]
[epoch 65], [iter 18 / 176], [train main loss -2.133558], [lr 0.006286] [batchtime 0.393]
[epoch 65], [iter 19 / 176], [train main loss -1.944594], [lr 0.006286] [batchtime 0.393]
[epoch 65], [iter 20 / 176], [train main loss -1.901400], [lr 0.006286] [batchtime 0.396]
[epoch 65], [iter 21 / 176], [train main loss -1.969859], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 22 / 176], [train main loss -1.967657], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 23 / 176], [train main loss -2.053531], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 24 / 176], [train main loss -2.147822], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 25 / 176], [train main loss -2.198219], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 26 / 176], [train main loss -2.222326], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 27 / 176], [train main loss -2.163051], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 28 / 176], [train main loss -2.140679], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 29 / 176], [train main loss -2.228103], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 30 / 176], [train main loss -2.207644], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 31 / 176], [train main loss -2.152619], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 32 / 176], [train main loss -2.223585], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 33 / 176], [train main loss -2.193709], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 34 / 176], [train main loss -2.174398], [lr 0.006286] [batchtime 0.397]
[epoch 65], [iter 35 / 176], [train main loss -2.220391], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 36 / 176], [train main loss -2.180285], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 37 / 176], [train main loss -2.128439], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 38 / 176], [train main loss -2.170005], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 39 / 176], [train main loss -2.180598], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 40 / 176], [train main loss -2.194331], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 41 / 176], [train main loss -2.162044], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 42 / 176], [train main loss -2.144385], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 43 / 176], [train main loss -2.096062], [lr 0.006286] [batchtime 0.398]
[epoch 65], [iter 44 / 176], [train main loss -2.134839], [lr 0.006286] [batchtime 0.413]
[epoch 65], [iter 45 / 176], [train main loss -2.099916], [lr 0.006286] [batchtime 0.417]
[epoch 65], [iter 46 / 176], [train main loss -2.025497], [lr 0.006286] [batchtime 0.416]
[epoch 65], [iter 47 / 176], [train main loss -2.044997], [lr 0.006286] [batchtime 0.415]
[epoch 65], [iter 48 / 176], [train main loss -2.128320], [lr 0.006286] [batchtime 0.415]
[epoch 65], [iter 49 / 176], [train main loss -2.095182], [lr 0.006286] [batchtime 0.414]
[epoch 65], [iter 50 / 176], [train main loss -2.095129], [lr 0.006286] [batchtime 0.414]
[epoch 65], [iter 51 / 176], [train main loss -2.106799], [lr 0.006286] [batchtime 0.413]
[epoch 65], [iter 52 / 176], [train main loss -2.138180], [lr 0.006286] [batchtime 0.413]
[epoch 65], [iter 53 / 176], [train main loss -2.134056], [lr 0.006286] [batchtime 0.413]
[epoch 65], [iter 54 / 176], [train main loss -2.150667], [lr 0.006286] [batchtime 0.412]
[epoch 65], [iter 55 / 176], [train main loss -2.122459], [lr 0.006286] [batchtime 0.412]
[epoch 65], [iter 56 / 176], [train main loss -2.097286], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 57 / 176], [train main loss -2.079925], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 58 / 176], [train main loss -2.025750], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 59 / 176], [train main loss -2.005990], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 60 / 176], [train main loss -2.000164], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 61 / 176], [train main loss -1.978618], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 62 / 176], [train main loss -1.940092], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 63 / 176], [train main loss -1.909462], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 64 / 176], [train main loss -1.939075], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 65 / 176], [train main loss -1.919630], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 66 / 176], [train main loss -1.904599], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 67 / 176], [train main loss -1.857275], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 68 / 176], [train main loss -1.900759], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 69 / 176], [train main loss -1.899268], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 70 / 176], [train main loss -1.887686], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 71 / 176], [train main loss -1.903695], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 72 / 176], [train main loss -1.938269], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 73 / 176], [train main loss -1.924307], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 74 / 176], [train main loss -1.894506], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 75 / 176], [train main loss -1.881923], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 76 / 176], [train main loss -1.891162], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 77 / 176], [train main loss -1.894296], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 78 / 176], [train main loss -1.891996], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 79 / 176], [train main loss -1.819221], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 80 / 176], [train main loss -1.848816], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 81 / 176], [train main loss -1.838733], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 82 / 176], [train main loss -1.849035], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 83 / 176], [train main loss -1.805589], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 84 / 176], [train main loss -1.804150], [lr 0.006286] [batchtime 0.404]
[epoch 65], [iter 85 / 176], [train main loss -1.821831], [lr 0.006286] [batchtime 0.404]
[epoch 65], [iter 86 / 176], [train main loss -1.801790], [lr 0.006286] [batchtime 0.404]
[epoch 65], [iter 87 / 176], [train main loss -1.806055], [lr 0.006286] [batchtime 0.404]
[epoch 65], [iter 88 / 176], [train main loss -1.823048], [lr 0.006286] [batchtime 0.404]
[epoch 65], [iter 89 / 176], [train main loss -1.807418], [lr 0.006286] [batchtime 0.404]
[epoch 65], [iter 90 / 176], [train main loss -1.833086], [lr 0.006286] [batchtime 0.403]
[epoch 65], [iter 91 / 176], [train main loss -1.847882], [lr 0.006286] [batchtime 0.403]
[epoch 65], [iter 92 / 176], [train main loss -1.840134], [lr 0.006286] [batchtime 0.403]
[epoch 65], [iter 93 / 176], [train main loss -1.838226], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 94 / 176], [train main loss -1.813944], [lr 0.006286] [batchtime 0.412]
[epoch 65], [iter 95 / 176], [train main loss -1.769471], [lr 0.006286] [batchtime 0.412]
[epoch 65], [iter 96 / 176], [train main loss -1.794575], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 97 / 176], [train main loss -1.780107], [lr 0.006286] [batchtime 0.412]
[epoch 65], [iter 98 / 176], [train main loss -1.769950], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 99 / 176], [train main loss -1.782986], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 100 / 176], [train main loss -1.802519], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 101 / 176], [train main loss -1.803081], [lr 0.006286] [batchtime 0.411]
[epoch 65], [iter 102 / 176], [train main loss -1.788866], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 103 / 176], [train main loss -1.788034], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 104 / 176], [train main loss -1.758896], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 105 / 176], [train main loss -1.767933], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 106 / 176], [train main loss -1.814438], [lr 0.006286] [batchtime 0.41]
[epoch 65], [iter 107 / 176], [train main loss -1.802873], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 108 / 176], [train main loss -1.809744], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 109 / 176], [train main loss -1.818181], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 110 / 176], [train main loss -1.815078], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 111 / 176], [train main loss -1.843378], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 112 / 176], [train main loss -1.867627], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 113 / 176], [train main loss -1.875188], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 114 / 176], [train main loss -1.881779], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 115 / 176], [train main loss -1.886714], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 116 / 176], [train main loss -1.910309], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 117 / 176], [train main loss -1.907269], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 118 / 176], [train main loss -1.928084], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 119 / 176], [train main loss -1.922100], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 120 / 176], [train main loss -1.927125], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 121 / 176], [train main loss -1.913561], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 122 / 176], [train main loss -1.898080], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 123 / 176], [train main loss -1.904787], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 124 / 176], [train main loss -1.919466], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 125 / 176], [train main loss -1.888091], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 126 / 176], [train main loss -1.877310], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 127 / 176], [train main loss -1.871222], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 128 / 176], [train main loss -1.877451], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 129 / 176], [train main loss -1.892292], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 130 / 176], [train main loss -1.897411], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 131 / 176], [train main loss -1.919284], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 132 / 176], [train main loss -1.931221], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 133 / 176], [train main loss -1.917077], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 134 / 176], [train main loss -1.905171], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 135 / 176], [train main loss -1.898448], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 136 / 176], [train main loss -1.891817], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 137 / 176], [train main loss -1.924482], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 138 / 176], [train main loss -1.935209], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 139 / 176], [train main loss -1.928360], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 140 / 176], [train main loss -1.938031], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 141 / 176], [train main loss -1.947654], [lr 0.006286] [batchtime 0.405]
[epoch 65], [iter 142 / 176], [train main loss -1.969708], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 143 / 176], [train main loss -1.975887], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 144 / 176], [train main loss -1.975989], [lr 0.006286] [batchtime 0.409]
[epoch 65], [iter 145 / 176], [train main loss -1.963749], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 146 / 176], [train main loss -1.961708], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 147 / 176], [train main loss -1.970905], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 148 / 176], [train main loss -1.970592], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 149 / 176], [train main loss -1.976004], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 150 / 176], [train main loss -1.986464], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 151 / 176], [train main loss -1.988184], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 152 / 176], [train main loss -1.994446], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 153 / 176], [train main loss -1.996624], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 154 / 176], [train main loss -1.991874], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 155 / 176], [train main loss -1.989730], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 156 / 176], [train main loss -1.972987], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 157 / 176], [train main loss -1.987835], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 158 / 176], [train main loss -1.980190], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 159 / 176], [train main loss -1.971416], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 160 / 176], [train main loss -1.962665], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 161 / 176], [train main loss -1.970584], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 162 / 176], [train main loss -1.972216], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 163 / 176], [train main loss -1.962205], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 164 / 176], [train main loss -1.956347], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 165 / 176], [train main loss -1.949366], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 166 / 176], [train main loss -1.944981], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 167 / 176], [train main loss -1.927657], [lr 0.006286] [batchtime 0.408]
[epoch 65], [iter 168 / 176], [train main loss -1.932283], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 169 / 176], [train main loss -1.915840], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 170 / 176], [train main loss -1.912243], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 171 / 176], [train main loss -1.915262], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 172 / 176], [train main loss -1.921655], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 173 / 176], [train main loss -1.921266], [lr 0.006286] [batchtime 0.407]
[epoch 65], [iter 174 / 176], [train main loss -1.927547], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 175 / 176], [train main loss -1.922013], [lr 0.006286] [batchtime 0.406]
[epoch 65], [iter 176 / 176], [train main loss -1.926584], [lr 0.006286] [batchtime 0.406]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.94  35.12    0.04  0.04         0.97      0.96
   1  sidewalk          63.27   5.12    0.29  0.29         0.78      0.77
   2  building          83.72  24.29    0.09  0.10         0.91      0.91
   3  wall              12.50   0.11    4.52  2.48         0.18      0.29
   4  fence             16.33   0.24    4.28  0.84         0.19      0.54
   5  pole              32.32   0.46    1.48  0.62         0.40      0.62
   6  traffic light      4.84   0.01   19.18  0.48         0.05      0.68
   7  traffic sign      12.59   0.07    6.60  0.34         0.13      0.75
   8  vegetation        80.66  11.56    0.07  0.17         0.93      0.85
   9  terrain           33.74   0.36    1.05  0.91         0.49      0.52
  10  sky               92.49   3.76    0.03  0.05         0.97      0.95
  11  person            45.32   0.94    0.63  0.58         0.61      0.63
  12  rider              1.71   0.00   55.63  1.77         0.02      0.36
  13  car               78.92   6.64    0.06  0.20         0.94      0.83
  14  truck              1.64   0.01   58.55  1.50         0.02      0.40
  15  bus               12.63   0.04    1.18  5.74         0.46      0.15
  16  train             14.23   0.03    4.96  1.07         0.17      0.48
  17  motorcycle         0.48   0.00  207.49  0.75         0.00      0.57
  18  bicycle           29.43   0.19    1.05  1.35         0.49      0.43
Mean: 37.36
-----------------------------------------------------------------------------------------------------------
this : [epoch 65], [val loss 0.36711], [acc 0.88950], [acc_cls 0.45863], [mean_iu 0.37356], [fwavacc 0.81178]
best : [epoch 63], [val loss 0.36725], [acc 0.89511], [acc_cls 0.46099], [mean_iu 0.38498], [fwavacc 0.82022]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 66], [iter 1 / 176], [train main loss -2.839334], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 2 / 176], [train main loss -2.467856], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 3 / 176], [train main loss -2.917151], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 4 / 176], [train main loss -2.922633], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 5 / 176], [train main loss -3.244211], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 6 / 176], [train main loss -3.489361], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 7 / 176], [train main loss -3.064199], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 8 / 176], [train main loss -2.875884], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 9 / 176], [train main loss -2.598422], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 10 / 176], [train main loss -2.713721], [lr 0.006229] [batchtime 0]
[epoch 66], [iter 11 / 176], [train main loss -2.730202], [lr 0.006229] [batchtime 0.377]
[epoch 66], [iter 12 / 176], [train main loss -2.591548], [lr 0.006229] [batchtime 0.388]
[epoch 66], [iter 13 / 176], [train main loss -2.514269], [lr 0.006229] [batchtime 0.393]
[epoch 66], [iter 14 / 176], [train main loss -2.373846], [lr 0.006229] [batchtime 0.391]
[epoch 66], [iter 15 / 176], [train main loss -2.537073], [lr 0.006229] [batchtime 0.392]
[epoch 66], [iter 16 / 176], [train main loss -2.498137], [lr 0.006229] [batchtime 0.395]
[epoch 66], [iter 17 / 176], [train main loss -2.298802], [lr 0.006229] [batchtime 0.396]
[epoch 66], [iter 18 / 176], [train main loss -2.341200], [lr 0.006229] [batchtime 0.395]
[epoch 66], [iter 19 / 176], [train main loss -2.249119], [lr 0.006229] [batchtime 0.396]
[epoch 66], [iter 20 / 176], [train main loss -2.272225], [lr 0.006229] [batchtime 0.396]
[epoch 66], [iter 21 / 176], [train main loss -2.211139], [lr 0.006229] [batchtime 0.396]
[epoch 66], [iter 22 / 176], [train main loss -2.144621], [lr 0.006229] [batchtime 0.396]
[epoch 66], [iter 23 / 176], [train main loss -2.069232], [lr 0.006229] [batchtime 0.397]
[epoch 66], [iter 24 / 176], [train main loss -1.958716], [lr 0.006229] [batchtime 0.397]
[epoch 66], [iter 25 / 176], [train main loss -1.953587], [lr 0.006229] [batchtime 0.398]
[epoch 66], [iter 26 / 176], [train main loss -1.863664], [lr 0.006229] [batchtime 0.411]
[epoch 66], [iter 27 / 176], [train main loss -1.835663], [lr 0.006229] [batchtime 0.489]
[epoch 66], [iter 28 / 176], [train main loss -1.844788], [lr 0.006229] [batchtime 0.484]
[epoch 66], [iter 29 / 176], [train main loss -1.919945], [lr 0.006229] [batchtime 0.478]
[epoch 66], [iter 30 / 176], [train main loss -1.900912], [lr 0.006229] [batchtime 0.474]
[epoch 66], [iter 31 / 176], [train main loss -1.859144], [lr 0.006229] [batchtime 0.47]
[epoch 66], [iter 32 / 176], [train main loss -1.827772], [lr 0.006229] [batchtime 0.467]
[epoch 66], [iter 33 / 176], [train main loss -1.959023], [lr 0.006229] [batchtime 0.464]
[epoch 66], [iter 34 / 176], [train main loss -1.982384], [lr 0.006229] [batchtime 0.461]
[epoch 66], [iter 35 / 176], [train main loss -1.871929], [lr 0.006229] [batchtime 0.459]
[epoch 66], [iter 36 / 176], [train main loss -1.968184], [lr 0.006229] [batchtime 0.457]
[epoch 66], [iter 37 / 176], [train main loss -1.978275], [lr 0.006229] [batchtime 0.455]
[epoch 66], [iter 38 / 176], [train main loss -1.943378], [lr 0.006229] [batchtime 0.453]
[epoch 66], [iter 39 / 176], [train main loss -1.948806], [lr 0.006229] [batchtime 0.451]
[epoch 66], [iter 40 / 176], [train main loss -1.961348], [lr 0.006229] [batchtime 0.449]
[epoch 66], [iter 41 / 176], [train main loss -1.956461], [lr 0.006229] [batchtime 0.448]
[epoch 66], [iter 42 / 176], [train main loss -1.936223], [lr 0.006229] [batchtime 0.446]
[epoch 66], [iter 43 / 176], [train main loss -1.873889], [lr 0.006229] [batchtime 0.445]
[epoch 66], [iter 44 / 176], [train main loss -1.879647], [lr 0.006229] [batchtime 0.443]
[epoch 66], [iter 45 / 176], [train main loss -1.889388], [lr 0.006229] [batchtime 0.442]
[epoch 66], [iter 46 / 176], [train main loss -1.898701], [lr 0.006229] [batchtime 0.441]
[epoch 66], [iter 47 / 176], [train main loss -1.899684], [lr 0.006229] [batchtime 0.44]
[epoch 66], [iter 48 / 176], [train main loss -1.910475], [lr 0.006229] [batchtime 0.439]
[epoch 66], [iter 49 / 176], [train main loss -1.926495], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 50 / 176], [train main loss -1.920014], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 51 / 176], [train main loss -1.921177], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 52 / 176], [train main loss -1.887162], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 53 / 176], [train main loss -1.834525], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 54 / 176], [train main loss -1.808472], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 55 / 176], [train main loss -1.821401], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 56 / 176], [train main loss -1.755992], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 57 / 176], [train main loss -1.729310], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 58 / 176], [train main loss -1.762053], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 59 / 176], [train main loss -1.766585], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 60 / 176], [train main loss -1.782058], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 61 / 176], [train main loss -1.758082], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 62 / 176], [train main loss -1.769283], [lr 0.006229] [batchtime 0.428]
[epoch 66], [iter 63 / 176], [train main loss -1.763527], [lr 0.006229] [batchtime 0.427]
[epoch 66], [iter 64 / 176], [train main loss -1.770738], [lr 0.006229] [batchtime 0.427]
[epoch 66], [iter 65 / 176], [train main loss -1.789749], [lr 0.006229] [batchtime 0.426]
[epoch 66], [iter 66 / 176], [train main loss -1.759787], [lr 0.006229] [batchtime 0.425]
[epoch 66], [iter 67 / 176], [train main loss -1.761194], [lr 0.006229] [batchtime 0.425]
[epoch 66], [iter 68 / 176], [train main loss -1.756378], [lr 0.006229] [batchtime 0.424]
[epoch 66], [iter 69 / 176], [train main loss -1.731287], [lr 0.006229] [batchtime 0.424]
[epoch 66], [iter 70 / 176], [train main loss -1.764868], [lr 0.006229] [batchtime 0.424]
[epoch 66], [iter 71 / 176], [train main loss -1.776030], [lr 0.006229] [batchtime 0.423]
[epoch 66], [iter 72 / 176], [train main loss -1.777178], [lr 0.006229] [batchtime 0.423]
[epoch 66], [iter 73 / 176], [train main loss -1.790416], [lr 0.006229] [batchtime 0.442]
[epoch 66], [iter 74 / 176], [train main loss -1.819256], [lr 0.006229] [batchtime 0.447]
[epoch 66], [iter 75 / 176], [train main loss -1.832756], [lr 0.006229] [batchtime 0.446]
[epoch 66], [iter 76 / 176], [train main loss -1.850200], [lr 0.006229] [batchtime 0.445]
[epoch 66], [iter 77 / 176], [train main loss -1.851795], [lr 0.006229] [batchtime 0.444]
[epoch 66], [iter 78 / 176], [train main loss -1.843072], [lr 0.006229] [batchtime 0.443]
[epoch 66], [iter 79 / 176], [train main loss -1.850207], [lr 0.006229] [batchtime 0.443]
[epoch 66], [iter 80 / 176], [train main loss -1.844114], [lr 0.006229] [batchtime 0.442]
[epoch 66], [iter 81 / 176], [train main loss -1.825769], [lr 0.006229] [batchtime 0.441]
[epoch 66], [iter 82 / 176], [train main loss -1.815827], [lr 0.006229] [batchtime 0.441]
[epoch 66], [iter 83 / 176], [train main loss -1.770150], [lr 0.006229] [batchtime 0.44]
[epoch 66], [iter 84 / 176], [train main loss -1.806678], [lr 0.006229] [batchtime 0.44]
[epoch 66], [iter 85 / 176], [train main loss -1.825981], [lr 0.006229] [batchtime 0.439]
[epoch 66], [iter 86 / 176], [train main loss -1.842083], [lr 0.006229] [batchtime 0.438]
[epoch 66], [iter 87 / 176], [train main loss -1.840342], [lr 0.006229] [batchtime 0.438]
[epoch 66], [iter 88 / 176], [train main loss -1.843744], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 89 / 176], [train main loss -1.851994], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 90 / 176], [train main loss -1.826676], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 91 / 176], [train main loss -1.817196], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 92 / 176], [train main loss -1.848906], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 93 / 176], [train main loss -1.855356], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 94 / 176], [train main loss -1.838460], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 95 / 176], [train main loss -1.841796], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 96 / 176], [train main loss -1.868839], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 97 / 176], [train main loss -1.842564], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 98 / 176], [train main loss -1.842067], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 99 / 176], [train main loss -1.865535], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 100 / 176], [train main loss -1.874798], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 101 / 176], [train main loss -1.852722], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 102 / 176], [train main loss -1.855602], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 103 / 176], [train main loss -1.871922], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 104 / 176], [train main loss -1.886728], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 105 / 176], [train main loss -1.887651], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 106 / 176], [train main loss -1.895473], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 107 / 176], [train main loss -1.896539], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 108 / 176], [train main loss -1.933603], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 109 / 176], [train main loss -1.933025], [lr 0.006229] [batchtime 0.428]
[epoch 66], [iter 110 / 176], [train main loss -1.925041], [lr 0.006229] [batchtime 0.428]
[epoch 66], [iter 111 / 176], [train main loss -1.930539], [lr 0.006229] [batchtime 0.428]
[epoch 66], [iter 112 / 176], [train main loss -1.922194], [lr 0.006229] [batchtime 0.427]
[epoch 66], [iter 113 / 176], [train main loss -1.930492], [lr 0.006229] [batchtime 0.427]
[epoch 66], [iter 114 / 176], [train main loss -1.938147], [lr 0.006229] [batchtime 0.427]
[epoch 66], [iter 115 / 176], [train main loss -1.908069], [lr 0.006229] [batchtime 0.427]
[epoch 66], [iter 116 / 176], [train main loss -1.885629], [lr 0.006229] [batchtime 0.426]
[epoch 66], [iter 117 / 176], [train main loss -1.898798], [lr 0.006229] [batchtime 0.426]
[epoch 66], [iter 118 / 176], [train main loss -1.910799], [lr 0.006229] [batchtime 0.426]
[epoch 66], [iter 119 / 176], [train main loss -1.892758], [lr 0.006229] [batchtime 0.425]
[epoch 66], [iter 120 / 176], [train main loss -1.885631], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 121 / 176], [train main loss -1.873107], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 122 / 176], [train main loss -1.897857], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 123 / 176], [train main loss -1.882284], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 124 / 176], [train main loss -1.894181], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 125 / 176], [train main loss -1.896076], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 126 / 176], [train main loss -1.908327], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 127 / 176], [train main loss -1.893540], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 128 / 176], [train main loss -1.877592], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 129 / 176], [train main loss -1.869251], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 130 / 176], [train main loss -1.879449], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 131 / 176], [train main loss -1.876308], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 132 / 176], [train main loss -1.864050], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 133 / 176], [train main loss -1.868132], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 134 / 176], [train main loss -1.874716], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 135 / 176], [train main loss -1.874240], [lr 0.006229] [batchtime 0.432]
[epoch 66], [iter 136 / 176], [train main loss -1.861374], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 137 / 176], [train main loss -1.865261], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 138 / 176], [train main loss -1.862901], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 139 / 176], [train main loss -1.867275], [lr 0.006229] [batchtime 0.431]
[epoch 66], [iter 140 / 176], [train main loss -1.877781], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 141 / 176], [train main loss -1.875443], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 142 / 176], [train main loss -1.879211], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 143 / 176], [train main loss -1.892967], [lr 0.006229] [batchtime 0.43]
[epoch 66], [iter 144 / 176], [train main loss -1.892979], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 145 / 176], [train main loss -1.885964], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 146 / 176], [train main loss -1.878818], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 147 / 176], [train main loss -1.888419], [lr 0.006229] [batchtime 0.429]
[epoch 66], [iter 148 / 176], [train main loss -1.905938], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 149 / 176], [train main loss -1.899060], [lr 0.006229] [batchtime 0.438]
[epoch 66], [iter 150 / 176], [train main loss -1.888196], [lr 0.006229] [batchtime 0.438]
[epoch 66], [iter 151 / 176], [train main loss -1.877418], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 152 / 176], [train main loss -1.879117], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 153 / 176], [train main loss -1.894021], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 154 / 176], [train main loss -1.900067], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 155 / 176], [train main loss -1.905661], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 156 / 176], [train main loss -1.922340], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 157 / 176], [train main loss -1.915823], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 158 / 176], [train main loss -1.922225], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 159 / 176], [train main loss -1.915368], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 160 / 176], [train main loss -1.920479], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 161 / 176], [train main loss -1.919799], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 162 / 176], [train main loss -1.911081], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 163 / 176], [train main loss -1.914113], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 164 / 176], [train main loss -1.915530], [lr 0.006229] [batchtime 0.437]
[epoch 66], [iter 165 / 176], [train main loss -1.922396], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 166 / 176], [train main loss -1.926254], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 167 / 176], [train main loss -1.921157], [lr 0.006229] [batchtime 0.436]
[epoch 66], [iter 168 / 176], [train main loss -1.924862], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 169 / 176], [train main loss -1.933311], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 170 / 176], [train main loss -1.934827], [lr 0.006229] [batchtime 0.435]
[epoch 66], [iter 171 / 176], [train main loss -1.930472], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 172 / 176], [train main loss -1.941015], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 173 / 176], [train main loss -1.951170], [lr 0.006229] [batchtime 0.434]
[epoch 66], [iter 174 / 176], [train main loss -1.947172], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 175 / 176], [train main loss -1.943800], [lr 0.006229] [batchtime 0.433]
[epoch 66], [iter 176 / 176], [train main loss -1.948025], [lr 0.006229] [batchtime 0.432]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.08  35.58    0.02  0.05         0.98      0.95
   1  sidewalk          60.95   4.63    0.42  0.22         0.70      0.82
   2  building          84.15  25.20    0.05  0.13         0.95      0.88
   3  wall              12.95   0.10    4.85  1.88         0.17      0.35
   4  fence             17.56   0.25    3.99  0.70         0.20      0.59
   5  pole              31.77   0.43    1.64  0.51         0.38      0.66
   6  traffic light      3.77   0.01   25.13  0.42         0.04      0.70
   7  traffic sign       7.39   0.04   12.31  0.22         0.08      0.82
   8  vegetation        82.43  11.18    0.11  0.11         0.90      0.90
   9  terrain           39.38   0.44    0.67  0.86         0.60      0.54
  10  sky               93.13   3.73    0.04  0.03         0.96      0.97
  11  person            45.31   0.88    0.74  0.47         0.58      0.68
  12  rider              1.61   0.00   59.87  1.30         0.02      0.44
  13  car               81.02   6.71    0.05  0.18         0.95      0.85
  14  truck              0.84   0.00  116.96  0.76         0.01      0.57
  15  bus               11.44   0.02    2.68  5.06         0.27      0.16
  16  train             19.85   0.04    3.07  0.96         0.25      0.51
  17  motorcycle         0.65   0.00  152.20  1.00         0.01      0.50
  18  bicycle           30.98   0.19    1.09  1.14         0.48      0.47
Mean: 37.80
-----------------------------------------------------------------------------------------------------------
this : [epoch 66], [val loss 0.37742], [acc 0.89446], [acc_cls 0.44780], [mean_iu 0.37802], [fwavacc 0.81620]
best : [epoch 63], [val loss 0.36725], [acc 0.89511], [acc_cls 0.46099], [mean_iu 0.38498], [fwavacc 0.82022]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 67], [iter 1 / 176], [train main loss -3.413535], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 2 / 176], [train main loss -3.067890], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 3 / 176], [train main loss -3.307852], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 4 / 176], [train main loss -3.654752], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 5 / 176], [train main loss -3.294071], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 6 / 176], [train main loss -2.404011], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 7 / 176], [train main loss -2.524264], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 8 / 176], [train main loss -2.376903], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 9 / 176], [train main loss -2.412757], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 10 / 176], [train main loss -2.372486], [lr 0.006171] [batchtime 0]
[epoch 67], [iter 11 / 176], [train main loss -2.032381], [lr 0.006171] [batchtime 0.364]
[epoch 67], [iter 12 / 176], [train main loss -1.847477], [lr 0.006171] [batchtime 0.386]
[epoch 67], [iter 13 / 176], [train main loss -1.765976], [lr 0.006171] [batchtime 0.391]
[epoch 67], [iter 14 / 176], [train main loss -1.969265], [lr 0.006171] [batchtime 0.392]
[epoch 67], [iter 15 / 176], [train main loss -1.921132], [lr 0.006171] [batchtime 0.394]
[epoch 67], [iter 16 / 176], [train main loss -1.946305], [lr 0.006171] [batchtime 0.394]
[epoch 67], [iter 17 / 176], [train main loss -1.926116], [lr 0.006171] [batchtime 0.393]
[epoch 67], [iter 18 / 176], [train main loss -1.845522], [lr 0.006171] [batchtime 0.395]
[epoch 67], [iter 19 / 176], [train main loss -1.813245], [lr 0.006171] [batchtime 0.395]
[epoch 67], [iter 20 / 176], [train main loss -1.728578], [lr 0.006171] [batchtime 0.396]
[epoch 67], [iter 21 / 176], [train main loss -1.763252], [lr 0.006171] [batchtime 0.397]
[epoch 67], [iter 22 / 176], [train main loss -1.603089], [lr 0.006171] [batchtime 0.396]
[epoch 67], [iter 23 / 176], [train main loss -1.550334], [lr 0.006171] [batchtime 0.402]
[epoch 67], [iter 24 / 176], [train main loss -1.545902], [lr 0.006171] [batchtime 0.414]
[epoch 67], [iter 25 / 176], [train main loss -1.554522], [lr 0.006171] [batchtime 0.412]
[epoch 67], [iter 26 / 176], [train main loss -1.519871], [lr 0.006171] [batchtime 0.411]
[epoch 67], [iter 27 / 176], [train main loss -1.504908], [lr 0.006171] [batchtime 0.41]
[epoch 67], [iter 28 / 176], [train main loss -1.472479], [lr 0.006171] [batchtime 0.409]
[epoch 67], [iter 29 / 176], [train main loss -1.476146], [lr 0.006171] [batchtime 0.409]
[epoch 67], [iter 30 / 176], [train main loss -1.584697], [lr 0.006171] [batchtime 0.408]
[epoch 67], [iter 31 / 176], [train main loss -1.552597], [lr 0.006171] [batchtime 0.407]
[epoch 67], [iter 32 / 176], [train main loss -1.439433], [lr 0.006171] [batchtime 0.407]
[epoch 67], [iter 33 / 176], [train main loss -1.444558], [lr 0.006171] [batchtime 0.407]
[epoch 67], [iter 34 / 176], [train main loss -1.400366], [lr 0.006171] [batchtime 0.406]
[epoch 67], [iter 35 / 176], [train main loss -1.395018], [lr 0.006171] [batchtime 0.406]
[epoch 67], [iter 36 / 176], [train main loss -1.475416], [lr 0.006171] [batchtime 0.406]
[epoch 67], [iter 37 / 176], [train main loss -1.484324], [lr 0.006171] [batchtime 0.405]
[epoch 67], [iter 38 / 176], [train main loss -1.487328], [lr 0.006171] [batchtime 0.405]
[epoch 67], [iter 39 / 176], [train main loss -1.543950], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 40 / 176], [train main loss -1.558982], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 41 / 176], [train main loss -1.561735], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 42 / 176], [train main loss -1.658940], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 43 / 176], [train main loss -1.629425], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 44 / 176], [train main loss -1.623408], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 45 / 176], [train main loss -1.625784], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 46 / 176], [train main loss -1.631867], [lr 0.006171] [batchtime 0.404]
[epoch 67], [iter 47 / 176], [train main loss -1.631154], [lr 0.006171] [batchtime 0.408]
[epoch 67], [iter 48 / 176], [train main loss -1.625637], [lr 0.006171] [batchtime 0.444]
[epoch 67], [iter 49 / 176], [train main loss -1.654515], [lr 0.006171] [batchtime 0.442]
[epoch 67], [iter 50 / 176], [train main loss -1.681764], [lr 0.006171] [batchtime 0.441]
[epoch 67], [iter 51 / 176], [train main loss -1.724371], [lr 0.006171] [batchtime 0.44]
[epoch 67], [iter 52 / 176], [train main loss -1.763761], [lr 0.006171] [batchtime 0.439]
[epoch 67], [iter 53 / 176], [train main loss -1.816332], [lr 0.006171] [batchtime 0.438]
[epoch 67], [iter 54 / 176], [train main loss -1.801618], [lr 0.006171] [batchtime 0.437]
[epoch 67], [iter 55 / 176], [train main loss -1.800047], [lr 0.006171] [batchtime 0.436]
[epoch 67], [iter 56 / 176], [train main loss -1.827788], [lr 0.006171] [batchtime 0.436]
[epoch 67], [iter 57 / 176], [train main loss -1.848461], [lr 0.006171] [batchtime 0.435]
[epoch 67], [iter 58 / 176], [train main loss -1.853413], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 59 / 176], [train main loss -1.840334], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 60 / 176], [train main loss -1.901037], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 61 / 176], [train main loss -1.909823], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 62 / 176], [train main loss -1.874145], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 63 / 176], [train main loss -1.838041], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 64 / 176], [train main loss -1.828244], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 65 / 176], [train main loss -1.819986], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 66 / 176], [train main loss -1.862560], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 67 / 176], [train main loss -1.868599], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 68 / 176], [train main loss -1.855329], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 69 / 176], [train main loss -1.875479], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 70 / 176], [train main loss -1.896804], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 71 / 176], [train main loss -1.864451], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 72 / 176], [train main loss -1.822197], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 73 / 176], [train main loss -1.834994], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 74 / 176], [train main loss -1.837356], [lr 0.006171] [batchtime 0.427]
[epoch 67], [iter 75 / 176], [train main loss -1.809161], [lr 0.006171] [batchtime 0.427]
[epoch 67], [iter 76 / 176], [train main loss -1.780346], [lr 0.006171] [batchtime 0.426]
[epoch 67], [iter 77 / 176], [train main loss -1.790491], [lr 0.006171] [batchtime 0.426]
[epoch 67], [iter 78 / 176], [train main loss -1.793507], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 79 / 176], [train main loss -1.813359], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 80 / 176], [train main loss -1.850085], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 81 / 176], [train main loss -1.863761], [lr 0.006171] [batchtime 0.424]
[epoch 67], [iter 82 / 176], [train main loss -1.898942], [lr 0.006171] [batchtime 0.424]
[epoch 67], [iter 83 / 176], [train main loss -1.907980], [lr 0.006171] [batchtime 0.423]
[epoch 67], [iter 84 / 176], [train main loss -1.907115], [lr 0.006171] [batchtime 0.423]
[epoch 67], [iter 85 / 176], [train main loss -1.890243], [lr 0.006171] [batchtime 0.423]
[epoch 67], [iter 86 / 176], [train main loss -1.877783], [lr 0.006171] [batchtime 0.422]
[epoch 67], [iter 87 / 176], [train main loss -1.894363], [lr 0.006171] [batchtime 0.422]
[epoch 67], [iter 88 / 176], [train main loss -1.881253], [lr 0.006171] [batchtime 0.422]
[epoch 67], [iter 89 / 176], [train main loss -1.869144], [lr 0.006171] [batchtime 0.421]
[epoch 67], [iter 90 / 176], [train main loss -1.845772], [lr 0.006171] [batchtime 0.421]
[epoch 67], [iter 91 / 176], [train main loss -1.834604], [lr 0.006171] [batchtime 0.421]
[epoch 67], [iter 92 / 176], [train main loss -1.835078], [lr 0.006171] [batchtime 0.421]
[epoch 67], [iter 93 / 176], [train main loss -1.848975], [lr 0.006171] [batchtime 0.423]
[epoch 67], [iter 94 / 176], [train main loss -1.849045], [lr 0.006171] [batchtime 0.438]
[epoch 67], [iter 95 / 176], [train main loss -1.853339], [lr 0.006171] [batchtime 0.438]
[epoch 67], [iter 96 / 176], [train main loss -1.830912], [lr 0.006171] [batchtime 0.437]
[epoch 67], [iter 97 / 176], [train main loss -1.818108], [lr 0.006171] [batchtime 0.437]
[epoch 67], [iter 98 / 176], [train main loss -1.841903], [lr 0.006171] [batchtime 0.436]
[epoch 67], [iter 99 / 176], [train main loss -1.845475], [lr 0.006171] [batchtime 0.435]
[epoch 67], [iter 100 / 176], [train main loss -1.874011], [lr 0.006171] [batchtime 0.435]
[epoch 67], [iter 101 / 176], [train main loss -1.858817], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 102 / 176], [train main loss -1.838570], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 103 / 176], [train main loss -1.841889], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 104 / 176], [train main loss -1.841837], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 105 / 176], [train main loss -1.845341], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 106 / 176], [train main loss -1.842738], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 107 / 176], [train main loss -1.823328], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 108 / 176], [train main loss -1.834361], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 109 / 176], [train main loss -1.816373], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 110 / 176], [train main loss -1.809990], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 111 / 176], [train main loss -1.795349], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 112 / 176], [train main loss -1.768141], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 113 / 176], [train main loss -1.747490], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 114 / 176], [train main loss -1.752950], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 115 / 176], [train main loss -1.762424], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 116 / 176], [train main loss -1.762751], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 117 / 176], [train main loss -1.776781], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 118 / 176], [train main loss -1.804422], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 119 / 176], [train main loss -1.817339], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 120 / 176], [train main loss -1.835314], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 121 / 176], [train main loss -1.825546], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 122 / 176], [train main loss -1.843473], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 123 / 176], [train main loss -1.861279], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 124 / 176], [train main loss -1.862149], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 125 / 176], [train main loss -1.871413], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 126 / 176], [train main loss -1.874514], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 127 / 176], [train main loss -1.876567], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 128 / 176], [train main loss -1.861792], [lr 0.006171] [batchtime 0.427]
[epoch 67], [iter 129 / 176], [train main loss -1.868691], [lr 0.006171] [batchtime 0.427]
[epoch 67], [iter 130 / 176], [train main loss -1.876524], [lr 0.006171] [batchtime 0.427]
[epoch 67], [iter 131 / 176], [train main loss -1.869271], [lr 0.006171] [batchtime 0.427]
[epoch 67], [iter 132 / 176], [train main loss -1.867662], [lr 0.006171] [batchtime 0.426]
[epoch 67], [iter 133 / 176], [train main loss -1.866588], [lr 0.006171] [batchtime 0.426]
[epoch 67], [iter 134 / 176], [train main loss -1.861410], [lr 0.006171] [batchtime 0.426]
[epoch 67], [iter 135 / 176], [train main loss -1.875388], [lr 0.006171] [batchtime 0.426]
[epoch 67], [iter 136 / 176], [train main loss -1.867531], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 137 / 176], [train main loss -1.882017], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 138 / 176], [train main loss -1.870117], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 139 / 176], [train main loss -1.885187], [lr 0.006171] [batchtime 0.425]
[epoch 67], [iter 140 / 176], [train main loss -1.904330], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 141 / 176], [train main loss -1.908406], [lr 0.006171] [batchtime 0.435]
[epoch 67], [iter 142 / 176], [train main loss -1.888641], [lr 0.006171] [batchtime 0.435]
[epoch 67], [iter 143 / 176], [train main loss -1.899739], [lr 0.006171] [batchtime 0.435]
[epoch 67], [iter 144 / 176], [train main loss -1.889393], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 145 / 176], [train main loss -1.883274], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 146 / 176], [train main loss -1.877501], [lr 0.006171] [batchtime 0.434]
[epoch 67], [iter 147 / 176], [train main loss -1.891866], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 148 / 176], [train main loss -1.895987], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 149 / 176], [train main loss -1.887732], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 150 / 176], [train main loss -1.895184], [lr 0.006171] [batchtime 0.433]
[epoch 67], [iter 151 / 176], [train main loss -1.889746], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 152 / 176], [train main loss -1.863413], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 153 / 176], [train main loss -1.865512], [lr 0.006171] [batchtime 0.432]
[epoch 67], [iter 154 / 176], [train main loss -1.864377], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 155 / 176], [train main loss -1.857975], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 156 / 176], [train main loss -1.847233], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 157 / 176], [train main loss -1.873347], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 158 / 176], [train main loss -1.876487], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 159 / 176], [train main loss -1.895799], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 160 / 176], [train main loss -1.889586], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 161 / 176], [train main loss -1.882784], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 162 / 176], [train main loss -1.876812], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 163 / 176], [train main loss -1.887700], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 164 / 176], [train main loss -1.893436], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 165 / 176], [train main loss -1.888948], [lr 0.006171] [batchtime 0.431]
[epoch 67], [iter 166 / 176], [train main loss -1.883404], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 167 / 176], [train main loss -1.875340], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 168 / 176], [train main loss -1.868891], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 169 / 176], [train main loss -1.866556], [lr 0.006171] [batchtime 0.43]
[epoch 67], [iter 170 / 176], [train main loss -1.860311], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 171 / 176], [train main loss -1.866039], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 172 / 176], [train main loss -1.861146], [lr 0.006171] [batchtime 0.429]
[epoch 67], [iter 173 / 176], [train main loss -1.866993], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 174 / 176], [train main loss -1.872396], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 175 / 176], [train main loss -1.857267], [lr 0.006171] [batchtime 0.428]
[epoch 67], [iter 176 / 176], [train main loss -1.844236], [lr 0.006171] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.84  35.53    0.02  0.04         0.98      0.96
   1  sidewalk          65.24   5.14    0.28  0.25         0.78      0.80
   2  building          84.09  24.86    0.07  0.12         0.94      0.89
   3  wall              13.66   0.11    4.26  2.07         0.19      0.33
   4  fence             15.45   0.22    4.77  0.70         0.17      0.59
   5  pole              32.97   0.47    1.43  0.60         0.41      0.62
   6  traffic light      3.57   0.01   26.60  0.39         0.04      0.72
   7  traffic sign      10.50   0.06    8.21  0.32         0.11      0.76
   8  vegetation        81.00  11.55    0.07  0.16         0.93      0.86
   9  terrain           37.04   0.34    1.13  0.57         0.47      0.64
  10  sky               93.50   3.75    0.03  0.04         0.97      0.96
  11  person            42.70   0.81    0.88  0.46         0.53      0.69
  12  rider              2.32   0.00   40.58  1.44         0.02      0.41
  13  car               84.21   6.49    0.09  0.10         0.92      0.91
  14  truck              0.24   0.00  416.42  2.81         0.00      0.26
  15  bus               14.37   0.03    2.29  3.67         0.30      0.21
  16  train             30.56   0.06    1.80  0.48         0.36      0.68
  17  motorcycle         0.37   0.00  269.86  0.82         0.00      0.55
  18  bicycle           29.01   0.25    0.58  1.87         0.63      0.35
Mean: 38.67
-----------------------------------------------------------------------------------------------------------
this : [epoch 67], [val loss 0.36974], [acc 0.89695], [acc_cls 0.46105], [mean_iu 0.38666], [fwavacc 0.82191]
best : [epoch 67], [val loss 0.36974], [acc 0.89695], [acc_cls 0.46105], [mean_iu 0.38666], [fwavacc 0.82191]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 68], [iter 1 / 176], [train main loss -0.386596], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 2 / 176], [train main loss -1.348694], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 3 / 176], [train main loss -2.433814], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 4 / 176], [train main loss -3.011481], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 5 / 176], [train main loss -3.145407], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 6 / 176], [train main loss -2.715628], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 7 / 176], [train main loss -2.658248], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 8 / 176], [train main loss -2.793289], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 9 / 176], [train main loss -2.472616], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 10 / 176], [train main loss -2.274743], [lr 0.006114] [batchtime 0]
[epoch 68], [iter 11 / 176], [train main loss -2.149613], [lr 0.006114] [batchtime 0.373]
[epoch 68], [iter 12 / 176], [train main loss -2.079488], [lr 0.006114] [batchtime 0.39]
[epoch 68], [iter 13 / 176], [train main loss -2.271277], [lr 0.006114] [batchtime 0.391]
[epoch 68], [iter 14 / 176], [train main loss -2.138015], [lr 0.006114] [batchtime 0.394]
[epoch 68], [iter 15 / 176], [train main loss -2.016713], [lr 0.006114] [batchtime 0.397]
[epoch 68], [iter 16 / 176], [train main loss -2.234948], [lr 0.006114] [batchtime 0.401]
[epoch 68], [iter 17 / 176], [train main loss -2.268688], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 18 / 176], [train main loss -2.215237], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 19 / 176], [train main loss -2.337588], [lr 0.006114] [batchtime 0.416]
[epoch 68], [iter 20 / 176], [train main loss -2.377259], [lr 0.006114] [batchtime 0.413]
[epoch 68], [iter 21 / 176], [train main loss -2.485676], [lr 0.006114] [batchtime 0.411]
[epoch 68], [iter 22 / 176], [train main loss -2.475891], [lr 0.006114] [batchtime 0.409]
[epoch 68], [iter 23 / 176], [train main loss -2.466461], [lr 0.006114] [batchtime 0.409]
[epoch 68], [iter 24 / 176], [train main loss -2.322173], [lr 0.006114] [batchtime 0.407]
[epoch 68], [iter 25 / 176], [train main loss -2.346232], [lr 0.006114] [batchtime 0.406]
[epoch 68], [iter 26 / 176], [train main loss -2.452654], [lr 0.006114] [batchtime 0.406]
[epoch 68], [iter 27 / 176], [train main loss -2.485990], [lr 0.006114] [batchtime 0.405]
[epoch 68], [iter 28 / 176], [train main loss -2.448002], [lr 0.006114] [batchtime 0.405]
[epoch 68], [iter 29 / 176], [train main loss -2.429381], [lr 0.006114] [batchtime 0.404]
[epoch 68], [iter 30 / 176], [train main loss -2.375601], [lr 0.006114] [batchtime 0.404]
[epoch 68], [iter 31 / 176], [train main loss -2.271183], [lr 0.006114] [batchtime 0.404]
[epoch 68], [iter 32 / 176], [train main loss -2.229935], [lr 0.006114] [batchtime 0.403]
[epoch 68], [iter 33 / 176], [train main loss -2.243553], [lr 0.006114] [batchtime 0.403]
[epoch 68], [iter 34 / 176], [train main loss -2.260444], [lr 0.006114] [batchtime 0.402]
[epoch 68], [iter 35 / 176], [train main loss -2.242407], [lr 0.006114] [batchtime 0.402]
[epoch 68], [iter 36 / 176], [train main loss -2.271403], [lr 0.006114] [batchtime 0.402]
[epoch 68], [iter 37 / 176], [train main loss -2.277158], [lr 0.006114] [batchtime 0.401]
[epoch 68], [iter 38 / 176], [train main loss -2.251939], [lr 0.006114] [batchtime 0.401]
[epoch 68], [iter 39 / 176], [train main loss -2.205186], [lr 0.006114] [batchtime 0.4]
[epoch 68], [iter 40 / 176], [train main loss -2.177256], [lr 0.006114] [batchtime 0.4]
[epoch 68], [iter 41 / 176], [train main loss -2.135907], [lr 0.006114] [batchtime 0.404]
[epoch 68], [iter 42 / 176], [train main loss -2.143431], [lr 0.006114] [batchtime 0.443]
[epoch 68], [iter 43 / 176], [train main loss -2.133724], [lr 0.006114] [batchtime 0.441]
[epoch 68], [iter 44 / 176], [train main loss -2.184263], [lr 0.006114] [batchtime 0.439]
[epoch 68], [iter 45 / 176], [train main loss -2.140420], [lr 0.006114] [batchtime 0.438]
[epoch 68], [iter 46 / 176], [train main loss -2.086229], [lr 0.006114] [batchtime 0.436]
[epoch 68], [iter 47 / 176], [train main loss -2.102062], [lr 0.006114] [batchtime 0.435]
[epoch 68], [iter 48 / 176], [train main loss -2.054663], [lr 0.006114] [batchtime 0.434]
[epoch 68], [iter 49 / 176], [train main loss -2.029125], [lr 0.006114] [batchtime 0.433]
[epoch 68], [iter 50 / 176], [train main loss -2.024017], [lr 0.006114] [batchtime 0.432]
[epoch 68], [iter 51 / 176], [train main loss -2.038693], [lr 0.006114] [batchtime 0.431]
[epoch 68], [iter 52 / 176], [train main loss -2.057076], [lr 0.006114] [batchtime 0.43]
[epoch 68], [iter 53 / 176], [train main loss -2.072764], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 54 / 176], [train main loss -2.064672], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 55 / 176], [train main loss -2.052609], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 56 / 176], [train main loss -2.026880], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 57 / 176], [train main loss -2.017744], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 58 / 176], [train main loss -2.008707], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 59 / 176], [train main loss -1.954173], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 60 / 176], [train main loss -1.965191], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 61 / 176], [train main loss -1.954481], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 62 / 176], [train main loss -1.931843], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 63 / 176], [train main loss -1.950674], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 64 / 176], [train main loss -1.953039], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 65 / 176], [train main loss -1.944721], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 66 / 176], [train main loss -1.953706], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 67 / 176], [train main loss -1.977508], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 68 / 176], [train main loss -2.001711], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 69 / 176], [train main loss -1.950723], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 70 / 176], [train main loss -1.944227], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 71 / 176], [train main loss -1.954562], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 72 / 176], [train main loss -1.924552], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 73 / 176], [train main loss -1.968305], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 74 / 176], [train main loss -1.996504], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 75 / 176], [train main loss -2.036239], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 76 / 176], [train main loss -2.040888], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 77 / 176], [train main loss -2.030986], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 78 / 176], [train main loss -2.021175], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 79 / 176], [train main loss -2.031617], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 80 / 176], [train main loss -2.064148], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 81 / 176], [train main loss -2.067955], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 82 / 176], [train main loss -2.087017], [lr 0.006114] [batchtime 0.418]
[epoch 68], [iter 83 / 176], [train main loss -2.102840], [lr 0.006114] [batchtime 0.418]
[epoch 68], [iter 84 / 176], [train main loss -2.101348], [lr 0.006114] [batchtime 0.418]
[epoch 68], [iter 85 / 176], [train main loss -2.055961], [lr 0.006114] [batchtime 0.417]
[epoch 68], [iter 86 / 176], [train main loss -2.053173], [lr 0.006114] [batchtime 0.417]
[epoch 68], [iter 87 / 176], [train main loss -2.033835], [lr 0.006114] [batchtime 0.417]
[epoch 68], [iter 88 / 176], [train main loss -2.046529], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 89 / 176], [train main loss -2.011841], [lr 0.006114] [batchtime 0.432]
[epoch 68], [iter 90 / 176], [train main loss -1.997540], [lr 0.006114] [batchtime 0.432]
[epoch 68], [iter 91 / 176], [train main loss -2.006049], [lr 0.006114] [batchtime 0.431]
[epoch 68], [iter 92 / 176], [train main loss -1.999074], [lr 0.006114] [batchtime 0.43]
[epoch 68], [iter 93 / 176], [train main loss -1.982585], [lr 0.006114] [batchtime 0.43]
[epoch 68], [iter 94 / 176], [train main loss -1.958343], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 95 / 176], [train main loss -1.940089], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 96 / 176], [train main loss -1.947830], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 97 / 176], [train main loss -1.941049], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 98 / 176], [train main loss -1.925314], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 99 / 176], [train main loss -1.917003], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 100 / 176], [train main loss -1.924830], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 101 / 176], [train main loss -1.911201], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 102 / 176], [train main loss -1.916422], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 103 / 176], [train main loss -1.915492], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 104 / 176], [train main loss -1.897414], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 105 / 176], [train main loss -1.916477], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 106 / 176], [train main loss -1.918600], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 107 / 176], [train main loss -1.964650], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 108 / 176], [train main loss -1.957013], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 109 / 176], [train main loss -1.937241], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 110 / 176], [train main loss -1.944958], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 111 / 176], [train main loss -1.934296], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 112 / 176], [train main loss -1.949811], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 113 / 176], [train main loss -1.939432], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 114 / 176], [train main loss -1.942203], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 115 / 176], [train main loss -1.909598], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 116 / 176], [train main loss -1.936300], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 117 / 176], [train main loss -1.928435], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 118 / 176], [train main loss -1.901053], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 119 / 176], [train main loss -1.907768], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 120 / 176], [train main loss -1.914245], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 121 / 176], [train main loss -1.914542], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 122 / 176], [train main loss -1.927400], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 123 / 176], [train main loss -1.926090], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 124 / 176], [train main loss -1.941716], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 125 / 176], [train main loss -1.955195], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 126 / 176], [train main loss -1.925707], [lr 0.006114] [batchtime 0.421]
[epoch 68], [iter 127 / 176], [train main loss -1.938332], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 128 / 176], [train main loss -1.946359], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 129 / 176], [train main loss -1.959312], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 130 / 176], [train main loss -1.972065], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 131 / 176], [train main loss -1.974065], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 132 / 176], [train main loss -1.977444], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 133 / 176], [train main loss -1.956540], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 134 / 176], [train main loss -1.956981], [lr 0.006114] [batchtime 0.419]
[epoch 68], [iter 135 / 176], [train main loss -1.945121], [lr 0.006114] [batchtime 0.42]
[epoch 68], [iter 136 / 176], [train main loss -1.965824], [lr 0.006114] [batchtime 0.43]
[epoch 68], [iter 137 / 176], [train main loss -1.965901], [lr 0.006114] [batchtime 0.43]
[epoch 68], [iter 138 / 176], [train main loss -1.976350], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 139 / 176], [train main loss -1.974526], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 140 / 176], [train main loss -1.970685], [lr 0.006114] [batchtime 0.429]
[epoch 68], [iter 141 / 176], [train main loss -1.984761], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 142 / 176], [train main loss -1.991639], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 143 / 176], [train main loss -1.989399], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 144 / 176], [train main loss -1.985152], [lr 0.006114] [batchtime 0.428]
[epoch 68], [iter 145 / 176], [train main loss -1.984310], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 146 / 176], [train main loss -1.999299], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 147 / 176], [train main loss -1.993471], [lr 0.006114] [batchtime 0.427]
[epoch 68], [iter 148 / 176], [train main loss -1.981190], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 149 / 176], [train main loss -1.969081], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 150 / 176], [train main loss -1.967277], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 151 / 176], [train main loss -1.960237], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 152 / 176], [train main loss -1.962852], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 153 / 176], [train main loss -1.970088], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 154 / 176], [train main loss -1.967168], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 155 / 176], [train main loss -1.975543], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 156 / 176], [train main loss -1.957177], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 157 / 176], [train main loss -1.958429], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 158 / 176], [train main loss -1.970417], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 159 / 176], [train main loss -1.975137], [lr 0.006114] [batchtime 0.426]
[epoch 68], [iter 160 / 176], [train main loss -1.975172], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 161 / 176], [train main loss -1.970834], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 162 / 176], [train main loss -1.964505], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 163 / 176], [train main loss -1.981922], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 164 / 176], [train main loss -1.977064], [lr 0.006114] [batchtime 0.425]
[epoch 68], [iter 165 / 176], [train main loss -1.978312], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 166 / 176], [train main loss -1.968316], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 167 / 176], [train main loss -1.984334], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 168 / 176], [train main loss -1.987452], [lr 0.006114] [batchtime 0.424]
[epoch 68], [iter 169 / 176], [train main loss -2.003124], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 170 / 176], [train main loss -2.001145], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 171 / 176], [train main loss -2.002984], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 172 / 176], [train main loss -1.998263], [lr 0.006114] [batchtime 0.423]
[epoch 68], [iter 173 / 176], [train main loss -1.995094], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 174 / 176], [train main loss -2.012431], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 175 / 176], [train main loss -2.015550], [lr 0.006114] [batchtime 0.422]
[epoch 68], [iter 176 / 176], [train main loss -2.027895], [lr 0.006114] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.93  35.36    0.03  0.04         0.97      0.96
   1  sidewalk          66.32   5.24    0.26  0.25         0.80      0.80
   2  building          84.53  24.86    0.07  0.11         0.94      0.90
   3  wall              13.75   0.11    4.33  1.94         0.19      0.34
   4  fence             18.47   0.27    3.65  0.77         0.22      0.57
   5  pole              33.36   0.46    1.46  0.54         0.41      0.65
   6  traffic light      7.24   0.01   12.26  0.56         0.08      0.64
   7  traffic sign      11.28   0.06    7.63  0.24         0.12      0.81
   8  vegetation        82.23  11.51    0.07  0.14         0.93      0.88
   9  terrain           39.14   0.37    0.99  0.57         0.50      0.64
  10  sky               93.01   3.72    0.04  0.03         0.96      0.97
  11  person            45.18   0.86    0.79  0.42         0.56      0.70
  12  rider              1.30   0.00   74.88  1.16         0.01      0.46
  13  car               81.22   6.76    0.05  0.18         0.96      0.84
  14  truck              0.59   0.00  166.88  0.48         0.01      0.67
  15  bus               11.97   0.03    2.35  5.00         0.30      0.17
  16  train             12.86   0.02    6.26  0.51         0.14      0.66
  17  motorcycle         0.35   0.00  285.22  0.88         0.00      0.53
  18  bicycle           31.65   0.21    0.89  1.27         0.53      0.44
Mean: 38.34
-----------------------------------------------------------------------------------------------------------
this : [epoch 68], [val loss 0.35083], [acc 0.89872], [acc_cls 0.45268], [mean_iu 0.38335], [fwavacc 0.82413]
best : [epoch 67], [val loss 0.36974], [acc 0.89695], [acc_cls 0.46105], [mean_iu 0.38666], [fwavacc 0.82191]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 69], [iter 1 / 176], [train main loss -3.004843], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 2 / 176], [train main loss -2.654567], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 3 / 176], [train main loss -1.718230], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 4 / 176], [train main loss -1.012974], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 5 / 176], [train main loss -1.690966], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 6 / 176], [train main loss -1.458198], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 7 / 176], [train main loss -1.516189], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 8 / 176], [train main loss -1.471673], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 9 / 176], [train main loss -1.593876], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 10 / 176], [train main loss -1.714806], [lr 0.006057] [batchtime 0]
[epoch 69], [iter 11 / 176], [train main loss -1.831854], [lr 0.006057] [batchtime 0.373]
[epoch 69], [iter 12 / 176], [train main loss -1.876627], [lr 0.006057] [batchtime 0.386]
[epoch 69], [iter 13 / 176], [train main loss -2.035069], [lr 0.006057] [batchtime 0.391]
[epoch 69], [iter 14 / 176], [train main loss -2.089884], [lr 0.006057] [batchtime 0.393]
[epoch 69], [iter 15 / 176], [train main loss -2.252616], [lr 0.006057] [batchtime 0.394]
[epoch 69], [iter 16 / 176], [train main loss -2.284570], [lr 0.006057] [batchtime 0.394]
[epoch 69], [iter 17 / 176], [train main loss -2.066656], [lr 0.006057] [batchtime 0.395]
[epoch 69], [iter 18 / 176], [train main loss -2.102503], [lr 0.006057] [batchtime 0.396]
[epoch 69], [iter 19 / 176], [train main loss -2.118926], [lr 0.006057] [batchtime 0.401]
[epoch 69], [iter 20 / 176], [train main loss -2.085444], [lr 0.006057] [batchtime 0.4]
[epoch 69], [iter 21 / 176], [train main loss -2.059727], [lr 0.006057] [batchtime 0.407]
[epoch 69], [iter 22 / 176], [train main loss -2.054891], [lr 0.006057] [batchtime 0.405]
[epoch 69], [iter 23 / 176], [train main loss -2.007556], [lr 0.006057] [batchtime 0.404]
[epoch 69], [iter 24 / 176], [train main loss -1.927383], [lr 0.006057] [batchtime 0.404]
[epoch 69], [iter 25 / 176], [train main loss -1.859400], [lr 0.006057] [batchtime 0.404]
[epoch 69], [iter 26 / 176], [train main loss -1.767576], [lr 0.006057] [batchtime 0.404]
[epoch 69], [iter 27 / 176], [train main loss -1.862498], [lr 0.006057] [batchtime 0.404]
[epoch 69], [iter 28 / 176], [train main loss -1.919679], [lr 0.006057] [batchtime 0.403]
[epoch 69], [iter 29 / 176], [train main loss -2.055642], [lr 0.006057] [batchtime 0.403]
[epoch 69], [iter 30 / 176], [train main loss -2.094373], [lr 0.006057] [batchtime 0.403]
[epoch 69], [iter 31 / 176], [train main loss -2.080183], [lr 0.006057] [batchtime 0.403]
[epoch 69], [iter 32 / 176], [train main loss -2.029928], [lr 0.006057] [batchtime 0.403]
[epoch 69], [iter 33 / 176], [train main loss -2.025205], [lr 0.006057] [batchtime 0.402]
[epoch 69], [iter 34 / 176], [train main loss -1.973650], [lr 0.006057] [batchtime 0.402]
[epoch 69], [iter 35 / 176], [train main loss -2.006225], [lr 0.006057] [batchtime 0.402]
[epoch 69], [iter 36 / 176], [train main loss -2.008601], [lr 0.006057] [batchtime 0.401]
[epoch 69], [iter 37 / 176], [train main loss -1.937343], [lr 0.006057] [batchtime 0.401]
[epoch 69], [iter 38 / 176], [train main loss -1.924755], [lr 0.006057] [batchtime 0.401]
[epoch 69], [iter 39 / 176], [train main loss -1.848951], [lr 0.006057] [batchtime 0.4]
[epoch 69], [iter 40 / 176], [train main loss -1.827840], [lr 0.006057] [batchtime 0.4]
[epoch 69], [iter 41 / 176], [train main loss -1.852259], [lr 0.006057] [batchtime 0.4]
[epoch 69], [iter 42 / 176], [train main loss -1.817418], [lr 0.006057] [batchtime 0.4]
[epoch 69], [iter 43 / 176], [train main loss -1.896028], [lr 0.006057] [batchtime 0.412]
[epoch 69], [iter 44 / 176], [train main loss -1.909592], [lr 0.006057] [batchtime 0.415]
[epoch 69], [iter 45 / 176], [train main loss -1.914731], [lr 0.006057] [batchtime 0.419]
[epoch 69], [iter 46 / 176], [train main loss -1.967308], [lr 0.006057] [batchtime 0.418]
[epoch 69], [iter 47 / 176], [train main loss -2.034814], [lr 0.006057] [batchtime 0.417]
[epoch 69], [iter 48 / 176], [train main loss -2.084358], [lr 0.006057] [batchtime 0.417]
[epoch 69], [iter 49 / 176], [train main loss -2.104630], [lr 0.006057] [batchtime 0.416]
[epoch 69], [iter 50 / 176], [train main loss -2.117669], [lr 0.006057] [batchtime 0.416]
[epoch 69], [iter 51 / 176], [train main loss -2.100663], [lr 0.006057] [batchtime 0.415]
[epoch 69], [iter 52 / 176], [train main loss -2.060501], [lr 0.006057] [batchtime 0.414]
[epoch 69], [iter 53 / 176], [train main loss -2.062174], [lr 0.006057] [batchtime 0.414]
[epoch 69], [iter 54 / 176], [train main loss -2.050811], [lr 0.006057] [batchtime 0.414]
[epoch 69], [iter 55 / 176], [train main loss -2.038780], [lr 0.006057] [batchtime 0.413]
[epoch 69], [iter 56 / 176], [train main loss -2.057391], [lr 0.006057] [batchtime 0.413]
[epoch 69], [iter 57 / 176], [train main loss -2.052180], [lr 0.006057] [batchtime 0.413]
[epoch 69], [iter 58 / 176], [train main loss -2.065891], [lr 0.006057] [batchtime 0.412]
[epoch 69], [iter 59 / 176], [train main loss -2.023862], [lr 0.006057] [batchtime 0.412]
[epoch 69], [iter 60 / 176], [train main loss -2.008886], [lr 0.006057] [batchtime 0.411]
[epoch 69], [iter 61 / 176], [train main loss -1.991255], [lr 0.006057] [batchtime 0.411]
[epoch 69], [iter 62 / 176], [train main loss -2.027253], [lr 0.006057] [batchtime 0.411]
[epoch 69], [iter 63 / 176], [train main loss -2.040106], [lr 0.006057] [batchtime 0.411]
[epoch 69], [iter 64 / 176], [train main loss -1.975387], [lr 0.006057] [batchtime 0.41]
[epoch 69], [iter 65 / 176], [train main loss -1.927883], [lr 0.006057] [batchtime 0.41]
[epoch 69], [iter 66 / 176], [train main loss -1.938256], [lr 0.006057] [batchtime 0.41]
[epoch 69], [iter 67 / 176], [train main loss -1.977462], [lr 0.006057] [batchtime 0.414]
[epoch 69], [iter 68 / 176], [train main loss -1.962675], [lr 0.006057] [batchtime 0.414]
[epoch 69], [iter 69 / 176], [train main loss -1.984002], [lr 0.006057] [batchtime 0.417]
[epoch 69], [iter 70 / 176], [train main loss -2.012114], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 71 / 176], [train main loss -2.062373], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 72 / 176], [train main loss -2.054963], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 73 / 176], [train main loss -2.070944], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 74 / 176], [train main loss -2.072801], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 75 / 176], [train main loss -2.086363], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 76 / 176], [train main loss -2.102317], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 77 / 176], [train main loss -2.122650], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 78 / 176], [train main loss -2.159571], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 79 / 176], [train main loss -2.180382], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 80 / 176], [train main loss -2.139635], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 81 / 176], [train main loss -2.106729], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 82 / 176], [train main loss -2.087388], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 83 / 176], [train main loss -2.102881], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 84 / 176], [train main loss -2.079073], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 85 / 176], [train main loss -2.111111], [lr 0.006057] [batchtime 0.424]
[epoch 69], [iter 86 / 176], [train main loss -2.104447], [lr 0.006057] [batchtime 0.424]
[epoch 69], [iter 87 / 176], [train main loss -2.123775], [lr 0.006057] [batchtime 0.423]
[epoch 69], [iter 88 / 176], [train main loss -2.134037], [lr 0.006057] [batchtime 0.423]
[epoch 69], [iter 89 / 176], [train main loss -2.120467], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 90 / 176], [train main loss -2.105733], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 91 / 176], [train main loss -2.111963], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 92 / 176], [train main loss -2.103335], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 93 / 176], [train main loss -2.088674], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 94 / 176], [train main loss -2.102271], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 95 / 176], [train main loss -2.094345], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 96 / 176], [train main loss -2.077712], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 97 / 176], [train main loss -2.098384], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 98 / 176], [train main loss -2.084655], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 99 / 176], [train main loss -2.061038], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 100 / 176], [train main loss -2.048642], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 101 / 176], [train main loss -2.049325], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 102 / 176], [train main loss -2.054305], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 103 / 176], [train main loss -2.070680], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 104 / 176], [train main loss -2.056732], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 105 / 176], [train main loss -2.025372], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 106 / 176], [train main loss -2.028131], [lr 0.006057] [batchtime 0.425]
[epoch 69], [iter 107 / 176], [train main loss -2.018063], [lr 0.006057] [batchtime 0.424]
[epoch 69], [iter 108 / 176], [train main loss -2.004460], [lr 0.006057] [batchtime 0.424]
[epoch 69], [iter 109 / 176], [train main loss -1.989163], [lr 0.006057] [batchtime 0.424]
[epoch 69], [iter 110 / 176], [train main loss -1.980668], [lr 0.006057] [batchtime 0.424]
[epoch 69], [iter 111 / 176], [train main loss -2.000446], [lr 0.006057] [batchtime 0.423]
[epoch 69], [iter 112 / 176], [train main loss -2.019207], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 113 / 176], [train main loss -2.015465], [lr 0.006057] [batchtime 0.435]
[epoch 69], [iter 114 / 176], [train main loss -2.023326], [lr 0.006057] [batchtime 0.434]
[epoch 69], [iter 115 / 176], [train main loss -2.018400], [lr 0.006057] [batchtime 0.434]
[epoch 69], [iter 116 / 176], [train main loss -2.013513], [lr 0.006057] [batchtime 0.433]
[epoch 69], [iter 117 / 176], [train main loss -1.984001], [lr 0.006057] [batchtime 0.433]
[epoch 69], [iter 118 / 176], [train main loss -1.977403], [lr 0.006057] [batchtime 0.433]
[epoch 69], [iter 119 / 176], [train main loss -1.966580], [lr 0.006057] [batchtime 0.432]
[epoch 69], [iter 120 / 176], [train main loss -1.966515], [lr 0.006057] [batchtime 0.432]
[epoch 69], [iter 121 / 176], [train main loss -1.996639], [lr 0.006057] [batchtime 0.432]
[epoch 69], [iter 122 / 176], [train main loss -1.990946], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 123 / 176], [train main loss -1.992603], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 124 / 176], [train main loss -1.962396], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 125 / 176], [train main loss -1.964366], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 126 / 176], [train main loss -1.963396], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 127 / 176], [train main loss -1.960878], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 128 / 176], [train main loss -1.972121], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 129 / 176], [train main loss -1.962224], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 130 / 176], [train main loss -1.955980], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 131 / 176], [train main loss -1.967537], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 132 / 176], [train main loss -1.955873], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 133 / 176], [train main loss -1.956449], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 134 / 176], [train main loss -1.960066], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 135 / 176], [train main loss -1.970554], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 136 / 176], [train main loss -1.968657], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 137 / 176], [train main loss -1.951038], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 138 / 176], [train main loss -1.927103], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 139 / 176], [train main loss -1.937034], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 140 / 176], [train main loss -1.938463], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 141 / 176], [train main loss -1.934544], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 142 / 176], [train main loss -1.942316], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 143 / 176], [train main loss -1.956362], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 144 / 176], [train main loss -1.955736], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 145 / 176], [train main loss -1.966781], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 146 / 176], [train main loss -1.971893], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 147 / 176], [train main loss -1.979430], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 148 / 176], [train main loss -1.968503], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 149 / 176], [train main loss -1.969129], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 150 / 176], [train main loss -1.938110], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 151 / 176], [train main loss -1.943791], [lr 0.006057] [batchtime 0.426]
[epoch 69], [iter 152 / 176], [train main loss -1.946437], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 153 / 176], [train main loss -1.936228], [lr 0.006057] [batchtime 0.434]
[epoch 69], [iter 154 / 176], [train main loss -1.921948], [lr 0.006057] [batchtime 0.433]
[epoch 69], [iter 155 / 176], [train main loss -1.919726], [lr 0.006057] [batchtime 0.433]
[epoch 69], [iter 156 / 176], [train main loss -1.925376], [lr 0.006057] [batchtime 0.433]
[epoch 69], [iter 157 / 176], [train main loss -1.909851], [lr 0.006057] [batchtime 0.432]
[epoch 69], [iter 158 / 176], [train main loss -1.907955], [lr 0.006057] [batchtime 0.432]
[epoch 69], [iter 159 / 176], [train main loss -1.906871], [lr 0.006057] [batchtime 0.432]
[epoch 69], [iter 160 / 176], [train main loss -1.898937], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 161 / 176], [train main loss -1.904168], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 162 / 176], [train main loss -1.905479], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 163 / 176], [train main loss -1.909434], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 164 / 176], [train main loss -1.930024], [lr 0.006057] [batchtime 0.431]
[epoch 69], [iter 165 / 176], [train main loss -1.933026], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 166 / 176], [train main loss -1.935570], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 167 / 176], [train main loss -1.935443], [lr 0.006057] [batchtime 0.43]
[epoch 69], [iter 168 / 176], [train main loss -1.938675], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 169 / 176], [train main loss -1.933603], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 170 / 176], [train main loss -1.927770], [lr 0.006057] [batchtime 0.429]
[epoch 69], [iter 171 / 176], [train main loss -1.901303], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 172 / 176], [train main loss -1.882321], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 173 / 176], [train main loss -1.873169], [lr 0.006057] [batchtime 0.428]
[epoch 69], [iter 174 / 176], [train main loss -1.869422], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 175 / 176], [train main loss -1.873639], [lr 0.006057] [batchtime 0.427]
[epoch 69], [iter 176 / 176], [train main loss -1.862896], [lr 0.006057] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.77  35.47    0.03  0.04         0.98      0.96
   1  sidewalk          64.60   5.08    0.30  0.25         0.77      0.80
   2  building          84.06  25.03    0.06  0.13         0.94      0.89
   3  wall              10.94   0.08    6.57  1.57         0.13      0.39
   4  fence             16.45   0.23    4.46  0.61         0.18      0.62
   5  pole              32.84   0.45    1.54  0.50         0.39      0.66
   6  traffic light      4.05   0.01   23.23  0.43         0.04      0.70
   7  traffic sign      13.33   0.08    6.18  0.32         0.14      0.76
   8  vegetation        81.70  11.56    0.07  0.15         0.94      0.87
   9  terrain           36.74   0.33    1.19  0.53         0.46      0.65
  10  sky               93.16   3.74    0.03  0.04         0.97      0.96
  11  person            43.95   0.83    0.84  0.43         0.54      0.70
  12  rider              3.71   0.00   24.39  1.54         0.04      0.39
  13  car               83.48   6.64    0.06  0.13         0.94      0.88
  14  truck              0.29   0.00  340.18  0.14         0.00      0.88
  15  bus               14.48   0.03    1.69  4.22         0.37      0.19
  16  train             14.32   0.03    5.83  0.15         0.15      0.87
  17  motorcycle         1.21   0.00   81.04  0.64         0.01      0.61
  18  bicycle           32.62   0.21    0.88  1.19         0.53      0.46
Mean: 38.20
-----------------------------------------------------------------------------------------------------------
this : [epoch 69], [val loss 0.36067], [acc 0.89805], [acc_cls 0.44844], [mean_iu 0.38195], [fwavacc 0.82152]
best : [epoch 67], [val loss 0.36974], [acc 0.89695], [acc_cls 0.46105], [mean_iu 0.38666], [fwavacc 0.82191]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 70], [iter 1 / 176], [train main loss -1.793850], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 2 / 176], [train main loss -2.205798], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 3 / 176], [train main loss -2.256806], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 4 / 176], [train main loss -2.516060], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 5 / 176], [train main loss -2.137773], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 6 / 176], [train main loss -2.119605], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 7 / 176], [train main loss -1.963109], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 8 / 176], [train main loss -2.065841], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 9 / 176], [train main loss -2.142483], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 10 / 176], [train main loss -2.209241], [lr 0.006000] [batchtime 0]
[epoch 70], [iter 11 / 176], [train main loss -2.297720], [lr 0.006000] [batchtime 0.363]
[epoch 70], [iter 12 / 176], [train main loss -2.359258], [lr 0.006000] [batchtime 0.379]
[epoch 70], [iter 13 / 176], [train main loss -2.294561], [lr 0.006000] [batchtime 0.389]
[epoch 70], [iter 14 / 176], [train main loss -2.163191], [lr 0.006000] [batchtime 0.39]
[epoch 70], [iter 15 / 176], [train main loss -2.249209], [lr 0.006000] [batchtime 0.39]
[epoch 70], [iter 16 / 176], [train main loss -2.183619], [lr 0.006000] [batchtime 0.392]
[epoch 70], [iter 17 / 176], [train main loss -2.188199], [lr 0.006000] [batchtime 0.394]
[epoch 70], [iter 18 / 176], [train main loss -2.322206], [lr 0.006000] [batchtime 0.393]
[epoch 70], [iter 19 / 176], [train main loss -2.327764], [lr 0.006000] [batchtime 0.393]
[epoch 70], [iter 20 / 176], [train main loss -2.318442], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 21 / 176], [train main loss -2.443646], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 22 / 176], [train main loss -2.404204], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 23 / 176], [train main loss -2.348681], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 24 / 176], [train main loss -2.390659], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 25 / 176], [train main loss -2.356594], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 26 / 176], [train main loss -2.238829], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 27 / 176], [train main loss -2.161032], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 28 / 176], [train main loss -2.178534], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 29 / 176], [train main loss -2.213064], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 30 / 176], [train main loss -2.073959], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 31 / 176], [train main loss -2.068608], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 32 / 176], [train main loss -2.091064], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 33 / 176], [train main loss -2.070030], [lr 0.006000] [batchtime 0.397]
[epoch 70], [iter 34 / 176], [train main loss -2.070674], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 35 / 176], [train main loss -2.065388], [lr 0.006000] [batchtime 0.398]
[epoch 70], [iter 36 / 176], [train main loss -2.170071], [lr 0.006000] [batchtime 0.402]
[epoch 70], [iter 37 / 176], [train main loss -2.084872], [lr 0.006000] [batchtime 0.402]
[epoch 70], [iter 38 / 176], [train main loss -2.065182], [lr 0.006000] [batchtime 0.402]
[epoch 70], [iter 39 / 176], [train main loss -2.114761], [lr 0.006000] [batchtime 0.402]
[epoch 70], [iter 40 / 176], [train main loss -2.104712], [lr 0.006000] [batchtime 0.401]
[epoch 70], [iter 41 / 176], [train main loss -2.128189], [lr 0.006000] [batchtime 0.401]
[epoch 70], [iter 42 / 176], [train main loss -2.161230], [lr 0.006000] [batchtime 0.401]
[epoch 70], [iter 43 / 176], [train main loss -2.165174], [lr 0.006000] [batchtime 0.401]
[epoch 70], [iter 44 / 176], [train main loss -2.147444], [lr 0.006000] [batchtime 0.405]
[epoch 70], [iter 45 / 176], [train main loss -2.215561], [lr 0.006000] [batchtime 0.442]
[epoch 70], [iter 46 / 176], [train main loss -2.192673], [lr 0.006000] [batchtime 0.44]
[epoch 70], [iter 47 / 176], [train main loss -2.163025], [lr 0.006000] [batchtime 0.438]
[epoch 70], [iter 48 / 176], [train main loss -2.222933], [lr 0.006000] [batchtime 0.437]
[epoch 70], [iter 49 / 176], [train main loss -2.194090], [lr 0.006000] [batchtime 0.436]
[epoch 70], [iter 50 / 176], [train main loss -2.224128], [lr 0.006000] [batchtime 0.435]
[epoch 70], [iter 51 / 176], [train main loss -2.233586], [lr 0.006000] [batchtime 0.434]
[epoch 70], [iter 52 / 176], [train main loss -2.254039], [lr 0.006000] [batchtime 0.433]
[epoch 70], [iter 53 / 176], [train main loss -2.268855], [lr 0.006000] [batchtime 0.432]
[epoch 70], [iter 54 / 176], [train main loss -2.215701], [lr 0.006000] [batchtime 0.431]
[epoch 70], [iter 55 / 176], [train main loss -2.296959], [lr 0.006000] [batchtime 0.431]
[epoch 70], [iter 56 / 176], [train main loss -2.313997], [lr 0.006000] [batchtime 0.43]
[epoch 70], [iter 57 / 176], [train main loss -2.336992], [lr 0.006000] [batchtime 0.429]
[epoch 70], [iter 58 / 176], [train main loss -2.310452], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 59 / 176], [train main loss -2.266006], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 60 / 176], [train main loss -2.209331], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 61 / 176], [train main loss -2.159619], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 62 / 176], [train main loss -2.098669], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 63 / 176], [train main loss -2.155834], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 64 / 176], [train main loss -2.163404], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 65 / 176], [train main loss -2.156006], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 66 / 176], [train main loss -2.162590], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 67 / 176], [train main loss -2.167919], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 68 / 176], [train main loss -2.157890], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 69 / 176], [train main loss -2.141835], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 70 / 176], [train main loss -2.165373], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 71 / 176], [train main loss -2.160356], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 72 / 176], [train main loss -2.148221], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 73 / 176], [train main loss -2.168616], [lr 0.006000] [batchtime 0.421]
[epoch 70], [iter 74 / 176], [train main loss -2.200490], [lr 0.006000] [batchtime 0.421]
[epoch 70], [iter 75 / 176], [train main loss -2.196257], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 76 / 176], [train main loss -2.211906], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 77 / 176], [train main loss -2.182776], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 78 / 176], [train main loss -2.182215], [lr 0.006000] [batchtime 0.419]
[epoch 70], [iter 79 / 176], [train main loss -2.185782], [lr 0.006000] [batchtime 0.419]
[epoch 70], [iter 80 / 176], [train main loss -2.182299], [lr 0.006000] [batchtime 0.418]
[epoch 70], [iter 81 / 176], [train main loss -2.124744], [lr 0.006000] [batchtime 0.418]
[epoch 70], [iter 82 / 176], [train main loss -2.136061], [lr 0.006000] [batchtime 0.418]
[epoch 70], [iter 83 / 176], [train main loss -2.170981], [lr 0.006000] [batchtime 0.417]
[epoch 70], [iter 84 / 176], [train main loss -2.185668], [lr 0.006000] [batchtime 0.417]
[epoch 70], [iter 85 / 176], [train main loss -2.154929], [lr 0.006000] [batchtime 0.417]
[epoch 70], [iter 86 / 176], [train main loss -2.146869], [lr 0.006000] [batchtime 0.416]
[epoch 70], [iter 87 / 176], [train main loss -2.153482], [lr 0.006000] [batchtime 0.416]
[epoch 70], [iter 88 / 176], [train main loss -2.152174], [lr 0.006000] [batchtime 0.416]
[epoch 70], [iter 89 / 176], [train main loss -2.152555], [lr 0.006000] [batchtime 0.415]
[epoch 70], [iter 90 / 176], [train main loss -2.185948], [lr 0.006000] [batchtime 0.415]
[epoch 70], [iter 91 / 176], [train main loss -2.164317], [lr 0.006000] [batchtime 0.417]
[epoch 70], [iter 92 / 176], [train main loss -2.186787], [lr 0.006000] [batchtime 0.433]
[epoch 70], [iter 93 / 176], [train main loss -2.173150], [lr 0.006000] [batchtime 0.432]
[epoch 70], [iter 94 / 176], [train main loss -2.156276], [lr 0.006000] [batchtime 0.431]
[epoch 70], [iter 95 / 176], [train main loss -2.165022], [lr 0.006000] [batchtime 0.431]
[epoch 70], [iter 96 / 176], [train main loss -2.120420], [lr 0.006000] [batchtime 0.431]
[epoch 70], [iter 97 / 176], [train main loss -2.110952], [lr 0.006000] [batchtime 0.43]
[epoch 70], [iter 98 / 176], [train main loss -2.118326], [lr 0.006000] [batchtime 0.43]
[epoch 70], [iter 99 / 176], [train main loss -2.104039], [lr 0.006000] [batchtime 0.429]
[epoch 70], [iter 100 / 176], [train main loss -2.095618], [lr 0.006000] [batchtime 0.429]
[epoch 70], [iter 101 / 176], [train main loss -2.077275], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 102 / 176], [train main loss -2.056588], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 103 / 176], [train main loss -2.082537], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 104 / 176], [train main loss -2.066209], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 105 / 176], [train main loss -2.065704], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 106 / 176], [train main loss -2.080923], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 107 / 176], [train main loss -2.071079], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 108 / 176], [train main loss -2.056939], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 109 / 176], [train main loss -2.039896], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 110 / 176], [train main loss -2.027797], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 111 / 176], [train main loss -2.019981], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 112 / 176], [train main loss -1.996313], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 113 / 176], [train main loss -1.984984], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 114 / 176], [train main loss -2.004131], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 115 / 176], [train main loss -2.002720], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 116 / 176], [train main loss -1.985289], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 117 / 176], [train main loss -1.997393], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 118 / 176], [train main loss -1.963022], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 119 / 176], [train main loss -1.966097], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 120 / 176], [train main loss -1.976220], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 121 / 176], [train main loss -2.001027], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 122 / 176], [train main loss -2.004751], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 123 / 176], [train main loss -1.993577], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 124 / 176], [train main loss -2.001167], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 125 / 176], [train main loss -1.991079], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 126 / 176], [train main loss -1.973855], [lr 0.006000] [batchtime 0.421]
[epoch 70], [iter 127 / 176], [train main loss -1.973467], [lr 0.006000] [batchtime 0.421]
[epoch 70], [iter 128 / 176], [train main loss -1.978241], [lr 0.006000] [batchtime 0.421]
[epoch 70], [iter 129 / 176], [train main loss -1.974117], [lr 0.006000] [batchtime 0.421]
[epoch 70], [iter 130 / 176], [train main loss -1.939286], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 131 / 176], [train main loss -1.934739], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 132 / 176], [train main loss -1.922276], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 133 / 176], [train main loss -1.917567], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 134 / 176], [train main loss -1.939906], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 135 / 176], [train main loss -1.938500], [lr 0.006000] [batchtime 0.419]
[epoch 70], [iter 136 / 176], [train main loss -1.918091], [lr 0.006000] [batchtime 0.419]
[epoch 70], [iter 137 / 176], [train main loss -1.941621], [lr 0.006000] [batchtime 0.419]
[epoch 70], [iter 138 / 176], [train main loss -1.923682], [lr 0.006000] [batchtime 0.42]
[epoch 70], [iter 139 / 176], [train main loss -1.914367], [lr 0.006000] [batchtime 0.43]
[epoch 70], [iter 140 / 176], [train main loss -1.921936], [lr 0.006000] [batchtime 0.43]
[epoch 70], [iter 141 / 176], [train main loss -1.918407], [lr 0.006000] [batchtime 0.429]
[epoch 70], [iter 142 / 176], [train main loss -1.906533], [lr 0.006000] [batchtime 0.429]
[epoch 70], [iter 143 / 176], [train main loss -1.925123], [lr 0.006000] [batchtime 0.429]
[epoch 70], [iter 144 / 176], [train main loss -1.934063], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 145 / 176], [train main loss -1.919042], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 146 / 176], [train main loss -1.925080], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 147 / 176], [train main loss -1.916602], [lr 0.006000] [batchtime 0.428]
[epoch 70], [iter 148 / 176], [train main loss -1.917848], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 149 / 176], [train main loss -1.911015], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 150 / 176], [train main loss -1.919325], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 151 / 176], [train main loss -1.910165], [lr 0.006000] [batchtime 0.427]
[epoch 70], [iter 152 / 176], [train main loss -1.896020], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 153 / 176], [train main loss -1.878513], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 154 / 176], [train main loss -1.889771], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 155 / 176], [train main loss -1.883397], [lr 0.006000] [batchtime 0.426]
[epoch 70], [iter 156 / 176], [train main loss -1.903177], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 157 / 176], [train main loss -1.895780], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 158 / 176], [train main loss -1.904639], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 159 / 176], [train main loss -1.895678], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 160 / 176], [train main loss -1.907435], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 161 / 176], [train main loss -1.916531], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 162 / 176], [train main loss -1.898650], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 163 / 176], [train main loss -1.902927], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 164 / 176], [train main loss -1.890879], [lr 0.006000] [batchtime 0.425]
[epoch 70], [iter 165 / 176], [train main loss -1.906341], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 166 / 176], [train main loss -1.885049], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 167 / 176], [train main loss -1.892673], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 168 / 176], [train main loss -1.910099], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 169 / 176], [train main loss -1.930183], [lr 0.006000] [batchtime 0.424]
[epoch 70], [iter 170 / 176], [train main loss -1.936835], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 171 / 176], [train main loss -1.921283], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 172 / 176], [train main loss -1.931913], [lr 0.006000] [batchtime 0.423]
[epoch 70], [iter 173 / 176], [train main loss -1.921191], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 174 / 176], [train main loss -1.919587], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 175 / 176], [train main loss -1.928168], [lr 0.006000] [batchtime 0.422]
[epoch 70], [iter 176 / 176], [train main loss -1.927541], [lr 0.006000] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              93.30  35.69   0.02  0.05         0.98      0.95
   1  sidewalk          61.86   4.70   0.40  0.21         0.71      0.82
   2  building          84.24  24.75   0.07  0.11         0.93      0.90
   3  wall              13.27   0.11   4.56  1.98         0.18      0.34
   4  fence             14.05   0.19   5.53  0.59         0.15      0.63
   5  pole              33.67   0.47   1.42  0.55         0.41      0.65
   6  traffic light      7.10   0.01  12.35  0.73         0.07      0.58
   7  traffic sign      13.26   0.08   6.25  0.30         0.14      0.77
   8  vegetation        80.86  11.65   0.06  0.18         0.94      0.85
   9  terrain           37.69   0.35   1.08  0.58         0.48      0.63
  10  sky               92.72   3.76   0.03  0.05         0.97      0.95
  11  person            45.50   0.89   0.72  0.48         0.58      0.67
  12  rider              3.85   0.00  23.15  1.79         0.04      0.36
  13  car               83.62   6.59   0.07  0.12         0.93      0.89
  14  truck              1.02   0.00  96.23  0.79         0.01      0.56
  15  bus               11.66   0.02   3.55  4.02         0.22      0.20
  16  train             36.34   0.08   1.22  0.54         0.45      0.65
  17  motorcycle         1.11   0.00  88.71  0.52         0.01      0.66
  18  bicycle           31.09   0.22   0.79  1.43         0.56      0.41
Mean: 39.27
-----------------------------------------------------------------------------------------------------------
this : [epoch 70], [val loss 0.37709], [acc 0.89573], [acc_cls 0.46250], [mean_iu 0.39274], [fwavacc 0.81796]
best : [epoch 70], [val loss 0.37709], [acc 0.89573], [acc_cls 0.46250], [mean_iu 0.39274], [fwavacc 0.81796]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 71], [iter 1 / 176], [train main loss -3.421794], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 2 / 176], [train main loss -1.941616], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 3 / 176], [train main loss -2.054597], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 4 / 176], [train main loss -1.705138], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 5 / 176], [train main loss -1.335244], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 6 / 176], [train main loss -1.378285], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 7 / 176], [train main loss -1.542063], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 8 / 176], [train main loss -1.446853], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 9 / 176], [train main loss -1.325001], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 10 / 176], [train main loss -1.280796], [lr 0.005943] [batchtime 0]
[epoch 71], [iter 11 / 176], [train main loss -1.293429], [lr 0.005943] [batchtime 0.386]
[epoch 71], [iter 12 / 176], [train main loss -1.178924], [lr 0.005943] [batchtime 0.389]
[epoch 71], [iter 13 / 176], [train main loss -1.252914], [lr 0.005943] [batchtime 0.392]
[epoch 71], [iter 14 / 176], [train main loss -1.420713], [lr 0.005943] [batchtime 0.438]
[epoch 71], [iter 15 / 176], [train main loss -1.420872], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 16 / 176], [train main loss -1.449956], [lr 0.005943] [batchtime 0.423]
[epoch 71], [iter 17 / 176], [train main loss -1.466074], [lr 0.005943] [batchtime 0.418]
[epoch 71], [iter 18 / 176], [train main loss -1.538059], [lr 0.005943] [batchtime 0.416]
[epoch 71], [iter 19 / 176], [train main loss -1.541221], [lr 0.005943] [batchtime 0.413]
[epoch 71], [iter 20 / 176], [train main loss -1.651053], [lr 0.005943] [batchtime 0.412]
[epoch 71], [iter 21 / 176], [train main loss -1.776452], [lr 0.005943] [batchtime 0.411]
[epoch 71], [iter 22 / 176], [train main loss -1.757354], [lr 0.005943] [batchtime 0.411]
[epoch 71], [iter 23 / 176], [train main loss -1.678911], [lr 0.005943] [batchtime 0.409]
[epoch 71], [iter 24 / 176], [train main loss -1.743986], [lr 0.005943] [batchtime 0.408]
[epoch 71], [iter 25 / 176], [train main loss -1.756667], [lr 0.005943] [batchtime 0.408]
[epoch 71], [iter 26 / 176], [train main loss -1.687517], [lr 0.005943] [batchtime 0.407]
[epoch 71], [iter 27 / 176], [train main loss -1.840413], [lr 0.005943] [batchtime 0.406]
[epoch 71], [iter 28 / 176], [train main loss -1.830609], [lr 0.005943] [batchtime 0.406]
[epoch 71], [iter 29 / 176], [train main loss -1.829539], [lr 0.005943] [batchtime 0.405]
[epoch 71], [iter 30 / 176], [train main loss -1.822542], [lr 0.005943] [batchtime 0.405]
[epoch 71], [iter 31 / 176], [train main loss -1.768907], [lr 0.005943] [batchtime 0.405]
[epoch 71], [iter 32 / 176], [train main loss -1.814310], [lr 0.005943] [batchtime 0.404]
[epoch 71], [iter 33 / 176], [train main loss -1.865091], [lr 0.005943] [batchtime 0.404]
[epoch 71], [iter 34 / 176], [train main loss -1.824989], [lr 0.005943] [batchtime 0.403]
[epoch 71], [iter 35 / 176], [train main loss -1.865360], [lr 0.005943] [batchtime 0.404]
[epoch 71], [iter 36 / 176], [train main loss -1.808165], [lr 0.005943] [batchtime 0.404]
[epoch 71], [iter 37 / 176], [train main loss -1.798060], [lr 0.005943] [batchtime 0.403]
[epoch 71], [iter 38 / 176], [train main loss -1.853244], [lr 0.005943] [batchtime 0.449]
[epoch 71], [iter 39 / 176], [train main loss -1.857514], [lr 0.005943] [batchtime 0.455]
[epoch 71], [iter 40 / 176], [train main loss -1.868984], [lr 0.005943] [batchtime 0.453]
[epoch 71], [iter 41 / 176], [train main loss -1.931966], [lr 0.005943] [batchtime 0.451]
[epoch 71], [iter 42 / 176], [train main loss -1.932937], [lr 0.005943] [batchtime 0.449]
[epoch 71], [iter 43 / 176], [train main loss -1.890599], [lr 0.005943] [batchtime 0.448]
[epoch 71], [iter 44 / 176], [train main loss -1.829389], [lr 0.005943] [batchtime 0.446]
[epoch 71], [iter 45 / 176], [train main loss -1.874330], [lr 0.005943] [batchtime 0.445]
[epoch 71], [iter 46 / 176], [train main loss -1.899945], [lr 0.005943] [batchtime 0.444]
[epoch 71], [iter 47 / 176], [train main loss -1.829874], [lr 0.005943] [batchtime 0.442]
[epoch 71], [iter 48 / 176], [train main loss -1.839671], [lr 0.005943] [batchtime 0.441]
[epoch 71], [iter 49 / 176], [train main loss -1.839156], [lr 0.005943] [batchtime 0.44]
[epoch 71], [iter 50 / 176], [train main loss -1.864834], [lr 0.005943] [batchtime 0.44]
[epoch 71], [iter 51 / 176], [train main loss -1.900198], [lr 0.005943] [batchtime 0.439]
[epoch 71], [iter 52 / 176], [train main loss -1.942053], [lr 0.005943] [batchtime 0.438]
[epoch 71], [iter 53 / 176], [train main loss -1.948026], [lr 0.005943] [batchtime 0.437]
[epoch 71], [iter 54 / 176], [train main loss -1.959026], [lr 0.005943] [batchtime 0.436]
[epoch 71], [iter 55 / 176], [train main loss -1.941217], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 56 / 176], [train main loss -1.935522], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 57 / 176], [train main loss -1.877746], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 58 / 176], [train main loss -1.897381], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 59 / 176], [train main loss -1.914706], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 60 / 176], [train main loss -1.912407], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 61 / 176], [train main loss -1.853031], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 62 / 176], [train main loss -1.823998], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 63 / 176], [train main loss -1.867218], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 64 / 176], [train main loss -1.868017], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 65 / 176], [train main loss -1.846755], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 66 / 176], [train main loss -1.832241], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 67 / 176], [train main loss -1.856494], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 68 / 176], [train main loss -1.884332], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 69 / 176], [train main loss -1.889500], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 70 / 176], [train main loss -1.856344], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 71 / 176], [train main loss -1.846528], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 72 / 176], [train main loss -1.859254], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 73 / 176], [train main loss -1.862165], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 74 / 176], [train main loss -1.875151], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 75 / 176], [train main loss -1.875568], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 76 / 176], [train main loss -1.884574], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 77 / 176], [train main loss -1.877204], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 78 / 176], [train main loss -1.865202], [lr 0.005943] [batchtime 0.424]
[epoch 71], [iter 79 / 176], [train main loss -1.864720], [lr 0.005943] [batchtime 0.424]
[epoch 71], [iter 80 / 176], [train main loss -1.851225], [lr 0.005943] [batchtime 0.423]
[epoch 71], [iter 81 / 176], [train main loss -1.843284], [lr 0.005943] [batchtime 0.423]
[epoch 71], [iter 82 / 176], [train main loss -1.799329], [lr 0.005943] [batchtime 0.423]
[epoch 71], [iter 83 / 176], [train main loss -1.786582], [lr 0.005943] [batchtime 0.422]
[epoch 71], [iter 84 / 176], [train main loss -1.802976], [lr 0.005943] [batchtime 0.424]
[epoch 71], [iter 85 / 176], [train main loss -1.807566], [lr 0.005943] [batchtime 0.441]
[epoch 71], [iter 86 / 176], [train main loss -1.817058], [lr 0.005943] [batchtime 0.44]
[epoch 71], [iter 87 / 176], [train main loss -1.823970], [lr 0.005943] [batchtime 0.44]
[epoch 71], [iter 88 / 176], [train main loss -1.836516], [lr 0.005943] [batchtime 0.439]
[epoch 71], [iter 89 / 176], [train main loss -1.847317], [lr 0.005943] [batchtime 0.438]
[epoch 71], [iter 90 / 176], [train main loss -1.824234], [lr 0.005943] [batchtime 0.438]
[epoch 71], [iter 91 / 176], [train main loss -1.815968], [lr 0.005943] [batchtime 0.437]
[epoch 71], [iter 92 / 176], [train main loss -1.834350], [lr 0.005943] [batchtime 0.437]
[epoch 71], [iter 93 / 176], [train main loss -1.840222], [lr 0.005943] [batchtime 0.436]
[epoch 71], [iter 94 / 176], [train main loss -1.820323], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 95 / 176], [train main loss -1.842994], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 96 / 176], [train main loss -1.845680], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 97 / 176], [train main loss -1.862455], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 98 / 176], [train main loss -1.871055], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 99 / 176], [train main loss -1.857606], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 100 / 176], [train main loss -1.866579], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 101 / 176], [train main loss -1.860790], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 102 / 176], [train main loss -1.866675], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 103 / 176], [train main loss -1.845774], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 104 / 176], [train main loss -1.828254], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 105 / 176], [train main loss -1.804812], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 106 / 176], [train main loss -1.813105], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 107 / 176], [train main loss -1.792174], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 108 / 176], [train main loss -1.797002], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 109 / 176], [train main loss -1.778456], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 110 / 176], [train main loss -1.783685], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 111 / 176], [train main loss -1.765071], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 112 / 176], [train main loss -1.766435], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 113 / 176], [train main loss -1.768337], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 114 / 176], [train main loss -1.766075], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 115 / 176], [train main loss -1.749052], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 116 / 176], [train main loss -1.738277], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 117 / 176], [train main loss -1.759869], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 118 / 176], [train main loss -1.755467], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 119 / 176], [train main loss -1.736125], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 120 / 176], [train main loss -1.768039], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 121 / 176], [train main loss -1.764323], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 122 / 176], [train main loss -1.778501], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 123 / 176], [train main loss -1.758759], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 124 / 176], [train main loss -1.755854], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 125 / 176], [train main loss -1.743705], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 126 / 176], [train main loss -1.746346], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 127 / 176], [train main loss -1.749006], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 128 / 176], [train main loss -1.745568], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 129 / 176], [train main loss -1.731234], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 130 / 176], [train main loss -1.718540], [lr 0.005943] [batchtime 0.424]
[epoch 71], [iter 131 / 176], [train main loss -1.714527], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 132 / 176], [train main loss -1.695765], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 133 / 176], [train main loss -1.703487], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 134 / 176], [train main loss -1.690525], [lr 0.005943] [batchtime 0.435]
[epoch 71], [iter 135 / 176], [train main loss -1.694254], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 136 / 176], [train main loss -1.679675], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 137 / 176], [train main loss -1.688168], [lr 0.005943] [batchtime 0.434]
[epoch 71], [iter 138 / 176], [train main loss -1.684661], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 139 / 176], [train main loss -1.702303], [lr 0.005943] [batchtime 0.433]
[epoch 71], [iter 140 / 176], [train main loss -1.700169], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 141 / 176], [train main loss -1.703105], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 142 / 176], [train main loss -1.684864], [lr 0.005943] [batchtime 0.432]
[epoch 71], [iter 143 / 176], [train main loss -1.692791], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 144 / 176], [train main loss -1.690601], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 145 / 176], [train main loss -1.679759], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 146 / 176], [train main loss -1.693505], [lr 0.005943] [batchtime 0.431]
[epoch 71], [iter 147 / 176], [train main loss -1.708255], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 148 / 176], [train main loss -1.695056], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 149 / 176], [train main loss -1.698245], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 150 / 176], [train main loss -1.691727], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 151 / 176], [train main loss -1.674991], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 152 / 176], [train main loss -1.654938], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 153 / 176], [train main loss -1.658363], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 154 / 176], [train main loss -1.677167], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 155 / 176], [train main loss -1.677740], [lr 0.005943] [batchtime 0.43]
[epoch 71], [iter 156 / 176], [train main loss -1.674448], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 157 / 176], [train main loss -1.672186], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 158 / 176], [train main loss -1.680829], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 159 / 176], [train main loss -1.690083], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 160 / 176], [train main loss -1.676420], [lr 0.005943] [batchtime 0.429]
[epoch 71], [iter 161 / 176], [train main loss -1.702479], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 162 / 176], [train main loss -1.696263], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 163 / 176], [train main loss -1.710957], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 164 / 176], [train main loss -1.719166], [lr 0.005943] [batchtime 0.428]
[epoch 71], [iter 165 / 176], [train main loss -1.708935], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 166 / 176], [train main loss -1.706444], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 167 / 176], [train main loss -1.717550], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 168 / 176], [train main loss -1.705371], [lr 0.005943] [batchtime 0.427]
[epoch 71], [iter 169 / 176], [train main loss -1.707687], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 170 / 176], [train main loss -1.712298], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 171 / 176], [train main loss -1.717568], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 172 / 176], [train main loss -1.710970], [lr 0.005943] [batchtime 0.426]
[epoch 71], [iter 173 / 176], [train main loss -1.687407], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 174 / 176], [train main loss -1.700354], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 175 / 176], [train main loss -1.714837], [lr 0.005943] [batchtime 0.425]
[epoch 71], [iter 176 / 176], [train main loss -1.720931], [lr 0.005943] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.83  35.29    0.03  0.04         0.97      0.97
   1  sidewalk          65.94   5.32    0.24  0.28         0.81      0.78
   2  building          84.23  24.18    0.10  0.09         0.91      0.92
   3  wall              14.09   0.12    3.81  2.29         0.21      0.30
   4  fence             20.91   0.33    2.81  0.97         0.26      0.51
   5  pole              33.91   0.48    1.36  0.59         0.42      0.63
   6  traffic light      7.50   0.01   11.84  0.50         0.08      0.67
   7  traffic sign      11.80   0.07    7.20  0.27         0.12      0.79
   8  vegetation        81.19  11.62    0.06  0.17         0.94      0.86
   9  terrain           38.06   0.36    1.04  0.59         0.49      0.63
  10  sky               93.17   3.73    0.04  0.03         0.96      0.97
  11  person            45.24   1.03    0.48  0.73         0.67      0.58
  12  rider              4.07   0.00   21.47  2.10         0.04      0.32
  13  car               82.72   6.70    0.06  0.15         0.95      0.87
  14  truck              0.37   0.00  267.95  0.15         0.00      0.87
  15  bus               12.01   0.04    1.10  6.22         0.48      0.14
  16  train             12.01   0.02    6.24  1.09         0.14      0.48
  17  motorcycle         1.76   0.00   54.59  1.19         0.02      0.46
  18  bicycle           30.92   0.22    0.76  1.48         0.57      0.40
Mean: 38.62
-----------------------------------------------------------------------------------------------------------
this : [epoch 71], [val loss 0.34546], [acc 0.89547], [acc_cls 0.47598], [mean_iu 0.38619], [fwavacc 0.82295]
best : [epoch 70], [val loss 0.37709], [acc 0.89573], [acc_cls 0.46250], [mean_iu 0.39274], [fwavacc 0.81796]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 72], [iter 1 / 176], [train main loss -2.730677], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 2 / 176], [train main loss -4.047404], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 3 / 176], [train main loss -3.084999], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 4 / 176], [train main loss -3.129253], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 5 / 176], [train main loss -2.651176], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 6 / 176], [train main loss -2.508105], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 7 / 176], [train main loss -2.213014], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 8 / 176], [train main loss -2.553346], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 9 / 176], [train main loss -2.565708], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 10 / 176], [train main loss -2.163118], [lr 0.005886] [batchtime 0]
[epoch 72], [iter 11 / 176], [train main loss -2.213328], [lr 0.005886] [batchtime 0.361]
[epoch 72], [iter 12 / 176], [train main loss -1.913803], [lr 0.005886] [batchtime 0.378]
[epoch 72], [iter 13 / 176], [train main loss -1.971203], [lr 0.005886] [batchtime 0.382]
[epoch 72], [iter 14 / 176], [train main loss -1.944452], [lr 0.005886] [batchtime 0.388]
[epoch 72], [iter 15 / 176], [train main loss -1.891105], [lr 0.005886] [batchtime 0.39]
[epoch 72], [iter 16 / 176], [train main loss -2.039274], [lr 0.005886] [batchtime 0.391]
[epoch 72], [iter 17 / 176], [train main loss -1.886922], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 18 / 176], [train main loss -1.727531], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 19 / 176], [train main loss -1.678241], [lr 0.005886] [batchtime 0.394]
[epoch 72], [iter 20 / 176], [train main loss -1.649180], [lr 0.005886] [batchtime 0.394]
[epoch 72], [iter 21 / 176], [train main loss -1.556581], [lr 0.005886] [batchtime 0.394]
[epoch 72], [iter 22 / 176], [train main loss -1.678307], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 23 / 176], [train main loss -1.631869], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 24 / 176], [train main loss -1.595462], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 25 / 176], [train main loss -1.715241], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 26 / 176], [train main loss -1.775999], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 27 / 176], [train main loss -1.856651], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 28 / 176], [train main loss -1.853480], [lr 0.005886] [batchtime 0.393]
[epoch 72], [iter 29 / 176], [train main loss -1.766051], [lr 0.005886] [batchtime 0.394]
[epoch 72], [iter 30 / 176], [train main loss -1.725584], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 31 / 176], [train main loss -1.814939], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 32 / 176], [train main loss -1.776399], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 33 / 176], [train main loss -1.736866], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 34 / 176], [train main loss -1.666210], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 35 / 176], [train main loss -1.697574], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 36 / 176], [train main loss -1.735012], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 37 / 176], [train main loss -1.822032], [lr 0.005886] [batchtime 0.395]
[epoch 72], [iter 38 / 176], [train main loss -1.729612], [lr 0.005886] [batchtime 0.394]
[epoch 72], [iter 39 / 176], [train main loss -1.777321], [lr 0.005886] [batchtime 0.441]
[epoch 72], [iter 40 / 176], [train main loss -1.727025], [lr 0.005886] [batchtime 0.448]
[epoch 72], [iter 41 / 176], [train main loss -1.667096], [lr 0.005886] [batchtime 0.446]
[epoch 72], [iter 42 / 176], [train main loss -1.758968], [lr 0.005886] [batchtime 0.444]
[epoch 72], [iter 43 / 176], [train main loss -1.848281], [lr 0.005886] [batchtime 0.442]
[epoch 72], [iter 44 / 176], [train main loss -1.841115], [lr 0.005886] [batchtime 0.441]
[epoch 72], [iter 45 / 176], [train main loss -1.830512], [lr 0.005886] [batchtime 0.439]
[epoch 72], [iter 46 / 176], [train main loss -1.824522], [lr 0.005886] [batchtime 0.438]
[epoch 72], [iter 47 / 176], [train main loss -1.806375], [lr 0.005886] [batchtime 0.436]
[epoch 72], [iter 48 / 176], [train main loss -1.777258], [lr 0.005886] [batchtime 0.435]
[epoch 72], [iter 49 / 176], [train main loss -1.779062], [lr 0.005886] [batchtime 0.434]
[epoch 72], [iter 50 / 176], [train main loss -1.711728], [lr 0.005886] [batchtime 0.433]
[epoch 72], [iter 51 / 176], [train main loss -1.678323], [lr 0.005886] [batchtime 0.432]
[epoch 72], [iter 52 / 176], [train main loss -1.634691], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 53 / 176], [train main loss -1.656829], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 54 / 176], [train main loss -1.676573], [lr 0.005886] [batchtime 0.429]
[epoch 72], [iter 55 / 176], [train main loss -1.701794], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 56 / 176], [train main loss -1.688787], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 57 / 176], [train main loss -1.647294], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 58 / 176], [train main loss -1.666992], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 59 / 176], [train main loss -1.674204], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 60 / 176], [train main loss -1.678981], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 61 / 176], [train main loss -1.700347], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 62 / 176], [train main loss -1.736073], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 63 / 176], [train main loss -1.704839], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 64 / 176], [train main loss -1.700724], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 65 / 176], [train main loss -1.720604], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 66 / 176], [train main loss -1.702969], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 67 / 176], [train main loss -1.711424], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 68 / 176], [train main loss -1.691033], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 69 / 176], [train main loss -1.678513], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 70 / 176], [train main loss -1.679887], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 71 / 176], [train main loss -1.671750], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 72 / 176], [train main loss -1.670857], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 73 / 176], [train main loss -1.669798], [lr 0.005886] [batchtime 0.419]
[epoch 72], [iter 74 / 176], [train main loss -1.719436], [lr 0.005886] [batchtime 0.419]
[epoch 72], [iter 75 / 176], [train main loss -1.699986], [lr 0.005886] [batchtime 0.418]
[epoch 72], [iter 76 / 176], [train main loss -1.697845], [lr 0.005886] [batchtime 0.418]
[epoch 72], [iter 77 / 176], [train main loss -1.690205], [lr 0.005886] [batchtime 0.418]
[epoch 72], [iter 78 / 176], [train main loss -1.699221], [lr 0.005886] [batchtime 0.417]
[epoch 72], [iter 79 / 176], [train main loss -1.719477], [lr 0.005886] [batchtime 0.417]
[epoch 72], [iter 80 / 176], [train main loss -1.722681], [lr 0.005886] [batchtime 0.416]
[epoch 72], [iter 81 / 176], [train main loss -1.755404], [lr 0.005886] [batchtime 0.416]
[epoch 72], [iter 82 / 176], [train main loss -1.728254], [lr 0.005886] [batchtime 0.416]
[epoch 72], [iter 83 / 176], [train main loss -1.738246], [lr 0.005886] [batchtime 0.415]
[epoch 72], [iter 84 / 176], [train main loss -1.722402], [lr 0.005886] [batchtime 0.415]
[epoch 72], [iter 85 / 176], [train main loss -1.705373], [lr 0.005886] [batchtime 0.415]
[epoch 72], [iter 86 / 176], [train main loss -1.702672], [lr 0.005886] [batchtime 0.432]
[epoch 72], [iter 87 / 176], [train main loss -1.704350], [lr 0.005886] [batchtime 0.433]
[epoch 72], [iter 88 / 176], [train main loss -1.702690], [lr 0.005886] [batchtime 0.433]
[epoch 72], [iter 89 / 176], [train main loss -1.736530], [lr 0.005886] [batchtime 0.432]
[epoch 72], [iter 90 / 176], [train main loss -1.710276], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 91 / 176], [train main loss -1.710228], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 92 / 176], [train main loss -1.692016], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 93 / 176], [train main loss -1.695317], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 94 / 176], [train main loss -1.725120], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 95 / 176], [train main loss -1.738308], [lr 0.005886] [batchtime 0.429]
[epoch 72], [iter 96 / 176], [train main loss -1.759322], [lr 0.005886] [batchtime 0.429]
[epoch 72], [iter 97 / 176], [train main loss -1.774369], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 98 / 176], [train main loss -1.740238], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 99 / 176], [train main loss -1.729220], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 100 / 176], [train main loss -1.724645], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 101 / 176], [train main loss -1.706727], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 102 / 176], [train main loss -1.708886], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 103 / 176], [train main loss -1.706755], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 104 / 176], [train main loss -1.713211], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 105 / 176], [train main loss -1.681389], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 106 / 176], [train main loss -1.696426], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 107 / 176], [train main loss -1.694669], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 108 / 176], [train main loss -1.709562], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 109 / 176], [train main loss -1.699743], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 110 / 176], [train main loss -1.697391], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 111 / 176], [train main loss -1.684780], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 112 / 176], [train main loss -1.694074], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 113 / 176], [train main loss -1.691230], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 114 / 176], [train main loss -1.707364], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 115 / 176], [train main loss -1.698139], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 116 / 176], [train main loss -1.710152], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 117 / 176], [train main loss -1.712900], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 118 / 176], [train main loss -1.743153], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 119 / 176], [train main loss -1.748730], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 120 / 176], [train main loss -1.732927], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 121 / 176], [train main loss -1.748178], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 122 / 176], [train main loss -1.742012], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 123 / 176], [train main loss -1.730007], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 124 / 176], [train main loss -1.732159], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 125 / 176], [train main loss -1.716578], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 126 / 176], [train main loss -1.726154], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 127 / 176], [train main loss -1.725854], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 128 / 176], [train main loss -1.725743], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 129 / 176], [train main loss -1.719255], [lr 0.005886] [batchtime 0.42]
[epoch 72], [iter 130 / 176], [train main loss -1.730427], [lr 0.005886] [batchtime 0.419]
[epoch 72], [iter 131 / 176], [train main loss -1.744465], [lr 0.005886] [batchtime 0.419]
[epoch 72], [iter 132 / 176], [train main loss -1.712461], [lr 0.005886] [batchtime 0.419]
[epoch 72], [iter 133 / 176], [train main loss -1.717532], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 134 / 176], [train main loss -1.710143], [lr 0.005886] [batchtime 0.432]
[epoch 72], [iter 135 / 176], [train main loss -1.711534], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 136 / 176], [train main loss -1.715326], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 137 / 176], [train main loss -1.713494], [lr 0.005886] [batchtime 0.431]
[epoch 72], [iter 138 / 176], [train main loss -1.699726], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 139 / 176], [train main loss -1.708934], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 140 / 176], [train main loss -1.700493], [lr 0.005886] [batchtime 0.43]
[epoch 72], [iter 141 / 176], [train main loss -1.716214], [lr 0.005886] [batchtime 0.429]
[epoch 72], [iter 142 / 176], [train main loss -1.710330], [lr 0.005886] [batchtime 0.429]
[epoch 72], [iter 143 / 176], [train main loss -1.701887], [lr 0.005886] [batchtime 0.429]
[epoch 72], [iter 144 / 176], [train main loss -1.698914], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 145 / 176], [train main loss -1.700795], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 146 / 176], [train main loss -1.689570], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 147 / 176], [train main loss -1.688114], [lr 0.005886] [batchtime 0.428]
[epoch 72], [iter 148 / 176], [train main loss -1.705243], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 149 / 176], [train main loss -1.722297], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 150 / 176], [train main loss -1.714388], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 151 / 176], [train main loss -1.713571], [lr 0.005886] [batchtime 0.427]
[epoch 72], [iter 152 / 176], [train main loss -1.729578], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 153 / 176], [train main loss -1.738919], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 154 / 176], [train main loss -1.735115], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 155 / 176], [train main loss -1.720617], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 156 / 176], [train main loss -1.726946], [lr 0.005886] [batchtime 0.426]
[epoch 72], [iter 157 / 176], [train main loss -1.743527], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 158 / 176], [train main loss -1.731857], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 159 / 176], [train main loss -1.735384], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 160 / 176], [train main loss -1.731333], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 161 / 176], [train main loss -1.726406], [lr 0.005886] [batchtime 0.425]
[epoch 72], [iter 162 / 176], [train main loss -1.721550], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 163 / 176], [train main loss -1.721313], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 164 / 176], [train main loss -1.711644], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 165 / 176], [train main loss -1.705630], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 166 / 176], [train main loss -1.699032], [lr 0.005886] [batchtime 0.424]
[epoch 72], [iter 167 / 176], [train main loss -1.702709], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 168 / 176], [train main loss -1.717981], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 169 / 176], [train main loss -1.715998], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 170 / 176], [train main loss -1.723279], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 171 / 176], [train main loss -1.722558], [lr 0.005886] [batchtime 0.423]
[epoch 72], [iter 172 / 176], [train main loss -1.720971], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 173 / 176], [train main loss -1.716084], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 174 / 176], [train main loss -1.719545], [lr 0.005886] [batchtime 0.422]
[epoch 72], [iter 175 / 176], [train main loss -1.731269], [lr 0.005886] [batchtime 0.421]
[epoch 72], [iter 176 / 176], [train main loss -1.730146], [lr 0.005886] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.78  35.49    0.02  0.04         0.98      0.96
   1  sidewalk          64.46   5.13    0.29  0.27         0.78      0.79
   2  building          84.51  24.58    0.08  0.10         0.92      0.91
   3  wall              13.60   0.11    4.60  1.75         0.18      0.36
   4  fence             20.24   0.30    3.21  0.73         0.24      0.58
   5  pole              34.69   0.51    1.25  0.64         0.45      0.61
   6  traffic light     10.17   0.02    7.89  0.94         0.11      0.51
   7  traffic sign      17.04   0.10    4.44  0.43         0.18      0.70
   8  vegetation        82.22  11.54    0.07  0.14         0.93      0.87
   9  terrain           38.78   0.39    0.91  0.67         0.52      0.60
  10  sky               91.79   3.75    0.03  0.06         0.97      0.95
  11  person            47.68   0.94    0.62  0.47         0.62      0.68
  12  rider              2.35   0.00   40.28  1.24         0.02      0.45
  13  car               82.61   6.70    0.06  0.15         0.95      0.87
  14  truck              0.50   0.00  199.98  0.13         0.00      0.88
  15  bus               11.83   0.04    1.28  6.17         0.44      0.14
  16  train              6.53   0.01   13.20  1.12         0.07      0.47
  17  motorcycle         1.19   0.00   82.94  0.29         0.01      0.77
  18  bicycle           32.51   0.19    1.01  1.06         0.50      0.48
Mean: 38.76
-----------------------------------------------------------------------------------------------------------
this : [epoch 72], [val loss 0.36031], [acc 0.89787], [acc_cls 0.46694], [mean_iu 0.38762], [fwavacc 0.82384]
best : [epoch 70], [val loss 0.37709], [acc 0.89573], [acc_cls 0.46250], [mean_iu 0.39274], [fwavacc 0.81796]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 73], [iter 1 / 176], [train main loss 2.091395], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 2 / 176], [train main loss -0.603351], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 3 / 176], [train main loss -1.500921], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 4 / 176], [train main loss -1.179554], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 5 / 176], [train main loss -1.249066], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 6 / 176], [train main loss -1.155071], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 7 / 176], [train main loss -0.880448], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 8 / 176], [train main loss -0.942353], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 9 / 176], [train main loss -1.193761], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 10 / 176], [train main loss -1.283454], [lr 0.005829] [batchtime 0]
[epoch 73], [iter 11 / 176], [train main loss -1.516192], [lr 0.005829] [batchtime 0.367]
[epoch 73], [iter 12 / 176], [train main loss -1.722885], [lr 0.005829] [batchtime 0.379]
[epoch 73], [iter 13 / 176], [train main loss -1.489266], [lr 0.005829] [batchtime 0.386]
[epoch 73], [iter 14 / 176], [train main loss -1.624298], [lr 0.005829] [batchtime 0.386]
[epoch 73], [iter 15 / 176], [train main loss -1.777440], [lr 0.005829] [batchtime 0.388]
[epoch 73], [iter 16 / 176], [train main loss -1.819583], [lr 0.005829] [batchtime 0.392]
[epoch 73], [iter 17 / 176], [train main loss -1.756389], [lr 0.005829] [batchtime 0.394]
[epoch 73], [iter 18 / 176], [train main loss -1.774707], [lr 0.005829] [batchtime 0.395]
[epoch 73], [iter 19 / 176], [train main loss -1.774849], [lr 0.005829] [batchtime 0.395]
[epoch 73], [iter 20 / 176], [train main loss -1.777202], [lr 0.005829] [batchtime 0.394]
[epoch 73], [iter 21 / 176], [train main loss -1.753338], [lr 0.005829] [batchtime 0.395]
[epoch 73], [iter 22 / 176], [train main loss -1.729023], [lr 0.005829] [batchtime 0.396]
[epoch 73], [iter 23 / 176], [train main loss -1.791083], [lr 0.005829] [batchtime 0.395]
[epoch 73], [iter 24 / 176], [train main loss -1.697816], [lr 0.005829] [batchtime 0.396]
[epoch 73], [iter 25 / 176], [train main loss -1.707638], [lr 0.005829] [batchtime 0.397]
[epoch 73], [iter 26 / 176], [train main loss -1.769675], [lr 0.005829] [batchtime 0.397]
[epoch 73], [iter 27 / 176], [train main loss -1.849198], [lr 0.005829] [batchtime 0.397]
[epoch 73], [iter 28 / 176], [train main loss -1.886944], [lr 0.005829] [batchtime 0.397]
[epoch 73], [iter 29 / 176], [train main loss -1.791524], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 30 / 176], [train main loss -1.844540], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 31 / 176], [train main loss -1.890138], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 32 / 176], [train main loss -1.902008], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 33 / 176], [train main loss -1.928004], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 34 / 176], [train main loss -1.864148], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 35 / 176], [train main loss -1.893283], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 36 / 176], [train main loss -1.961436], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 37 / 176], [train main loss -1.945417], [lr 0.005829] [batchtime 0.397]
[epoch 73], [iter 38 / 176], [train main loss -1.879776], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 39 / 176], [train main loss -1.854563], [lr 0.005829] [batchtime 0.398]
[epoch 73], [iter 40 / 176], [train main loss -1.856406], [lr 0.005829] [batchtime 0.413]
[epoch 73], [iter 41 / 176], [train main loss -1.826000], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 42 / 176], [train main loss -1.869089], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 43 / 176], [train main loss -1.866306], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 44 / 176], [train main loss -1.864767], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 45 / 176], [train main loss -1.860613], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 46 / 176], [train main loss -1.919219], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 47 / 176], [train main loss -1.927084], [lr 0.005829] [batchtime 0.413]
[epoch 73], [iter 48 / 176], [train main loss -1.870620], [lr 0.005829] [batchtime 0.412]
[epoch 73], [iter 49 / 176], [train main loss -1.896047], [lr 0.005829] [batchtime 0.412]
[epoch 73], [iter 50 / 176], [train main loss -1.863937], [lr 0.005829] [batchtime 0.411]
[epoch 73], [iter 51 / 176], [train main loss -1.864166], [lr 0.005829] [batchtime 0.411]
[epoch 73], [iter 52 / 176], [train main loss -1.878894], [lr 0.005829] [batchtime 0.411]
[epoch 73], [iter 53 / 176], [train main loss -1.807635], [lr 0.005829] [batchtime 0.41]
[epoch 73], [iter 54 / 176], [train main loss -1.788659], [lr 0.005829] [batchtime 0.41]
[epoch 73], [iter 55 / 176], [train main loss -1.760982], [lr 0.005829] [batchtime 0.409]
[epoch 73], [iter 56 / 176], [train main loss -1.743215], [lr 0.005829] [batchtime 0.409]
[epoch 73], [iter 57 / 176], [train main loss -1.694136], [lr 0.005829] [batchtime 0.409]
[epoch 73], [iter 58 / 176], [train main loss -1.739593], [lr 0.005829] [batchtime 0.408]
[epoch 73], [iter 59 / 176], [train main loss -1.727789], [lr 0.005829] [batchtime 0.408]
[epoch 73], [iter 60 / 176], [train main loss -1.790735], [lr 0.005829] [batchtime 0.408]
[epoch 73], [iter 61 / 176], [train main loss -1.774764], [lr 0.005829] [batchtime 0.408]
[epoch 73], [iter 62 / 176], [train main loss -1.774133], [lr 0.005829] [batchtime 0.408]
[epoch 73], [iter 63 / 176], [train main loss -1.761244], [lr 0.005829] [batchtime 0.407]
[epoch 73], [iter 64 / 176], [train main loss -1.749146], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 65 / 176], [train main loss -1.727022], [lr 0.005829] [batchtime 0.423]
[epoch 73], [iter 66 / 176], [train main loss -1.738610], [lr 0.005829] [batchtime 0.422]
[epoch 73], [iter 67 / 176], [train main loss -1.744648], [lr 0.005829] [batchtime 0.422]
[epoch 73], [iter 68 / 176], [train main loss -1.785277], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 69 / 176], [train main loss -1.786245], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 70 / 176], [train main loss -1.793708], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 71 / 176], [train main loss -1.818826], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 72 / 176], [train main loss -1.850720], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 73 / 176], [train main loss -1.860760], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 74 / 176], [train main loss -1.880947], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 75 / 176], [train main loss -1.918907], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 76 / 176], [train main loss -1.915439], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 77 / 176], [train main loss -1.908119], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 78 / 176], [train main loss -1.880508], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 79 / 176], [train main loss -1.874655], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 80 / 176], [train main loss -1.858895], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 81 / 176], [train main loss -1.878157], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 82 / 176], [train main loss -1.886230], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 83 / 176], [train main loss -1.868420], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 84 / 176], [train main loss -1.851350], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 85 / 176], [train main loss -1.862550], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 86 / 176], [train main loss -1.846181], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 87 / 176], [train main loss -1.852877], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 88 / 176], [train main loss -1.806666], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 89 / 176], [train main loss -1.812479], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 90 / 176], [train main loss -1.811874], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 91 / 176], [train main loss -1.813503], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 92 / 176], [train main loss -1.803574], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 93 / 176], [train main loss -1.810309], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 94 / 176], [train main loss -1.805529], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 95 / 176], [train main loss -1.829812], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 96 / 176], [train main loss -1.836491], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 97 / 176], [train main loss -1.846235], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 98 / 176], [train main loss -1.868814], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 99 / 176], [train main loss -1.864772], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 100 / 176], [train main loss -1.869394], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 101 / 176], [train main loss -1.873644], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 102 / 176], [train main loss -1.871568], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 103 / 176], [train main loss -1.890085], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 104 / 176], [train main loss -1.911174], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 105 / 176], [train main loss -1.898820], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 106 / 176], [train main loss -1.904536], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 107 / 176], [train main loss -1.929625], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 108 / 176], [train main loss -1.945709], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 109 / 176], [train main loss -1.975045], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 110 / 176], [train main loss -1.991374], [lr 0.005829] [batchtime 0.414]
[epoch 73], [iter 111 / 176], [train main loss -1.995619], [lr 0.005829] [batchtime 0.413]
[epoch 73], [iter 112 / 176], [train main loss -1.990208], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 113 / 176], [train main loss -2.002481], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 114 / 176], [train main loss -1.989934], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 115 / 176], [train main loss -2.005792], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 116 / 176], [train main loss -1.975938], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 117 / 176], [train main loss -1.972238], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 118 / 176], [train main loss -1.964239], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 119 / 176], [train main loss -1.957697], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 120 / 176], [train main loss -1.949257], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 121 / 176], [train main loss -1.946153], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 122 / 176], [train main loss -1.954389], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 123 / 176], [train main loss -1.954823], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 124 / 176], [train main loss -1.940347], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 125 / 176], [train main loss -1.949526], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 126 / 176], [train main loss -1.942322], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 127 / 176], [train main loss -1.939951], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 128 / 176], [train main loss -1.934393], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 129 / 176], [train main loss -1.935457], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 130 / 176], [train main loss -1.968767], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 131 / 176], [train main loss -1.969210], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 132 / 176], [train main loss -1.943082], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 133 / 176], [train main loss -1.945155], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 134 / 176], [train main loss -1.922540], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 135 / 176], [train main loss -1.922283], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 136 / 176], [train main loss -1.920330], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 137 / 176], [train main loss -1.916403], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 138 / 176], [train main loss -1.915928], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 139 / 176], [train main loss -1.905783], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 140 / 176], [train main loss -1.886160], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 141 / 176], [train main loss -1.894301], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 142 / 176], [train main loss -1.886723], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 143 / 176], [train main loss -1.900466], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 144 / 176], [train main loss -1.903105], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 145 / 176], [train main loss -1.908468], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 146 / 176], [train main loss -1.921689], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 147 / 176], [train main loss -1.924783], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 148 / 176], [train main loss -1.943478], [lr 0.005829] [batchtime 0.417]
[epoch 73], [iter 149 / 176], [train main loss -1.951054], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 150 / 176], [train main loss -1.962842], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 151 / 176], [train main loss -1.951537], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 152 / 176], [train main loss -1.957630], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 153 / 176], [train main loss -1.975463], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 154 / 176], [train main loss -1.969690], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 155 / 176], [train main loss -1.978476], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 156 / 176], [train main loss -1.987380], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 157 / 176], [train main loss -1.994814], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 158 / 176], [train main loss -2.006410], [lr 0.005829] [batchtime 0.415]
[epoch 73], [iter 159 / 176], [train main loss -1.993836], [lr 0.005829] [batchtime 0.416]
[epoch 73], [iter 160 / 176], [train main loss -1.986917], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 161 / 176], [train main loss -1.980923], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 162 / 176], [train main loss -1.970707], [lr 0.005829] [batchtime 0.421]
[epoch 73], [iter 163 / 176], [train main loss -1.974355], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 164 / 176], [train main loss -1.972549], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 165 / 176], [train main loss -1.976009], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 166 / 176], [train main loss -1.972401], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 167 / 176], [train main loss -1.972478], [lr 0.005829] [batchtime 0.42]
[epoch 73], [iter 168 / 176], [train main loss -1.967344], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 169 / 176], [train main loss -1.965598], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 170 / 176], [train main loss -1.968732], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 171 / 176], [train main loss -1.975165], [lr 0.005829] [batchtime 0.419]
[epoch 73], [iter 172 / 176], [train main loss -1.968916], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 173 / 176], [train main loss -1.965986], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 174 / 176], [train main loss -1.951718], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 175 / 176], [train main loss -1.941790], [lr 0.005829] [batchtime 0.418]
[epoch 73], [iter 176 / 176], [train main loss -1.939808], [lr 0.005829] [batchtime 0.417]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.52  35.49    0.02  0.04         0.98      0.96
   1  sidewalk          63.30   5.06    0.30  0.28         0.77      0.78
   2  building          84.64  24.48    0.09  0.10         0.92      0.91
   3  wall              12.42   0.10    4.83  2.22         0.17      0.31
   4  fence             19.41   0.29    3.31  0.84         0.23      0.54
   5  pole              34.38   0.51    1.25  0.66         0.44      0.60
   6  traffic light      8.46   0.01   10.05  0.78         0.09      0.56
   7  traffic sign      15.13   0.09    5.26  0.35         0.16      0.74
   8  vegetation        82.23  11.37    0.09  0.13         0.92      0.89
   9  terrain           34.96   0.39    0.89  0.97         0.53      0.51
  10  sky               92.37   3.77    0.03  0.05         0.97      0.95
  11  person            45.94   0.95    0.62  0.55         0.62      0.64
  12  rider              4.61   0.00   18.73  1.98         0.05      0.34
  13  car               81.80   6.69    0.06  0.17         0.95      0.86
  14  truck              0.92   0.00  107.18  0.54         0.01      0.65
  15  bus               11.02   0.03    1.53  6.54         0.40      0.13
  16  train              9.47   0.02    7.60  1.96         0.12      0.34
  17  motorcycle         1.21   0.00   80.92  0.92         0.01      0.52
  18  bicycle           30.43   0.23    0.69  1.60         0.59      0.39
Mean: 38.22
-----------------------------------------------------------------------------------------------------------
this : [epoch 73], [val loss 0.34463], [acc 0.89493], [acc_cls 0.46958], [mean_iu 0.38222], [fwavacc 0.82126]
best : [epoch 70], [val loss 0.37709], [acc 0.89573], [acc_cls 0.46250], [mean_iu 0.39274], [fwavacc 0.81796]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 74], [iter 1 / 176], [train main loss -1.409661], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 2 / 176], [train main loss -1.196079], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 3 / 176], [train main loss -1.551784], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 4 / 176], [train main loss -1.524226], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 5 / 176], [train main loss -1.619961], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 6 / 176], [train main loss -1.276801], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 7 / 176], [train main loss -1.100855], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 8 / 176], [train main loss -0.992099], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 9 / 176], [train main loss -0.727352], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 10 / 176], [train main loss -0.808069], [lr 0.005771] [batchtime 0]
[epoch 74], [iter 11 / 176], [train main loss -0.627544], [lr 0.005771] [batchtime 0.378]
[epoch 74], [iter 12 / 176], [train main loss -0.748704], [lr 0.005771] [batchtime 0.388]
[epoch 74], [iter 13 / 176], [train main loss -0.968599], [lr 0.005771] [batchtime 0.394]
[epoch 74], [iter 14 / 176], [train main loss -1.163801], [lr 0.005771] [batchtime 0.396]
[epoch 74], [iter 15 / 176], [train main loss -1.362509], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 16 / 176], [train main loss -1.370899], [lr 0.005771] [batchtime 0.397]
[epoch 74], [iter 17 / 176], [train main loss -1.341289], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 18 / 176], [train main loss -1.487459], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 19 / 176], [train main loss -1.428755], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 20 / 176], [train main loss -1.399961], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 21 / 176], [train main loss -1.525501], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 22 / 176], [train main loss -1.570691], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 23 / 176], [train main loss -1.529805], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 24 / 176], [train main loss -1.568867], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 25 / 176], [train main loss -1.504725], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 26 / 176], [train main loss -1.494487], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 27 / 176], [train main loss -1.441416], [lr 0.005771] [batchtime 0.398]
[epoch 74], [iter 28 / 176], [train main loss -1.503148], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 29 / 176], [train main loss -1.549047], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 30 / 176], [train main loss -1.520006], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 31 / 176], [train main loss -1.540152], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 32 / 176], [train main loss -1.536339], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 33 / 176], [train main loss -1.579758], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 34 / 176], [train main loss -1.572345], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 35 / 176], [train main loss -1.601895], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 36 / 176], [train main loss -1.662745], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 37 / 176], [train main loss -1.664414], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 38 / 176], [train main loss -1.632236], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 39 / 176], [train main loss -1.620246], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 40 / 176], [train main loss -1.637251], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 41 / 176], [train main loss -1.597201], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 42 / 176], [train main loss -1.590567], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 43 / 176], [train main loss -1.585958], [lr 0.005771] [batchtime 0.399]
[epoch 74], [iter 44 / 176], [train main loss -1.607538], [lr 0.005771] [batchtime 0.403]
[epoch 74], [iter 45 / 176], [train main loss -1.595579], [lr 0.005771] [batchtime 0.431]
[epoch 74], [iter 46 / 176], [train main loss -1.608743], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 47 / 176], [train main loss -1.615808], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 48 / 176], [train main loss -1.579798], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 49 / 176], [train main loss -1.636142], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 50 / 176], [train main loss -1.717714], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 51 / 176], [train main loss -1.678235], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 52 / 176], [train main loss -1.703738], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 53 / 176], [train main loss -1.645846], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 54 / 176], [train main loss -1.648031], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 55 / 176], [train main loss -1.653413], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 56 / 176], [train main loss -1.638357], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 57 / 176], [train main loss -1.653139], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 58 / 176], [train main loss -1.654056], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 59 / 176], [train main loss -1.677786], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 60 / 176], [train main loss -1.647846], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 61 / 176], [train main loss -1.683647], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 62 / 176], [train main loss -1.733630], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 63 / 176], [train main loss -1.748576], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 64 / 176], [train main loss -1.753528], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 65 / 176], [train main loss -1.766554], [lr 0.005771] [batchtime 0.419]
[epoch 74], [iter 66 / 176], [train main loss -1.741907], [lr 0.005771] [batchtime 0.419]
[epoch 74], [iter 67 / 176], [train main loss -1.731037], [lr 0.005771] [batchtime 0.418]
[epoch 74], [iter 68 / 176], [train main loss -1.719820], [lr 0.005771] [batchtime 0.418]
[epoch 74], [iter 69 / 176], [train main loss -1.719827], [lr 0.005771] [batchtime 0.418]
[epoch 74], [iter 70 / 176], [train main loss -1.759909], [lr 0.005771] [batchtime 0.417]
[epoch 74], [iter 71 / 176], [train main loss -1.750286], [lr 0.005771] [batchtime 0.417]
[epoch 74], [iter 72 / 176], [train main loss -1.778989], [lr 0.005771] [batchtime 0.417]
[epoch 74], [iter 73 / 176], [train main loss -1.778615], [lr 0.005771] [batchtime 0.417]
[epoch 74], [iter 74 / 176], [train main loss -1.781095], [lr 0.005771] [batchtime 0.416]
[epoch 74], [iter 75 / 176], [train main loss -1.795871], [lr 0.005771] [batchtime 0.416]
[epoch 74], [iter 76 / 176], [train main loss -1.804813], [lr 0.005771] [batchtime 0.416]
[epoch 74], [iter 77 / 176], [train main loss -1.833332], [lr 0.005771] [batchtime 0.415]
[epoch 74], [iter 78 / 176], [train main loss -1.825141], [lr 0.005771] [batchtime 0.415]
[epoch 74], [iter 79 / 176], [train main loss -1.840833], [lr 0.005771] [batchtime 0.415]
[epoch 74], [iter 80 / 176], [train main loss -1.817729], [lr 0.005771] [batchtime 0.415]
[epoch 74], [iter 81 / 176], [train main loss -1.771741], [lr 0.005771] [batchtime 0.414]
[epoch 74], [iter 82 / 176], [train main loss -1.756445], [lr 0.005771] [batchtime 0.414]
[epoch 74], [iter 83 / 176], [train main loss -1.739479], [lr 0.005771] [batchtime 0.414]
[epoch 74], [iter 84 / 176], [train main loss -1.735738], [lr 0.005771] [batchtime 0.414]
[epoch 74], [iter 85 / 176], [train main loss -1.698266], [lr 0.005771] [batchtime 0.414]
[epoch 74], [iter 86 / 176], [train main loss -1.694454], [lr 0.005771] [batchtime 0.413]
[epoch 74], [iter 87 / 176], [train main loss -1.714752], [lr 0.005771] [batchtime 0.413]
[epoch 74], [iter 88 / 176], [train main loss -1.686193], [lr 0.005771] [batchtime 0.413]
[epoch 74], [iter 89 / 176], [train main loss -1.679497], [lr 0.005771] [batchtime 0.413]
[epoch 74], [iter 90 / 176], [train main loss -1.709793], [lr 0.005771] [batchtime 0.413]
[epoch 74], [iter 91 / 176], [train main loss -1.734686], [lr 0.005771] [batchtime 0.413]
[epoch 74], [iter 92 / 176], [train main loss -1.746446], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 93 / 176], [train main loss -1.752170], [lr 0.005771] [batchtime 0.432]
[epoch 74], [iter 94 / 176], [train main loss -1.753049], [lr 0.005771] [batchtime 0.432]
[epoch 74], [iter 95 / 176], [train main loss -1.728355], [lr 0.005771] [batchtime 0.431]
[epoch 74], [iter 96 / 176], [train main loss -1.705046], [lr 0.005771] [batchtime 0.431]
[epoch 74], [iter 97 / 176], [train main loss -1.712308], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 98 / 176], [train main loss -1.719733], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 99 / 176], [train main loss -1.718164], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 100 / 176], [train main loss -1.697825], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 101 / 176], [train main loss -1.675530], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 102 / 176], [train main loss -1.650023], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 103 / 176], [train main loss -1.657042], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 104 / 176], [train main loss -1.669022], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 105 / 176], [train main loss -1.678787], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 106 / 176], [train main loss -1.680336], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 107 / 176], [train main loss -1.672167], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 108 / 176], [train main loss -1.673973], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 109 / 176], [train main loss -1.704266], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 110 / 176], [train main loss -1.704747], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 111 / 176], [train main loss -1.696342], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 112 / 176], [train main loss -1.693778], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 113 / 176], [train main loss -1.670065], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 114 / 176], [train main loss -1.664366], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 115 / 176], [train main loss -1.677449], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 116 / 176], [train main loss -1.684599], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 117 / 176], [train main loss -1.678451], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 118 / 176], [train main loss -1.679228], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 119 / 176], [train main loss -1.688739], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 120 / 176], [train main loss -1.691559], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 121 / 176], [train main loss -1.706135], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 122 / 176], [train main loss -1.707578], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 123 / 176], [train main loss -1.712226], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 124 / 176], [train main loss -1.711418], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 125 / 176], [train main loss -1.716391], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 126 / 176], [train main loss -1.696789], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 127 / 176], [train main loss -1.676874], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 128 / 176], [train main loss -1.673601], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 129 / 176], [train main loss -1.683540], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 130 / 176], [train main loss -1.675126], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 131 / 176], [train main loss -1.678284], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 132 / 176], [train main loss -1.671127], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 133 / 176], [train main loss -1.677031], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 134 / 176], [train main loss -1.686511], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 135 / 176], [train main loss -1.683757], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 136 / 176], [train main loss -1.706148], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 137 / 176], [train main loss -1.693632], [lr 0.005771] [batchtime 0.42]
[epoch 74], [iter 138 / 176], [train main loss -1.669051], [lr 0.005771] [batchtime 0.421]
[epoch 74], [iter 139 / 176], [train main loss -1.681384], [lr 0.005771] [batchtime 0.431]
[epoch 74], [iter 140 / 176], [train main loss -1.672188], [lr 0.005771] [batchtime 0.431]
[epoch 74], [iter 141 / 176], [train main loss -1.688722], [lr 0.005771] [batchtime 0.431]
[epoch 74], [iter 142 / 176], [train main loss -1.666832], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 143 / 176], [train main loss -1.677030], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 144 / 176], [train main loss -1.698942], [lr 0.005771] [batchtime 0.43]
[epoch 74], [iter 145 / 176], [train main loss -1.730922], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 146 / 176], [train main loss -1.737287], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 147 / 176], [train main loss -1.759102], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 148 / 176], [train main loss -1.747619], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 149 / 176], [train main loss -1.752130], [lr 0.005771] [batchtime 0.429]
[epoch 74], [iter 150 / 176], [train main loss -1.765834], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 151 / 176], [train main loss -1.752736], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 152 / 176], [train main loss -1.766873], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 153 / 176], [train main loss -1.762120], [lr 0.005771] [batchtime 0.428]
[epoch 74], [iter 154 / 176], [train main loss -1.757042], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 155 / 176], [train main loss -1.759979], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 156 / 176], [train main loss -1.763034], [lr 0.005771] [batchtime 0.427]
[epoch 74], [iter 157 / 176], [train main loss -1.780075], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 158 / 176], [train main loss -1.790651], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 159 / 176], [train main loss -1.796893], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 160 / 176], [train main loss -1.793174], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 161 / 176], [train main loss -1.810893], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 162 / 176], [train main loss -1.801703], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 163 / 176], [train main loss -1.804735], [lr 0.005771] [batchtime 0.426]
[epoch 74], [iter 164 / 176], [train main loss -1.810688], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 165 / 176], [train main loss -1.814173], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 166 / 176], [train main loss -1.808134], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 167 / 176], [train main loss -1.817958], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 168 / 176], [train main loss -1.810503], [lr 0.005771] [batchtime 0.425]
[epoch 74], [iter 169 / 176], [train main loss -1.798063], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 170 / 176], [train main loss -1.779708], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 171 / 176], [train main loss -1.770089], [lr 0.005771] [batchtime 0.424]
[epoch 74], [iter 172 / 176], [train main loss -1.761450], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 173 / 176], [train main loss -1.775831], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 174 / 176], [train main loss -1.782998], [lr 0.005771] [batchtime 0.423]
[epoch 74], [iter 175 / 176], [train main loss -1.775987], [lr 0.005771] [batchtime 0.422]
[epoch 74], [iter 176 / 176], [train main loss -1.768391], [lr 0.005771] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.95  35.45    0.03  0.04         0.98      0.96
   1  sidewalk          65.56   5.15    0.28  0.25         0.78      0.80
   2  building          84.78  24.63    0.08  0.10         0.93      0.91
   3  wall              15.46   0.13    3.39  2.07         0.23      0.33
   4  fence             18.46   0.27    3.78  0.64         0.21      0.61
   5  pole              35.17   0.51    1.21  0.63         0.45      0.61
   6  traffic light      9.70   0.02    8.59  0.72         0.10      0.58
   7  traffic sign      12.93   0.08    6.44  0.30         0.13      0.77
   8  vegetation        81.10  11.66    0.06  0.17         0.94      0.85
   9  terrain           37.74   0.36    1.06  0.59         0.49      0.63
  10  sky               93.18   3.73    0.04  0.03         0.96      0.97
  11  person            48.24   0.98    0.56  0.51         0.64      0.66
  12  rider              4.21   0.00   20.95  1.80         0.05      0.36
  13  car               84.15   6.64    0.07  0.12         0.94      0.89
  14  truck              0.50   0.00  198.58  0.41         0.01      0.71
  15  bus               16.15   0.04    1.10  4.09         0.48      0.20
  16  train             17.67   0.04    4.09  0.57         0.20      0.64
  17  motorcycle         0.71   0.00  138.65  0.86         0.01      0.54
  18  bicycle           33.37   0.23    0.69  1.31         0.59      0.43
Mean: 39.63
-----------------------------------------------------------------------------------------------------------
this : [epoch 74], [val loss 0.35524], [acc 0.89915], [acc_cls 0.47909], [mean_iu 0.39634], [fwavacc 0.82615]
best : [epoch 74], [val loss 0.35524], [acc 0.89915], [acc_cls 0.47909], [mean_iu 0.39634], [fwavacc 0.82615]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 75], [iter 1 / 176], [train main loss -3.093369], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 2 / 176], [train main loss -1.450472], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 3 / 176], [train main loss -1.119695], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 4 / 176], [train main loss -1.484746], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 5 / 176], [train main loss -1.732526], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 6 / 176], [train main loss -1.436087], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 7 / 176], [train main loss -1.395572], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 8 / 176], [train main loss -1.135497], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 9 / 176], [train main loss -1.125266], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 10 / 176], [train main loss -1.236893], [lr 0.005714] [batchtime 0]
[epoch 75], [iter 11 / 176], [train main loss -1.262918], [lr 0.005714] [batchtime 0.364]
[epoch 75], [iter 12 / 176], [train main loss -1.196567], [lr 0.005714] [batchtime 0.378]
[epoch 75], [iter 13 / 176], [train main loss -1.233123], [lr 0.005714] [batchtime 0.385]
[epoch 75], [iter 14 / 176], [train main loss -1.462774], [lr 0.005714] [batchtime 0.392]
[epoch 75], [iter 15 / 176], [train main loss -1.527569], [lr 0.005714] [batchtime 0.416]
[epoch 75], [iter 16 / 176], [train main loss -1.577886], [lr 0.005714] [batchtime 0.414]
[epoch 75], [iter 17 / 176], [train main loss -1.546792], [lr 0.005714] [batchtime 0.411]
[epoch 75], [iter 18 / 176], [train main loss -1.534137], [lr 0.005714] [batchtime 0.409]
[epoch 75], [iter 19 / 176], [train main loss -1.714837], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 20 / 176], [train main loss -1.589945], [lr 0.005714] [batchtime 0.409]
[epoch 75], [iter 21 / 176], [train main loss -1.670236], [lr 0.005714] [batchtime 0.407]
[epoch 75], [iter 22 / 176], [train main loss -1.676585], [lr 0.005714] [batchtime 0.407]
[epoch 75], [iter 23 / 176], [train main loss -1.783767], [lr 0.005714] [batchtime 0.406]
[epoch 75], [iter 24 / 176], [train main loss -1.800548], [lr 0.005714] [batchtime 0.405]
[epoch 75], [iter 25 / 176], [train main loss -1.857483], [lr 0.005714] [batchtime 0.405]
[epoch 75], [iter 26 / 176], [train main loss -1.805845], [lr 0.005714] [batchtime 0.404]
[epoch 75], [iter 27 / 176], [train main loss -1.791313], [lr 0.005714] [batchtime 0.404]
[epoch 75], [iter 28 / 176], [train main loss -1.703087], [lr 0.005714] [batchtime 0.403]
[epoch 75], [iter 29 / 176], [train main loss -1.714494], [lr 0.005714] [batchtime 0.402]
[epoch 75], [iter 30 / 176], [train main loss -1.764481], [lr 0.005714] [batchtime 0.402]
[epoch 75], [iter 31 / 176], [train main loss -1.780808], [lr 0.005714] [batchtime 0.402]
[epoch 75], [iter 32 / 176], [train main loss -1.756201], [lr 0.005714] [batchtime 0.401]
[epoch 75], [iter 33 / 176], [train main loss -1.735982], [lr 0.005714] [batchtime 0.401]
[epoch 75], [iter 34 / 176], [train main loss -1.697995], [lr 0.005714] [batchtime 0.401]
[epoch 75], [iter 35 / 176], [train main loss -1.720331], [lr 0.005714] [batchtime 0.401]
[epoch 75], [iter 36 / 176], [train main loss -1.724530], [lr 0.005714] [batchtime 0.4]
[epoch 75], [iter 37 / 176], [train main loss -1.666657], [lr 0.005714] [batchtime 0.4]
[epoch 75], [iter 38 / 176], [train main loss -1.665752], [lr 0.005714] [batchtime 0.4]
[epoch 75], [iter 39 / 176], [train main loss -1.717974], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 40 / 176], [train main loss -1.675315], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 41 / 176], [train main loss -1.728967], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 42 / 176], [train main loss -1.730719], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 43 / 176], [train main loss -1.728576], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 44 / 176], [train main loss -1.726023], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 45 / 176], [train main loss -1.790503], [lr 0.005714] [batchtime 0.421]
[epoch 75], [iter 46 / 176], [train main loss -1.749104], [lr 0.005714] [batchtime 0.421]
[epoch 75], [iter 47 / 176], [train main loss -1.772915], [lr 0.005714] [batchtime 0.42]
[epoch 75], [iter 48 / 176], [train main loss -1.769459], [lr 0.005714] [batchtime 0.42]
[epoch 75], [iter 49 / 176], [train main loss -1.802082], [lr 0.005714] [batchtime 0.419]
[epoch 75], [iter 50 / 176], [train main loss -1.846842], [lr 0.005714] [batchtime 0.418]
[epoch 75], [iter 51 / 176], [train main loss -1.856551], [lr 0.005714] [batchtime 0.418]
[epoch 75], [iter 52 / 176], [train main loss -1.914682], [lr 0.005714] [batchtime 0.417]
[epoch 75], [iter 53 / 176], [train main loss -1.927300], [lr 0.005714] [batchtime 0.416]
[epoch 75], [iter 54 / 176], [train main loss -1.978411], [lr 0.005714] [batchtime 0.416]
[epoch 75], [iter 55 / 176], [train main loss -1.978945], [lr 0.005714] [batchtime 0.416]
[epoch 75], [iter 56 / 176], [train main loss -1.988046], [lr 0.005714] [batchtime 0.415]
[epoch 75], [iter 57 / 176], [train main loss -1.990068], [lr 0.005714] [batchtime 0.415]
[epoch 75], [iter 58 / 176], [train main loss -2.004255], [lr 0.005714] [batchtime 0.414]
[epoch 75], [iter 59 / 176], [train main loss -2.018822], [lr 0.005714] [batchtime 0.414]
[epoch 75], [iter 60 / 176], [train main loss -2.060405], [lr 0.005714] [batchtime 0.414]
[epoch 75], [iter 61 / 176], [train main loss -2.079490], [lr 0.005714] [batchtime 0.413]
[epoch 75], [iter 62 / 176], [train main loss -2.100140], [lr 0.005714] [batchtime 0.413]
[epoch 75], [iter 63 / 176], [train main loss -2.098323], [lr 0.005714] [batchtime 0.415]
[epoch 75], [iter 64 / 176], [train main loss -2.092633], [lr 0.005714] [batchtime 0.414]
[epoch 75], [iter 65 / 176], [train main loss -2.071415], [lr 0.005714] [batchtime 0.414]
[epoch 75], [iter 66 / 176], [train main loss -2.059742], [lr 0.005714] [batchtime 0.413]
[epoch 75], [iter 67 / 176], [train main loss -2.051716], [lr 0.005714] [batchtime 0.413]
[epoch 75], [iter 68 / 176], [train main loss -2.043939], [lr 0.005714] [batchtime 0.413]
[epoch 75], [iter 69 / 176], [train main loss -2.076709], [lr 0.005714] [batchtime 0.412]
[epoch 75], [iter 70 / 176], [train main loss -2.094216], [lr 0.005714] [batchtime 0.412]
[epoch 75], [iter 71 / 176], [train main loss -2.052872], [lr 0.005714] [batchtime 0.412]
[epoch 75], [iter 72 / 176], [train main loss -2.024270], [lr 0.005714] [batchtime 0.411]
[epoch 75], [iter 73 / 176], [train main loss -2.035052], [lr 0.005714] [batchtime 0.411]
[epoch 75], [iter 74 / 176], [train main loss -2.070601], [lr 0.005714] [batchtime 0.411]
[epoch 75], [iter 75 / 176], [train main loss -2.081852], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 76 / 176], [train main loss -2.106424], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 77 / 176], [train main loss -2.102765], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 78 / 176], [train main loss -2.093769], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 79 / 176], [train main loss -2.120189], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 80 / 176], [train main loss -2.112045], [lr 0.005714] [batchtime 0.409]
[epoch 75], [iter 81 / 176], [train main loss -2.133728], [lr 0.005714] [batchtime 0.409]
[epoch 75], [iter 82 / 176], [train main loss -2.112482], [lr 0.005714] [batchtime 0.409]
[epoch 75], [iter 83 / 176], [train main loss -2.114626], [lr 0.005714] [batchtime 0.408]
[epoch 75], [iter 84 / 176], [train main loss -2.129241], [lr 0.005714] [batchtime 0.408]
[epoch 75], [iter 85 / 176], [train main loss -2.118958], [lr 0.005714] [batchtime 0.408]
[epoch 75], [iter 86 / 176], [train main loss -2.127406], [lr 0.005714] [batchtime 0.408]
[epoch 75], [iter 87 / 176], [train main loss -2.106123], [lr 0.005714] [batchtime 0.41]
[epoch 75], [iter 88 / 176], [train main loss -2.113229], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 89 / 176], [train main loss -2.101693], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 90 / 176], [train main loss -2.087241], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 91 / 176], [train main loss -2.081802], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 92 / 176], [train main loss -2.075965], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 93 / 176], [train main loss -2.086960], [lr 0.005714] [batchtime 0.436]
[epoch 75], [iter 94 / 176], [train main loss -2.082597], [lr 0.005714] [batchtime 0.435]
[epoch 75], [iter 95 / 176], [train main loss -2.098078], [lr 0.005714] [batchtime 0.434]
[epoch 75], [iter 96 / 176], [train main loss -2.121727], [lr 0.005714] [batchtime 0.434]
[epoch 75], [iter 97 / 176], [train main loss -2.134021], [lr 0.005714] [batchtime 0.433]
[epoch 75], [iter 98 / 176], [train main loss -2.131986], [lr 0.005714] [batchtime 0.433]
[epoch 75], [iter 99 / 176], [train main loss -2.123783], [lr 0.005714] [batchtime 0.432]
[epoch 75], [iter 100 / 176], [train main loss -2.115656], [lr 0.005714] [batchtime 0.432]
[epoch 75], [iter 101 / 176], [train main loss -2.104771], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 102 / 176], [train main loss -2.110108], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 103 / 176], [train main loss -2.104076], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 104 / 176], [train main loss -2.120373], [lr 0.005714] [batchtime 0.43]
[epoch 75], [iter 105 / 176], [train main loss -2.123288], [lr 0.005714] [batchtime 0.43]
[epoch 75], [iter 106 / 176], [train main loss -2.120884], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 107 / 176], [train main loss -2.118407], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 108 / 176], [train main loss -2.108769], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 109 / 176], [train main loss -2.085514], [lr 0.005714] [batchtime 0.428]
[epoch 75], [iter 110 / 176], [train main loss -2.058007], [lr 0.005714] [batchtime 0.428]
[epoch 75], [iter 111 / 176], [train main loss -2.063422], [lr 0.005714] [batchtime 0.428]
[epoch 75], [iter 112 / 176], [train main loss -2.032769], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 113 / 176], [train main loss -2.022701], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 114 / 176], [train main loss -2.009468], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 115 / 176], [train main loss -2.022971], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 116 / 176], [train main loss -2.014332], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 117 / 176], [train main loss -2.017723], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 118 / 176], [train main loss -2.017716], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 119 / 176], [train main loss -2.039943], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 120 / 176], [train main loss -2.033076], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 121 / 176], [train main loss -2.047005], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 122 / 176], [train main loss -2.037045], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 123 / 176], [train main loss -2.035629], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 124 / 176], [train main loss -2.031620], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 125 / 176], [train main loss -2.021270], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 126 / 176], [train main loss -2.012989], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 127 / 176], [train main loss -1.999262], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 128 / 176], [train main loss -2.008480], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 129 / 176], [train main loss -2.002029], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 130 / 176], [train main loss -2.006745], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 131 / 176], [train main loss -2.003498], [lr 0.005714] [batchtime 0.421]
[epoch 75], [iter 132 / 176], [train main loss -1.988070], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 133 / 176], [train main loss -2.005227], [lr 0.005714] [batchtime 0.433]
[epoch 75], [iter 134 / 176], [train main loss -2.011064], [lr 0.005714] [batchtime 0.433]
[epoch 75], [iter 135 / 176], [train main loss -2.005732], [lr 0.005714] [batchtime 0.433]
[epoch 75], [iter 136 / 176], [train main loss -2.001387], [lr 0.005714] [batchtime 0.432]
[epoch 75], [iter 137 / 176], [train main loss -2.000009], [lr 0.005714] [batchtime 0.432]
[epoch 75], [iter 138 / 176], [train main loss -1.970405], [lr 0.005714] [batchtime 0.432]
[epoch 75], [iter 139 / 176], [train main loss -1.972278], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 140 / 176], [train main loss -1.970457], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 141 / 176], [train main loss -1.962787], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 142 / 176], [train main loss -1.951976], [lr 0.005714] [batchtime 0.431]
[epoch 75], [iter 143 / 176], [train main loss -1.949609], [lr 0.005714] [batchtime 0.43]
[epoch 75], [iter 144 / 176], [train main loss -1.963036], [lr 0.005714] [batchtime 0.43]
[epoch 75], [iter 145 / 176], [train main loss -1.964698], [lr 0.005714] [batchtime 0.43]
[epoch 75], [iter 146 / 176], [train main loss -1.961442], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 147 / 176], [train main loss -1.974830], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 148 / 176], [train main loss -1.984568], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 149 / 176], [train main loss -2.000470], [lr 0.005714] [batchtime 0.429]
[epoch 75], [iter 150 / 176], [train main loss -1.980906], [lr 0.005714] [batchtime 0.428]
[epoch 75], [iter 151 / 176], [train main loss -1.977415], [lr 0.005714] [batchtime 0.428]
[epoch 75], [iter 152 / 176], [train main loss -1.976618], [lr 0.005714] [batchtime 0.428]
[epoch 75], [iter 153 / 176], [train main loss -1.977941], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 154 / 176], [train main loss -1.968574], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 155 / 176], [train main loss -1.973267], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 156 / 176], [train main loss -1.984700], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 157 / 176], [train main loss -1.999119], [lr 0.005714] [batchtime 0.427]
[epoch 75], [iter 158 / 176], [train main loss -1.997627], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 159 / 176], [train main loss -1.990434], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 160 / 176], [train main loss -1.984033], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 161 / 176], [train main loss -1.991990], [lr 0.005714] [batchtime 0.426]
[epoch 75], [iter 162 / 176], [train main loss -1.986139], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 163 / 176], [train main loss -1.977465], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 164 / 176], [train main loss -1.992561], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 165 / 176], [train main loss -2.010955], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 166 / 176], [train main loss -2.007146], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 167 / 176], [train main loss -2.004973], [lr 0.005714] [batchtime 0.425]
[epoch 75], [iter 168 / 176], [train main loss -2.006163], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 169 / 176], [train main loss -2.011460], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 170 / 176], [train main loss -2.016650], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 171 / 176], [train main loss -2.037372], [lr 0.005714] [batchtime 0.424]
[epoch 75], [iter 172 / 176], [train main loss -2.036394], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 173 / 176], [train main loss -2.032899], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 174 / 176], [train main loss -2.025520], [lr 0.005714] [batchtime 0.423]
[epoch 75], [iter 175 / 176], [train main loss -2.043023], [lr 0.005714] [batchtime 0.422]
[epoch 75], [iter 176 / 176], [train main loss -2.056756], [lr 0.005714] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.18  35.44    0.03  0.04         0.97      0.97
   1  sidewalk          66.98   5.24    0.26  0.24         0.80      0.81
   2  building          84.71  24.78    0.07  0.11         0.93      0.90
   3  wall              12.73   0.10    5.11  1.74         0.16      0.36
   4  fence             23.46   0.38    2.35  0.91         0.30      0.52
   5  pole              34.12   0.48    1.37  0.56         0.42      0.64
   6  traffic light      5.92   0.01   15.38  0.51         0.06      0.66
   7  traffic sign      12.41   0.07    6.82  0.24         0.13      0.81
   8  vegetation        80.95  11.63    0.06  0.17         0.94      0.85
   9  terrain           38.17   0.40    0.84  0.78         0.54      0.56
  10  sky               93.30   3.77    0.03  0.04         0.97      0.96
  11  person            43.75   0.79    0.94  0.35         0.52      0.74
  12  rider              3.77   0.00   24.24  1.31         0.04      0.43
  13  car               83.54   6.59    0.07  0.12         0.93      0.89
  14  truck              0.29   0.00  344.80  0.51         0.00      0.66
  15  bus               13.42   0.03    2.13  4.32         0.32      0.19
  16  train             34.92   0.08    1.36  0.50         0.42      0.67
  17  motorcycle         0.78   0.00  127.34  0.57         0.01      0.64
  18  bicycle           33.44   0.22    0.73  1.26         0.58      0.44
Mean: 40.04
-----------------------------------------------------------------------------------------------------------
this : [epoch 75], [val loss 0.35083], [acc 0.90006], [acc_cls 0.47628], [mean_iu 0.40044], [fwavacc 0.82706]
best : [epoch 75], [val loss 0.35083], [acc 0.90006], [acc_cls 0.47628], [mean_iu 0.40044], [fwavacc 0.82706]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 76], [iter 1 / 176], [train main loss -3.301604], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 2 / 176], [train main loss -1.899656], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 3 / 176], [train main loss -2.321526], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 4 / 176], [train main loss -2.167356], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 5 / 176], [train main loss -2.016923], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 6 / 176], [train main loss -1.854757], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 7 / 176], [train main loss -2.080537], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 8 / 176], [train main loss -1.867701], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 9 / 176], [train main loss -1.852303], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 10 / 176], [train main loss -1.992492], [lr 0.005657] [batchtime 0]
[epoch 76], [iter 11 / 176], [train main loss -1.833418], [lr 0.005657] [batchtime 0.367]
[epoch 76], [iter 12 / 176], [train main loss -1.755115], [lr 0.005657] [batchtime 0.39]
[epoch 76], [iter 13 / 176], [train main loss -1.620608], [lr 0.005657] [batchtime 0.393]
[epoch 76], [iter 14 / 176], [train main loss -1.695355], [lr 0.005657] [batchtime 0.392]
[epoch 76], [iter 15 / 176], [train main loss -1.720067], [lr 0.005657] [batchtime 0.393]
[epoch 76], [iter 16 / 176], [train main loss -1.851541], [lr 0.005657] [batchtime 0.394]
[epoch 76], [iter 17 / 176], [train main loss -1.770097], [lr 0.005657] [batchtime 0.396]
[epoch 76], [iter 18 / 176], [train main loss -1.773727], [lr 0.005657] [batchtime 0.396]
[epoch 76], [iter 19 / 176], [train main loss -1.872257], [lr 0.005657] [batchtime 0.397]
[epoch 76], [iter 20 / 176], [train main loss -1.915845], [lr 0.005657] [batchtime 0.397]
[epoch 76], [iter 21 / 176], [train main loss -1.974175], [lr 0.005657] [batchtime 0.398]
[epoch 76], [iter 22 / 176], [train main loss -1.898796], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 23 / 176], [train main loss -1.846175], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 24 / 176], [train main loss -1.853002], [lr 0.005657] [batchtime 0.398]
[epoch 76], [iter 25 / 176], [train main loss -1.845685], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 26 / 176], [train main loss -1.826316], [lr 0.005657] [batchtime 0.398]
[epoch 76], [iter 27 / 176], [train main loss -1.854678], [lr 0.005657] [batchtime 0.398]
[epoch 76], [iter 28 / 176], [train main loss -1.845738], [lr 0.005657] [batchtime 0.398]
[epoch 76], [iter 29 / 176], [train main loss -1.788075], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 30 / 176], [train main loss -1.805472], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 31 / 176], [train main loss -1.800360], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 32 / 176], [train main loss -1.728971], [lr 0.005657] [batchtime 0.399]
[epoch 76], [iter 33 / 176], [train main loss -1.754965], [lr 0.005657] [batchtime 0.398]
[epoch 76], [iter 34 / 176], [train main loss -1.840956], [lr 0.005657] [batchtime 0.405]
[epoch 76], [iter 35 / 176], [train main loss -1.951001], [lr 0.005657] [batchtime 0.435]
[epoch 76], [iter 36 / 176], [train main loss -1.956662], [lr 0.005657] [batchtime 0.433]
[epoch 76], [iter 37 / 176], [train main loss -2.003191], [lr 0.005657] [batchtime 0.431]
[epoch 76], [iter 38 / 176], [train main loss -1.959379], [lr 0.005657] [batchtime 0.429]
[epoch 76], [iter 39 / 176], [train main loss -1.925217], [lr 0.005657] [batchtime 0.428]
[epoch 76], [iter 40 / 176], [train main loss -1.926273], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 41 / 176], [train main loss -2.001784], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 42 / 176], [train main loss -1.993815], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 43 / 176], [train main loss -2.010306], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 44 / 176], [train main loss -2.044420], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 45 / 176], [train main loss -2.045956], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 46 / 176], [train main loss -2.031923], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 47 / 176], [train main loss -2.060931], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 48 / 176], [train main loss -2.086323], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 49 / 176], [train main loss -2.114673], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 50 / 176], [train main loss -2.090729], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 51 / 176], [train main loss -2.094673], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 52 / 176], [train main loss -2.093500], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 53 / 176], [train main loss -2.074796], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 54 / 176], [train main loss -2.058926], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 55 / 176], [train main loss -2.060946], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 56 / 176], [train main loss -2.018900], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 57 / 176], [train main loss -2.032090], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 58 / 176], [train main loss -2.002261], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 59 / 176], [train main loss -1.998752], [lr 0.005657] [batchtime 0.415]
[epoch 76], [iter 60 / 176], [train main loss -1.943215], [lr 0.005657] [batchtime 0.415]
[epoch 76], [iter 61 / 176], [train main loss -1.948174], [lr 0.005657] [batchtime 0.414]
[epoch 76], [iter 62 / 176], [train main loss -1.932785], [lr 0.005657] [batchtime 0.414]
[epoch 76], [iter 63 / 176], [train main loss -1.900913], [lr 0.005657] [batchtime 0.413]
[epoch 76], [iter 64 / 176], [train main loss -1.902820], [lr 0.005657] [batchtime 0.413]
[epoch 76], [iter 65 / 176], [train main loss -1.892739], [lr 0.005657] [batchtime 0.413]
[epoch 76], [iter 66 / 176], [train main loss -1.893927], [lr 0.005657] [batchtime 0.413]
[epoch 76], [iter 67 / 176], [train main loss -1.886146], [lr 0.005657] [batchtime 0.412]
[epoch 76], [iter 68 / 176], [train main loss -1.890739], [lr 0.005657] [batchtime 0.412]
[epoch 76], [iter 69 / 176], [train main loss -1.880830], [lr 0.005657] [batchtime 0.412]
[epoch 76], [iter 70 / 176], [train main loss -1.862171], [lr 0.005657] [batchtime 0.412]
[epoch 76], [iter 71 / 176], [train main loss -1.873625], [lr 0.005657] [batchtime 0.411]
[epoch 76], [iter 72 / 176], [train main loss -1.856586], [lr 0.005657] [batchtime 0.411]
[epoch 76], [iter 73 / 176], [train main loss -1.863789], [lr 0.005657] [batchtime 0.411]
[epoch 76], [iter 74 / 176], [train main loss -1.865863], [lr 0.005657] [batchtime 0.411]
[epoch 76], [iter 75 / 176], [train main loss -1.854907], [lr 0.005657] [batchtime 0.411]
[epoch 76], [iter 76 / 176], [train main loss -1.835109], [lr 0.005657] [batchtime 0.41]
[epoch 76], [iter 77 / 176], [train main loss -1.826915], [lr 0.005657] [batchtime 0.41]
[epoch 76], [iter 78 / 176], [train main loss -1.790085], [lr 0.005657] [batchtime 0.41]
[epoch 76], [iter 79 / 176], [train main loss -1.811967], [lr 0.005657] [batchtime 0.41]
[epoch 76], [iter 80 / 176], [train main loss -1.841472], [lr 0.005657] [batchtime 0.41]
[epoch 76], [iter 81 / 176], [train main loss -1.809993], [lr 0.005657] [batchtime 0.409]
[epoch 76], [iter 82 / 176], [train main loss -1.800871], [lr 0.005657] [batchtime 0.409]
[epoch 76], [iter 83 / 176], [train main loss -1.828039], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 84 / 176], [train main loss -1.842207], [lr 0.005657] [batchtime 0.429]
[epoch 76], [iter 85 / 176], [train main loss -1.876943], [lr 0.005657] [batchtime 0.429]
[epoch 76], [iter 86 / 176], [train main loss -1.886348], [lr 0.005657] [batchtime 0.428]
[epoch 76], [iter 87 / 176], [train main loss -1.941759], [lr 0.005657] [batchtime 0.428]
[epoch 76], [iter 88 / 176], [train main loss -1.972995], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 89 / 176], [train main loss -1.973661], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 90 / 176], [train main loss -1.979819], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 91 / 176], [train main loss -1.982958], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 92 / 176], [train main loss -1.969609], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 93 / 176], [train main loss -1.939670], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 94 / 176], [train main loss -1.934977], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 95 / 176], [train main loss -1.951378], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 96 / 176], [train main loss -1.972826], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 97 / 176], [train main loss -1.982346], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 98 / 176], [train main loss -2.003824], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 99 / 176], [train main loss -2.012980], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 100 / 176], [train main loss -2.020497], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 101 / 176], [train main loss -2.016375], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 102 / 176], [train main loss -2.015303], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 103 / 176], [train main loss -2.015497], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 104 / 176], [train main loss -2.011955], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 105 / 176], [train main loss -2.014280], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 106 / 176], [train main loss -2.017450], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 107 / 176], [train main loss -2.028797], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 108 / 176], [train main loss -2.029607], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 109 / 176], [train main loss -2.023028], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 110 / 176], [train main loss -2.018262], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 111 / 176], [train main loss -2.001159], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 112 / 176], [train main loss -1.992356], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 113 / 176], [train main loss -2.001025], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 114 / 176], [train main loss -1.976646], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 115 / 176], [train main loss -1.983363], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 116 / 176], [train main loss -1.991114], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 117 / 176], [train main loss -1.996773], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 118 / 176], [train main loss -1.984498], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 119 / 176], [train main loss -2.005712], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 120 / 176], [train main loss -1.991258], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 121 / 176], [train main loss -1.989613], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 122 / 176], [train main loss -1.966261], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 123 / 176], [train main loss -1.974763], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 124 / 176], [train main loss -1.961883], [lr 0.005657] [batchtime 0.417]
[epoch 76], [iter 125 / 176], [train main loss -1.960736], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 126 / 176], [train main loss -1.965503], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 127 / 176], [train main loss -1.955389], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 128 / 176], [train main loss -1.974158], [lr 0.005657] [batchtime 0.416]
[epoch 76], [iter 129 / 176], [train main loss -1.980343], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 130 / 176], [train main loss -1.975957], [lr 0.005657] [batchtime 0.429]
[epoch 76], [iter 131 / 176], [train main loss -1.977887], [lr 0.005657] [batchtime 0.428]
[epoch 76], [iter 132 / 176], [train main loss -1.984229], [lr 0.005657] [batchtime 0.428]
[epoch 76], [iter 133 / 176], [train main loss -1.986425], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 134 / 176], [train main loss -1.985957], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 135 / 176], [train main loss -1.985175], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 136 / 176], [train main loss -1.996201], [lr 0.005657] [batchtime 0.427]
[epoch 76], [iter 137 / 176], [train main loss -1.995621], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 138 / 176], [train main loss -2.003252], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 139 / 176], [train main loss -2.003151], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 140 / 176], [train main loss -2.018097], [lr 0.005657] [batchtime 0.426]
[epoch 76], [iter 141 / 176], [train main loss -2.014131], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 142 / 176], [train main loss -2.018456], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 143 / 176], [train main loss -1.994828], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 144 / 176], [train main loss -2.004316], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 145 / 176], [train main loss -2.003491], [lr 0.005657] [batchtime 0.425]
[epoch 76], [iter 146 / 176], [train main loss -2.003115], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 147 / 176], [train main loss -2.009294], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 148 / 176], [train main loss -2.025867], [lr 0.005657] [batchtime 0.424]
[epoch 76], [iter 149 / 176], [train main loss -2.030405], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 150 / 176], [train main loss -2.035568], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 151 / 176], [train main loss -2.019364], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 152 / 176], [train main loss -2.011239], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 153 / 176], [train main loss -1.995055], [lr 0.005657] [batchtime 0.423]
[epoch 76], [iter 154 / 176], [train main loss -1.998130], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 155 / 176], [train main loss -2.005567], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 156 / 176], [train main loss -1.997909], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 157 / 176], [train main loss -1.984877], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 158 / 176], [train main loss -2.005201], [lr 0.005657] [batchtime 0.422]
[epoch 76], [iter 159 / 176], [train main loss -2.000177], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 160 / 176], [train main loss -1.999987], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 161 / 176], [train main loss -1.996059], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 162 / 176], [train main loss -1.993141], [lr 0.005657] [batchtime 0.421]
[epoch 76], [iter 163 / 176], [train main loss -1.984065], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 164 / 176], [train main loss -1.970982], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 165 / 176], [train main loss -1.967078], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 166 / 176], [train main loss -1.959768], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 167 / 176], [train main loss -1.957807], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 168 / 176], [train main loss -1.952975], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 169 / 176], [train main loss -1.952432], [lr 0.005657] [batchtime 0.42]
[epoch 76], [iter 170 / 176], [train main loss -1.933854], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 171 / 176], [train main loss -1.932879], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 172 / 176], [train main loss -1.930092], [lr 0.005657] [batchtime 0.419]
[epoch 76], [iter 173 / 176], [train main loss -1.941974], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 174 / 176], [train main loss -1.953098], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 175 / 176], [train main loss -1.940093], [lr 0.005657] [batchtime 0.418]
[epoch 76], [iter 176 / 176], [train main loss -1.944408], [lr 0.005657] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.05  35.45   0.03  0.04         0.97      0.96
   1  sidewalk          67.00   5.27   0.25  0.24         0.80      0.81
   2  building          84.81  24.65   0.08  0.10         0.93      0.91
   3  wall              15.91   0.14   3.32  1.96         0.23      0.34
   4  fence             22.44   0.36   2.50  0.95         0.29      0.51
   5  pole              35.52   0.52   1.18  0.63         0.46      0.61
   6  traffic light      9.46   0.02   8.69  0.88         0.10      0.53
   7  traffic sign      16.31   0.10   4.74  0.40         0.17      0.72
   8  vegetation        82.27  11.53   0.07  0.14         0.93      0.87
   9  terrain           38.54   0.40   0.84  0.76         0.54      0.57
  10  sky               92.19   3.74   0.04  0.05         0.97      0.95
  11  person            47.83   0.92   0.66  0.43         0.60      0.70
  12  rider              4.34   0.00  20.24  1.78         0.05      0.36
  13  car               83.59   6.59   0.07  0.12         0.93      0.89
  14  truck              1.49   0.00  65.16  0.87         0.02      0.54
  15  bus               12.51   0.04   1.34  5.66         0.43      0.15
  16  train             34.37   0.08   1.13  0.78         0.47      0.56
  17  motorcycle         1.42   0.00  68.62  0.93         0.01      0.52
  18  bicycle           34.03   0.22   0.79  1.15         0.56      0.46
Mean: 40.95
-----------------------------------------------------------------------------------------------------------
this : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 77], [iter 1 / 176], [train main loss -2.176187], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 2 / 176], [train main loss -2.122559], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 3 / 176], [train main loss -2.734228], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 4 / 176], [train main loss -2.145989], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 5 / 176], [train main loss -2.839267], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 6 / 176], [train main loss -2.950411], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 7 / 176], [train main loss -2.352034], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 8 / 176], [train main loss -2.203620], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 9 / 176], [train main loss -2.604640], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 10 / 176], [train main loss -2.521601], [lr 0.005600] [batchtime 0]
[epoch 77], [iter 11 / 176], [train main loss -2.159707], [lr 0.005600] [batchtime 0.384]
[epoch 77], [iter 12 / 176], [train main loss -2.101490], [lr 0.005600] [batchtime 0.391]
[epoch 77], [iter 13 / 176], [train main loss -2.029312], [lr 0.005600] [batchtime 0.392]
[epoch 77], [iter 14 / 176], [train main loss -1.998338], [lr 0.005600] [batchtime 0.391]
[epoch 77], [iter 15 / 176], [train main loss -2.018740], [lr 0.005600] [batchtime 0.392]
[epoch 77], [iter 16 / 176], [train main loss -1.878033], [lr 0.005600] [batchtime 0.394]
[epoch 77], [iter 17 / 176], [train main loss -1.924000], [lr 0.005600] [batchtime 0.393]
[epoch 77], [iter 18 / 176], [train main loss -1.872722], [lr 0.005600] [batchtime 0.393]
[epoch 77], [iter 19 / 176], [train main loss -1.806732], [lr 0.005600] [batchtime 0.394]
[epoch 77], [iter 20 / 176], [train main loss -1.770589], [lr 0.005600] [batchtime 0.396]
[epoch 77], [iter 21 / 176], [train main loss -1.900239], [lr 0.005600] [batchtime 0.396]
[epoch 77], [iter 22 / 176], [train main loss -1.878010], [lr 0.005600] [batchtime 0.396]
[epoch 77], [iter 23 / 176], [train main loss -1.817340], [lr 0.005600] [batchtime 0.396]
[epoch 77], [iter 24 / 176], [train main loss -1.911988], [lr 0.005600] [batchtime 0.397]
[epoch 77], [iter 25 / 176], [train main loss -2.029079], [lr 0.005600] [batchtime 0.397]
[epoch 77], [iter 26 / 176], [train main loss -2.118139], [lr 0.005600] [batchtime 0.397]
[epoch 77], [iter 27 / 176], [train main loss -2.130276], [lr 0.005600] [batchtime 0.398]
[epoch 77], [iter 28 / 176], [train main loss -2.093537], [lr 0.005600] [batchtime 0.398]
[epoch 77], [iter 29 / 176], [train main loss -2.104350], [lr 0.005600] [batchtime 0.398]
[epoch 77], [iter 30 / 176], [train main loss -2.081098], [lr 0.005600] [batchtime 0.398]
[epoch 77], [iter 31 / 176], [train main loss -2.037100], [lr 0.005600] [batchtime 0.408]
[epoch 77], [iter 32 / 176], [train main loss -2.014105], [lr 0.005600] [batchtime 0.416]
[epoch 77], [iter 33 / 176], [train main loss -2.065372], [lr 0.005600] [batchtime 0.415]
[epoch 77], [iter 34 / 176], [train main loss -2.020079], [lr 0.005600] [batchtime 0.414]
[epoch 77], [iter 35 / 176], [train main loss -2.034082], [lr 0.005600] [batchtime 0.413]
[epoch 77], [iter 36 / 176], [train main loss -1.981922], [lr 0.005600] [batchtime 0.412]
[epoch 77], [iter 37 / 176], [train main loss -2.029694], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 38 / 176], [train main loss -1.996856], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 39 / 176], [train main loss -2.011587], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 40 / 176], [train main loss -1.944788], [lr 0.005600] [batchtime 0.41]
[epoch 77], [iter 41 / 176], [train main loss -1.967045], [lr 0.005600] [batchtime 0.41]
[epoch 77], [iter 42 / 176], [train main loss -1.962339], [lr 0.005600] [batchtime 0.41]
[epoch 77], [iter 43 / 176], [train main loss -1.921167], [lr 0.005600] [batchtime 0.409]
[epoch 77], [iter 44 / 176], [train main loss -1.883665], [lr 0.005600] [batchtime 0.409]
[epoch 77], [iter 45 / 176], [train main loss -1.879909], [lr 0.005600] [batchtime 0.408]
[epoch 77], [iter 46 / 176], [train main loss -1.883468], [lr 0.005600] [batchtime 0.408]
[epoch 77], [iter 47 / 176], [train main loss -1.843145], [lr 0.005600] [batchtime 0.408]
[epoch 77], [iter 48 / 176], [train main loss -1.857424], [lr 0.005600] [batchtime 0.408]
[epoch 77], [iter 49 / 176], [train main loss -1.869117], [lr 0.005600] [batchtime 0.407]
[epoch 77], [iter 50 / 176], [train main loss -1.908502], [lr 0.005600] [batchtime 0.407]
[epoch 77], [iter 51 / 176], [train main loss -1.880842], [lr 0.005600] [batchtime 0.407]
[epoch 77], [iter 52 / 176], [train main loss -1.892778], [lr 0.005600] [batchtime 0.406]
[epoch 77], [iter 53 / 176], [train main loss -1.898989], [lr 0.005600] [batchtime 0.406]
[epoch 77], [iter 54 / 176], [train main loss -1.929520], [lr 0.005600] [batchtime 0.406]
[epoch 77], [iter 55 / 176], [train main loss -1.902929], [lr 0.005600] [batchtime 0.406]
[epoch 77], [iter 56 / 176], [train main loss -1.888226], [lr 0.005600] [batchtime 0.405]
[epoch 77], [iter 57 / 176], [train main loss -1.935459], [lr 0.005600] [batchtime 0.405]
[epoch 77], [iter 58 / 176], [train main loss -1.931330], [lr 0.005600] [batchtime 0.405]
[epoch 77], [iter 59 / 176], [train main loss -1.982136], [lr 0.005600] [batchtime 0.405]
[epoch 77], [iter 60 / 176], [train main loss -1.978961], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 61 / 176], [train main loss -1.976603], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 62 / 176], [train main loss -1.970150], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 63 / 176], [train main loss -2.002931], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 64 / 176], [train main loss -2.008631], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 65 / 176], [train main loss -1.974110], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 66 / 176], [train main loss -2.012845], [lr 0.005600] [batchtime 0.404]
[epoch 77], [iter 67 / 176], [train main loss -2.011850], [lr 0.005600] [batchtime 0.403]
[epoch 77], [iter 68 / 176], [train main loss -2.018833], [lr 0.005600] [batchtime 0.403]
[epoch 77], [iter 69 / 176], [train main loss -2.042609], [lr 0.005600] [batchtime 0.403]
[epoch 77], [iter 70 / 176], [train main loss -2.041024], [lr 0.005600] [batchtime 0.403]
[epoch 77], [iter 71 / 176], [train main loss -2.033942], [lr 0.005600] [batchtime 0.403]
[epoch 77], [iter 72 / 176], [train main loss -2.018468], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 73 / 176], [train main loss -2.005790], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 74 / 176], [train main loss -1.983327], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 75 / 176], [train main loss -1.965807], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 76 / 176], [train main loss -1.955036], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 77 / 176], [train main loss -1.924898], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 78 / 176], [train main loss -1.959820], [lr 0.005600] [batchtime 0.402]
[epoch 77], [iter 79 / 176], [train main loss -1.943575], [lr 0.005600] [batchtime 0.405]
[epoch 77], [iter 80 / 176], [train main loss -1.978035], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 81 / 176], [train main loss -1.958760], [lr 0.005600] [batchtime 0.42]
[epoch 77], [iter 82 / 176], [train main loss -1.989787], [lr 0.005600] [batchtime 0.419]
[epoch 77], [iter 83 / 176], [train main loss -1.974894], [lr 0.005600] [batchtime 0.419]
[epoch 77], [iter 84 / 176], [train main loss -1.955157], [lr 0.005600] [batchtime 0.419]
[epoch 77], [iter 85 / 176], [train main loss -1.960036], [lr 0.005600] [batchtime 0.418]
[epoch 77], [iter 86 / 176], [train main loss -1.977698], [lr 0.005600] [batchtime 0.418]
[epoch 77], [iter 87 / 176], [train main loss -2.000743], [lr 0.005600] [batchtime 0.418]
[epoch 77], [iter 88 / 176], [train main loss -2.035895], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 89 / 176], [train main loss -2.019247], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 90 / 176], [train main loss -2.037055], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 91 / 176], [train main loss -2.051633], [lr 0.005600] [batchtime 0.416]
[epoch 77], [iter 92 / 176], [train main loss -2.045584], [lr 0.005600] [batchtime 0.416]
[epoch 77], [iter 93 / 176], [train main loss -2.032632], [lr 0.005600] [batchtime 0.416]
[epoch 77], [iter 94 / 176], [train main loss -2.034124], [lr 0.005600] [batchtime 0.415]
[epoch 77], [iter 95 / 176], [train main loss -2.024086], [lr 0.005600] [batchtime 0.415]
[epoch 77], [iter 96 / 176], [train main loss -2.014938], [lr 0.005600] [batchtime 0.415]
[epoch 77], [iter 97 / 176], [train main loss -2.044692], [lr 0.005600] [batchtime 0.415]
[epoch 77], [iter 98 / 176], [train main loss -2.040775], [lr 0.005600] [batchtime 0.414]
[epoch 77], [iter 99 / 176], [train main loss -2.015381], [lr 0.005600] [batchtime 0.414]
[epoch 77], [iter 100 / 176], [train main loss -2.012822], [lr 0.005600] [batchtime 0.414]
[epoch 77], [iter 101 / 176], [train main loss -2.011268], [lr 0.005600] [batchtime 0.414]
[epoch 77], [iter 102 / 176], [train main loss -2.052938], [lr 0.005600] [batchtime 0.413]
[epoch 77], [iter 103 / 176], [train main loss -2.069326], [lr 0.005600] [batchtime 0.413]
[epoch 77], [iter 104 / 176], [train main loss -2.053754], [lr 0.005600] [batchtime 0.413]
[epoch 77], [iter 105 / 176], [train main loss -2.034699], [lr 0.005600] [batchtime 0.413]
[epoch 77], [iter 106 / 176], [train main loss -2.037695], [lr 0.005600] [batchtime 0.413]
[epoch 77], [iter 107 / 176], [train main loss -2.049905], [lr 0.005600] [batchtime 0.412]
[epoch 77], [iter 108 / 176], [train main loss -2.030158], [lr 0.005600] [batchtime 0.412]
[epoch 77], [iter 109 / 176], [train main loss -2.019499], [lr 0.005600] [batchtime 0.412]
[epoch 77], [iter 110 / 176], [train main loss -2.009013], [lr 0.005600] [batchtime 0.412]
[epoch 77], [iter 111 / 176], [train main loss -1.989747], [lr 0.005600] [batchtime 0.412]
[epoch 77], [iter 112 / 176], [train main loss -1.998724], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 113 / 176], [train main loss -1.995818], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 114 / 176], [train main loss -1.974824], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 115 / 176], [train main loss -1.988598], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 116 / 176], [train main loss -1.987229], [lr 0.005600] [batchtime 0.411]
[epoch 77], [iter 117 / 176], [train main loss -1.998987], [lr 0.005600] [batchtime 0.419]
[epoch 77], [iter 118 / 176], [train main loss -1.979537], [lr 0.005600] [batchtime 0.419]
[epoch 77], [iter 119 / 176], [train main loss -1.974883], [lr 0.005600] [batchtime 0.418]
[epoch 77], [iter 120 / 176], [train main loss -1.962681], [lr 0.005600] [batchtime 0.418]
[epoch 77], [iter 121 / 176], [train main loss -1.974613], [lr 0.005600] [batchtime 0.418]
[epoch 77], [iter 122 / 176], [train main loss -1.971530], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 123 / 176], [train main loss -1.956699], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 124 / 176], [train main loss -1.958152], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 125 / 176], [train main loss -1.959399], [lr 0.005600] [batchtime 0.417]
[epoch 77], [iter 126 / 176], [train main loss -1.970570], [lr 0.005600] [batchtime 0.428]
[epoch 77], [iter 127 / 176], [train main loss -1.962028], [lr 0.005600] [batchtime 0.43]
[epoch 77], [iter 128 / 176], [train main loss -1.941787], [lr 0.005600] [batchtime 0.429]
[epoch 77], [iter 129 / 176], [train main loss -1.930945], [lr 0.005600] [batchtime 0.429]
[epoch 77], [iter 130 / 176], [train main loss -1.940294], [lr 0.005600] [batchtime 0.428]
[epoch 77], [iter 131 / 176], [train main loss -1.934979], [lr 0.005600] [batchtime 0.428]
[epoch 77], [iter 132 / 176], [train main loss -1.936138], [lr 0.005600] [batchtime 0.428]
[epoch 77], [iter 133 / 176], [train main loss -1.926104], [lr 0.005600] [batchtime 0.427]
[epoch 77], [iter 134 / 176], [train main loss -1.908209], [lr 0.005600] [batchtime 0.427]
[epoch 77], [iter 135 / 176], [train main loss -1.891879], [lr 0.005600] [batchtime 0.427]
[epoch 77], [iter 136 / 176], [train main loss -1.914289], [lr 0.005600] [batchtime 0.427]
[epoch 77], [iter 137 / 176], [train main loss -1.901186], [lr 0.005600] [batchtime 0.426]
[epoch 77], [iter 138 / 176], [train main loss -1.873584], [lr 0.005600] [batchtime 0.426]
[epoch 77], [iter 139 / 176], [train main loss -1.864153], [lr 0.005600] [batchtime 0.426]
[epoch 77], [iter 140 / 176], [train main loss -1.862424], [lr 0.005600] [batchtime 0.426]
[epoch 77], [iter 141 / 176], [train main loss -1.864060], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 142 / 176], [train main loss -1.862805], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 143 / 176], [train main loss -1.870185], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 144 / 176], [train main loss -1.860179], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 145 / 176], [train main loss -1.864674], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 146 / 176], [train main loss -1.856623], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 147 / 176], [train main loss -1.859551], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 148 / 176], [train main loss -1.857454], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 149 / 176], [train main loss -1.860027], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 150 / 176], [train main loss -1.850270], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 151 / 176], [train main loss -1.843294], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 152 / 176], [train main loss -1.851177], [lr 0.005600] [batchtime 0.425]
[epoch 77], [iter 153 / 176], [train main loss -1.841637], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 154 / 176], [train main loss -1.842606], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 155 / 176], [train main loss -1.830473], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 156 / 176], [train main loss -1.844977], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 157 / 176], [train main loss -1.869817], [lr 0.005600] [batchtime 0.423]
[epoch 77], [iter 158 / 176], [train main loss -1.871989], [lr 0.005600] [batchtime 0.423]
[epoch 77], [iter 159 / 176], [train main loss -1.871808], [lr 0.005600] [batchtime 0.423]
[epoch 77], [iter 160 / 176], [train main loss -1.867550], [lr 0.005600] [batchtime 0.423]
[epoch 77], [iter 161 / 176], [train main loss -1.861478], [lr 0.005600] [batchtime 0.423]
[epoch 77], [iter 162 / 176], [train main loss -1.854289], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 163 / 176], [train main loss -1.863357], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 164 / 176], [train main loss -1.856764], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 165 / 176], [train main loss -1.857530], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 166 / 176], [train main loss -1.864520], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 167 / 176], [train main loss -1.842711], [lr 0.005600] [batchtime 0.421]
[epoch 77], [iter 168 / 176], [train main loss -1.849400], [lr 0.005600] [batchtime 0.421]
[epoch 77], [iter 169 / 176], [train main loss -1.857961], [lr 0.005600] [batchtime 0.421]
[epoch 77], [iter 170 / 176], [train main loss -1.850014], [lr 0.005600] [batchtime 0.421]
[epoch 77], [iter 171 / 176], [train main loss -1.852783], [lr 0.005600] [batchtime 0.42]
[epoch 77], [iter 172 / 176], [train main loss -1.854201], [lr 0.005600] [batchtime 0.42]
[epoch 77], [iter 173 / 176], [train main loss -1.837706], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 174 / 176], [train main loss -1.846279], [lr 0.005600] [batchtime 0.422]
[epoch 77], [iter 175 / 176], [train main loss -1.861435], [lr 0.005600] [batchtime 0.424]
[epoch 77], [iter 176 / 176], [train main loss -1.865465], [lr 0.005600] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.25  35.44   0.03  0.04         0.97      0.97
   1  sidewalk          67.51   5.32   0.24  0.24         0.81      0.80
   2  building          85.08  25.15   0.06  0.12         0.95      0.89
   3  wall              16.61   0.14   3.16  1.86         0.24      0.35
   4  fence             17.54   0.25   4.05  0.65         0.20      0.61
   5  pole              33.89   0.46   1.47  0.48         0.40      0.68
   6  traffic light      5.34   0.01  17.28  0.45         0.05      0.69
   7  traffic sign      11.34   0.06   7.62  0.20         0.12      0.83
   8  vegetation        82.67  11.55   0.07  0.14         0.93      0.88
   9  terrain           37.09   0.35   1.10  0.60         0.48      0.63
  10  sky               93.08   3.73   0.04  0.03         0.96      0.97
  11  person            48.09   0.96   0.60  0.48         0.62      0.68
  12  rider              4.77   0.00  18.62  1.37         0.05      0.42
  13  car               84.75   6.58   0.08  0.10         0.93      0.91
  14  truck              1.13   0.00  86.68  0.76         0.01      0.57
  15  bus               13.79   0.03   2.02  4.23         0.33      0.19
  16  train             40.78   0.09   0.97  0.49         0.51      0.67
  17  motorcycle         1.19   0.00  82.36  0.97         0.01      0.51
  18  bicycle           34.23   0.21   0.86  1.06         0.54      0.49
Mean: 40.69
-----------------------------------------------------------------------------------------------------------
this : [epoch 77], [val loss 0.35075], [acc 0.90336], [acc_cls 0.47999], [mean_iu 0.40691], [fwavacc 0.83170]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 78], [iter 1 / 176], [train main loss -3.645384], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 2 / 176], [train main loss -1.802846], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 3 / 176], [train main loss -1.164098], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 4 / 176], [train main loss -1.349091], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 5 / 176], [train main loss -1.570914], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 6 / 176], [train main loss -1.610992], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 7 / 176], [train main loss -1.728072], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 8 / 176], [train main loss -1.796484], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 9 / 176], [train main loss -1.674074], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 10 / 176], [train main loss -1.601940], [lr 0.005543] [batchtime 0]
[epoch 78], [iter 11 / 176], [train main loss -1.640109], [lr 0.005543] [batchtime 0.374]
[epoch 78], [iter 12 / 176], [train main loss -1.998923], [lr 0.005543] [batchtime 0.387]
[epoch 78], [iter 13 / 176], [train main loss -1.984796], [lr 0.005543] [batchtime 0.393]
[epoch 78], [iter 14 / 176], [train main loss -1.855451], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 15 / 176], [train main loss -1.987915], [lr 0.005543] [batchtime 0.397]
[epoch 78], [iter 16 / 176], [train main loss -1.842335], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 17 / 176], [train main loss -1.727743], [lr 0.005543] [batchtime 0.397]
[epoch 78], [iter 18 / 176], [train main loss -1.666661], [lr 0.005543] [batchtime 0.397]
[epoch 78], [iter 19 / 176], [train main loss -1.769926], [lr 0.005543] [batchtime 0.397]
[epoch 78], [iter 20 / 176], [train main loss -1.788494], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 21 / 176], [train main loss -1.857521], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 22 / 176], [train main loss -2.098152], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 23 / 176], [train main loss -1.987862], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 24 / 176], [train main loss -2.007010], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 25 / 176], [train main loss -2.099830], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 26 / 176], [train main loss -2.154345], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 27 / 176], [train main loss -2.194592], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 28 / 176], [train main loss -2.208499], [lr 0.005543] [batchtime 0.396]
[epoch 78], [iter 29 / 176], [train main loss -2.216770], [lr 0.005543] [batchtime 0.397]
[epoch 78], [iter 30 / 176], [train main loss -2.108391], [lr 0.005543] [batchtime 0.404]
[epoch 78], [iter 31 / 176], [train main loss -2.113934], [lr 0.005543] [batchtime 0.414]
[epoch 78], [iter 32 / 176], [train main loss -2.153568], [lr 0.005543] [batchtime 0.616]
[epoch 78], [iter 33 / 176], [train main loss -2.217526], [lr 0.005543] [batchtime 0.605]
[epoch 78], [iter 34 / 176], [train main loss -2.227643], [lr 0.005543] [batchtime 0.596]
[epoch 78], [iter 35 / 176], [train main loss -2.198051], [lr 0.005543] [batchtime 0.589]
[epoch 78], [iter 36 / 176], [train main loss -2.166931], [lr 0.005543] [batchtime 0.581]
[epoch 78], [iter 37 / 176], [train main loss -2.198412], [lr 0.005543] [batchtime 0.574]
[epoch 78], [iter 38 / 176], [train main loss -2.228439], [lr 0.005543] [batchtime 0.568]
[epoch 78], [iter 39 / 176], [train main loss -2.327492], [lr 0.005543] [batchtime 0.562]
[epoch 78], [iter 40 / 176], [train main loss -2.311290], [lr 0.005543] [batchtime 0.556]
[epoch 78], [iter 41 / 176], [train main loss -2.228100], [lr 0.005543] [batchtime 0.551]
[epoch 78], [iter 42 / 176], [train main loss -2.266923], [lr 0.005543] [batchtime 0.546]
[epoch 78], [iter 43 / 176], [train main loss -2.293774], [lr 0.005543] [batchtime 0.542]
[epoch 78], [iter 44 / 176], [train main loss -2.291997], [lr 0.005543] [batchtime 0.538]
[epoch 78], [iter 45 / 176], [train main loss -2.261583], [lr 0.005543] [batchtime 0.534]
[epoch 78], [iter 46 / 176], [train main loss -2.327574], [lr 0.005543] [batchtime 0.533]
[epoch 78], [iter 47 / 176], [train main loss -2.346608], [lr 0.005543] [batchtime 0.53]
[epoch 78], [iter 48 / 176], [train main loss -2.379666], [lr 0.005543] [batchtime 0.526]
[epoch 78], [iter 49 / 176], [train main loss -2.426324], [lr 0.005543] [batchtime 0.523]
[epoch 78], [iter 50 / 176], [train main loss -2.407770], [lr 0.005543] [batchtime 0.52]
[epoch 78], [iter 51 / 176], [train main loss -2.442717], [lr 0.005543] [batchtime 0.517]
[epoch 78], [iter 52 / 176], [train main loss -2.424932], [lr 0.005543] [batchtime 0.514]
[epoch 78], [iter 53 / 176], [train main loss -2.407102], [lr 0.005543] [batchtime 0.511]
[epoch 78], [iter 54 / 176], [train main loss -2.363597], [lr 0.005543] [batchtime 0.508]
[epoch 78], [iter 55 / 176], [train main loss -2.345909], [lr 0.005543] [batchtime 0.506]
[epoch 78], [iter 56 / 176], [train main loss -2.339279], [lr 0.005543] [batchtime 0.504]
[epoch 78], [iter 57 / 176], [train main loss -2.337614], [lr 0.005543] [batchtime 0.502]
[epoch 78], [iter 58 / 176], [train main loss -2.318390], [lr 0.005543] [batchtime 0.5]
[epoch 78], [iter 59 / 176], [train main loss -2.329423], [lr 0.005543] [batchtime 0.498]
[epoch 78], [iter 60 / 176], [train main loss -2.343144], [lr 0.005543] [batchtime 0.496]
[epoch 78], [iter 61 / 176], [train main loss -2.294253], [lr 0.005543] [batchtime 0.494]
[epoch 78], [iter 62 / 176], [train main loss -2.280623], [lr 0.005543] [batchtime 0.492]
[epoch 78], [iter 63 / 176], [train main loss -2.282883], [lr 0.005543] [batchtime 0.491]
[epoch 78], [iter 64 / 176], [train main loss -2.254061], [lr 0.005543] [batchtime 0.489]
[epoch 78], [iter 65 / 176], [train main loss -2.230863], [lr 0.005543] [batchtime 0.487]
[epoch 78], [iter 66 / 176], [train main loss -2.211265], [lr 0.005543] [batchtime 0.486]
[epoch 78], [iter 67 / 176], [train main loss -2.259260], [lr 0.005543] [batchtime 0.484]
[epoch 78], [iter 68 / 176], [train main loss -2.226401], [lr 0.005543] [batchtime 0.483]
[epoch 78], [iter 69 / 176], [train main loss -2.255966], [lr 0.005543] [batchtime 0.481]
[epoch 78], [iter 70 / 176], [train main loss -2.259134], [lr 0.005543] [batchtime 0.486]
[epoch 78], [iter 71 / 176], [train main loss -2.259641], [lr 0.005543] [batchtime 0.485]
[epoch 78], [iter 72 / 176], [train main loss -2.255697], [lr 0.005543] [batchtime 0.483]
[epoch 78], [iter 73 / 176], [train main loss -2.258975], [lr 0.005543] [batchtime 0.482]
[epoch 78], [iter 74 / 176], [train main loss -2.267859], [lr 0.005543] [batchtime 0.481]
[epoch 78], [iter 75 / 176], [train main loss -2.270594], [lr 0.005543] [batchtime 0.479]
[epoch 78], [iter 76 / 176], [train main loss -2.323744], [lr 0.005543] [batchtime 0.478]
[epoch 78], [iter 77 / 176], [train main loss -2.320260], [lr 0.005543] [batchtime 0.477]
[epoch 78], [iter 78 / 176], [train main loss -2.292864], [lr 0.005543] [batchtime 0.475]
[epoch 78], [iter 79 / 176], [train main loss -2.287481], [lr 0.005543] [batchtime 0.474]
[epoch 78], [iter 80 / 176], [train main loss -2.254544], [lr 0.005543] [batchtime 0.473]
[epoch 78], [iter 81 / 176], [train main loss -2.246264], [lr 0.005543] [batchtime 0.472]
[epoch 78], [iter 82 / 176], [train main loss -2.209886], [lr 0.005543] [batchtime 0.471]
[epoch 78], [iter 83 / 176], [train main loss -2.198290], [lr 0.005543] [batchtime 0.47]
[epoch 78], [iter 84 / 176], [train main loss -2.205824], [lr 0.005543] [batchtime 0.469]
[epoch 78], [iter 85 / 176], [train main loss -2.227100], [lr 0.005543] [batchtime 0.468]
[epoch 78], [iter 86 / 176], [train main loss -2.207130], [lr 0.005543] [batchtime 0.467]
[epoch 78], [iter 87 / 176], [train main loss -2.208602], [lr 0.005543] [batchtime 0.466]
[epoch 78], [iter 88 / 176], [train main loss -2.198225], [lr 0.005543] [batchtime 0.465]
[epoch 78], [iter 89 / 176], [train main loss -2.215914], [lr 0.005543] [batchtime 0.464]
[epoch 78], [iter 90 / 176], [train main loss -2.226358], [lr 0.005543] [batchtime 0.464]
[epoch 78], [iter 91 / 176], [train main loss -2.215910], [lr 0.005543] [batchtime 0.463]
[epoch 78], [iter 92 / 176], [train main loss -2.232353], [lr 0.005543] [batchtime 0.462]
[epoch 78], [iter 93 / 176], [train main loss -2.219730], [lr 0.005543] [batchtime 0.461]
[epoch 78], [iter 94 / 176], [train main loss -2.194181], [lr 0.005543] [batchtime 0.461]
[epoch 78], [iter 95 / 176], [train main loss -2.177434], [lr 0.005543] [batchtime 0.461]
[epoch 78], [iter 96 / 176], [train main loss -2.174108], [lr 0.005543] [batchtime 0.461]
[epoch 78], [iter 97 / 176], [train main loss -2.183094], [lr 0.005543] [batchtime 0.46]
[epoch 78], [iter 98 / 176], [train main loss -2.176959], [lr 0.005543] [batchtime 0.459]
[epoch 78], [iter 99 / 176], [train main loss -2.159374], [lr 0.005543] [batchtime 0.458]
[epoch 78], [iter 100 / 176], [train main loss -2.175575], [lr 0.005543] [batchtime 0.458]
[epoch 78], [iter 101 / 176], [train main loss -2.165815], [lr 0.005543] [batchtime 0.457]
[epoch 78], [iter 102 / 176], [train main loss -2.174761], [lr 0.005543] [batchtime 0.456]
[epoch 78], [iter 103 / 176], [train main loss -2.156591], [lr 0.005543] [batchtime 0.455]
[epoch 78], [iter 104 / 176], [train main loss -2.163492], [lr 0.005543] [batchtime 0.455]
[epoch 78], [iter 105 / 176], [train main loss -2.159243], [lr 0.005543] [batchtime 0.454]
[epoch 78], [iter 106 / 176], [train main loss -2.121427], [lr 0.005543] [batchtime 0.454]
[epoch 78], [iter 107 / 176], [train main loss -2.112721], [lr 0.005543] [batchtime 0.453]
[epoch 78], [iter 108 / 176], [train main loss -2.095492], [lr 0.005543] [batchtime 0.452]
[epoch 78], [iter 109 / 176], [train main loss -2.071305], [lr 0.005543] [batchtime 0.452]
[epoch 78], [iter 110 / 176], [train main loss -2.060666], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 111 / 176], [train main loss -2.100960], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 112 / 176], [train main loss -2.112076], [lr 0.005543] [batchtime 0.45]
[epoch 78], [iter 113 / 176], [train main loss -2.098074], [lr 0.005543] [batchtime 0.449]
[epoch 78], [iter 114 / 176], [train main loss -2.099694], [lr 0.005543] [batchtime 0.452]
[epoch 78], [iter 115 / 176], [train main loss -2.113276], [lr 0.005543] [batchtime 0.452]
[epoch 78], [iter 116 / 176], [train main loss -2.110274], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 117 / 176], [train main loss -2.116738], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 118 / 176], [train main loss -2.101417], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 119 / 176], [train main loss -2.115685], [lr 0.005543] [batchtime 0.453]
[epoch 78], [iter 120 / 176], [train main loss -2.107480], [lr 0.005543] [batchtime 0.453]
[epoch 78], [iter 121 / 176], [train main loss -2.098565], [lr 0.005543] [batchtime 0.452]
[epoch 78], [iter 122 / 176], [train main loss -2.090662], [lr 0.005543] [batchtime 0.452]
[epoch 78], [iter 123 / 176], [train main loss -2.079060], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 124 / 176], [train main loss -2.078440], [lr 0.005543] [batchtime 0.451]
[epoch 78], [iter 125 / 176], [train main loss -2.090640], [lr 0.005543] [batchtime 0.45]
[epoch 78], [iter 126 / 176], [train main loss -2.092816], [lr 0.005543] [batchtime 0.449]
[epoch 78], [iter 127 / 176], [train main loss -2.112326], [lr 0.005543] [batchtime 0.449]
[epoch 78], [iter 128 / 176], [train main loss -2.111612], [lr 0.005543] [batchtime 0.448]
[epoch 78], [iter 129 / 176], [train main loss -2.105942], [lr 0.005543] [batchtime 0.448]
[epoch 78], [iter 130 / 176], [train main loss -2.117750], [lr 0.005543] [batchtime 0.448]
[epoch 78], [iter 131 / 176], [train main loss -2.149806], [lr 0.005543] [batchtime 0.447]
[epoch 78], [iter 132 / 176], [train main loss -2.139680], [lr 0.005543] [batchtime 0.447]
[epoch 78], [iter 133 / 176], [train main loss -2.126068], [lr 0.005543] [batchtime 0.447]
[epoch 78], [iter 134 / 176], [train main loss -2.118720], [lr 0.005543] [batchtime 0.446]
[epoch 78], [iter 135 / 176], [train main loss -2.112736], [lr 0.005543] [batchtime 0.446]
[epoch 78], [iter 136 / 176], [train main loss -2.111680], [lr 0.005543] [batchtime 0.446]
[epoch 78], [iter 137 / 176], [train main loss -2.104424], [lr 0.005543] [batchtime 0.445]
[epoch 78], [iter 138 / 176], [train main loss -2.112674], [lr 0.005543] [batchtime 0.445]
[epoch 78], [iter 139 / 176], [train main loss -2.113463], [lr 0.005543] [batchtime 0.444]
[epoch 78], [iter 140 / 176], [train main loss -2.094487], [lr 0.005543] [batchtime 0.444]
[epoch 78], [iter 141 / 176], [train main loss -2.089501], [lr 0.005543] [batchtime 0.448]
[epoch 78], [iter 142 / 176], [train main loss -2.094228], [lr 0.005543] [batchtime 0.448]
[epoch 78], [iter 143 / 176], [train main loss -2.098562], [lr 0.005543] [batchtime 0.447]
[epoch 78], [iter 144 / 176], [train main loss -2.086415], [lr 0.005543] [batchtime 0.447]
[epoch 78], [iter 145 / 176], [train main loss -2.091167], [lr 0.005543] [batchtime 0.447]
[epoch 78], [iter 146 / 176], [train main loss -2.095320], [lr 0.005543] [batchtime 0.446]
[epoch 78], [iter 147 / 176], [train main loss -2.091658], [lr 0.005543] [batchtime 0.446]
[epoch 78], [iter 148 / 176], [train main loss -2.128621], [lr 0.005543] [batchtime 0.445]
[epoch 78], [iter 149 / 176], [train main loss -2.116435], [lr 0.005543] [batchtime 0.445]
[epoch 78], [iter 150 / 176], [train main loss -2.118682], [lr 0.005543] [batchtime 0.445]
[epoch 78], [iter 151 / 176], [train main loss -2.121005], [lr 0.005543] [batchtime 0.444]
[epoch 78], [iter 152 / 176], [train main loss -2.139409], [lr 0.005543] [batchtime 0.444]
[epoch 78], [iter 153 / 176], [train main loss -2.156668], [lr 0.005543] [batchtime 0.444]
[epoch 78], [iter 154 / 176], [train main loss -2.151113], [lr 0.005543] [batchtime 0.443]
[epoch 78], [iter 155 / 176], [train main loss -2.162310], [lr 0.005543] [batchtime 0.443]
[epoch 78], [iter 156 / 176], [train main loss -2.150990], [lr 0.005543] [batchtime 0.443]
[epoch 78], [iter 157 / 176], [train main loss -2.146554], [lr 0.005543] [batchtime 0.442]
[epoch 78], [iter 158 / 176], [train main loss -2.149165], [lr 0.005543] [batchtime 0.442]
[epoch 78], [iter 159 / 176], [train main loss -2.154117], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 160 / 176], [train main loss -2.151429], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 161 / 176], [train main loss -2.165626], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 162 / 176], [train main loss -2.150501], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 163 / 176], [train main loss -2.141128], [lr 0.005543] [batchtime 0.44]
[epoch 78], [iter 164 / 176], [train main loss -2.136485], [lr 0.005543] [batchtime 0.44]
[epoch 78], [iter 165 / 176], [train main loss -2.154800], [lr 0.005543] [batchtime 0.44]
[epoch 78], [iter 166 / 176], [train main loss -2.153090], [lr 0.005543] [batchtime 0.44]
[epoch 78], [iter 167 / 176], [train main loss -2.150978], [lr 0.005543] [batchtime 0.442]
[epoch 78], [iter 168 / 176], [train main loss -2.164143], [lr 0.005543] [batchtime 0.442]
[epoch 78], [iter 169 / 176], [train main loss -2.173987], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 170 / 176], [train main loss -2.157044], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 171 / 176], [train main loss -2.152069], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 172 / 176], [train main loss -2.146099], [lr 0.005543] [batchtime 0.441]
[epoch 78], [iter 173 / 176], [train main loss -2.129716], [lr 0.005543] [batchtime 0.44]
[epoch 78], [iter 174 / 176], [train main loss -2.127549], [lr 0.005543] [batchtime 0.44]
[epoch 78], [iter 175 / 176], [train main loss -2.125615], [lr 0.005543] [batchtime 0.439]
[epoch 78], [iter 176 / 176], [train main loss -2.122850], [lr 0.005543] [batchtime 0.439]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              92.45  34.47    0.05  0.03         0.95      0.97
   1  sidewalk          63.25   5.63    0.17  0.41         0.85      0.71
   2  building          84.66  24.67    0.08  0.10         0.93      0.91
   3  wall              15.60   0.12    3.84  1.58         0.21      0.39
   4  fence             17.89   0.25    4.02  0.57         0.20      0.64
   5  pole              35.44   0.52    1.18  0.64         0.46      0.61
   6  traffic light     10.79   0.02    7.68  0.59         0.12      0.63
   7  traffic sign      14.12   0.08    5.85  0.23         0.15      0.81
   8  vegetation        81.56  11.67    0.06  0.17         0.94      0.86
   9  terrain           35.98   0.31    1.35  0.43         0.43      0.70
  10  sky               92.03   3.77    0.03  0.06         0.97      0.94
  11  person            48.00   0.95    0.62  0.47         0.62      0.68
  12  rider              4.04   0.00   22.30  1.42         0.04      0.41
  13  car               84.19   6.67    0.06  0.13         0.94      0.89
  14  truck              0.40   0.00  249.68  0.15         0.00      0.87
  15  bus               13.92   0.03    1.77  4.41         0.36      0.18
  16  train             20.02   0.04    3.55  0.45         0.22      0.69
  17  motorcycle         1.03   0.00   95.24  0.79         0.01      0.56
  18  bicycle           33.59   0.23    0.66  1.32         0.60      0.43
Mean: 39.42
-----------------------------------------------------------------------------------------------------------
this : [epoch 78], [val loss 0.34717], [acc 0.89446], [acc_cls 0.47366], [mean_iu 0.39419], [fwavacc 0.81893]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 79], [iter 1 / 176], [train main loss -0.952881], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 2 / 176], [train main loss -3.058545], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 3 / 176], [train main loss -3.125869], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 4 / 176], [train main loss -2.812722], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 5 / 176], [train main loss -2.595878], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 6 / 176], [train main loss -2.416776], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 7 / 176], [train main loss -2.840154], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 8 / 176], [train main loss -2.842126], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 9 / 176], [train main loss -2.634637], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 10 / 176], [train main loss -2.779169], [lr 0.005486] [batchtime 0]
[epoch 79], [iter 11 / 176], [train main loss -2.779370], [lr 0.005486] [batchtime 0.366]
[epoch 79], [iter 12 / 176], [train main loss -2.744366], [lr 0.005486] [batchtime 0.382]
[epoch 79], [iter 13 / 176], [train main loss -2.712807], [lr 0.005486] [batchtime 0.39]
[epoch 79], [iter 14 / 176], [train main loss -2.525444], [lr 0.005486] [batchtime 0.395]
[epoch 79], [iter 15 / 176], [train main loss -2.457653], [lr 0.005486] [batchtime 0.395]
[epoch 79], [iter 16 / 176], [train main loss -2.399140], [lr 0.005486] [batchtime 0.395]
[epoch 79], [iter 17 / 176], [train main loss -2.394013], [lr 0.005486] [batchtime 0.395]
[epoch 79], [iter 18 / 176], [train main loss -2.420742], [lr 0.005486] [batchtime 0.396]
[epoch 79], [iter 19 / 176], [train main loss -2.247009], [lr 0.005486] [batchtime 0.397]
[epoch 79], [iter 20 / 176], [train main loss -2.095180], [lr 0.005486] [batchtime 0.397]
[epoch 79], [iter 21 / 176], [train main loss -2.089662], [lr 0.005486] [batchtime 0.397]
[epoch 79], [iter 22 / 176], [train main loss -2.067239], [lr 0.005486] [batchtime 0.397]
[epoch 79], [iter 23 / 176], [train main loss -2.127273], [lr 0.005486] [batchtime 0.397]
[epoch 79], [iter 24 / 176], [train main loss -2.160856], [lr 0.005486] [batchtime 0.396]
[epoch 79], [iter 25 / 176], [train main loss -2.104040], [lr 0.005486] [batchtime 0.396]
[epoch 79], [iter 26 / 176], [train main loss -2.076984], [lr 0.005486] [batchtime 0.396]
[epoch 79], [iter 27 / 176], [train main loss -2.125908], [lr 0.005486] [batchtime 0.411]
[epoch 79], [iter 28 / 176], [train main loss -2.232806], [lr 0.005486] [batchtime 0.419]
[epoch 79], [iter 29 / 176], [train main loss -2.215031], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 30 / 176], [train main loss -2.153397], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 31 / 176], [train main loss -2.188245], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 32 / 176], [train main loss -2.234006], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 33 / 176], [train main loss -2.267781], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 34 / 176], [train main loss -2.243111], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 35 / 176], [train main loss -2.241606], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 36 / 176], [train main loss -2.222470], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 37 / 176], [train main loss -2.175094], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 38 / 176], [train main loss -2.099206], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 39 / 176], [train main loss -2.010304], [lr 0.005486] [batchtime 0.411]
[epoch 79], [iter 40 / 176], [train main loss -2.061522], [lr 0.005486] [batchtime 0.411]
[epoch 79], [iter 41 / 176], [train main loss -2.054421], [lr 0.005486] [batchtime 0.411]
[epoch 79], [iter 42 / 176], [train main loss -2.065326], [lr 0.005486] [batchtime 0.41]
[epoch 79], [iter 43 / 176], [train main loss -2.047409], [lr 0.005486] [batchtime 0.41]
[epoch 79], [iter 44 / 176], [train main loss -2.040558], [lr 0.005486] [batchtime 0.41]
[epoch 79], [iter 45 / 176], [train main loss -1.981516], [lr 0.005486] [batchtime 0.41]
[epoch 79], [iter 46 / 176], [train main loss -1.998052], [lr 0.005486] [batchtime 0.409]
[epoch 79], [iter 47 / 176], [train main loss -2.032517], [lr 0.005486] [batchtime 0.409]
[epoch 79], [iter 48 / 176], [train main loss -2.075146], [lr 0.005486] [batchtime 0.409]
[epoch 79], [iter 49 / 176], [train main loss -2.082978], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 50 / 176], [train main loss -2.074128], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 51 / 176], [train main loss -2.020022], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 52 / 176], [train main loss -2.055203], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 53 / 176], [train main loss -2.066409], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 54 / 176], [train main loss -2.104375], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 55 / 176], [train main loss -2.125656], [lr 0.005486] [batchtime 0.408]
[epoch 79], [iter 56 / 176], [train main loss -2.153608], [lr 0.005486] [batchtime 0.407]
[epoch 79], [iter 57 / 176], [train main loss -2.176776], [lr 0.005486] [batchtime 0.407]
[epoch 79], [iter 58 / 176], [train main loss -2.180457], [lr 0.005486] [batchtime 0.407]
[epoch 79], [iter 59 / 176], [train main loss -2.177174], [lr 0.005486] [batchtime 0.407]
[epoch 79], [iter 60 / 176], [train main loss -2.160856], [lr 0.005486] [batchtime 0.407]
[epoch 79], [iter 61 / 176], [train main loss -2.132925], [lr 0.005486] [batchtime 0.406]
[epoch 79], [iter 62 / 176], [train main loss -2.119793], [lr 0.005486] [batchtime 0.406]
[epoch 79], [iter 63 / 176], [train main loss -2.187821], [lr 0.005486] [batchtime 0.406]
[epoch 79], [iter 64 / 176], [train main loss -2.134071], [lr 0.005486] [batchtime 0.406]
[epoch 79], [iter 65 / 176], [train main loss -2.112628], [lr 0.005486] [batchtime 0.406]
[epoch 79], [iter 66 / 176], [train main loss -2.149221], [lr 0.005486] [batchtime 0.406]
[epoch 79], [iter 67 / 176], [train main loss -2.149829], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 68 / 176], [train main loss -2.148785], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 69 / 176], [train main loss -2.119286], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 70 / 176], [train main loss -2.090008], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 71 / 176], [train main loss -2.081705], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 72 / 176], [train main loss -2.065199], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 73 / 176], [train main loss -2.091942], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 74 / 176], [train main loss -2.089985], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 75 / 176], [train main loss -2.106860], [lr 0.005486] [batchtime 0.405]
[epoch 79], [iter 76 / 176], [train main loss -2.099164], [lr 0.005486] [batchtime 0.42]
[epoch 79], [iter 77 / 176], [train main loss -2.078940], [lr 0.005486] [batchtime 0.424]
[epoch 79], [iter 78 / 176], [train main loss -2.063715], [lr 0.005486] [batchtime 0.423]
[epoch 79], [iter 79 / 176], [train main loss -2.039763], [lr 0.005486] [batchtime 0.423]
[epoch 79], [iter 80 / 176], [train main loss -2.039245], [lr 0.005486] [batchtime 0.423]
[epoch 79], [iter 81 / 176], [train main loss -2.020352], [lr 0.005486] [batchtime 0.422]
[epoch 79], [iter 82 / 176], [train main loss -2.024345], [lr 0.005486] [batchtime 0.422]
[epoch 79], [iter 83 / 176], [train main loss -2.020679], [lr 0.005486] [batchtime 0.422]
[epoch 79], [iter 84 / 176], [train main loss -2.019587], [lr 0.005486] [batchtime 0.421]
[epoch 79], [iter 85 / 176], [train main loss -2.018460], [lr 0.005486] [batchtime 0.421]
[epoch 79], [iter 86 / 176], [train main loss -2.026101], [lr 0.005486] [batchtime 0.42]
[epoch 79], [iter 87 / 176], [train main loss -2.032041], [lr 0.005486] [batchtime 0.42]
[epoch 79], [iter 88 / 176], [train main loss -2.011686], [lr 0.005486] [batchtime 0.419]
[epoch 79], [iter 89 / 176], [train main loss -1.984282], [lr 0.005486] [batchtime 0.419]
[epoch 79], [iter 90 / 176], [train main loss -1.990007], [lr 0.005486] [batchtime 0.419]
[epoch 79], [iter 91 / 176], [train main loss -1.990869], [lr 0.005486] [batchtime 0.419]
[epoch 79], [iter 92 / 176], [train main loss -1.975859], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 93 / 176], [train main loss -1.992264], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 94 / 176], [train main loss -1.985465], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 95 / 176], [train main loss -1.998200], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 96 / 176], [train main loss -1.990220], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 97 / 176], [train main loss -1.983533], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 98 / 176], [train main loss -2.018452], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 99 / 176], [train main loss -2.021347], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 100 / 176], [train main loss -2.035858], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 101 / 176], [train main loss -1.997362], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 102 / 176], [train main loss -2.007802], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 103 / 176], [train main loss -2.011290], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 104 / 176], [train main loss -2.006944], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 105 / 176], [train main loss -2.016629], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 106 / 176], [train main loss -2.017181], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 107 / 176], [train main loss -1.997674], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 108 / 176], [train main loss -1.984579], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 109 / 176], [train main loss -1.981920], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 110 / 176], [train main loss -1.973052], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 111 / 176], [train main loss -1.979152], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 112 / 176], [train main loss -1.972959], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 113 / 176], [train main loss -1.976066], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 114 / 176], [train main loss -1.960471], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 115 / 176], [train main loss -1.958886], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 116 / 176], [train main loss -1.950205], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 117 / 176], [train main loss -1.939839], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 118 / 176], [train main loss -1.920565], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 119 / 176], [train main loss -1.924151], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 120 / 176], [train main loss -1.932663], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 121 / 176], [train main loss -1.946991], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 122 / 176], [train main loss -1.958799], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 123 / 176], [train main loss -1.924932], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 124 / 176], [train main loss -1.929929], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 125 / 176], [train main loss -1.932652], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 126 / 176], [train main loss -1.965894], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 127 / 176], [train main loss -1.953759], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 128 / 176], [train main loss -1.936740], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 129 / 176], [train main loss -1.937090], [lr 0.005486] [batchtime 0.418]
[epoch 79], [iter 130 / 176], [train main loss -1.933147], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 131 / 176], [train main loss -1.922356], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 132 / 176], [train main loss -1.937861], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 133 / 176], [train main loss -1.929178], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 134 / 176], [train main loss -1.919420], [lr 0.005486] [batchtime 0.417]
[epoch 79], [iter 135 / 176], [train main loss -1.914260], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 136 / 176], [train main loss -1.920619], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 137 / 176], [train main loss -1.920227], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 138 / 176], [train main loss -1.916253], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 139 / 176], [train main loss -1.920385], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 140 / 176], [train main loss -1.916677], [lr 0.005486] [batchtime 0.416]
[epoch 79], [iter 141 / 176], [train main loss -1.920310], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 142 / 176], [train main loss -1.937573], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 143 / 176], [train main loss -1.927194], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 144 / 176], [train main loss -1.934052], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 145 / 176], [train main loss -1.944630], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 146 / 176], [train main loss -1.942979], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 147 / 176], [train main loss -1.946520], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 148 / 176], [train main loss -1.944021], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 149 / 176], [train main loss -1.943877], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 150 / 176], [train main loss -1.917920], [lr 0.005486] [batchtime 0.415]
[epoch 79], [iter 151 / 176], [train main loss -1.918112], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 152 / 176], [train main loss -1.903808], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 153 / 176], [train main loss -1.917604], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 154 / 176], [train main loss -1.914829], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 155 / 176], [train main loss -1.914543], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 156 / 176], [train main loss -1.922156], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 157 / 176], [train main loss -1.920322], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 158 / 176], [train main loss -1.906482], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 159 / 176], [train main loss -1.899639], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 160 / 176], [train main loss -1.905599], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 161 / 176], [train main loss -1.901474], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 162 / 176], [train main loss -1.901004], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 163 / 176], [train main loss -1.906008], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 164 / 176], [train main loss -1.910404], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 165 / 176], [train main loss -1.902916], [lr 0.005486] [batchtime 0.413]
[epoch 79], [iter 166 / 176], [train main loss -1.906614], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 167 / 176], [train main loss -1.914537], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 168 / 176], [train main loss -1.906900], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 169 / 176], [train main loss -1.902507], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 170 / 176], [train main loss -1.910444], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 171 / 176], [train main loss -1.922024], [lr 0.005486] [batchtime 0.412]
[epoch 79], [iter 172 / 176], [train main loss -1.924792], [lr 0.005486] [batchtime 0.414]
[epoch 79], [iter 173 / 176], [train main loss -1.942756], [lr 0.005486] [batchtime 0.424]
[epoch 79], [iter 174 / 176], [train main loss -1.943514], [lr 0.005486] [batchtime 0.423]
[epoch 79], [iter 175 / 176], [train main loss -1.927536], [lr 0.005486] [batchtime 0.423]
[epoch 79], [iter 176 / 176], [train main loss -1.936753], [lr 0.005486] [batchtime 0.423]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.97  35.07    0.04  0.03         0.96      0.97
   1  sidewalk          67.03   5.56    0.18  0.31         0.84      0.76
   2  building          85.00  24.74    0.07  0.10         0.93      0.91
   3  wall              14.78   0.12    4.02  1.74         0.20      0.36
   4  fence             21.66   0.33    2.89  0.73         0.26      0.58
   5  pole              36.08   0.52    1.18  0.59         0.46      0.63
   6  traffic light     10.38   0.02    7.96  0.67         0.11      0.60
   7  traffic sign      15.02   0.09    5.37  0.29         0.16      0.78
   8  vegetation        81.55  11.61    0.06  0.16         0.94      0.86
   9  terrain           37.31   0.33    1.23  0.45         0.45      0.69
  10  sky               93.19   3.74    0.03  0.04         0.97      0.96
  11  person            44.38   0.82    0.86  0.39         0.54      0.72
  12  rider              6.80   0.01   12.04  1.66         0.08      0.38
  13  car               84.43   6.68    0.06  0.12         0.94      0.89
  14  truck              0.76   0.00  130.02  0.36         0.01      0.73
  15  bus               13.88   0.03    2.13  4.07         0.32      0.20
  16  train             31.45   0.06    1.88  0.30         0.35      0.77
  17  motorcycle         1.18   0.00   82.61  1.48         0.01      0.40
  18  bicycle           28.20   0.27    0.46  2.08         0.68      0.32
Mean: 40.37
-----------------------------------------------------------------------------------------------------------
this : [epoch 79], [val loss 0.33609], [acc 0.89994], [acc_cls 0.48448], [mean_iu 0.40371], [fwavacc 0.82858]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 80], [iter 1 / 176], [train main loss 0.634187], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 2 / 176], [train main loss -1.360623], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 3 / 176], [train main loss -1.462801], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 4 / 176], [train main loss -1.565097], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 5 / 176], [train main loss -1.880541], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 6 / 176], [train main loss -1.578342], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 7 / 176], [train main loss -1.638005], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 8 / 176], [train main loss -1.922482], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 9 / 176], [train main loss -1.807157], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 10 / 176], [train main loss -1.684974], [lr 0.005429] [batchtime 0]
[epoch 80], [iter 11 / 176], [train main loss -1.844553], [lr 0.005429] [batchtime 0.379]
[epoch 80], [iter 12 / 176], [train main loss -1.836014], [lr 0.005429] [batchtime 0.39]
[epoch 80], [iter 13 / 176], [train main loss -1.767914], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 14 / 176], [train main loss -1.923487], [lr 0.005429] [batchtime 0.399]
[epoch 80], [iter 15 / 176], [train main loss -1.832374], [lr 0.005429] [batchtime 0.398]
[epoch 80], [iter 16 / 176], [train main loss -1.684705], [lr 0.005429] [batchtime 0.397]
[epoch 80], [iter 17 / 176], [train main loss -1.802413], [lr 0.005429] [batchtime 0.397]
[epoch 80], [iter 18 / 176], [train main loss -1.760945], [lr 0.005429] [batchtime 0.396]
[epoch 80], [iter 19 / 176], [train main loss -1.582251], [lr 0.005429] [batchtime 0.395]
[epoch 80], [iter 20 / 176], [train main loss -1.619007], [lr 0.005429] [batchtime 0.396]
[epoch 80], [iter 21 / 176], [train main loss -1.518250], [lr 0.005429] [batchtime 0.395]
[epoch 80], [iter 22 / 176], [train main loss -1.527526], [lr 0.005429] [batchtime 0.395]
[epoch 80], [iter 23 / 176], [train main loss -1.447508], [lr 0.005429] [batchtime 0.395]
[epoch 80], [iter 24 / 176], [train main loss -1.369142], [lr 0.005429] [batchtime 0.396]
[epoch 80], [iter 25 / 176], [train main loss -1.356781], [lr 0.005429] [batchtime 0.4]
[epoch 80], [iter 26 / 176], [train main loss -1.365973], [lr 0.005429] [batchtime 0.413]
[epoch 80], [iter 27 / 176], [train main loss -1.349981], [lr 0.005429] [batchtime 0.411]
[epoch 80], [iter 28 / 176], [train main loss -1.398780], [lr 0.005429] [batchtime 0.41]
[epoch 80], [iter 29 / 176], [train main loss -1.366022], [lr 0.005429] [batchtime 0.409]
[epoch 80], [iter 30 / 176], [train main loss -1.328842], [lr 0.005429] [batchtime 0.409]
[epoch 80], [iter 31 / 176], [train main loss -1.318543], [lr 0.005429] [batchtime 0.408]
[epoch 80], [iter 32 / 176], [train main loss -1.396885], [lr 0.005429] [batchtime 0.408]
[epoch 80], [iter 33 / 176], [train main loss -1.363646], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 34 / 176], [train main loss -1.366945], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 35 / 176], [train main loss -1.436818], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 36 / 176], [train main loss -1.423509], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 37 / 176], [train main loss -1.416369], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 38 / 176], [train main loss -1.394178], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 39 / 176], [train main loss -1.428533], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 40 / 176], [train main loss -1.410146], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 41 / 176], [train main loss -1.416078], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 42 / 176], [train main loss -1.430215], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 43 / 176], [train main loss -1.414919], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 44 / 176], [train main loss -1.443953], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 45 / 176], [train main loss -1.506718], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 46 / 176], [train main loss -1.538216], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 47 / 176], [train main loss -1.599903], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 48 / 176], [train main loss -1.588528], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 49 / 176], [train main loss -1.556019], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 50 / 176], [train main loss -1.570679], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 51 / 176], [train main loss -1.527646], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 52 / 176], [train main loss -1.535929], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 53 / 176], [train main loss -1.598174], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 54 / 176], [train main loss -1.607008], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 55 / 176], [train main loss -1.618856], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 56 / 176], [train main loss -1.578913], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 57 / 176], [train main loss -1.631735], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 58 / 176], [train main loss -1.628861], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 59 / 176], [train main loss -1.692277], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 60 / 176], [train main loss -1.708008], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 61 / 176], [train main loss -1.706820], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 62 / 176], [train main loss -1.732073], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 63 / 176], [train main loss -1.722688], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 64 / 176], [train main loss -1.702070], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 65 / 176], [train main loss -1.764500], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 66 / 176], [train main loss -1.753733], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 67 / 176], [train main loss -1.764264], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 68 / 176], [train main loss -1.784132], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 69 / 176], [train main loss -1.824187], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 70 / 176], [train main loss -1.826147], [lr 0.005429] [batchtime 0.401]
[epoch 80], [iter 71 / 176], [train main loss -1.837062], [lr 0.005429] [batchtime 0.401]
[epoch 80], [iter 72 / 176], [train main loss -1.818367], [lr 0.005429] [batchtime 0.401]
[epoch 80], [iter 73 / 176], [train main loss -1.802689], [lr 0.005429] [batchtime 0.401]
[epoch 80], [iter 74 / 176], [train main loss -1.809836], [lr 0.005429] [batchtime 0.401]
[epoch 80], [iter 75 / 176], [train main loss -1.822725], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 76 / 176], [train main loss -1.827368], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 77 / 176], [train main loss -1.853678], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 78 / 176], [train main loss -1.864083], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 79 / 176], [train main loss -1.843278], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 80 / 176], [train main loss -1.827059], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 81 / 176], [train main loss -1.811329], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 82 / 176], [train main loss -1.841004], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 83 / 176], [train main loss -1.832892], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 84 / 176], [train main loss -1.791844], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 85 / 176], [train main loss -1.738085], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 86 / 176], [train main loss -1.754258], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 87 / 176], [train main loss -1.735850], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 88 / 176], [train main loss -1.734740], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 89 / 176], [train main loss -1.728709], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 90 / 176], [train main loss -1.726377], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 91 / 176], [train main loss -1.751075], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 92 / 176], [train main loss -1.777123], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 93 / 176], [train main loss -1.784465], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 94 / 176], [train main loss -1.768709], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 95 / 176], [train main loss -1.769671], [lr 0.005429] [batchtime 0.403]
[epoch 80], [iter 96 / 176], [train main loss -1.803738], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 97 / 176], [train main loss -1.807354], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 98 / 176], [train main loss -1.855957], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 99 / 176], [train main loss -1.849236], [lr 0.005429] [batchtime 0.402]
[epoch 80], [iter 100 / 176], [train main loss -1.858812], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 101 / 176], [train main loss -1.864813], [lr 0.005429] [batchtime 0.408]
[epoch 80], [iter 102 / 176], [train main loss -1.843989], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 103 / 176], [train main loss -1.852587], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 104 / 176], [train main loss -1.840041], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 105 / 176], [train main loss -1.843367], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 106 / 176], [train main loss -1.849208], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 107 / 176], [train main loss -1.855769], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 108 / 176], [train main loss -1.863086], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 109 / 176], [train main loss -1.864398], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 110 / 176], [train main loss -1.843275], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 111 / 176], [train main loss -1.852942], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 112 / 176], [train main loss -1.848265], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 113 / 176], [train main loss -1.860448], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 114 / 176], [train main loss -1.875825], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 115 / 176], [train main loss -1.871408], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 116 / 176], [train main loss -1.844755], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 117 / 176], [train main loss -1.846332], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 118 / 176], [train main loss -1.843512], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 119 / 176], [train main loss -1.851841], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 120 / 176], [train main loss -1.846385], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 121 / 176], [train main loss -1.835696], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 122 / 176], [train main loss -1.816996], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 123 / 176], [train main loss -1.827949], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 124 / 176], [train main loss -1.841703], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 125 / 176], [train main loss -1.818601], [lr 0.005429] [batchtime 0.407]
[epoch 80], [iter 126 / 176], [train main loss -1.830470], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 127 / 176], [train main loss -1.847117], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 128 / 176], [train main loss -1.845192], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 129 / 176], [train main loss -1.851274], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 130 / 176], [train main loss -1.856590], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 131 / 176], [train main loss -1.858641], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 132 / 176], [train main loss -1.838295], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 133 / 176], [train main loss -1.837673], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 134 / 176], [train main loss -1.859842], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 135 / 176], [train main loss -1.862149], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 136 / 176], [train main loss -1.859267], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 137 / 176], [train main loss -1.858092], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 138 / 176], [train main loss -1.868068], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 139 / 176], [train main loss -1.871699], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 140 / 176], [train main loss -1.869792], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 141 / 176], [train main loss -1.864084], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 142 / 176], [train main loss -1.860632], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 143 / 176], [train main loss -1.844928], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 144 / 176], [train main loss -1.841114], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 145 / 176], [train main loss -1.847343], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 146 / 176], [train main loss -1.838237], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 147 / 176], [train main loss -1.842547], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 148 / 176], [train main loss -1.861820], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 149 / 176], [train main loss -1.861974], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 150 / 176], [train main loss -1.880374], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 151 / 176], [train main loss -1.879266], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 152 / 176], [train main loss -1.876406], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 153 / 176], [train main loss -1.874540], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 154 / 176], [train main loss -1.868542], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 155 / 176], [train main loss -1.858900], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 156 / 176], [train main loss -1.852873], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 157 / 176], [train main loss -1.862115], [lr 0.005429] [batchtime 0.406]
[epoch 80], [iter 158 / 176], [train main loss -1.864050], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 159 / 176], [train main loss -1.863451], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 160 / 176], [train main loss -1.843275], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 161 / 176], [train main loss -1.845484], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 162 / 176], [train main loss -1.856570], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 163 / 176], [train main loss -1.855468], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 164 / 176], [train main loss -1.854308], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 165 / 176], [train main loss -1.866231], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 166 / 176], [train main loss -1.864118], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 167 / 176], [train main loss -1.849967], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 168 / 176], [train main loss -1.848434], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 169 / 176], [train main loss -1.867169], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 170 / 176], [train main loss -1.877403], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 171 / 176], [train main loss -1.888721], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 172 / 176], [train main loss -1.892603], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 173 / 176], [train main loss -1.881250], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 174 / 176], [train main loss -1.870717], [lr 0.005429] [batchtime 0.404]
[epoch 80], [iter 175 / 176], [train main loss -1.863186], [lr 0.005429] [batchtime 0.405]
[epoch 80], [iter 176 / 176], [train main loss -1.861896], [lr 0.005429] [batchtime 0.405]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              92.04  34.26   0.06  0.03         0.94      0.98
   1  sidewalk          62.68   5.69   0.16  0.44         0.86      0.70
   2  building          85.35  24.54   0.08  0.09         0.92      0.92
   3  wall              14.47   0.11   4.18  1.73         0.19      0.37
   4  fence             21.30   0.32   2.98  0.71         0.25      0.58
   5  pole              36.77   0.53   1.13  0.59         0.47      0.63
   6  traffic light      9.91   0.02   8.35  0.74         0.11      0.57
   7  traffic sign      20.53   0.13   3.41  0.46         0.23      0.68
   8  vegetation        81.97  11.73   0.05  0.17         0.95      0.86
   9  terrain           37.90   0.35   1.11  0.53         0.47      0.65
  10  sky               93.38   3.72   0.04  0.03         0.96      0.97
  11  person            50.07   1.04   0.47  0.52         0.68      0.66
  12  rider              3.41   0.00  27.02  1.32         0.04      0.43
  13  car               84.53   6.69   0.06  0.13         0.95      0.89
  14  truck              1.58   0.01  61.84  0.56         0.02      0.64
  15  bus               13.87   0.04   1.11  5.09         0.47      0.16
  16  train             17.43   0.04   3.77  0.96         0.21      0.51
  17  motorcycle         1.05   0.00  93.29  0.64         0.01      0.61
  18  bicycle           34.88   0.25   0.59  1.28         0.63      0.44
Mean: 40.16
-----------------------------------------------------------------------------------------------------------
this : [epoch 80], [val loss 0.34916], [acc 0.89467], [acc_cls 0.49271], [mean_iu 0.40164], [fwavacc 0.82153]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 81], [iter 1 / 176], [train main loss -3.162107], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 2 / 176], [train main loss -2.009904], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 3 / 176], [train main loss -1.543745], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 4 / 176], [train main loss -1.222805], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 5 / 176], [train main loss -0.955183], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 6 / 176], [train main loss -1.287684], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 7 / 176], [train main loss -1.281083], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 8 / 176], [train main loss -1.388145], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 9 / 176], [train main loss -1.353647], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 10 / 176], [train main loss -1.351513], [lr 0.005371] [batchtime 0]
[epoch 81], [iter 11 / 176], [train main loss -1.595613], [lr 0.005371] [batchtime 0.37]
[epoch 81], [iter 12 / 176], [train main loss -1.589974], [lr 0.005371] [batchtime 0.387]
[epoch 81], [iter 13 / 176], [train main loss -1.845675], [lr 0.005371] [batchtime 0.395]
[epoch 81], [iter 14 / 176], [train main loss -1.886496], [lr 0.005371] [batchtime 0.395]
[epoch 81], [iter 15 / 176], [train main loss -1.828753], [lr 0.005371] [batchtime 0.395]
[epoch 81], [iter 16 / 176], [train main loss -1.909583], [lr 0.005371] [batchtime 0.396]
[epoch 81], [iter 17 / 176], [train main loss -1.846837], [lr 0.005371] [batchtime 0.395]
[epoch 81], [iter 18 / 176], [train main loss -1.842078], [lr 0.005371] [batchtime 0.397]
[epoch 81], [iter 19 / 176], [train main loss -1.764231], [lr 0.005371] [batchtime 0.397]
[epoch 81], [iter 20 / 176], [train main loss -1.660599], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 21 / 176], [train main loss -1.702781], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 22 / 176], [train main loss -1.718930], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 23 / 176], [train main loss -1.781951], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 24 / 176], [train main loss -1.779233], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 25 / 176], [train main loss -1.767448], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 26 / 176], [train main loss -1.806421], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 27 / 176], [train main loss -1.781390], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 28 / 176], [train main loss -1.793179], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 29 / 176], [train main loss -1.770689], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 30 / 176], [train main loss -1.760217], [lr 0.005371] [batchtime 0.399]
[epoch 81], [iter 31 / 176], [train main loss -1.770049], [lr 0.005371] [batchtime 0.398]
[epoch 81], [iter 32 / 176], [train main loss -1.753666], [lr 0.005371] [batchtime 0.405]
[epoch 81], [iter 33 / 176], [train main loss -1.881882], [lr 0.005371] [batchtime 0.404]
[epoch 81], [iter 34 / 176], [train main loss -1.964559], [lr 0.005371] [batchtime 0.404]
[epoch 81], [iter 35 / 176], [train main loss -2.006828], [lr 0.005371] [batchtime 0.412]
[epoch 81], [iter 36 / 176], [train main loss -1.994176], [lr 0.005371] [batchtime 0.46]
[epoch 81], [iter 37 / 176], [train main loss -1.966333], [lr 0.005371] [batchtime 0.457]
[epoch 81], [iter 38 / 176], [train main loss -1.933057], [lr 0.005371] [batchtime 0.454]
[epoch 81], [iter 39 / 176], [train main loss -1.892300], [lr 0.005371] [batchtime 0.452]
[epoch 81], [iter 40 / 176], [train main loss -1.918104], [lr 0.005371] [batchtime 0.451]
[epoch 81], [iter 41 / 176], [train main loss -1.942116], [lr 0.005371] [batchtime 0.449]
[epoch 81], [iter 42 / 176], [train main loss -1.962073], [lr 0.005371] [batchtime 0.447]
[epoch 81], [iter 43 / 176], [train main loss -2.009706], [lr 0.005371] [batchtime 0.446]
[epoch 81], [iter 44 / 176], [train main loss -2.048136], [lr 0.005371] [batchtime 0.444]
[epoch 81], [iter 45 / 176], [train main loss -2.004620], [lr 0.005371] [batchtime 0.443]
[epoch 81], [iter 46 / 176], [train main loss -2.005164], [lr 0.005371] [batchtime 0.442]
[epoch 81], [iter 47 / 176], [train main loss -1.995627], [lr 0.005371] [batchtime 0.441]
[epoch 81], [iter 48 / 176], [train main loss -1.994812], [lr 0.005371] [batchtime 0.44]
[epoch 81], [iter 49 / 176], [train main loss -1.974804], [lr 0.005371] [batchtime 0.439]
[epoch 81], [iter 50 / 176], [train main loss -1.922140], [lr 0.005371] [batchtime 0.438]
[epoch 81], [iter 51 / 176], [train main loss -1.938089], [lr 0.005371] [batchtime 0.437]
[epoch 81], [iter 52 / 176], [train main loss -1.907913], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 53 / 176], [train main loss -1.917668], [lr 0.005371] [batchtime 0.435]
[epoch 81], [iter 54 / 176], [train main loss -1.895019], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 55 / 176], [train main loss -1.930364], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 56 / 176], [train main loss -1.886639], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 57 / 176], [train main loss -1.924452], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 58 / 176], [train main loss -1.939832], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 59 / 176], [train main loss -1.925070], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 60 / 176], [train main loss -1.913403], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 61 / 176], [train main loss -1.913831], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 62 / 176], [train main loss -1.950664], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 63 / 176], [train main loss -1.956274], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 64 / 176], [train main loss -1.967155], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 65 / 176], [train main loss -1.968512], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 66 / 176], [train main loss -1.997598], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 67 / 176], [train main loss -2.011810], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 68 / 176], [train main loss -2.006015], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 69 / 176], [train main loss -2.041102], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 70 / 176], [train main loss -2.013274], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 71 / 176], [train main loss -2.005957], [lr 0.005371] [batchtime 0.425]
[epoch 81], [iter 72 / 176], [train main loss -1.965210], [lr 0.005371] [batchtime 0.425]
[epoch 81], [iter 73 / 176], [train main loss -1.973395], [lr 0.005371] [batchtime 0.424]
[epoch 81], [iter 74 / 176], [train main loss -1.975011], [lr 0.005371] [batchtime 0.424]
[epoch 81], [iter 75 / 176], [train main loss -1.994853], [lr 0.005371] [batchtime 0.423]
[epoch 81], [iter 76 / 176], [train main loss -2.004452], [lr 0.005371] [batchtime 0.423]
[epoch 81], [iter 77 / 176], [train main loss -2.010807], [lr 0.005371] [batchtime 0.423]
[epoch 81], [iter 78 / 176], [train main loss -2.031095], [lr 0.005371] [batchtime 0.422]
[epoch 81], [iter 79 / 176], [train main loss -2.032487], [lr 0.005371] [batchtime 0.422]
[epoch 81], [iter 80 / 176], [train main loss -2.015131], [lr 0.005371] [batchtime 0.422]
[epoch 81], [iter 81 / 176], [train main loss -2.009013], [lr 0.005371] [batchtime 0.421]
[epoch 81], [iter 82 / 176], [train main loss -2.001315], [lr 0.005371] [batchtime 0.439]
[epoch 81], [iter 83 / 176], [train main loss -2.045434], [lr 0.005371] [batchtime 0.443]
[epoch 81], [iter 84 / 176], [train main loss -2.020401], [lr 0.005371] [batchtime 0.443]
[epoch 81], [iter 85 / 176], [train main loss -2.053320], [lr 0.005371] [batchtime 0.442]
[epoch 81], [iter 86 / 176], [train main loss -2.059762], [lr 0.005371] [batchtime 0.441]
[epoch 81], [iter 87 / 176], [train main loss -2.059557], [lr 0.005371] [batchtime 0.441]
[epoch 81], [iter 88 / 176], [train main loss -2.092748], [lr 0.005371] [batchtime 0.44]
[epoch 81], [iter 89 / 176], [train main loss -2.087990], [lr 0.005371] [batchtime 0.44]
[epoch 81], [iter 90 / 176], [train main loss -2.069875], [lr 0.005371] [batchtime 0.439]
[epoch 81], [iter 91 / 176], [train main loss -2.082948], [lr 0.005371] [batchtime 0.439]
[epoch 81], [iter 92 / 176], [train main loss -2.058817], [lr 0.005371] [batchtime 0.438]
[epoch 81], [iter 93 / 176], [train main loss -2.034744], [lr 0.005371] [batchtime 0.437]
[epoch 81], [iter 94 / 176], [train main loss -2.007401], [lr 0.005371] [batchtime 0.437]
[epoch 81], [iter 95 / 176], [train main loss -2.022147], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 96 / 176], [train main loss -2.014056], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 97 / 176], [train main loss -2.032322], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 98 / 176], [train main loss -2.049374], [lr 0.005371] [batchtime 0.435]
[epoch 81], [iter 99 / 176], [train main loss -2.054740], [lr 0.005371] [batchtime 0.435]
[epoch 81], [iter 100 / 176], [train main loss -2.055711], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 101 / 176], [train main loss -2.066063], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 102 / 176], [train main loss -2.052175], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 103 / 176], [train main loss -2.023347], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 104 / 176], [train main loss -2.026854], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 105 / 176], [train main loss -2.045236], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 106 / 176], [train main loss -2.042063], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 107 / 176], [train main loss -2.039691], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 108 / 176], [train main loss -2.010817], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 109 / 176], [train main loss -2.012977], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 110 / 176], [train main loss -2.020923], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 111 / 176], [train main loss -2.034466], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 112 / 176], [train main loss -2.036212], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 113 / 176], [train main loss -2.011061], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 114 / 176], [train main loss -1.995321], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 115 / 176], [train main loss -2.007681], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 116 / 176], [train main loss -2.009939], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 117 / 176], [train main loss -1.985678], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 118 / 176], [train main loss -1.983007], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 119 / 176], [train main loss -1.972769], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 120 / 176], [train main loss -1.955301], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 121 / 176], [train main loss -1.938541], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 122 / 176], [train main loss -1.916841], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 123 / 176], [train main loss -1.907861], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 124 / 176], [train main loss -1.900900], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 125 / 176], [train main loss -1.907014], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 126 / 176], [train main loss -1.933214], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 127 / 176], [train main loss -1.927634], [lr 0.005371] [batchtime 0.425]
[epoch 81], [iter 128 / 176], [train main loss -1.926225], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 129 / 176], [train main loss -1.899522], [lr 0.005371] [batchtime 0.437]
[epoch 81], [iter 130 / 176], [train main loss -1.905724], [lr 0.005371] [batchtime 0.437]
[epoch 81], [iter 131 / 176], [train main loss -1.893075], [lr 0.005371] [batchtime 0.437]
[epoch 81], [iter 132 / 176], [train main loss -1.904243], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 133 / 176], [train main loss -1.919158], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 134 / 176], [train main loss -1.913132], [lr 0.005371] [batchtime 0.436]
[epoch 81], [iter 135 / 176], [train main loss -1.912364], [lr 0.005371] [batchtime 0.435]
[epoch 81], [iter 136 / 176], [train main loss -1.899401], [lr 0.005371] [batchtime 0.435]
[epoch 81], [iter 137 / 176], [train main loss -1.907378], [lr 0.005371] [batchtime 0.435]
[epoch 81], [iter 138 / 176], [train main loss -1.906095], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 139 / 176], [train main loss -1.914738], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 140 / 176], [train main loss -1.908370], [lr 0.005371] [batchtime 0.434]
[epoch 81], [iter 141 / 176], [train main loss -1.892145], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 142 / 176], [train main loss -1.884606], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 143 / 176], [train main loss -1.881808], [lr 0.005371] [batchtime 0.433]
[epoch 81], [iter 144 / 176], [train main loss -1.897434], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 145 / 176], [train main loss -1.891584], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 146 / 176], [train main loss -1.879877], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 147 / 176], [train main loss -1.871706], [lr 0.005371] [batchtime 0.432]
[epoch 81], [iter 148 / 176], [train main loss -1.876391], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 149 / 176], [train main loss -1.884595], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 150 / 176], [train main loss -1.906591], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 151 / 176], [train main loss -1.901402], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 152 / 176], [train main loss -1.922758], [lr 0.005371] [batchtime 0.431]
[epoch 81], [iter 153 / 176], [train main loss -1.909547], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 154 / 176], [train main loss -1.910022], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 155 / 176], [train main loss -1.924665], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 156 / 176], [train main loss -1.920570], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 157 / 176], [train main loss -1.916211], [lr 0.005371] [batchtime 0.43]
[epoch 81], [iter 158 / 176], [train main loss -1.924603], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 159 / 176], [train main loss -1.936327], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 160 / 176], [train main loss -1.941204], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 161 / 176], [train main loss -1.933371], [lr 0.005371] [batchtime 0.429]
[epoch 81], [iter 162 / 176], [train main loss -1.924907], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 163 / 176], [train main loss -1.938915], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 164 / 176], [train main loss -1.939481], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 165 / 176], [train main loss -1.950065], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 166 / 176], [train main loss -1.966881], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 167 / 176], [train main loss -1.949236], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 168 / 176], [train main loss -1.960056], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 169 / 176], [train main loss -1.964620], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 170 / 176], [train main loss -1.966923], [lr 0.005371] [batchtime 0.427]
[epoch 81], [iter 171 / 176], [train main loss -1.953590], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 172 / 176], [train main loss -1.954627], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 173 / 176], [train main loss -1.975563], [lr 0.005371] [batchtime 0.426]
[epoch 81], [iter 174 / 176], [train main loss -1.987598], [lr 0.005371] [batchtime 0.425]
[epoch 81], [iter 175 / 176], [train main loss -1.988856], [lr 0.005371] [batchtime 0.428]
[epoch 81], [iter 176 / 176], [train main loss -1.993727], [lr 0.005371] [batchtime 0.435]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.32  34.94    0.04  0.03         0.96      0.97
   1  sidewalk          65.30   5.51    0.20  0.33         0.84      0.75
   2  building          85.44  24.95    0.07  0.11         0.94      0.90
   3  wall              15.55   0.12    3.78  1.65         0.21      0.38
   4  fence             23.17   0.36    2.55  0.77         0.28      0.57
   5  pole              36.02   0.52    1.20  0.58         0.46      0.63
   6  traffic light     10.85   0.02    7.62  0.60         0.12      0.63
   7  traffic sign      12.77   0.07    6.64  0.20         0.13      0.84
   8  vegetation        83.22  11.45    0.08  0.12         0.93      0.89
   9  terrain           36.75   0.33    1.26  0.46         0.44      0.68
  10  sky               93.14   3.76    0.03  0.04         0.97      0.96
  11  person            48.62   0.96    0.60  0.46         0.63      0.68
  12  rider              3.59   0.00   25.49  1.37         0.04      0.42
  13  car               84.34   6.68    0.06  0.13         0.94      0.89
  14  truck              0.95   0.00  104.09  0.16         0.01      0.86
  15  bus               12.14   0.04    1.33  5.91         0.43      0.14
  16  train             22.55   0.05    2.62  0.81         0.28      0.55
  17  motorcycle         2.15   0.00   44.80  0.71         0.02      0.58
  18  bicycle           32.46   0.25    0.56  1.52         0.64      0.40
Mean: 40.12
-----------------------------------------------------------------------------------------------------------
this : [epoch 81], [val loss 0.32795], [acc 0.90006], [acc_cls 0.48702], [mean_iu 0.40122], [fwavacc 0.82891]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 82], [iter 1 / 176], [train main loss -0.522635], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 2 / 176], [train main loss 0.141367], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 3 / 176], [train main loss -0.732274], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 4 / 176], [train main loss -0.910444], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 5 / 176], [train main loss -1.113373], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 6 / 176], [train main loss -1.245734], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 7 / 176], [train main loss -1.187386], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 8 / 176], [train main loss -1.221045], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 9 / 176], [train main loss -1.021503], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 10 / 176], [train main loss -1.398081], [lr 0.005314] [batchtime 0]
[epoch 82], [iter 11 / 176], [train main loss -1.588449], [lr 0.005314] [batchtime 0.381]
[epoch 82], [iter 12 / 176], [train main loss -1.628625], [lr 0.005314] [batchtime 0.389]
[epoch 82], [iter 13 / 176], [train main loss -1.635672], [lr 0.005314] [batchtime 0.392]
[epoch 82], [iter 14 / 176], [train main loss -1.548213], [lr 0.005314] [batchtime 0.391]
[epoch 82], [iter 15 / 176], [train main loss -1.536522], [lr 0.005314] [batchtime 0.394]
[epoch 82], [iter 16 / 176], [train main loss -1.534906], [lr 0.005314] [batchtime 0.395]
[epoch 82], [iter 17 / 176], [train main loss -1.605354], [lr 0.005314] [batchtime 0.396]
[epoch 82], [iter 18 / 176], [train main loss -1.785782], [lr 0.005314] [batchtime 0.397]
[epoch 82], [iter 19 / 176], [train main loss -1.775534], [lr 0.005314] [batchtime 0.397]
[epoch 82], [iter 20 / 176], [train main loss -1.859932], [lr 0.005314] [batchtime 0.397]
[epoch 82], [iter 21 / 176], [train main loss -1.902490], [lr 0.005314] [batchtime 0.396]
[epoch 82], [iter 22 / 176], [train main loss -1.931542], [lr 0.005314] [batchtime 0.397]
[epoch 82], [iter 23 / 176], [train main loss -2.006842], [lr 0.005314] [batchtime 0.397]
[epoch 82], [iter 24 / 176], [train main loss -1.946143], [lr 0.005314] [batchtime 0.398]
[epoch 82], [iter 25 / 176], [train main loss -1.901848], [lr 0.005314] [batchtime 0.399]
[epoch 82], [iter 26 / 176], [train main loss -1.883312], [lr 0.005314] [batchtime 0.399]
[epoch 82], [iter 27 / 176], [train main loss -1.937819], [lr 0.005314] [batchtime 0.4]
[epoch 82], [iter 28 / 176], [train main loss -1.996158], [lr 0.005314] [batchtime 0.403]
[epoch 82], [iter 29 / 176], [train main loss -1.975376], [lr 0.005314] [batchtime 0.403]
[epoch 82], [iter 30 / 176], [train main loss -1.974589], [lr 0.005314] [batchtime 0.403]
[epoch 82], [iter 31 / 176], [train main loss -2.048005], [lr 0.005314] [batchtime 0.402]
[epoch 82], [iter 32 / 176], [train main loss -2.082760], [lr 0.005314] [batchtime 0.427]
[epoch 82], [iter 33 / 176], [train main loss -2.099775], [lr 0.005314] [batchtime 0.433]
[epoch 82], [iter 34 / 176], [train main loss -2.156413], [lr 0.005314] [batchtime 0.431]
[epoch 82], [iter 35 / 176], [train main loss -2.111423], [lr 0.005314] [batchtime 0.429]
[epoch 82], [iter 36 / 176], [train main loss -2.056337], [lr 0.005314] [batchtime 0.428]
[epoch 82], [iter 37 / 176], [train main loss -2.027593], [lr 0.005314] [batchtime 0.428]
[epoch 82], [iter 38 / 176], [train main loss -2.018343], [lr 0.005314] [batchtime 0.426]
[epoch 82], [iter 39 / 176], [train main loss -1.991802], [lr 0.005314] [batchtime 0.425]
[epoch 82], [iter 40 / 176], [train main loss -1.984200], [lr 0.005314] [batchtime 0.424]
[epoch 82], [iter 41 / 176], [train main loss -1.999782], [lr 0.005314] [batchtime 0.423]
[epoch 82], [iter 42 / 176], [train main loss -2.030514], [lr 0.005314] [batchtime 0.422]
[epoch 82], [iter 43 / 176], [train main loss -1.992133], [lr 0.005314] [batchtime 0.421]
[epoch 82], [iter 44 / 176], [train main loss -1.977926], [lr 0.005314] [batchtime 0.421]
[epoch 82], [iter 45 / 176], [train main loss -1.964293], [lr 0.005314] [batchtime 0.42]
[epoch 82], [iter 46 / 176], [train main loss -2.019323], [lr 0.005314] [batchtime 0.42]
[epoch 82], [iter 47 / 176], [train main loss -2.033708], [lr 0.005314] [batchtime 0.419]
[epoch 82], [iter 48 / 176], [train main loss -2.023253], [lr 0.005314] [batchtime 0.419]
[epoch 82], [iter 49 / 176], [train main loss -1.962274], [lr 0.005314] [batchtime 0.418]
[epoch 82], [iter 50 / 176], [train main loss -1.968635], [lr 0.005314] [batchtime 0.418]
[epoch 82], [iter 51 / 176], [train main loss -1.927955], [lr 0.005314] [batchtime 0.417]
[epoch 82], [iter 52 / 176], [train main loss -1.945270], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 53 / 176], [train main loss -1.932175], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 54 / 176], [train main loss -1.924150], [lr 0.005314] [batchtime 0.415]
[epoch 82], [iter 55 / 176], [train main loss -1.979658], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 56 / 176], [train main loss -2.044642], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 57 / 176], [train main loss -2.062898], [lr 0.005314] [batchtime 0.415]
[epoch 82], [iter 58 / 176], [train main loss -2.103805], [lr 0.005314] [batchtime 0.414]
[epoch 82], [iter 59 / 176], [train main loss -2.100162], [lr 0.005314] [batchtime 0.414]
[epoch 82], [iter 60 / 176], [train main loss -2.114755], [lr 0.005314] [batchtime 0.414]
[epoch 82], [iter 61 / 176], [train main loss -2.131594], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 62 / 176], [train main loss -2.130790], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 63 / 176], [train main loss -2.145154], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 64 / 176], [train main loss -2.139966], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 65 / 176], [train main loss -2.134089], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 66 / 176], [train main loss -2.119590], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 67 / 176], [train main loss -2.100120], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 68 / 176], [train main loss -2.089855], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 69 / 176], [train main loss -2.078715], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 70 / 176], [train main loss -2.078768], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 71 / 176], [train main loss -2.066420], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 72 / 176], [train main loss -2.067006], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 73 / 176], [train main loss -2.055129], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 74 / 176], [train main loss -2.092634], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 75 / 176], [train main loss -2.078614], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 76 / 176], [train main loss -2.061588], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 77 / 176], [train main loss -2.081457], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 78 / 176], [train main loss -2.070672], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 79 / 176], [train main loss -2.076012], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 80 / 176], [train main loss -2.122910], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 81 / 176], [train main loss -2.098782], [lr 0.005314] [batchtime 0.415]
[epoch 82], [iter 82 / 176], [train main loss -2.116270], [lr 0.005314] [batchtime 0.417]
[epoch 82], [iter 83 / 176], [train main loss -2.127296], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 84 / 176], [train main loss -2.103097], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 85 / 176], [train main loss -2.106709], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 86 / 176], [train main loss -2.088817], [lr 0.005314] [batchtime 0.416]
[epoch 82], [iter 87 / 176], [train main loss -2.089410], [lr 0.005314] [batchtime 0.415]
[epoch 82], [iter 88 / 176], [train main loss -2.061416], [lr 0.005314] [batchtime 0.415]
[epoch 82], [iter 89 / 176], [train main loss -2.066538], [lr 0.005314] [batchtime 0.415]
[epoch 82], [iter 90 / 176], [train main loss -2.113872], [lr 0.005314] [batchtime 0.414]
[epoch 82], [iter 91 / 176], [train main loss -2.113328], [lr 0.005314] [batchtime 0.414]
[epoch 82], [iter 92 / 176], [train main loss -2.107810], [lr 0.005314] [batchtime 0.414]
[epoch 82], [iter 93 / 176], [train main loss -2.077638], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 94 / 176], [train main loss -2.078628], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 95 / 176], [train main loss -2.104946], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 96 / 176], [train main loss -2.105362], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 97 / 176], [train main loss -2.125975], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 98 / 176], [train main loss -2.170922], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 99 / 176], [train main loss -2.186736], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 100 / 176], [train main loss -2.214626], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 101 / 176], [train main loss -2.224167], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 102 / 176], [train main loss -2.215298], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 103 / 176], [train main loss -2.238722], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 104 / 176], [train main loss -2.222067], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 105 / 176], [train main loss -2.224560], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 106 / 176], [train main loss -2.230147], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 107 / 176], [train main loss -2.254576], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 108 / 176], [train main loss -2.246741], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 109 / 176], [train main loss -2.231582], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 110 / 176], [train main loss -2.225069], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 111 / 176], [train main loss -2.229352], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 112 / 176], [train main loss -2.212380], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 113 / 176], [train main loss -2.226111], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 114 / 176], [train main loss -2.205258], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 115 / 176], [train main loss -2.232128], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 116 / 176], [train main loss -2.206968], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 117 / 176], [train main loss -2.197690], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 118 / 176], [train main loss -2.197346], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 119 / 176], [train main loss -2.184537], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 120 / 176], [train main loss -2.199506], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 121 / 176], [train main loss -2.215336], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 122 / 176], [train main loss -2.205740], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 123 / 176], [train main loss -2.225757], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 124 / 176], [train main loss -2.225335], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 125 / 176], [train main loss -2.221551], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 126 / 176], [train main loss -2.229728], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 127 / 176], [train main loss -2.222030], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 128 / 176], [train main loss -2.234996], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 129 / 176], [train main loss -2.218157], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 130 / 176], [train main loss -2.237435], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 131 / 176], [train main loss -2.225245], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 132 / 176], [train main loss -2.222449], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 133 / 176], [train main loss -2.202766], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 134 / 176], [train main loss -2.195039], [lr 0.005314] [batchtime 0.413]
[epoch 82], [iter 135 / 176], [train main loss -2.169053], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 136 / 176], [train main loss -2.191555], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 137 / 176], [train main loss -2.185494], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 138 / 176], [train main loss -2.175523], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 139 / 176], [train main loss -2.176284], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 140 / 176], [train main loss -2.171719], [lr 0.005314] [batchtime 0.412]
[epoch 82], [iter 141 / 176], [train main loss -2.185055], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 142 / 176], [train main loss -2.171164], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 143 / 176], [train main loss -2.157982], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 144 / 176], [train main loss -2.155143], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 145 / 176], [train main loss -2.148708], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 146 / 176], [train main loss -2.162577], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 147 / 176], [train main loss -2.168464], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 148 / 176], [train main loss -2.171459], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 149 / 176], [train main loss -2.174441], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 150 / 176], [train main loss -2.163438], [lr 0.005314] [batchtime 0.411]
[epoch 82], [iter 151 / 176], [train main loss -2.173424], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 152 / 176], [train main loss -2.176643], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 153 / 176], [train main loss -2.193494], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 154 / 176], [train main loss -2.186422], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 155 / 176], [train main loss -2.180448], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 156 / 176], [train main loss -2.194954], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 157 / 176], [train main loss -2.183534], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 158 / 176], [train main loss -2.172881], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 159 / 176], [train main loss -2.183237], [lr 0.005314] [batchtime 0.41]
[epoch 82], [iter 160 / 176], [train main loss -2.176003], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 161 / 176], [train main loss -2.188037], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 162 / 176], [train main loss -2.182610], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 163 / 176], [train main loss -2.173720], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 164 / 176], [train main loss -2.164923], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 165 / 176], [train main loss -2.158767], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 166 / 176], [train main loss -2.139919], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 167 / 176], [train main loss -2.137674], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 168 / 176], [train main loss -2.127156], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 169 / 176], [train main loss -2.110799], [lr 0.005314] [batchtime 0.409]
[epoch 82], [iter 170 / 176], [train main loss -2.099272], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 171 / 176], [train main loss -2.096480], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 172 / 176], [train main loss -2.078423], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 173 / 176], [train main loss -2.091296], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 174 / 176], [train main loss -2.101101], [lr 0.005314] [batchtime 0.408]
[epoch 82], [iter 175 / 176], [train main loss -2.094094], [lr 0.005314] [batchtime 0.407]
[epoch 82], [iter 176 / 176], [train main loss -2.088636], [lr 0.005314] [batchtime 0.407]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.18  35.37   0.03  0.03         0.97      0.97
   1  sidewalk          67.42   5.37   0.23  0.26         0.82      0.80
   2  building          85.16  24.94   0.07  0.11         0.94      0.90
   3  wall              15.33   0.13   3.71  1.81         0.21      0.36
   4  fence             19.23   0.28   3.58  0.62         0.22      0.62
   5  pole              34.84   0.49   1.30  0.57         0.44      0.64
   6  traffic light     10.24   0.02   8.17  0.60         0.11      0.63
   7  traffic sign      14.50   0.08   5.64  0.26         0.15      0.79
   8  vegetation        82.17  11.60   0.07  0.15         0.94      0.87
   9  terrain           36.10   0.32   1.30  0.47         0.43      0.68
  10  sky               92.35   3.71   0.04  0.04         0.96      0.96
  11  person            49.06   1.03   0.49  0.55         0.67      0.65
  12  rider              3.53   0.00  26.23  1.10         0.04      0.48
  13  car               84.48   6.53   0.08  0.10         0.92      0.91
  14  truck              1.57   0.01  62.22  0.64         0.02      0.61
  15  bus               12.58   0.04   1.40  5.55         0.42      0.15
  16  train             38.09   0.09   1.00  0.63         0.50      0.62
  17  motorcycle         1.88   0.00  51.89  0.39         0.02      0.72
  18  bicycle           34.49   0.22   0.80  1.10         0.55      0.48
Mean: 40.91
-----------------------------------------------------------------------------------------------------------
this : [epoch 82], [val loss 0.33019], [acc 0.90229], [acc_cls 0.49056], [mean_iu 0.40906], [fwavacc 0.83105]
best : [epoch 76], [val loss 0.34459], [acc 0.90032], [acc_cls 0.49810], [mean_iu 0.40951], [fwavacc 0.82929]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 83], [iter 1 / 176], [train main loss -0.816833], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 2 / 176], [train main loss -2.403111], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 3 / 176], [train main loss -1.654843], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 4 / 176], [train main loss -1.366986], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 5 / 176], [train main loss -1.458699], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 6 / 176], [train main loss -1.484278], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 7 / 176], [train main loss -1.542662], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 8 / 176], [train main loss -1.571454], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 9 / 176], [train main loss -1.498809], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 10 / 176], [train main loss -1.542171], [lr 0.005257] [batchtime 0]
[epoch 83], [iter 11 / 176], [train main loss -1.505408], [lr 0.005257] [batchtime 0.365]
[epoch 83], [iter 12 / 176], [train main loss -1.528311], [lr 0.005257] [batchtime 0.378]
[epoch 83], [iter 13 / 176], [train main loss -1.506346], [lr 0.005257] [batchtime 0.383]
[epoch 83], [iter 14 / 176], [train main loss -1.484623], [lr 0.005257] [batchtime 0.4]
[epoch 83], [iter 15 / 176], [train main loss -1.516222], [lr 0.005257] [batchtime 0.399]
[epoch 83], [iter 16 / 176], [train main loss -1.582681], [lr 0.005257] [batchtime 0.396]
[epoch 83], [iter 17 / 176], [train main loss -1.628347], [lr 0.005257] [batchtime 0.396]
[epoch 83], [iter 18 / 176], [train main loss -1.608661], [lr 0.005257] [batchtime 0.394]
[epoch 83], [iter 19 / 176], [train main loss -1.718031], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 20 / 176], [train main loss -1.723910], [lr 0.005257] [batchtime 0.396]
[epoch 83], [iter 21 / 176], [train main loss -1.856878], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 22 / 176], [train main loss -1.873769], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 23 / 176], [train main loss -1.898474], [lr 0.005257] [batchtime 0.394]
[epoch 83], [iter 24 / 176], [train main loss -1.945550], [lr 0.005257] [batchtime 0.394]
[epoch 83], [iter 25 / 176], [train main loss -1.922250], [lr 0.005257] [batchtime 0.394]
[epoch 83], [iter 26 / 176], [train main loss -1.941275], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 27 / 176], [train main loss -1.891872], [lr 0.005257] [batchtime 0.394]
[epoch 83], [iter 28 / 176], [train main loss -1.779430], [lr 0.005257] [batchtime 0.394]
[epoch 83], [iter 29 / 176], [train main loss -1.811988], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 30 / 176], [train main loss -1.885736], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 31 / 176], [train main loss -1.888727], [lr 0.005257] [batchtime 0.395]
[epoch 83], [iter 32 / 176], [train main loss -1.895055], [lr 0.005257] [batchtime 0.407]
[epoch 83], [iter 33 / 176], [train main loss -1.931383], [lr 0.005257] [batchtime 0.405]
[epoch 83], [iter 34 / 176], [train main loss -1.920921], [lr 0.005257] [batchtime 0.405]
[epoch 83], [iter 35 / 176], [train main loss -1.957445], [lr 0.005257] [batchtime 0.404]
[epoch 83], [iter 36 / 176], [train main loss -1.930508], [lr 0.005257] [batchtime 0.404]
[epoch 83], [iter 37 / 176], [train main loss -1.983236], [lr 0.005257] [batchtime 0.403]
[epoch 83], [iter 38 / 176], [train main loss -1.917727], [lr 0.005257] [batchtime 0.403]
[epoch 83], [iter 39 / 176], [train main loss -1.927823], [lr 0.005257] [batchtime 0.426]
[epoch 83], [iter 40 / 176], [train main loss -1.963190], [lr 0.005257] [batchtime 0.429]
[epoch 83], [iter 41 / 176], [train main loss -1.958974], [lr 0.005257] [batchtime 0.427]
[epoch 83], [iter 42 / 176], [train main loss -1.917390], [lr 0.005257] [batchtime 0.426]
[epoch 83], [iter 43 / 176], [train main loss -1.816141], [lr 0.005257] [batchtime 0.425]
[epoch 83], [iter 44 / 176], [train main loss -1.804315], [lr 0.005257] [batchtime 0.424]
[epoch 83], [iter 45 / 176], [train main loss -1.839026], [lr 0.005257] [batchtime 0.423]
[epoch 83], [iter 46 / 176], [train main loss -1.808669], [lr 0.005257] [batchtime 0.422]
[epoch 83], [iter 47 / 176], [train main loss -1.770283], [lr 0.005257] [batchtime 0.421]
[epoch 83], [iter 48 / 176], [train main loss -1.780390], [lr 0.005257] [batchtime 0.421]
[epoch 83], [iter 49 / 176], [train main loss -1.683877], [lr 0.005257] [batchtime 0.42]
[epoch 83], [iter 50 / 176], [train main loss -1.668022], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 51 / 176], [train main loss -1.647253], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 52 / 176], [train main loss -1.634759], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 53 / 176], [train main loss -1.665858], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 54 / 176], [train main loss -1.712133], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 55 / 176], [train main loss -1.714161], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 56 / 176], [train main loss -1.731781], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 57 / 176], [train main loss -1.779011], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 58 / 176], [train main loss -1.785115], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 59 / 176], [train main loss -1.779256], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 60 / 176], [train main loss -1.817878], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 61 / 176], [train main loss -1.807123], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 62 / 176], [train main loss -1.804631], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 63 / 176], [train main loss -1.809247], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 64 / 176], [train main loss -1.827645], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 65 / 176], [train main loss -1.822905], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 66 / 176], [train main loss -1.796204], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 67 / 176], [train main loss -1.821078], [lr 0.005257] [batchtime 0.412]
[epoch 83], [iter 68 / 176], [train main loss -1.847560], [lr 0.005257] [batchtime 0.412]
[epoch 83], [iter 69 / 176], [train main loss -1.816116], [lr 0.005257] [batchtime 0.412]
[epoch 83], [iter 70 / 176], [train main loss -1.786025], [lr 0.005257] [batchtime 0.411]
[epoch 83], [iter 71 / 176], [train main loss -1.794303], [lr 0.005257] [batchtime 0.411]
[epoch 83], [iter 72 / 176], [train main loss -1.800175], [lr 0.005257] [batchtime 0.411]
[epoch 83], [iter 73 / 176], [train main loss -1.842804], [lr 0.005257] [batchtime 0.411]
[epoch 83], [iter 74 / 176], [train main loss -1.841191], [lr 0.005257] [batchtime 0.41]
[epoch 83], [iter 75 / 176], [train main loss -1.830445], [lr 0.005257] [batchtime 0.41]
[epoch 83], [iter 76 / 176], [train main loss -1.857550], [lr 0.005257] [batchtime 0.41]
[epoch 83], [iter 77 / 176], [train main loss -1.854293], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 78 / 176], [train main loss -1.869888], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 79 / 176], [train main loss -1.885149], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 80 / 176], [train main loss -1.903590], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 81 / 176], [train main loss -1.946534], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 82 / 176], [train main loss -1.963117], [lr 0.005257] [batchtime 0.408]
[epoch 83], [iter 83 / 176], [train main loss -1.980947], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 84 / 176], [train main loss -1.967193], [lr 0.005257] [batchtime 0.409]
[epoch 83], [iter 85 / 176], [train main loss -1.974686], [lr 0.005257] [batchtime 0.408]
[epoch 83], [iter 86 / 176], [train main loss -1.997569], [lr 0.005257] [batchtime 0.408]
[epoch 83], [iter 87 / 176], [train main loss -2.026742], [lr 0.005257] [batchtime 0.41]
[epoch 83], [iter 88 / 176], [train main loss -2.018436], [lr 0.005257] [batchtime 0.426]
[epoch 83], [iter 89 / 176], [train main loss -2.011969], [lr 0.005257] [batchtime 0.426]
[epoch 83], [iter 90 / 176], [train main loss -2.016815], [lr 0.005257] [batchtime 0.425]
[epoch 83], [iter 91 / 176], [train main loss -2.021141], [lr 0.005257] [batchtime 0.425]
[epoch 83], [iter 92 / 176], [train main loss -2.027810], [lr 0.005257] [batchtime 0.424]
[epoch 83], [iter 93 / 176], [train main loss -2.037194], [lr 0.005257] [batchtime 0.424]
[epoch 83], [iter 94 / 176], [train main loss -2.037001], [lr 0.005257] [batchtime 0.423]
[epoch 83], [iter 95 / 176], [train main loss -2.026416], [lr 0.005257] [batchtime 0.423]
[epoch 83], [iter 96 / 176], [train main loss -2.030749], [lr 0.005257] [batchtime 0.423]
[epoch 83], [iter 97 / 176], [train main loss -2.043738], [lr 0.005257] [batchtime 0.422]
[epoch 83], [iter 98 / 176], [train main loss -2.040022], [lr 0.005257] [batchtime 0.422]
[epoch 83], [iter 99 / 176], [train main loss -2.028633], [lr 0.005257] [batchtime 0.422]
[epoch 83], [iter 100 / 176], [train main loss -2.028113], [lr 0.005257] [batchtime 0.421]
[epoch 83], [iter 101 / 176], [train main loss -2.024827], [lr 0.005257] [batchtime 0.421]
[epoch 83], [iter 102 / 176], [train main loss -2.035014], [lr 0.005257] [batchtime 0.421]
[epoch 83], [iter 103 / 176], [train main loss -2.055758], [lr 0.005257] [batchtime 0.42]
[epoch 83], [iter 104 / 176], [train main loss -2.043826], [lr 0.005257] [batchtime 0.42]
[epoch 83], [iter 105 / 176], [train main loss -2.048016], [lr 0.005257] [batchtime 0.42]
[epoch 83], [iter 106 / 176], [train main loss -2.024043], [lr 0.005257] [batchtime 0.42]
[epoch 83], [iter 107 / 176], [train main loss -2.042135], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 108 / 176], [train main loss -2.059089], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 109 / 176], [train main loss -2.060195], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 110 / 176], [train main loss -2.058886], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 111 / 176], [train main loss -2.069839], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 112 / 176], [train main loss -2.061310], [lr 0.005257] [batchtime 0.419]
[epoch 83], [iter 113 / 176], [train main loss -2.071909], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 114 / 176], [train main loss -2.083984], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 115 / 176], [train main loss -2.099497], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 116 / 176], [train main loss -2.104087], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 117 / 176], [train main loss -2.113936], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 118 / 176], [train main loss -2.105468], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 119 / 176], [train main loss -2.108172], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 120 / 176], [train main loss -2.115244], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 121 / 176], [train main loss -2.125034], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 122 / 176], [train main loss -2.123845], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 123 / 176], [train main loss -2.115037], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 124 / 176], [train main loss -2.105227], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 125 / 176], [train main loss -2.097212], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 126 / 176], [train main loss -2.099765], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 127 / 176], [train main loss -2.113956], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 128 / 176], [train main loss -2.106215], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 129 / 176], [train main loss -2.093709], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 130 / 176], [train main loss -2.092340], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 131 / 176], [train main loss -2.093850], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 132 / 176], [train main loss -2.069080], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 133 / 176], [train main loss -2.058911], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 134 / 176], [train main loss -2.060135], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 135 / 176], [train main loss -2.060026], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 136 / 176], [train main loss -2.066361], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 137 / 176], [train main loss -2.082387], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 138 / 176], [train main loss -2.080040], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 139 / 176], [train main loss -2.074405], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 140 / 176], [train main loss -2.056444], [lr 0.005257] [batchtime 0.418]
[epoch 83], [iter 141 / 176], [train main loss -2.045070], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 142 / 176], [train main loss -2.060851], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 143 / 176], [train main loss -2.085018], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 144 / 176], [train main loss -2.061601], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 145 / 176], [train main loss -2.066889], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 146 / 176], [train main loss -2.074524], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 147 / 176], [train main loss -2.091241], [lr 0.005257] [batchtime 0.417]
[epoch 83], [iter 148 / 176], [train main loss -2.088312], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 149 / 176], [train main loss -2.076021], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 150 / 176], [train main loss -2.063312], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 151 / 176], [train main loss -2.063888], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 152 / 176], [train main loss -2.073585], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 153 / 176], [train main loss -2.076249], [lr 0.005257] [batchtime 0.416]
[epoch 83], [iter 154 / 176], [train main loss -2.064093], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 155 / 176], [train main loss -2.077856], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 156 / 176], [train main loss -2.066103], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 157 / 176], [train main loss -2.067454], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 158 / 176], [train main loss -2.073771], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 159 / 176], [train main loss -2.070823], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 160 / 176], [train main loss -2.060426], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 161 / 176], [train main loss -2.066527], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 162 / 176], [train main loss -2.073590], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 163 / 176], [train main loss -2.075179], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 164 / 176], [train main loss -2.078769], [lr 0.005257] [batchtime 0.415]
[epoch 83], [iter 165 / 176], [train main loss -2.057451], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 166 / 176], [train main loss -2.044374], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 167 / 176], [train main loss -2.054004], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 168 / 176], [train main loss -2.041114], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 169 / 176], [train main loss -2.037195], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 170 / 176], [train main loss -2.030068], [lr 0.005257] [batchtime 0.414]
[epoch 83], [iter 171 / 176], [train main loss -2.011370], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 172 / 176], [train main loss -2.011245], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 173 / 176], [train main loss -2.008585], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 174 / 176], [train main loss -2.008910], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 175 / 176], [train main loss -2.014039], [lr 0.005257] [batchtime 0.413]
[epoch 83], [iter 176 / 176], [train main loss -2.013889], [lr 0.005257] [batchtime 0.412]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.12  35.63   0.02  0.04         0.98      0.96
   1  sidewalk          65.89   5.07   0.30  0.22         0.77      0.82
   2  building          85.07  24.91   0.07  0.11         0.94      0.90
   3  wall              14.34   0.11   4.25  1.72         0.19      0.37
   4  fence             23.25   0.36   2.55  0.75         0.28      0.57
   5  pole              36.08   0.52   1.17  0.61         0.46      0.62
   6  traffic light     10.61   0.02   7.77  0.65         0.11      0.61
   7  traffic sign      19.32   0.12   3.81  0.36         0.21      0.73
   8  vegetation        82.25  11.39   0.09  0.13         0.92      0.88
   9  terrain           37.53   0.38   0.95  0.72         0.51      0.58
  10  sky               93.03   3.78   0.03  0.05         0.98      0.95
  11  person            49.35   0.99   0.55  0.48         0.65      0.68
  12  rider              5.57   0.01  15.71  1.25         0.06      0.45
  13  car               85.26   6.62   0.07  0.10         0.94      0.91
  14  truck              1.75   0.01  55.61  0.44         0.02      0.69
  15  bus               13.45   0.03   1.98  4.45         0.34      0.18
  16  train             35.54   0.09   0.92  0.89         0.52      0.53
  17  motorcycle         1.43   0.00  68.51  0.53         0.01      0.65
  18  bicycle           35.09   0.23   0.70  1.15         0.59      0.47
Mean: 41.52
-----------------------------------------------------------------------------------------------------------
this : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 84], [iter 1 / 176], [train main loss -4.864114], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 2 / 176], [train main loss -3.748250], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 3 / 176], [train main loss -3.220749], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 4 / 176], [train main loss -3.032825], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 5 / 176], [train main loss -2.742075], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 6 / 176], [train main loss -2.832167], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 7 / 176], [train main loss -2.474656], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 8 / 176], [train main loss -2.255759], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 9 / 176], [train main loss -2.223293], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 10 / 176], [train main loss -2.084322], [lr 0.005200] [batchtime 0]
[epoch 84], [iter 11 / 176], [train main loss -1.935700], [lr 0.005200] [batchtime 0.401]
[epoch 84], [iter 12 / 176], [train main loss -1.963548], [lr 0.005200] [batchtime 0.398]
[epoch 84], [iter 13 / 176], [train main loss -1.879045], [lr 0.005200] [batchtime 0.403]
[epoch 84], [iter 14 / 176], [train main loss -1.884394], [lr 0.005200] [batchtime 0.401]
[epoch 84], [iter 15 / 176], [train main loss -1.767265], [lr 0.005200] [batchtime 0.401]
[epoch 84], [iter 16 / 176], [train main loss -1.831423], [lr 0.005200] [batchtime 0.401]
[epoch 84], [iter 17 / 176], [train main loss -1.900718], [lr 0.005200] [batchtime 0.403]
[epoch 84], [iter 18 / 176], [train main loss -1.754383], [lr 0.005200] [batchtime 0.403]
[epoch 84], [iter 19 / 176], [train main loss -1.698965], [lr 0.005200] [batchtime 0.402]
[epoch 84], [iter 20 / 176], [train main loss -1.746640], [lr 0.005200] [batchtime 0.402]
[epoch 84], [iter 21 / 176], [train main loss -1.698332], [lr 0.005200] [batchtime 0.401]
[epoch 84], [iter 22 / 176], [train main loss -1.721411], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 23 / 176], [train main loss -1.715762], [lr 0.005200] [batchtime 0.401]
[epoch 84], [iter 24 / 176], [train main loss -1.784143], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 25 / 176], [train main loss -1.805617], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 26 / 176], [train main loss -1.917216], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 27 / 176], [train main loss -1.970496], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 28 / 176], [train main loss -1.869301], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 29 / 176], [train main loss -1.865442], [lr 0.005200] [batchtime 0.4]
[epoch 84], [iter 30 / 176], [train main loss -1.842765], [lr 0.005200] [batchtime 0.407]
[epoch 84], [iter 31 / 176], [train main loss -1.819478], [lr 0.005200] [batchtime 0.406]
[epoch 84], [iter 32 / 176], [train main loss -1.854497], [lr 0.005200] [batchtime 0.405]
[epoch 84], [iter 33 / 176], [train main loss -1.859838], [lr 0.005200] [batchtime 0.405]
[epoch 84], [iter 34 / 176], [train main loss -1.889736], [lr 0.005200] [batchtime 0.404]
[epoch 84], [iter 35 / 176], [train main loss -1.855477], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 36 / 176], [train main loss -1.867777], [lr 0.005200] [batchtime 0.434]
[epoch 84], [iter 37 / 176], [train main loss -1.928401], [lr 0.005200] [batchtime 0.432]
[epoch 84], [iter 38 / 176], [train main loss -1.970990], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 39 / 176], [train main loss -2.012923], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 40 / 176], [train main loss -2.044178], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 41 / 176], [train main loss -2.076953], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 42 / 176], [train main loss -2.084765], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 43 / 176], [train main loss -2.063239], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 44 / 176], [train main loss -2.080374], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 45 / 176], [train main loss -2.084681], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 46 / 176], [train main loss -2.131486], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 47 / 176], [train main loss -2.174170], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 48 / 176], [train main loss -2.197274], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 49 / 176], [train main loss -2.159725], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 50 / 176], [train main loss -2.131434], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 51 / 176], [train main loss -2.190233], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 52 / 176], [train main loss -2.224516], [lr 0.005200] [batchtime 0.419]
[epoch 84], [iter 53 / 176], [train main loss -2.219915], [lr 0.005200] [batchtime 0.419]
[epoch 84], [iter 54 / 176], [train main loss -2.195182], [lr 0.005200] [batchtime 0.418]
[epoch 84], [iter 55 / 176], [train main loss -2.239043], [lr 0.005200] [batchtime 0.417]
[epoch 84], [iter 56 / 176], [train main loss -2.252780], [lr 0.005200] [batchtime 0.417]
[epoch 84], [iter 57 / 176], [train main loss -2.223377], [lr 0.005200] [batchtime 0.417]
[epoch 84], [iter 58 / 176], [train main loss -2.201455], [lr 0.005200] [batchtime 0.416]
[epoch 84], [iter 59 / 176], [train main loss -2.182033], [lr 0.005200] [batchtime 0.416]
[epoch 84], [iter 60 / 176], [train main loss -2.215840], [lr 0.005200] [batchtime 0.416]
[epoch 84], [iter 61 / 176], [train main loss -2.205021], [lr 0.005200] [batchtime 0.416]
[epoch 84], [iter 62 / 176], [train main loss -2.201133], [lr 0.005200] [batchtime 0.415]
[epoch 84], [iter 63 / 176], [train main loss -2.202763], [lr 0.005200] [batchtime 0.415]
[epoch 84], [iter 64 / 176], [train main loss -2.208721], [lr 0.005200] [batchtime 0.415]
[epoch 84], [iter 65 / 176], [train main loss -2.204639], [lr 0.005200] [batchtime 0.414]
[epoch 84], [iter 66 / 176], [train main loss -2.205746], [lr 0.005200] [batchtime 0.414]
[epoch 84], [iter 67 / 176], [train main loss -2.228843], [lr 0.005200] [batchtime 0.413]
[epoch 84], [iter 68 / 176], [train main loss -2.281600], [lr 0.005200] [batchtime 0.413]
[epoch 84], [iter 69 / 176], [train main loss -2.256102], [lr 0.005200] [batchtime 0.413]
[epoch 84], [iter 70 / 176], [train main loss -2.188090], [lr 0.005200] [batchtime 0.413]
[epoch 84], [iter 71 / 176], [train main loss -2.148185], [lr 0.005200] [batchtime 0.412]
[epoch 84], [iter 72 / 176], [train main loss -2.119446], [lr 0.005200] [batchtime 0.412]
[epoch 84], [iter 73 / 176], [train main loss -2.149626], [lr 0.005200] [batchtime 0.412]
[epoch 84], [iter 74 / 176], [train main loss -2.158375], [lr 0.005200] [batchtime 0.412]
[epoch 84], [iter 75 / 176], [train main loss -2.171423], [lr 0.005200] [batchtime 0.412]
[epoch 84], [iter 76 / 176], [train main loss -2.157042], [lr 0.005200] [batchtime 0.412]
[epoch 84], [iter 77 / 176], [train main loss -2.195673], [lr 0.005200] [batchtime 0.411]
[epoch 84], [iter 78 / 176], [train main loss -2.166294], [lr 0.005200] [batchtime 0.411]
[epoch 84], [iter 79 / 176], [train main loss -2.192286], [lr 0.005200] [batchtime 0.411]
[epoch 84], [iter 80 / 176], [train main loss -2.198263], [lr 0.005200] [batchtime 0.411]
[epoch 84], [iter 81 / 176], [train main loss -2.209000], [lr 0.005200] [batchtime 0.411]
[epoch 84], [iter 82 / 176], [train main loss -2.199188], [lr 0.005200] [batchtime 0.411]
[epoch 84], [iter 83 / 176], [train main loss -2.186787], [lr 0.005200] [batchtime 0.413]
[epoch 84], [iter 84 / 176], [train main loss -2.198783], [lr 0.005200] [batchtime 0.433]
[epoch 84], [iter 85 / 176], [train main loss -2.159135], [lr 0.005200] [batchtime 0.432]
[epoch 84], [iter 86 / 176], [train main loss -2.165267], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 87 / 176], [train main loss -2.207269], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 88 / 176], [train main loss -2.198872], [lr 0.005200] [batchtime 0.43]
[epoch 84], [iter 89 / 176], [train main loss -2.209773], [lr 0.005200] [batchtime 0.43]
[epoch 84], [iter 90 / 176], [train main loss -2.205830], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 91 / 176], [train main loss -2.219817], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 92 / 176], [train main loss -2.175947], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 93 / 176], [train main loss -2.162698], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 94 / 176], [train main loss -2.132385], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 95 / 176], [train main loss -2.139622], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 96 / 176], [train main loss -2.135393], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 97 / 176], [train main loss -2.151806], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 98 / 176], [train main loss -2.120621], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 99 / 176], [train main loss -2.129387], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 100 / 176], [train main loss -2.122877], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 101 / 176], [train main loss -2.118877], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 102 / 176], [train main loss -2.122496], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 103 / 176], [train main loss -2.124375], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 104 / 176], [train main loss -2.125054], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 105 / 176], [train main loss -2.128891], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 106 / 176], [train main loss -2.130500], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 107 / 176], [train main loss -2.162704], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 108 / 176], [train main loss -2.163624], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 109 / 176], [train main loss -2.165943], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 110 / 176], [train main loss -2.160563], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 111 / 176], [train main loss -2.136512], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 112 / 176], [train main loss -2.129531], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 113 / 176], [train main loss -2.120212], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 114 / 176], [train main loss -2.086752], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 115 / 176], [train main loss -2.099113], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 116 / 176], [train main loss -2.078652], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 117 / 176], [train main loss -2.059741], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 118 / 176], [train main loss -2.049761], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 119 / 176], [train main loss -2.033918], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 120 / 176], [train main loss -2.037070], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 121 / 176], [train main loss -2.030951], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 122 / 176], [train main loss -2.050722], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 123 / 176], [train main loss -2.055767], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 124 / 176], [train main loss -2.050762], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 125 / 176], [train main loss -2.037610], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 126 / 176], [train main loss -2.055678], [lr 0.005200] [batchtime 0.42]
[epoch 84], [iter 127 / 176], [train main loss -2.043399], [lr 0.005200] [batchtime 0.419]
[epoch 84], [iter 128 / 176], [train main loss -2.047169], [lr 0.005200] [batchtime 0.419]
[epoch 84], [iter 129 / 176], [train main loss -2.022131], [lr 0.005200] [batchtime 0.421]
[epoch 84], [iter 130 / 176], [train main loss -2.020928], [lr 0.005200] [batchtime 0.432]
[epoch 84], [iter 131 / 176], [train main loss -1.990061], [lr 0.005200] [batchtime 0.432]
[epoch 84], [iter 132 / 176], [train main loss -1.990235], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 133 / 176], [train main loss -1.993529], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 134 / 176], [train main loss -1.991124], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 135 / 176], [train main loss -2.006874], [lr 0.005200] [batchtime 0.431]
[epoch 84], [iter 136 / 176], [train main loss -2.003257], [lr 0.005200] [batchtime 0.43]
[epoch 84], [iter 137 / 176], [train main loss -1.998353], [lr 0.005200] [batchtime 0.43]
[epoch 84], [iter 138 / 176], [train main loss -1.984737], [lr 0.005200] [batchtime 0.43]
[epoch 84], [iter 139 / 176], [train main loss -1.999861], [lr 0.005200] [batchtime 0.43]
[epoch 84], [iter 140 / 176], [train main loss -2.002929], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 141 / 176], [train main loss -1.998571], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 142 / 176], [train main loss -1.985919], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 143 / 176], [train main loss -1.975558], [lr 0.005200] [batchtime 0.429]
[epoch 84], [iter 144 / 176], [train main loss -1.956281], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 145 / 176], [train main loss -1.975546], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 146 / 176], [train main loss -1.977768], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 147 / 176], [train main loss -1.966579], [lr 0.005200] [batchtime 0.428]
[epoch 84], [iter 148 / 176], [train main loss -1.953491], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 149 / 176], [train main loss -1.960083], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 150 / 176], [train main loss -1.951527], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 151 / 176], [train main loss -1.946529], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 152 / 176], [train main loss -1.938308], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 153 / 176], [train main loss -1.949903], [lr 0.005200] [batchtime 0.427]
[epoch 84], [iter 154 / 176], [train main loss -1.951721], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 155 / 176], [train main loss -1.953296], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 156 / 176], [train main loss -1.946160], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 157 / 176], [train main loss -1.950017], [lr 0.005200] [batchtime 0.426]
[epoch 84], [iter 158 / 176], [train main loss -1.955905], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 159 / 176], [train main loss -1.950952], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 160 / 176], [train main loss -1.939839], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 161 / 176], [train main loss -1.944205], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 162 / 176], [train main loss -1.945066], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 163 / 176], [train main loss -1.939060], [lr 0.005200] [batchtime 0.425]
[epoch 84], [iter 164 / 176], [train main loss -1.924150], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 165 / 176], [train main loss -1.941769], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 166 / 176], [train main loss -1.954826], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 167 / 176], [train main loss -1.943396], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 168 / 176], [train main loss -1.959200], [lr 0.005200] [batchtime 0.424]
[epoch 84], [iter 169 / 176], [train main loss -1.953344], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 170 / 176], [train main loss -1.946074], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 171 / 176], [train main loss -1.947254], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 172 / 176], [train main loss -1.935688], [lr 0.005200] [batchtime 0.423]
[epoch 84], [iter 173 / 176], [train main loss -1.940534], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 174 / 176], [train main loss -1.941103], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 175 / 176], [train main loss -1.918578], [lr 0.005200] [batchtime 0.422]
[epoch 84], [iter 176 / 176], [train main loss -1.918814], [lr 0.005200] [batchtime 0.423]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.14  35.45   0.03  0.04         0.97      0.96
   1  sidewalk          66.97   5.21   0.27  0.23         0.79      0.81
   2  building          85.25  24.91   0.07  0.11         0.94      0.90
   3  wall              17.75   0.15   2.86  1.78         0.26      0.36
   4  fence             20.73   0.31   3.14  0.68         0.24      0.59
   5  pole              35.71   0.50   1.28  0.52         0.44      0.66
   6  traffic light     10.27   0.02   8.16  0.57         0.11      0.64
   7  traffic sign      15.90   0.09   5.02  0.27         0.17      0.79
   8  vegetation        81.93  11.67   0.06  0.16         0.94      0.86
   9  terrain           34.02   0.30   1.44  0.50         0.41      0.67
  10  sky               93.36   3.72   0.04  0.03         0.96      0.97
  11  person            48.78   0.93   0.65  0.40         0.61      0.72
  12  rider              5.78   0.01  14.83  1.49         0.06      0.40
  13  car               83.97   6.66   0.06  0.13         0.94      0.89
  14  truck              1.13   0.00  87.04  0.38         0.01      0.72
  15  bus               11.97   0.03   2.04  5.31         0.33      0.16
  16  train             39.56   0.10   0.80  0.73         0.56      0.58
  17  motorcycle         1.76   0.00  55.25  0.63         0.02      0.61
  18  bicycle           35.72   0.22   0.77  1.03         0.56      0.49
Mean: 41.30
-----------------------------------------------------------------------------------------------------------
this : [epoch 84], [val loss 0.33949], [acc 0.90271], [acc_cls 0.49050], [mean_iu 0.41299], [fwavacc 0.83092]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 85], [iter 1 / 176], [train main loss -3.578698], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 2 / 176], [train main loss -2.372009], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 3 / 176], [train main loss -2.085930], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 4 / 176], [train main loss -2.393484], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 5 / 176], [train main loss -2.750787], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 6 / 176], [train main loss -2.692490], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 7 / 176], [train main loss -2.990993], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 8 / 176], [train main loss -2.724037], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 9 / 176], [train main loss -2.534050], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 10 / 176], [train main loss -2.389852], [lr 0.005143] [batchtime 0]
[epoch 85], [iter 11 / 176], [train main loss -2.574903], [lr 0.005143] [batchtime 0.369]
[epoch 85], [iter 12 / 176], [train main loss -2.339717], [lr 0.005143] [batchtime 0.383]
[epoch 85], [iter 13 / 176], [train main loss -2.364868], [lr 0.005143] [batchtime 0.387]
[epoch 85], [iter 14 / 176], [train main loss -2.385972], [lr 0.005143] [batchtime 0.39]
[epoch 85], [iter 15 / 176], [train main loss -2.247557], [lr 0.005143] [batchtime 0.392]
[epoch 85], [iter 16 / 176], [train main loss -2.244026], [lr 0.005143] [batchtime 0.394]
[epoch 85], [iter 17 / 176], [train main loss -2.169111], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 18 / 176], [train main loss -2.244673], [lr 0.005143] [batchtime 0.394]
[epoch 85], [iter 19 / 176], [train main loss -2.227173], [lr 0.005143] [batchtime 0.394]
[epoch 85], [iter 20 / 176], [train main loss -2.350803], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 21 / 176], [train main loss -2.288314], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 22 / 176], [train main loss -2.187560], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 23 / 176], [train main loss -2.082728], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 24 / 176], [train main loss -2.056389], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 25 / 176], [train main loss -2.010763], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 26 / 176], [train main loss -1.959017], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 27 / 176], [train main loss -2.069388], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 28 / 176], [train main loss -2.092343], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 29 / 176], [train main loss -2.068316], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 30 / 176], [train main loss -1.999043], [lr 0.005143] [batchtime 0.394]
[epoch 85], [iter 31 / 176], [train main loss -1.884879], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 32 / 176], [train main loss -1.909992], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 33 / 176], [train main loss -1.908011], [lr 0.005143] [batchtime 0.393]
[epoch 85], [iter 34 / 176], [train main loss -1.939913], [lr 0.005143] [batchtime 0.431]
[epoch 85], [iter 35 / 176], [train main loss -1.932056], [lr 0.005143] [batchtime 0.44]
[epoch 85], [iter 36 / 176], [train main loss -1.919645], [lr 0.005143] [batchtime 0.438]
[epoch 85], [iter 37 / 176], [train main loss -1.936912], [lr 0.005143] [batchtime 0.436]
[epoch 85], [iter 38 / 176], [train main loss -1.994846], [lr 0.005143] [batchtime 0.434]
[epoch 85], [iter 39 / 176], [train main loss -1.945216], [lr 0.005143] [batchtime 0.433]
[epoch 85], [iter 40 / 176], [train main loss -1.994610], [lr 0.005143] [batchtime 0.432]
[epoch 85], [iter 41 / 176], [train main loss -1.996260], [lr 0.005143] [batchtime 0.43]
[epoch 85], [iter 42 / 176], [train main loss -2.003478], [lr 0.005143] [batchtime 0.429]
[epoch 85], [iter 43 / 176], [train main loss -1.975362], [lr 0.005143] [batchtime 0.428]
[epoch 85], [iter 44 / 176], [train main loss -1.988833], [lr 0.005143] [batchtime 0.427]
[epoch 85], [iter 45 / 176], [train main loss -2.004652], [lr 0.005143] [batchtime 0.426]
[epoch 85], [iter 46 / 176], [train main loss -2.006829], [lr 0.005143] [batchtime 0.425]
[epoch 85], [iter 47 / 176], [train main loss -1.966857], [lr 0.005143] [batchtime 0.425]
[epoch 85], [iter 48 / 176], [train main loss -1.938355], [lr 0.005143] [batchtime 0.424]
[epoch 85], [iter 49 / 176], [train main loss -1.968946], [lr 0.005143] [batchtime 0.423]
[epoch 85], [iter 50 / 176], [train main loss -1.968922], [lr 0.005143] [batchtime 0.423]
[epoch 85], [iter 51 / 176], [train main loss -1.965449], [lr 0.005143] [batchtime 0.422]
[epoch 85], [iter 52 / 176], [train main loss -1.946489], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 53 / 176], [train main loss -1.946775], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 54 / 176], [train main loss -1.991416], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 55 / 176], [train main loss -2.013555], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 56 / 176], [train main loss -2.018968], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 57 / 176], [train main loss -2.024396], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 58 / 176], [train main loss -2.081999], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 59 / 176], [train main loss -2.084040], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 60 / 176], [train main loss -2.061173], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 61 / 176], [train main loss -2.047358], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 62 / 176], [train main loss -2.070095], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 63 / 176], [train main loss -2.042943], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 64 / 176], [train main loss -2.024139], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 65 / 176], [train main loss -1.996679], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 66 / 176], [train main loss -2.011965], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 67 / 176], [train main loss -1.996136], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 68 / 176], [train main loss -2.004788], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 69 / 176], [train main loss -2.056624], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 70 / 176], [train main loss -2.055308], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 71 / 176], [train main loss -2.050804], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 72 / 176], [train main loss -2.012638], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 73 / 176], [train main loss -2.024821], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 74 / 176], [train main loss -2.002642], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 75 / 176], [train main loss -1.995872], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 76 / 176], [train main loss -1.988408], [lr 0.005143] [batchtime 0.41]
[epoch 85], [iter 77 / 176], [train main loss -1.946941], [lr 0.005143] [batchtime 0.41]
[epoch 85], [iter 78 / 176], [train main loss -1.956129], [lr 0.005143] [batchtime 0.41]
[epoch 85], [iter 79 / 176], [train main loss -1.968624], [lr 0.005143] [batchtime 0.41]
[epoch 85], [iter 80 / 176], [train main loss -1.963928], [lr 0.005143] [batchtime 0.409]
[epoch 85], [iter 81 / 176], [train main loss -1.943357], [lr 0.005143] [batchtime 0.409]
[epoch 85], [iter 82 / 176], [train main loss -1.939534], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 83 / 176], [train main loss -1.949697], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 84 / 176], [train main loss -1.951109], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 85 / 176], [train main loss -1.939524], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 86 / 176], [train main loss -1.957525], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 87 / 176], [train main loss -1.965313], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 88 / 176], [train main loss -1.984601], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 89 / 176], [train main loss -1.973045], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 90 / 176], [train main loss -1.985431], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 91 / 176], [train main loss -1.996535], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 92 / 176], [train main loss -2.007523], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 93 / 176], [train main loss -1.982582], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 94 / 176], [train main loss -1.970557], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 95 / 176], [train main loss -1.967903], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 96 / 176], [train main loss -1.996149], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 97 / 176], [train main loss -1.960042], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 98 / 176], [train main loss -1.953087], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 99 / 176], [train main loss -1.923129], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 100 / 176], [train main loss -1.915248], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 101 / 176], [train main loss -1.947242], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 102 / 176], [train main loss -1.940790], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 103 / 176], [train main loss -1.947040], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 104 / 176], [train main loss -1.916456], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 105 / 176], [train main loss -1.933831], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 106 / 176], [train main loss -1.936510], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 107 / 176], [train main loss -1.928522], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 108 / 176], [train main loss -1.918479], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 109 / 176], [train main loss -1.889449], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 110 / 176], [train main loss -1.895109], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 111 / 176], [train main loss -1.910847], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 112 / 176], [train main loss -1.901752], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 113 / 176], [train main loss -1.881841], [lr 0.005143] [batchtime 0.413]
[epoch 85], [iter 114 / 176], [train main loss -1.875302], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 115 / 176], [train main loss -1.855291], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 116 / 176], [train main loss -1.895373], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 117 / 176], [train main loss -1.918111], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 118 / 176], [train main loss -1.896852], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 119 / 176], [train main loss -1.908907], [lr 0.005143] [batchtime 0.412]
[epoch 85], [iter 120 / 176], [train main loss -1.911857], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 121 / 176], [train main loss -1.914121], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 122 / 176], [train main loss -1.910474], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 123 / 176], [train main loss -1.924887], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 124 / 176], [train main loss -1.918038], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 125 / 176], [train main loss -1.934417], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 126 / 176], [train main loss -1.924918], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 127 / 176], [train main loss -1.935728], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 128 / 176], [train main loss -1.931518], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 129 / 176], [train main loss -1.895810], [lr 0.005143] [batchtime 0.411]
[epoch 85], [iter 130 / 176], [train main loss -1.902621], [lr 0.005143] [batchtime 0.41]
[epoch 85], [iter 131 / 176], [train main loss -1.892047], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 132 / 176], [train main loss -1.923036], [lr 0.005143] [batchtime 0.422]
[epoch 85], [iter 133 / 176], [train main loss -1.916006], [lr 0.005143] [batchtime 0.422]
[epoch 85], [iter 134 / 176], [train main loss -1.914590], [lr 0.005143] [batchtime 0.422]
[epoch 85], [iter 135 / 176], [train main loss -1.918171], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 136 / 176], [train main loss -1.915811], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 137 / 176], [train main loss -1.930637], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 138 / 176], [train main loss -1.922109], [lr 0.005143] [batchtime 0.421]
[epoch 85], [iter 139 / 176], [train main loss -1.917729], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 140 / 176], [train main loss -1.921861], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 141 / 176], [train main loss -1.936409], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 142 / 176], [train main loss -1.920151], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 143 / 176], [train main loss -1.923812], [lr 0.005143] [batchtime 0.42]
[epoch 85], [iter 144 / 176], [train main loss -1.930405], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 145 / 176], [train main loss -1.931446], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 146 / 176], [train main loss -1.929639], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 147 / 176], [train main loss -1.924568], [lr 0.005143] [batchtime 0.419]
[epoch 85], [iter 148 / 176], [train main loss -1.918510], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 149 / 176], [train main loss -1.937874], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 150 / 176], [train main loss -1.938644], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 151 / 176], [train main loss -1.936039], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 152 / 176], [train main loss -1.920747], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 153 / 176], [train main loss -1.905257], [lr 0.005143] [batchtime 0.418]
[epoch 85], [iter 154 / 176], [train main loss -1.900933], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 155 / 176], [train main loss -1.906877], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 156 / 176], [train main loss -1.908100], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 157 / 176], [train main loss -1.913175], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 158 / 176], [train main loss -1.916400], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 159 / 176], [train main loss -1.926361], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 160 / 176], [train main loss -1.945296], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 161 / 176], [train main loss -1.924521], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 162 / 176], [train main loss -1.937961], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 163 / 176], [train main loss -1.955648], [lr 0.005143] [batchtime 0.417]
[epoch 85], [iter 164 / 176], [train main loss -1.947416], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 165 / 176], [train main loss -1.942931], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 166 / 176], [train main loss -1.942229], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 167 / 176], [train main loss -1.942453], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 168 / 176], [train main loss -1.944330], [lr 0.005143] [batchtime 0.416]
[epoch 85], [iter 169 / 176], [train main loss -1.949586], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 170 / 176], [train main loss -1.936498], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 171 / 176], [train main loss -1.939858], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 172 / 176], [train main loss -1.922399], [lr 0.005143] [batchtime 0.415]
[epoch 85], [iter 173 / 176], [train main loss -1.943941], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 174 / 176], [train main loss -1.943638], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 175 / 176], [train main loss -1.948475], [lr 0.005143] [batchtime 0.414]
[epoch 85], [iter 176 / 176], [train main loss -1.947434], [lr 0.005143] [batchtime 0.414]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              93.76  35.72   0.02  0.05         0.98      0.95
   1  sidewalk          64.72   4.91   0.34  0.20         0.75      0.83
   2  building          85.41  24.96   0.06  0.11         0.94      0.90
   3  wall              13.67   0.10   4.69  1.62         0.18      0.38
   4  fence             20.03   0.29   3.37  0.62         0.23      0.62
   5  pole              35.31   0.50   1.27  0.57         0.44      0.64
   6  traffic light      7.95   0.01  11.17  0.40         0.08      0.71
   7  traffic sign      12.20   0.07   6.96  0.24         0.13      0.81
   8  vegetation        83.05  11.64   0.06  0.14         0.94      0.88
   9  terrain           37.04   0.33   1.25  0.45         0.44      0.69
  10  sky               93.33   3.75   0.03  0.04         0.97      0.96
  11  person            49.91   1.01   0.52  0.48         0.66      0.67
  12  rider              5.96   0.01  14.50  1.27         0.06      0.44
  13  car               84.34   6.65   0.06  0.12         0.94      0.89
  14  truck              1.92   0.01  50.46  0.54         0.02      0.65
  15  bus               12.52   0.04   1.29  5.70         0.44      0.15
  16  train             27.19   0.07   1.68  0.99         0.37      0.50
  17  motorcycle         2.43   0.00  39.55  0.61         0.02      0.62
  18  bicycle           35.45   0.20   0.93  0.89         0.52      0.53
Mean: 40.33
-----------------------------------------------------------------------------------------------------------
this : [epoch 85], [val loss 0.33707], [acc 0.90260], [acc_cls 0.47937], [mean_iu 0.40327], [fwavacc 0.82974]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 86], [iter 1 / 176], [train main loss -2.220759], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 2 / 176], [train main loss -1.598984], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 3 / 176], [train main loss -1.295206], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 4 / 176], [train main loss -0.616490], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 5 / 176], [train main loss -0.713263], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 6 / 176], [train main loss -0.904165], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 7 / 176], [train main loss -1.119231], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 8 / 176], [train main loss -1.347586], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 9 / 176], [train main loss -1.472560], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 10 / 176], [train main loss -1.555126], [lr 0.005086] [batchtime 0]
[epoch 86], [iter 11 / 176], [train main loss -1.807695], [lr 0.005086] [batchtime 0.378]
[epoch 86], [iter 12 / 176], [train main loss -1.910582], [lr 0.005086] [batchtime 0.387]
[epoch 86], [iter 13 / 176], [train main loss -1.948533], [lr 0.005086] [batchtime 0.388]
[epoch 86], [iter 14 / 176], [train main loss -1.904185], [lr 0.005086] [batchtime 0.391]
[epoch 86], [iter 15 / 176], [train main loss -1.784162], [lr 0.005086] [batchtime 0.391]
[epoch 86], [iter 16 / 176], [train main loss -1.661490], [lr 0.005086] [batchtime 0.393]
[epoch 86], [iter 17 / 176], [train main loss -1.602755], [lr 0.005086] [batchtime 0.393]
[epoch 86], [iter 18 / 176], [train main loss -1.802745], [lr 0.005086] [batchtime 0.393]
[epoch 86], [iter 19 / 176], [train main loss -1.798455], [lr 0.005086] [batchtime 0.394]
[epoch 86], [iter 20 / 176], [train main loss -1.853889], [lr 0.005086] [batchtime 0.395]
[epoch 86], [iter 21 / 176], [train main loss -1.963291], [lr 0.005086] [batchtime 0.394]
[epoch 86], [iter 22 / 176], [train main loss -1.970772], [lr 0.005086] [batchtime 0.394]
[epoch 86], [iter 23 / 176], [train main loss -1.958310], [lr 0.005086] [batchtime 0.395]
[epoch 86], [iter 24 / 176], [train main loss -1.926168], [lr 0.005086] [batchtime 0.396]
[epoch 86], [iter 25 / 176], [train main loss -1.889952], [lr 0.005086] [batchtime 0.396]
[epoch 86], [iter 26 / 176], [train main loss -1.915071], [lr 0.005086] [batchtime 0.397]
[epoch 86], [iter 27 / 176], [train main loss -1.839368], [lr 0.005086] [batchtime 0.397]
[epoch 86], [iter 28 / 176], [train main loss -1.969550], [lr 0.005086] [batchtime 0.397]
[epoch 86], [iter 29 / 176], [train main loss -2.075908], [lr 0.005086] [batchtime 0.397]
[epoch 86], [iter 30 / 176], [train main loss -2.058244], [lr 0.005086] [batchtime 0.397]
[epoch 86], [iter 31 / 176], [train main loss -2.133895], [lr 0.005086] [batchtime 0.404]
[epoch 86], [iter 32 / 176], [train main loss -2.101474], [lr 0.005086] [batchtime 0.479]
[epoch 86], [iter 33 / 176], [train main loss -2.143185], [lr 0.005086] [batchtime 0.479]
[epoch 86], [iter 34 / 176], [train main loss -2.201991], [lr 0.005086] [batchtime 0.475]
[epoch 86], [iter 35 / 176], [train main loss -2.241419], [lr 0.005086] [batchtime 0.472]
[epoch 86], [iter 36 / 176], [train main loss -2.215524], [lr 0.005086] [batchtime 0.469]
[epoch 86], [iter 37 / 176], [train main loss -2.195649], [lr 0.005086] [batchtime 0.466]
[epoch 86], [iter 38 / 176], [train main loss -2.182656], [lr 0.005086] [batchtime 0.464]
[epoch 86], [iter 39 / 176], [train main loss -2.062889], [lr 0.005086] [batchtime 0.461]
[epoch 86], [iter 40 / 176], [train main loss -2.012852], [lr 0.005086] [batchtime 0.459]
[epoch 86], [iter 41 / 176], [train main loss -2.017547], [lr 0.005086] [batchtime 0.457]
[epoch 86], [iter 42 / 176], [train main loss -2.000620], [lr 0.005086] [batchtime 0.455]
[epoch 86], [iter 43 / 176], [train main loss -1.978901], [lr 0.005086] [batchtime 0.453]
[epoch 86], [iter 44 / 176], [train main loss -1.942368], [lr 0.005086] [batchtime 0.452]
[epoch 86], [iter 45 / 176], [train main loss -1.995301], [lr 0.005086] [batchtime 0.45]
[epoch 86], [iter 46 / 176], [train main loss -2.027601], [lr 0.005086] [batchtime 0.449]
[epoch 86], [iter 47 / 176], [train main loss -1.979155], [lr 0.005086] [batchtime 0.447]
[epoch 86], [iter 48 / 176], [train main loss -1.971741], [lr 0.005086] [batchtime 0.446]
[epoch 86], [iter 49 / 176], [train main loss -1.922812], [lr 0.005086] [batchtime 0.445]
[epoch 86], [iter 50 / 176], [train main loss -1.923836], [lr 0.005086] [batchtime 0.444]
[epoch 86], [iter 51 / 176], [train main loss -1.886562], [lr 0.005086] [batchtime 0.443]
[epoch 86], [iter 52 / 176], [train main loss -1.908537], [lr 0.005086] [batchtime 0.442]
[epoch 86], [iter 53 / 176], [train main loss -1.926630], [lr 0.005086] [batchtime 0.441]
[epoch 86], [iter 54 / 176], [train main loss -1.936660], [lr 0.005086] [batchtime 0.44]
[epoch 86], [iter 55 / 176], [train main loss -1.918414], [lr 0.005086] [batchtime 0.439]
[epoch 86], [iter 56 / 176], [train main loss -1.949671], [lr 0.005086] [batchtime 0.438]
[epoch 86], [iter 57 / 176], [train main loss -1.884402], [lr 0.005086] [batchtime 0.441]
[epoch 86], [iter 58 / 176], [train main loss -1.911133], [lr 0.005086] [batchtime 0.44]
[epoch 86], [iter 59 / 176], [train main loss -1.922326], [lr 0.005086] [batchtime 0.439]
[epoch 86], [iter 60 / 176], [train main loss -1.975497], [lr 0.005086] [batchtime 0.438]
[epoch 86], [iter 61 / 176], [train main loss -1.995063], [lr 0.005086] [batchtime 0.437]
[epoch 86], [iter 62 / 176], [train main loss -1.987007], [lr 0.005086] [batchtime 0.436]
[epoch 86], [iter 63 / 176], [train main loss -1.994670], [lr 0.005086] [batchtime 0.436]
[epoch 86], [iter 64 / 176], [train main loss -2.006674], [lr 0.005086] [batchtime 0.435]
[epoch 86], [iter 65 / 176], [train main loss -2.001837], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 66 / 176], [train main loss -1.994206], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 67 / 176], [train main loss -2.006877], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 68 / 176], [train main loss -2.017497], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 69 / 176], [train main loss -2.045606], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 70 / 176], [train main loss -2.032082], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 71 / 176], [train main loss -2.033759], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 72 / 176], [train main loss -2.021092], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 73 / 176], [train main loss -2.027775], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 74 / 176], [train main loss -2.045462], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 75 / 176], [train main loss -2.071986], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 76 / 176], [train main loss -2.030939], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 77 / 176], [train main loss -1.968928], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 78 / 176], [train main loss -1.944713], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 79 / 176], [train main loss -1.948959], [lr 0.005086] [batchtime 0.426]
[epoch 86], [iter 80 / 176], [train main loss -1.920123], [lr 0.005086] [batchtime 0.426]
[epoch 86], [iter 81 / 176], [train main loss -1.939013], [lr 0.005086] [batchtime 0.438]
[epoch 86], [iter 82 / 176], [train main loss -1.906551], [lr 0.005086] [batchtime 0.44]
[epoch 86], [iter 83 / 176], [train main loss -1.904182], [lr 0.005086] [batchtime 0.439]
[epoch 86], [iter 84 / 176], [train main loss -1.930318], [lr 0.005086] [batchtime 0.443]
[epoch 86], [iter 85 / 176], [train main loss -1.937798], [lr 0.005086] [batchtime 0.442]
[epoch 86], [iter 86 / 176], [train main loss -1.920375], [lr 0.005086] [batchtime 0.441]
[epoch 86], [iter 87 / 176], [train main loss -1.916815], [lr 0.005086] [batchtime 0.44]
[epoch 86], [iter 88 / 176], [train main loss -1.912550], [lr 0.005086] [batchtime 0.44]
[epoch 86], [iter 89 / 176], [train main loss -1.914357], [lr 0.005086] [batchtime 0.439]
[epoch 86], [iter 90 / 176], [train main loss -1.914402], [lr 0.005086] [batchtime 0.439]
[epoch 86], [iter 91 / 176], [train main loss -1.913013], [lr 0.005086] [batchtime 0.438]
[epoch 86], [iter 92 / 176], [train main loss -1.930937], [lr 0.005086] [batchtime 0.438]
[epoch 86], [iter 93 / 176], [train main loss -1.974961], [lr 0.005086] [batchtime 0.437]
[epoch 86], [iter 94 / 176], [train main loss -1.993607], [lr 0.005086] [batchtime 0.437]
[epoch 86], [iter 95 / 176], [train main loss -1.990837], [lr 0.005086] [batchtime 0.436]
[epoch 86], [iter 96 / 176], [train main loss -2.008384], [lr 0.005086] [batchtime 0.436]
[epoch 86], [iter 97 / 176], [train main loss -1.989039], [lr 0.005086] [batchtime 0.435]
[epoch 86], [iter 98 / 176], [train main loss -1.990605], [lr 0.005086] [batchtime 0.435]
[epoch 86], [iter 99 / 176], [train main loss -1.977644], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 100 / 176], [train main loss -1.993143], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 101 / 176], [train main loss -2.003449], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 102 / 176], [train main loss -1.992213], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 103 / 176], [train main loss -2.005691], [lr 0.005086] [batchtime 0.435]
[epoch 86], [iter 104 / 176], [train main loss -2.003123], [lr 0.005086] [batchtime 0.435]
[epoch 86], [iter 105 / 176], [train main loss -2.043499], [lr 0.005086] [batchtime 0.435]
[epoch 86], [iter 106 / 176], [train main loss -2.034714], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 107 / 176], [train main loss -2.042965], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 108 / 176], [train main loss -2.047440], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 109 / 176], [train main loss -2.058758], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 110 / 176], [train main loss -2.063155], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 111 / 176], [train main loss -2.073170], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 112 / 176], [train main loss -2.071208], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 113 / 176], [train main loss -2.044445], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 114 / 176], [train main loss -2.050540], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 115 / 176], [train main loss -2.048106], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 116 / 176], [train main loss -2.037771], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 117 / 176], [train main loss -2.039972], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 118 / 176], [train main loss -2.036418], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 119 / 176], [train main loss -2.035594], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 120 / 176], [train main loss -2.036124], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 121 / 176], [train main loss -2.036296], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 122 / 176], [train main loss -2.051676], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 123 / 176], [train main loss -2.053894], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 124 / 176], [train main loss -2.037257], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 125 / 176], [train main loss -2.019549], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 126 / 176], [train main loss -2.037285], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 127 / 176], [train main loss -2.031192], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 128 / 176], [train main loss -2.027471], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 129 / 176], [train main loss -2.041039], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 130 / 176], [train main loss -2.052678], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 131 / 176], [train main loss -2.051364], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 132 / 176], [train main loss -2.044742], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 133 / 176], [train main loss -2.052373], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 134 / 176], [train main loss -2.041562], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 135 / 176], [train main loss -2.039125], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 136 / 176], [train main loss -2.047513], [lr 0.005086] [batchtime 0.434]
[epoch 86], [iter 137 / 176], [train main loss -2.056303], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 138 / 176], [train main loss -2.074060], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 139 / 176], [train main loss -2.047213], [lr 0.005086] [batchtime 0.433]
[epoch 86], [iter 140 / 176], [train main loss -2.056154], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 141 / 176], [train main loss -2.058608], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 142 / 176], [train main loss -2.068342], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 143 / 176], [train main loss -2.067377], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 144 / 176], [train main loss -2.070954], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 145 / 176], [train main loss -2.064428], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 146 / 176], [train main loss -2.061414], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 147 / 176], [train main loss -2.053383], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 148 / 176], [train main loss -2.042117], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 149 / 176], [train main loss -2.036823], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 150 / 176], [train main loss -2.036700], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 151 / 176], [train main loss -2.033246], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 152 / 176], [train main loss -2.035499], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 153 / 176], [train main loss -2.039199], [lr 0.005086] [batchtime 0.432]
[epoch 86], [iter 154 / 176], [train main loss -2.021541], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 155 / 176], [train main loss -2.024343], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 156 / 176], [train main loss -2.014721], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 157 / 176], [train main loss -2.007662], [lr 0.005086] [batchtime 0.431]
[epoch 86], [iter 158 / 176], [train main loss -1.992992], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 159 / 176], [train main loss -1.991298], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 160 / 176], [train main loss -1.983691], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 161 / 176], [train main loss -1.992640], [lr 0.005086] [batchtime 0.43]
[epoch 86], [iter 162 / 176], [train main loss -1.991028], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 163 / 176], [train main loss -1.994861], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 164 / 176], [train main loss -1.994919], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 165 / 176], [train main loss -2.002038], [lr 0.005086] [batchtime 0.429]
[epoch 86], [iter 166 / 176], [train main loss -1.998303], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 167 / 176], [train main loss -1.997677], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 168 / 176], [train main loss -1.991232], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 169 / 176], [train main loss -1.998516], [lr 0.005086] [batchtime 0.428]
[epoch 86], [iter 170 / 176], [train main loss -1.997104], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 171 / 176], [train main loss -2.013226], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 172 / 176], [train main loss -1.997171], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 173 / 176], [train main loss -2.003444], [lr 0.005086] [batchtime 0.426]
[epoch 86], [iter 174 / 176], [train main loss -2.014834], [lr 0.005086] [batchtime 0.426]
[epoch 86], [iter 175 / 176], [train main loss -2.000364], [lr 0.005086] [batchtime 0.427]
[epoch 86], [iter 176 / 176], [train main loss -2.006248], [lr 0.005086] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.04  35.26   0.03  0.03         0.97      0.97
   1  sidewalk          67.64   5.29   0.25  0.23         0.80      0.81
   2  building          85.32  24.62   0.08  0.09         0.93      0.92
   3  wall              16.69   0.15   2.99  2.00         0.25      0.33
   4  fence             23.30   0.37   2.42  0.88         0.29      0.53
   5  pole              36.61   0.53   1.15  0.58         0.46      0.63
   6  traffic light     14.00   0.02   5.32  0.82         0.16      0.55
   7  traffic sign      17.61   0.10   4.42  0.26         0.18      0.80
   8  vegetation        82.82  11.65   0.06  0.15         0.94      0.87
   9  terrain           40.25   0.39   0.91  0.58         0.52      0.63
  10  sky               93.20   3.73   0.04  0.04         0.96      0.97
  11  person            50.18   1.06   0.44  0.55         0.69      0.64
  12  rider              4.82   0.00  18.50  1.24         0.05      0.45
  13  car               83.59   6.73   0.05  0.15         0.95      0.87
  14  truck              1.12   0.00  87.37  0.68         0.01      0.59
  15  bus               13.65   0.04   1.24  5.08         0.45      0.16
  16  train             19.42   0.05   2.66  1.49         0.27      0.40
  17  motorcycle         2.24   0.00  43.10  0.53         0.02      0.65
  18  bicycle           36.22   0.23   0.68  1.08         0.59      0.48
Mean: 41.20
-----------------------------------------------------------------------------------------------------------
this : [epoch 86], [val loss 0.32432], [acc 0.90236], [acc_cls 0.50120], [mean_iu 0.41196], [fwavacc 0.83285]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 87], [iter 1 / 176], [train main loss -1.622046], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 2 / 176], [train main loss -2.336096], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 3 / 176], [train main loss -3.208308], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 4 / 176], [train main loss -2.449018], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 5 / 176], [train main loss -2.082708], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 6 / 176], [train main loss -2.001962], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 7 / 176], [train main loss -1.566056], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 8 / 176], [train main loss -1.795822], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 9 / 176], [train main loss -1.774041], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 10 / 176], [train main loss -1.988927], [lr 0.005029] [batchtime 0]
[epoch 87], [iter 11 / 176], [train main loss -1.810072], [lr 0.005029] [batchtime 0.369]
[epoch 87], [iter 12 / 176], [train main loss -1.823805], [lr 0.005029] [batchtime 0.385]
[epoch 87], [iter 13 / 176], [train main loss -1.907469], [lr 0.005029] [batchtime 0.389]
[epoch 87], [iter 14 / 176], [train main loss -1.894655], [lr 0.005029] [batchtime 0.392]
[epoch 87], [iter 15 / 176], [train main loss -1.808167], [lr 0.005029] [batchtime 0.392]
[epoch 87], [iter 16 / 176], [train main loss -1.783051], [lr 0.005029] [batchtime 0.394]
[epoch 87], [iter 17 / 176], [train main loss -1.884224], [lr 0.005029] [batchtime 0.394]
[epoch 87], [iter 18 / 176], [train main loss -1.971492], [lr 0.005029] [batchtime 0.392]
[epoch 87], [iter 19 / 176], [train main loss -1.884203], [lr 0.005029] [batchtime 0.393]
[epoch 87], [iter 20 / 176], [train main loss -1.846924], [lr 0.005029] [batchtime 0.394]
[epoch 87], [iter 21 / 176], [train main loss -1.826465], [lr 0.005029] [batchtime 0.394]
[epoch 87], [iter 22 / 176], [train main loss -1.796556], [lr 0.005029] [batchtime 0.394]
[epoch 87], [iter 23 / 176], [train main loss -1.792841], [lr 0.005029] [batchtime 0.394]
[epoch 87], [iter 24 / 176], [train main loss -1.794720], [lr 0.005029] [batchtime 0.395]
[epoch 87], [iter 25 / 176], [train main loss -1.741227], [lr 0.005029] [batchtime 0.395]
[epoch 87], [iter 26 / 176], [train main loss -1.680410], [lr 0.005029] [batchtime 0.396]
[epoch 87], [iter 27 / 176], [train main loss -1.698262], [lr 0.005029] [batchtime 0.395]
[epoch 87], [iter 28 / 176], [train main loss -1.826827], [lr 0.005029] [batchtime 0.408]
[epoch 87], [iter 29 / 176], [train main loss -1.779339], [lr 0.005029] [batchtime 0.407]
[epoch 87], [iter 30 / 176], [train main loss -1.739989], [lr 0.005029] [batchtime 0.406]
[epoch 87], [iter 31 / 176], [train main loss -1.737335], [lr 0.005029] [batchtime 0.406]
[epoch 87], [iter 32 / 176], [train main loss -1.788030], [lr 0.005029] [batchtime 0.405]
[epoch 87], [iter 33 / 176], [train main loss -1.807627], [lr 0.005029] [batchtime 0.405]
[epoch 87], [iter 34 / 176], [train main loss -1.713864], [lr 0.005029] [batchtime 0.411]
[epoch 87], [iter 35 / 176], [train main loss -1.704580], [lr 0.005029] [batchtime 0.453]
[epoch 87], [iter 36 / 176], [train main loss -1.729769], [lr 0.005029] [batchtime 0.451]
[epoch 87], [iter 37 / 176], [train main loss -1.808469], [lr 0.005029] [batchtime 0.448]
[epoch 87], [iter 38 / 176], [train main loss -1.824470], [lr 0.005029] [batchtime 0.446]
[epoch 87], [iter 39 / 176], [train main loss -1.804041], [lr 0.005029] [batchtime 0.444]
[epoch 87], [iter 40 / 176], [train main loss -1.812443], [lr 0.005029] [batchtime 0.442]
[epoch 87], [iter 41 / 176], [train main loss -1.818176], [lr 0.005029] [batchtime 0.441]
[epoch 87], [iter 42 / 176], [train main loss -1.867521], [lr 0.005029] [batchtime 0.439]
[epoch 87], [iter 43 / 176], [train main loss -1.886602], [lr 0.005029] [batchtime 0.438]
[epoch 87], [iter 44 / 176], [train main loss -1.900200], [lr 0.005029] [batchtime 0.437]
[epoch 87], [iter 45 / 176], [train main loss -1.892505], [lr 0.005029] [batchtime 0.436]
[epoch 87], [iter 46 / 176], [train main loss -1.890795], [lr 0.005029] [batchtime 0.435]
[epoch 87], [iter 47 / 176], [train main loss -1.851391], [lr 0.005029] [batchtime 0.434]
[epoch 87], [iter 48 / 176], [train main loss -1.823676], [lr 0.005029] [batchtime 0.433]
[epoch 87], [iter 49 / 176], [train main loss -1.811286], [lr 0.005029] [batchtime 0.432]
[epoch 87], [iter 50 / 176], [train main loss -1.834130], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 51 / 176], [train main loss -1.781122], [lr 0.005029] [batchtime 0.43]
[epoch 87], [iter 52 / 176], [train main loss -1.791235], [lr 0.005029] [batchtime 0.444]
[epoch 87], [iter 53 / 176], [train main loss -1.800268], [lr 0.005029] [batchtime 0.442]
[epoch 87], [iter 54 / 176], [train main loss -1.823065], [lr 0.005029] [batchtime 0.441]
[epoch 87], [iter 55 / 176], [train main loss -1.806606], [lr 0.005029] [batchtime 0.44]
[epoch 87], [iter 56 / 176], [train main loss -1.785860], [lr 0.005029] [batchtime 0.439]
[epoch 87], [iter 57 / 176], [train main loss -1.842852], [lr 0.005029] [batchtime 0.438]
[epoch 87], [iter 58 / 176], [train main loss -1.875872], [lr 0.005029] [batchtime 0.437]
[epoch 87], [iter 59 / 176], [train main loss -1.852832], [lr 0.005029] [batchtime 0.437]
[epoch 87], [iter 60 / 176], [train main loss -1.837337], [lr 0.005029] [batchtime 0.436]
[epoch 87], [iter 61 / 176], [train main loss -1.819345], [lr 0.005029] [batchtime 0.435]
[epoch 87], [iter 62 / 176], [train main loss -1.846160], [lr 0.005029] [batchtime 0.434]
[epoch 87], [iter 63 / 176], [train main loss -1.826966], [lr 0.005029] [batchtime 0.434]
[epoch 87], [iter 64 / 176], [train main loss -1.840239], [lr 0.005029] [batchtime 0.433]
[epoch 87], [iter 65 / 176], [train main loss -1.843451], [lr 0.005029] [batchtime 0.432]
[epoch 87], [iter 66 / 176], [train main loss -1.843264], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 67 / 176], [train main loss -1.884438], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 68 / 176], [train main loss -1.902814], [lr 0.005029] [batchtime 0.43]
[epoch 87], [iter 69 / 176], [train main loss -1.909688], [lr 0.005029] [batchtime 0.43]
[epoch 87], [iter 70 / 176], [train main loss -1.934385], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 71 / 176], [train main loss -1.930834], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 72 / 176], [train main loss -1.920260], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 73 / 176], [train main loss -1.900666], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 74 / 176], [train main loss -1.919373], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 75 / 176], [train main loss -1.905946], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 76 / 176], [train main loss -1.887901], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 77 / 176], [train main loss -1.887312], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 78 / 176], [train main loss -1.880487], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 79 / 176], [train main loss -1.916015], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 80 / 176], [train main loss -1.923788], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 81 / 176], [train main loss -1.937395], [lr 0.005029] [batchtime 0.434]
[epoch 87], [iter 82 / 176], [train main loss -1.918150], [lr 0.005029] [batchtime 0.436]
[epoch 87], [iter 83 / 176], [train main loss -1.907580], [lr 0.005029] [batchtime 0.435]
[epoch 87], [iter 84 / 176], [train main loss -1.955036], [lr 0.005029] [batchtime 0.435]
[epoch 87], [iter 85 / 176], [train main loss -1.981496], [lr 0.005029] [batchtime 0.434]
[epoch 87], [iter 86 / 176], [train main loss -2.003328], [lr 0.005029] [batchtime 0.433]
[epoch 87], [iter 87 / 176], [train main loss -1.993161], [lr 0.005029] [batchtime 0.433]
[epoch 87], [iter 88 / 176], [train main loss -1.983859], [lr 0.005029] [batchtime 0.432]
[epoch 87], [iter 89 / 176], [train main loss -1.965234], [lr 0.005029] [batchtime 0.432]
[epoch 87], [iter 90 / 176], [train main loss -2.003951], [lr 0.005029] [batchtime 0.432]
[epoch 87], [iter 91 / 176], [train main loss -1.998098], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 92 / 176], [train main loss -1.960105], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 93 / 176], [train main loss -1.968837], [lr 0.005029] [batchtime 0.43]
[epoch 87], [iter 94 / 176], [train main loss -1.962119], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 95 / 176], [train main loss -1.950814], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 96 / 176], [train main loss -1.953330], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 97 / 176], [train main loss -1.945285], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 98 / 176], [train main loss -1.962693], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 99 / 176], [train main loss -1.976819], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 100 / 176], [train main loss -1.960388], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 101 / 176], [train main loss -1.961105], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 102 / 176], [train main loss -1.971321], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 103 / 176], [train main loss -2.000192], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 104 / 176], [train main loss -1.975981], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 105 / 176], [train main loss -1.972172], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 106 / 176], [train main loss -1.993991], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 107 / 176], [train main loss -1.969068], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 108 / 176], [train main loss -2.006790], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 109 / 176], [train main loss -2.006414], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 110 / 176], [train main loss -1.988702], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 111 / 176], [train main loss -1.994114], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 112 / 176], [train main loss -1.991851], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 113 / 176], [train main loss -1.965289], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 114 / 176], [train main loss -1.971522], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 115 / 176], [train main loss -1.985611], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 116 / 176], [train main loss -1.988860], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 117 / 176], [train main loss -1.995933], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 118 / 176], [train main loss -2.004774], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 119 / 176], [train main loss -2.006151], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 120 / 176], [train main loss -1.995484], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 121 / 176], [train main loss -1.999298], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 122 / 176], [train main loss -2.003816], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 123 / 176], [train main loss -2.007189], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 124 / 176], [train main loss -2.018638], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 125 / 176], [train main loss -2.018218], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 126 / 176], [train main loss -2.006778], [lr 0.005029] [batchtime 0.419]
[epoch 87], [iter 127 / 176], [train main loss -2.008776], [lr 0.005029] [batchtime 0.419]
[epoch 87], [iter 128 / 176], [train main loss -1.996391], [lr 0.005029] [batchtime 0.419]
[epoch 87], [iter 129 / 176], [train main loss -1.985693], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 130 / 176], [train main loss -1.994490], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 131 / 176], [train main loss -2.002683], [lr 0.005029] [batchtime 0.431]
[epoch 87], [iter 132 / 176], [train main loss -1.998093], [lr 0.005029] [batchtime 0.43]
[epoch 87], [iter 133 / 176], [train main loss -1.999023], [lr 0.005029] [batchtime 0.43]
[epoch 87], [iter 134 / 176], [train main loss -1.983776], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 135 / 176], [train main loss -1.981101], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 136 / 176], [train main loss -1.981961], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 137 / 176], [train main loss -1.959877], [lr 0.005029] [batchtime 0.429]
[epoch 87], [iter 138 / 176], [train main loss -1.969900], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 139 / 176], [train main loss -1.961089], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 140 / 176], [train main loss -1.980451], [lr 0.005029] [batchtime 0.428]
[epoch 87], [iter 141 / 176], [train main loss -1.984181], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 142 / 176], [train main loss -1.986142], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 143 / 176], [train main loss -1.988377], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 144 / 176], [train main loss -1.998876], [lr 0.005029] [batchtime 0.427]
[epoch 87], [iter 145 / 176], [train main loss -1.995494], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 146 / 176], [train main loss -1.998930], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 147 / 176], [train main loss -1.994907], [lr 0.005029] [batchtime 0.426]
[epoch 87], [iter 148 / 176], [train main loss -1.986569], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 149 / 176], [train main loss -1.978457], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 150 / 176], [train main loss -1.983451], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 151 / 176], [train main loss -1.982487], [lr 0.005029] [batchtime 0.425]
[epoch 87], [iter 152 / 176], [train main loss -1.980087], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 153 / 176], [train main loss -1.969540], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 154 / 176], [train main loss -1.968005], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 155 / 176], [train main loss -1.963025], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 156 / 176], [train main loss -1.978938], [lr 0.005029] [batchtime 0.424]
[epoch 87], [iter 157 / 176], [train main loss -1.977307], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 158 / 176], [train main loss -1.980997], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 159 / 176], [train main loss -1.982448], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 160 / 176], [train main loss -1.989086], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 161 / 176], [train main loss -1.986814], [lr 0.005029] [batchtime 0.423]
[epoch 87], [iter 162 / 176], [train main loss -1.996308], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 163 / 176], [train main loss -1.990238], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 164 / 176], [train main loss -1.980468], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 165 / 176], [train main loss -1.968547], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 166 / 176], [train main loss -1.979949], [lr 0.005029] [batchtime 0.422]
[epoch 87], [iter 167 / 176], [train main loss -1.972670], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 168 / 176], [train main loss -1.978711], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 169 / 176], [train main loss -1.987100], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 170 / 176], [train main loss -1.993340], [lr 0.005029] [batchtime 0.421]
[epoch 87], [iter 171 / 176], [train main loss -1.984183], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 172 / 176], [train main loss -2.005567], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 173 / 176], [train main loss -2.015737], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 174 / 176], [train main loss -2.010870], [lr 0.005029] [batchtime 0.42]
[epoch 87], [iter 175 / 176], [train main loss -2.008140], [lr 0.005029] [batchtime 0.419]
[epoch 87], [iter 176 / 176], [train main loss -2.000842], [lr 0.005029] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.21  35.44    0.03  0.04         0.97      0.97
   1  sidewalk          67.07   5.21    0.27  0.23         0.79      0.82
   2  building          85.66  25.34    0.05  0.12         0.95      0.89
   3  wall              16.89   0.14    3.36  1.56         0.23      0.39
   4  fence             21.29   0.31    3.08  0.62         0.25      0.62
   5  pole              35.62   0.49    1.30  0.51         0.43      0.66
   6  traffic light     10.31   0.02    8.14  0.56         0.11      0.64
   7  traffic sign      15.39   0.09    5.28  0.22         0.16      0.82
   8  vegetation        83.46  11.55    0.07  0.13         0.93      0.89
   9  terrain           38.41   0.34    1.13  0.47         0.47      0.68
  10  sky               93.51   3.74    0.04  0.03         0.97      0.97
  11  person            47.53   0.88    0.74  0.37         0.58      0.73
  12  rider              5.48   0.01   15.74  1.52         0.06      0.40
  13  car               85.35   6.62    0.07  0.10         0.94      0.91
  14  truck              0.72   0.00  137.09  0.39         0.01      0.72
  15  bus               15.79   0.03    1.68  3.65         0.37      0.22
  16  train             36.19   0.08    1.34  0.42         0.43      0.70
  17  motorcycle         2.30   0.00   41.72  0.85         0.02      0.54
  18  bicycle           32.74   0.26    0.47  1.58         0.68      0.39
Mean: 41.47
-----------------------------------------------------------------------------------------------------------
this : [epoch 87], [val loss 0.33309], [acc 0.90545], [acc_cls 0.49178], [mean_iu 0.41470], [fwavacc 0.83525]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 88], [iter 1 / 176], [train main loss -4.499423], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 2 / 176], [train main loss -2.779989], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 3 / 176], [train main loss -2.794770], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 4 / 176], [train main loss -2.774475], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 5 / 176], [train main loss -2.310356], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 6 / 176], [train main loss -2.240455], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 7 / 176], [train main loss -2.088352], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 8 / 176], [train main loss -1.973847], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 9 / 176], [train main loss -1.799817], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 10 / 176], [train main loss -1.806920], [lr 0.004971] [batchtime 0]
[epoch 88], [iter 11 / 176], [train main loss -1.638064], [lr 0.004971] [batchtime 0.376]
[epoch 88], [iter 12 / 176], [train main loss -1.551059], [lr 0.004971] [batchtime 0.385]
[epoch 88], [iter 13 / 176], [train main loss -1.554208], [lr 0.004971] [batchtime 0.387]
[epoch 88], [iter 14 / 176], [train main loss -1.473665], [lr 0.004971] [batchtime 0.39]
[epoch 88], [iter 15 / 176], [train main loss -1.438554], [lr 0.004971] [batchtime 0.391]
[epoch 88], [iter 16 / 176], [train main loss -1.570829], [lr 0.004971] [batchtime 0.393]
[epoch 88], [iter 17 / 176], [train main loss -1.590795], [lr 0.004971] [batchtime 0.392]
[epoch 88], [iter 18 / 176], [train main loss -1.669983], [lr 0.004971] [batchtime 0.393]
[epoch 88], [iter 19 / 176], [train main loss -1.792984], [lr 0.004971] [batchtime 0.393]
[epoch 88], [iter 20 / 176], [train main loss -1.878444], [lr 0.004971] [batchtime 0.395]
[epoch 88], [iter 21 / 176], [train main loss -1.816725], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 22 / 176], [train main loss -1.757473], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 23 / 176], [train main loss -1.759329], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 24 / 176], [train main loss -1.734476], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 25 / 176], [train main loss -1.833022], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 26 / 176], [train main loss -1.767694], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 27 / 176], [train main loss -1.761684], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 28 / 176], [train main loss -1.634910], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 29 / 176], [train main loss -1.594327], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 30 / 176], [train main loss -1.580462], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 31 / 176], [train main loss -1.575335], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 32 / 176], [train main loss -1.604509], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 33 / 176], [train main loss -1.564862], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 34 / 176], [train main loss -1.591665], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 35 / 176], [train main loss -1.619813], [lr 0.004971] [batchtime 0.394]
[epoch 88], [iter 36 / 176], [train main loss -1.602324], [lr 0.004971] [batchtime 0.395]
[epoch 88], [iter 37 / 176], [train main loss -1.574480], [lr 0.004971] [batchtime 0.403]
[epoch 88], [iter 38 / 176], [train main loss -1.556271], [lr 0.004971] [batchtime 0.403]
[epoch 88], [iter 39 / 176], [train main loss -1.622992], [lr 0.004971] [batchtime 0.402]
[epoch 88], [iter 40 / 176], [train main loss -1.689116], [lr 0.004971] [batchtime 0.402]
[epoch 88], [iter 41 / 176], [train main loss -1.713653], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 42 / 176], [train main loss -1.649477], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 43 / 176], [train main loss -1.604330], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 44 / 176], [train main loss -1.588585], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 45 / 176], [train main loss -1.597060], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 46 / 176], [train main loss -1.580905], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 47 / 176], [train main loss -1.608990], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 48 / 176], [train main loss -1.631535], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 49 / 176], [train main loss -1.630486], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 50 / 176], [train main loss -1.655564], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 51 / 176], [train main loss -1.696551], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 52 / 176], [train main loss -1.720488], [lr 0.004971] [batchtime 0.401]
[epoch 88], [iter 53 / 176], [train main loss -1.716665], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 54 / 176], [train main loss -1.744984], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 55 / 176], [train main loss -1.759150], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 56 / 176], [train main loss -1.766837], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 57 / 176], [train main loss -1.743496], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 58 / 176], [train main loss -1.750918], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 59 / 176], [train main loss -1.754428], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 60 / 176], [train main loss -1.743425], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 61 / 176], [train main loss -1.726332], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 62 / 176], [train main loss -1.771669], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 63 / 176], [train main loss -1.732076], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 64 / 176], [train main loss -1.741598], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 65 / 176], [train main loss -1.736754], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 66 / 176], [train main loss -1.723913], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 67 / 176], [train main loss -1.745963], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 68 / 176], [train main loss -1.738897], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 69 / 176], [train main loss -1.711376], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 70 / 176], [train main loss -1.698555], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 71 / 176], [train main loss -1.703528], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 72 / 176], [train main loss -1.687288], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 73 / 176], [train main loss -1.677338], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 74 / 176], [train main loss -1.674654], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 75 / 176], [train main loss -1.668006], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 76 / 176], [train main loss -1.689449], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 77 / 176], [train main loss -1.719412], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 78 / 176], [train main loss -1.752982], [lr 0.004971] [batchtime 0.399]
[epoch 88], [iter 79 / 176], [train main loss -1.748510], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 80 / 176], [train main loss -1.747631], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 81 / 176], [train main loss -1.753813], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 82 / 176], [train main loss -1.786901], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 83 / 176], [train main loss -1.777370], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 84 / 176], [train main loss -1.745117], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 85 / 176], [train main loss -1.757937], [lr 0.004971] [batchtime 0.398]
[epoch 88], [iter 86 / 176], [train main loss -1.748719], [lr 0.004971] [batchtime 0.4]
[epoch 88], [iter 87 / 176], [train main loss -1.726998], [lr 0.004971] [batchtime 0.418]
[epoch 88], [iter 88 / 176], [train main loss -1.724621], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 89 / 176], [train main loss -1.725578], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 90 / 176], [train main loss -1.706196], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 91 / 176], [train main loss -1.731790], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 92 / 176], [train main loss -1.727315], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 93 / 176], [train main loss -1.737938], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 94 / 176], [train main loss -1.713815], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 95 / 176], [train main loss -1.682510], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 96 / 176], [train main loss -1.684252], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 97 / 176], [train main loss -1.675578], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 98 / 176], [train main loss -1.679110], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 99 / 176], [train main loss -1.693830], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 100 / 176], [train main loss -1.714019], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 101 / 176], [train main loss -1.682907], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 102 / 176], [train main loss -1.691206], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 103 / 176], [train main loss -1.685551], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 104 / 176], [train main loss -1.687727], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 105 / 176], [train main loss -1.722962], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 106 / 176], [train main loss -1.739223], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 107 / 176], [train main loss -1.723471], [lr 0.004971] [batchtime 0.412]
[epoch 88], [iter 108 / 176], [train main loss -1.744096], [lr 0.004971] [batchtime 0.412]
[epoch 88], [iter 109 / 176], [train main loss -1.769625], [lr 0.004971] [batchtime 0.412]
[epoch 88], [iter 110 / 176], [train main loss -1.782990], [lr 0.004971] [batchtime 0.412]
[epoch 88], [iter 111 / 176], [train main loss -1.770024], [lr 0.004971] [batchtime 0.411]
[epoch 88], [iter 112 / 176], [train main loss -1.773216], [lr 0.004971] [batchtime 0.411]
[epoch 88], [iter 113 / 176], [train main loss -1.762956], [lr 0.004971] [batchtime 0.411]
[epoch 88], [iter 114 / 176], [train main loss -1.741485], [lr 0.004971] [batchtime 0.411]
[epoch 88], [iter 115 / 176], [train main loss -1.763646], [lr 0.004971] [batchtime 0.411]
[epoch 88], [iter 116 / 176], [train main loss -1.761472], [lr 0.004971] [batchtime 0.411]
[epoch 88], [iter 117 / 176], [train main loss -1.760995], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 118 / 176], [train main loss -1.727375], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 119 / 176], [train main loss -1.736412], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 120 / 176], [train main loss -1.759242], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 121 / 176], [train main loss -1.754666], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 122 / 176], [train main loss -1.774462], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 123 / 176], [train main loss -1.770056], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 124 / 176], [train main loss -1.786570], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 125 / 176], [train main loss -1.786413], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 126 / 176], [train main loss -1.776766], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 127 / 176], [train main loss -1.766677], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 128 / 176], [train main loss -1.773628], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 129 / 176], [train main loss -1.794314], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 130 / 176], [train main loss -1.823018], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 131 / 176], [train main loss -1.808521], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 132 / 176], [train main loss -1.803417], [lr 0.004971] [batchtime 0.409]
[epoch 88], [iter 133 / 176], [train main loss -1.808223], [lr 0.004971] [batchtime 0.41]
[epoch 88], [iter 134 / 176], [train main loss -1.798751], [lr 0.004971] [batchtime 0.421]
[epoch 88], [iter 135 / 176], [train main loss -1.814805], [lr 0.004971] [batchtime 0.421]
[epoch 88], [iter 136 / 176], [train main loss -1.821555], [lr 0.004971] [batchtime 0.421]
[epoch 88], [iter 137 / 176], [train main loss -1.834821], [lr 0.004971] [batchtime 0.42]
[epoch 88], [iter 138 / 176], [train main loss -1.835833], [lr 0.004971] [batchtime 0.42]
[epoch 88], [iter 139 / 176], [train main loss -1.837288], [lr 0.004971] [batchtime 0.42]
[epoch 88], [iter 140 / 176], [train main loss -1.824277], [lr 0.004971] [batchtime 0.42]
[epoch 88], [iter 141 / 176], [train main loss -1.825171], [lr 0.004971] [batchtime 0.42]
[epoch 88], [iter 142 / 176], [train main loss -1.821562], [lr 0.004971] [batchtime 0.419]
[epoch 88], [iter 143 / 176], [train main loss -1.827638], [lr 0.004971] [batchtime 0.419]
[epoch 88], [iter 144 / 176], [train main loss -1.848151], [lr 0.004971] [batchtime 0.419]
[epoch 88], [iter 145 / 176], [train main loss -1.842661], [lr 0.004971] [batchtime 0.419]
[epoch 88], [iter 146 / 176], [train main loss -1.844458], [lr 0.004971] [batchtime 0.419]
[epoch 88], [iter 147 / 176], [train main loss -1.837237], [lr 0.004971] [batchtime 0.418]
[epoch 88], [iter 148 / 176], [train main loss -1.846379], [lr 0.004971] [batchtime 0.418]
[epoch 88], [iter 149 / 176], [train main loss -1.850280], [lr 0.004971] [batchtime 0.418]
[epoch 88], [iter 150 / 176], [train main loss -1.858808], [lr 0.004971] [batchtime 0.418]
[epoch 88], [iter 151 / 176], [train main loss -1.854605], [lr 0.004971] [batchtime 0.418]
[epoch 88], [iter 152 / 176], [train main loss -1.868937], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 153 / 176], [train main loss -1.893665], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 154 / 176], [train main loss -1.899972], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 155 / 176], [train main loss -1.915919], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 156 / 176], [train main loss -1.923910], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 157 / 176], [train main loss -1.915564], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 158 / 176], [train main loss -1.914746], [lr 0.004971] [batchtime 0.417]
[epoch 88], [iter 159 / 176], [train main loss -1.908621], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 160 / 176], [train main loss -1.914331], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 161 / 176], [train main loss -1.922633], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 162 / 176], [train main loss -1.929132], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 163 / 176], [train main loss -1.931988], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 164 / 176], [train main loss -1.929643], [lr 0.004971] [batchtime 0.416]
[epoch 88], [iter 165 / 176], [train main loss -1.942846], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 166 / 176], [train main loss -1.936462], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 167 / 176], [train main loss -1.945019], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 168 / 176], [train main loss -1.934432], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 169 / 176], [train main loss -1.943919], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 170 / 176], [train main loss -1.943487], [lr 0.004971] [batchtime 0.415]
[epoch 88], [iter 171 / 176], [train main loss -1.940640], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 172 / 176], [train main loss -1.930517], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 173 / 176], [train main loss -1.916198], [lr 0.004971] [batchtime 0.414]
[epoch 88], [iter 174 / 176], [train main loss -1.915489], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 175 / 176], [train main loss -1.913116], [lr 0.004971] [batchtime 0.413]
[epoch 88], [iter 176 / 176], [train main loss -1.913133], [lr 0.004971] [batchtime 0.413]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.03  35.15   0.03  0.03         0.97      0.97
   1  sidewalk          67.32   5.45   0.21  0.28         0.83      0.78
   2  building          85.78  25.09   0.06  0.11         0.94      0.90
   3  wall              15.85   0.13   3.61  1.70         0.22      0.37
   4  fence             20.14   0.29   3.38  0.59         0.23      0.63
   5  pole              36.29   0.51   1.23  0.53         0.45      0.65
   6  traffic light     11.40   0.02   7.37  0.41         0.12      0.71
   7  traffic sign      15.07   0.09   5.41  0.23         0.16      0.82
   8  vegetation        83.56  11.53   0.07  0.12         0.93      0.89
   9  terrain           37.93   0.36   1.05  0.58         0.49      0.63
  10  sky               93.48   3.75   0.03  0.04         0.97      0.96
  11  person            51.23   1.06   0.45  0.50         0.69      0.67
  12  rider              6.92   0.01  11.86  1.60         0.08      0.38
  13  car               84.92   6.70   0.06  0.12         0.95      0.89
  14  truck              1.54   0.01  63.36  0.58         0.02      0.63
  15  bus               14.06   0.04   1.37  4.74         0.42      0.17
  16  train             26.73   0.06   1.88  0.86         0.35      0.54
  17  motorcycle         2.28   0.00  42.05  0.72         0.02      0.58
  18  bicycle           36.19   0.25   0.58  1.18         0.63      0.46
Mean: 41.30
-----------------------------------------------------------------------------------------------------------
this : [epoch 88], [val loss 0.31933], [acc 0.90470], [acc_cls 0.49725], [mean_iu 0.41301], [fwavacc 0.83528]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 89], [iter 1 / 176], [train main loss -0.392522], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 2 / 176], [train main loss -2.035941], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 3 / 176], [train main loss -1.088758], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 4 / 176], [train main loss -1.775041], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 5 / 176], [train main loss -2.134702], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 6 / 176], [train main loss -2.520141], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 7 / 176], [train main loss -2.177203], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 8 / 176], [train main loss -2.210003], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 9 / 176], [train main loss -2.166681], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 10 / 176], [train main loss -2.300022], [lr 0.004914] [batchtime 0]
[epoch 89], [iter 11 / 176], [train main loss -2.367066], [lr 0.004914] [batchtime 0.364]
[epoch 89], [iter 12 / 176], [train main loss -2.655378], [lr 0.004914] [batchtime 0.377]
[epoch 89], [iter 13 / 176], [train main loss -2.566148], [lr 0.004914] [batchtime 0.383]
[epoch 89], [iter 14 / 176], [train main loss -2.581960], [lr 0.004914] [batchtime 0.385]
[epoch 89], [iter 15 / 176], [train main loss -2.524352], [lr 0.004914] [batchtime 0.387]
[epoch 89], [iter 16 / 176], [train main loss -2.578424], [lr 0.004914] [batchtime 0.388]
[epoch 89], [iter 17 / 176], [train main loss -2.623057], [lr 0.004914] [batchtime 0.391]
[epoch 89], [iter 18 / 176], [train main loss -2.639584], [lr 0.004914] [batchtime 0.392]
[epoch 89], [iter 19 / 176], [train main loss -2.750503], [lr 0.004914] [batchtime 0.393]
[epoch 89], [iter 20 / 176], [train main loss -2.681358], [lr 0.004914] [batchtime 0.394]
[epoch 89], [iter 21 / 176], [train main loss -2.744859], [lr 0.004914] [batchtime 0.395]
[epoch 89], [iter 22 / 176], [train main loss -2.663764], [lr 0.004914] [batchtime 0.396]
[epoch 89], [iter 23 / 176], [train main loss -2.549297], [lr 0.004914] [batchtime 0.396]
[epoch 89], [iter 24 / 176], [train main loss -2.349036], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 25 / 176], [train main loss -2.304160], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 26 / 176], [train main loss -2.335138], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 27 / 176], [train main loss -2.406993], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 28 / 176], [train main loss -2.424636], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 29 / 176], [train main loss -2.423314], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 30 / 176], [train main loss -2.338965], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 31 / 176], [train main loss -2.295683], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 32 / 176], [train main loss -2.262187], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 33 / 176], [train main loss -2.206803], [lr 0.004914] [batchtime 0.397]
[epoch 89], [iter 34 / 176], [train main loss -2.194869], [lr 0.004914] [batchtime 0.398]
[epoch 89], [iter 35 / 176], [train main loss -2.210329], [lr 0.004914] [batchtime 0.398]
[epoch 89], [iter 36 / 176], [train main loss -2.231943], [lr 0.004914] [batchtime 0.398]
[epoch 89], [iter 37 / 176], [train main loss -2.247579], [lr 0.004914] [batchtime 0.399]
[epoch 89], [iter 38 / 176], [train main loss -2.161793], [lr 0.004914] [batchtime 0.398]
[epoch 89], [iter 39 / 176], [train main loss -2.222048], [lr 0.004914] [batchtime 0.398]
[epoch 89], [iter 40 / 176], [train main loss -2.183713], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 41 / 176], [train main loss -2.237236], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 42 / 176], [train main loss -2.249441], [lr 0.004914] [batchtime 0.409]
[epoch 89], [iter 43 / 176], [train main loss -2.264378], [lr 0.004914] [batchtime 0.408]
[epoch 89], [iter 44 / 176], [train main loss -2.247665], [lr 0.004914] [batchtime 0.408]
[epoch 89], [iter 45 / 176], [train main loss -2.221911], [lr 0.004914] [batchtime 0.407]
[epoch 89], [iter 46 / 176], [train main loss -2.189325], [lr 0.004914] [batchtime 0.407]
[epoch 89], [iter 47 / 176], [train main loss -2.233424], [lr 0.004914] [batchtime 0.407]
[epoch 89], [iter 48 / 176], [train main loss -2.281472], [lr 0.004914] [batchtime 0.406]
[epoch 89], [iter 49 / 176], [train main loss -2.216439], [lr 0.004914] [batchtime 0.406]
[epoch 89], [iter 50 / 176], [train main loss -2.190627], [lr 0.004914] [batchtime 0.406]
[epoch 89], [iter 51 / 176], [train main loss -2.276781], [lr 0.004914] [batchtime 0.406]
[epoch 89], [iter 52 / 176], [train main loss -2.218832], [lr 0.004914] [batchtime 0.406]
[epoch 89], [iter 53 / 176], [train main loss -2.255079], [lr 0.004914] [batchtime 0.405]
[epoch 89], [iter 54 / 176], [train main loss -2.258610], [lr 0.004914] [batchtime 0.406]
[epoch 89], [iter 55 / 176], [train main loss -2.222266], [lr 0.004914] [batchtime 0.405]
[epoch 89], [iter 56 / 176], [train main loss -2.282324], [lr 0.004914] [batchtime 0.405]
[epoch 89], [iter 57 / 176], [train main loss -2.312702], [lr 0.004914] [batchtime 0.405]
[epoch 89], [iter 58 / 176], [train main loss -2.265663], [lr 0.004914] [batchtime 0.405]
[epoch 89], [iter 59 / 176], [train main loss -2.232567], [lr 0.004914] [batchtime 0.405]
[epoch 89], [iter 60 / 176], [train main loss -2.235767], [lr 0.004914] [batchtime 0.404]
[epoch 89], [iter 61 / 176], [train main loss -2.259286], [lr 0.004914] [batchtime 0.404]
[epoch 89], [iter 62 / 176], [train main loss -2.278653], [lr 0.004914] [batchtime 0.404]
[epoch 89], [iter 63 / 176], [train main loss -2.298710], [lr 0.004914] [batchtime 0.404]
[epoch 89], [iter 64 / 176], [train main loss -2.312979], [lr 0.004914] [batchtime 0.404]
[epoch 89], [iter 65 / 176], [train main loss -2.274333], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 66 / 176], [train main loss -2.239554], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 67 / 176], [train main loss -2.265236], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 68 / 176], [train main loss -2.269082], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 69 / 176], [train main loss -2.212670], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 70 / 176], [train main loss -2.188797], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 71 / 176], [train main loss -2.152634], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 72 / 176], [train main loss -2.150700], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 73 / 176], [train main loss -2.158652], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 74 / 176], [train main loss -2.147217], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 75 / 176], [train main loss -2.132629], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 76 / 176], [train main loss -2.150291], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 77 / 176], [train main loss -2.147911], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 78 / 176], [train main loss -2.124342], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 79 / 176], [train main loss -2.121485], [lr 0.004914] [batchtime 0.401]
[epoch 89], [iter 80 / 176], [train main loss -2.091891], [lr 0.004914] [batchtime 0.401]
[epoch 89], [iter 81 / 176], [train main loss -2.073123], [lr 0.004914] [batchtime 0.401]
[epoch 89], [iter 82 / 176], [train main loss -2.053188], [lr 0.004914] [batchtime 0.403]
[epoch 89], [iter 83 / 176], [train main loss -2.067169], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 84 / 176], [train main loss -2.064190], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 85 / 176], [train main loss -2.052621], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 86 / 176], [train main loss -2.097572], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 87 / 176], [train main loss -2.114173], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 88 / 176], [train main loss -2.112051], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 89 / 176], [train main loss -2.126800], [lr 0.004914] [batchtime 0.402]
[epoch 89], [iter 90 / 176], [train main loss -2.134638], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 91 / 176], [train main loss -2.125295], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 92 / 176], [train main loss -2.126690], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 93 / 176], [train main loss -2.156581], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 94 / 176], [train main loss -2.179039], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 95 / 176], [train main loss -2.167635], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 96 / 176], [train main loss -2.206404], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 97 / 176], [train main loss -2.193691], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 98 / 176], [train main loss -2.181575], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 99 / 176], [train main loss -2.188667], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 100 / 176], [train main loss -2.188959], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 101 / 176], [train main loss -2.164064], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 102 / 176], [train main loss -2.149876], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 103 / 176], [train main loss -2.133489], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 104 / 176], [train main loss -2.123501], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 105 / 176], [train main loss -2.171311], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 106 / 176], [train main loss -2.164111], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 107 / 176], [train main loss -2.178118], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 108 / 176], [train main loss -2.179715], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 109 / 176], [train main loss -2.163271], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 110 / 176], [train main loss -2.170411], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 111 / 176], [train main loss -2.165267], [lr 0.004914] [batchtime 0.413]
[epoch 89], [iter 112 / 176], [train main loss -2.184543], [lr 0.004914] [batchtime 0.413]
[epoch 89], [iter 113 / 176], [train main loss -2.190346], [lr 0.004914] [batchtime 0.413]
[epoch 89], [iter 114 / 176], [train main loss -2.202539], [lr 0.004914] [batchtime 0.413]
[epoch 89], [iter 115 / 176], [train main loss -2.179757], [lr 0.004914] [batchtime 0.413]
[epoch 89], [iter 116 / 176], [train main loss -2.206152], [lr 0.004914] [batchtime 0.412]
[epoch 89], [iter 117 / 176], [train main loss -2.203891], [lr 0.004914] [batchtime 0.412]
[epoch 89], [iter 118 / 176], [train main loss -2.214317], [lr 0.004914] [batchtime 0.412]
[epoch 89], [iter 119 / 176], [train main loss -2.202595], [lr 0.004914] [batchtime 0.412]
[epoch 89], [iter 120 / 176], [train main loss -2.235444], [lr 0.004914] [batchtime 0.412]
[epoch 89], [iter 121 / 176], [train main loss -2.218168], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 122 / 176], [train main loss -2.229715], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 123 / 176], [train main loss -2.241880], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 124 / 176], [train main loss -2.231401], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 125 / 176], [train main loss -2.241266], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 126 / 176], [train main loss -2.256746], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 127 / 176], [train main loss -2.256575], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 128 / 176], [train main loss -2.264216], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 129 / 176], [train main loss -2.271632], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 130 / 176], [train main loss -2.272807], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 131 / 176], [train main loss -2.276593], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 132 / 176], [train main loss -2.247290], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 133 / 176], [train main loss -2.232419], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 134 / 176], [train main loss -2.231682], [lr 0.004914] [batchtime 0.41]
[epoch 89], [iter 135 / 176], [train main loss -2.215698], [lr 0.004914] [batchtime 0.409]
[epoch 89], [iter 136 / 176], [train main loss -2.201189], [lr 0.004914] [batchtime 0.409]
[epoch 89], [iter 137 / 176], [train main loss -2.197982], [lr 0.004914] [batchtime 0.411]
[epoch 89], [iter 138 / 176], [train main loss -2.202662], [lr 0.004914] [batchtime 0.421]
[epoch 89], [iter 139 / 176], [train main loss -2.192103], [lr 0.004914] [batchtime 0.421]
[epoch 89], [iter 140 / 176], [train main loss -2.186568], [lr 0.004914] [batchtime 0.42]
[epoch 89], [iter 141 / 176], [train main loss -2.188234], [lr 0.004914] [batchtime 0.42]
[epoch 89], [iter 142 / 176], [train main loss -2.208944], [lr 0.004914] [batchtime 0.42]
[epoch 89], [iter 143 / 176], [train main loss -2.213942], [lr 0.004914] [batchtime 0.42]
[epoch 89], [iter 144 / 176], [train main loss -2.219418], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 145 / 176], [train main loss -2.214419], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 146 / 176], [train main loss -2.220431], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 147 / 176], [train main loss -2.212662], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 148 / 176], [train main loss -2.220909], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 149 / 176], [train main loss -2.223582], [lr 0.004914] [batchtime 0.419]
[epoch 89], [iter 150 / 176], [train main loss -2.211267], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 151 / 176], [train main loss -2.212390], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 152 / 176], [train main loss -2.215892], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 153 / 176], [train main loss -2.212330], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 154 / 176], [train main loss -2.212354], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 155 / 176], [train main loss -2.218600], [lr 0.004914] [batchtime 0.418]
[epoch 89], [iter 156 / 176], [train main loss -2.215642], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 157 / 176], [train main loss -2.217127], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 158 / 176], [train main loss -2.215351], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 159 / 176], [train main loss -2.218604], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 160 / 176], [train main loss -2.225202], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 161 / 176], [train main loss -2.215343], [lr 0.004914] [batchtime 0.417]
[epoch 89], [iter 162 / 176], [train main loss -2.209008], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 163 / 176], [train main loss -2.201237], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 164 / 176], [train main loss -2.208349], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 165 / 176], [train main loss -2.192934], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 166 / 176], [train main loss -2.200519], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 167 / 176], [train main loss -2.186713], [lr 0.004914] [batchtime 0.416]
[epoch 89], [iter 168 / 176], [train main loss -2.199333], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 169 / 176], [train main loss -2.202958], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 170 / 176], [train main loss -2.197726], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 171 / 176], [train main loss -2.196530], [lr 0.004914] [batchtime 0.415]
[epoch 89], [iter 172 / 176], [train main loss -2.198890], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 173 / 176], [train main loss -2.185326], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 174 / 176], [train main loss -2.188395], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 175 / 176], [train main loss -2.184607], [lr 0.004914] [batchtime 0.414]
[epoch 89], [iter 176 / 176], [train main loss -2.168016], [lr 0.004914] [batchtime 0.413]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.86  35.30    0.03  0.04         0.97      0.97
   1  sidewalk          66.34   5.04    0.31  0.20         0.77      0.83
   2  building          85.18  24.71    0.08  0.10         0.93      0.91
   3  wall              16.73   0.17    2.47  2.51         0.29      0.29
   4  fence             24.65   0.42    2.00  1.06         0.33      0.49
   5  pole              36.16   0.51    1.22  0.55         0.45      0.65
   6  traffic light     10.86   0.02    7.71  0.50         0.11      0.67
   7  traffic sign      12.68   0.07    6.72  0.17         0.13      0.86
   8  vegetation        82.66  11.62    0.06  0.15         0.94      0.87
   9  terrain           37.02   0.38    0.94  0.76         0.52      0.57
  10  sky               93.23   3.74    0.04  0.04         0.97      0.96
  11  person            48.21   0.92    0.67  0.41         0.60      0.71
  12  rider              4.43   0.00   20.47  1.09         0.05      0.48
  13  car               82.51   6.66    0.06  0.15         0.94      0.87
  14  truck              0.50   0.00  200.58  0.31         0.00      0.76
  15  bus               10.89   0.04    1.22  6.96         0.45      0.13
  16  train             20.61   0.07    1.74  2.11         0.36      0.32
  17  motorcycle         2.45   0.00   38.84  0.92         0.03      0.52
  18  bicycle           33.32   0.24    0.66  1.35         0.60      0.43
Mean: 40.12
-----------------------------------------------------------------------------------------------------------
this : [epoch 89], [val loss 0.33604], [acc 0.89911], [acc_cls 0.49689], [mean_iu 0.40121], [fwavacc 0.82913]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 90], [iter 1 / 176], [train main loss -2.281645], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 2 / 176], [train main loss -1.809233], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 3 / 176], [train main loss -0.837686], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 4 / 176], [train main loss -0.883762], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 5 / 176], [train main loss -0.989107], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 6 / 176], [train main loss -1.175814], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 7 / 176], [train main loss -1.580988], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 8 / 176], [train main loss -1.548642], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 9 / 176], [train main loss -1.442130], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 10 / 176], [train main loss -1.733373], [lr 0.004857] [batchtime 0]
[epoch 90], [iter 11 / 176], [train main loss -1.845974], [lr 0.004857] [batchtime 0.372]
[epoch 90], [iter 12 / 176], [train main loss -1.808352], [lr 0.004857] [batchtime 0.384]
[epoch 90], [iter 13 / 176], [train main loss -1.857509], [lr 0.004857] [batchtime 0.387]
[epoch 90], [iter 14 / 176], [train main loss -1.933083], [lr 0.004857] [batchtime 0.39]
[epoch 90], [iter 15 / 176], [train main loss -1.861595], [lr 0.004857] [batchtime 0.395]
[epoch 90], [iter 16 / 176], [train main loss -1.825412], [lr 0.004857] [batchtime 0.395]
[epoch 90], [iter 17 / 176], [train main loss -1.753716], [lr 0.004857] [batchtime 0.394]
[epoch 90], [iter 18 / 176], [train main loss -1.722475], [lr 0.004857] [batchtime 0.394]
[epoch 90], [iter 19 / 176], [train main loss -1.757858], [lr 0.004857] [batchtime 0.395]
[epoch 90], [iter 20 / 176], [train main loss -1.783261], [lr 0.004857] [batchtime 0.395]
[epoch 90], [iter 21 / 176], [train main loss -1.689903], [lr 0.004857] [batchtime 0.397]
[epoch 90], [iter 22 / 176], [train main loss -1.676860], [lr 0.004857] [batchtime 0.407]
[epoch 90], [iter 23 / 176], [train main loss -1.794890], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 24 / 176], [train main loss -1.724102], [lr 0.004857] [batchtime 0.418]
[epoch 90], [iter 25 / 176], [train main loss -1.701904], [lr 0.004857] [batchtime 0.416]
[epoch 90], [iter 26 / 176], [train main loss -1.781380], [lr 0.004857] [batchtime 0.414]
[epoch 90], [iter 27 / 176], [train main loss -1.793380], [lr 0.004857] [batchtime 0.413]
[epoch 90], [iter 28 / 176], [train main loss -1.742052], [lr 0.004857] [batchtime 0.412]
[epoch 90], [iter 29 / 176], [train main loss -1.736911], [lr 0.004857] [batchtime 0.411]
[epoch 90], [iter 30 / 176], [train main loss -1.775435], [lr 0.004857] [batchtime 0.41]
[epoch 90], [iter 31 / 176], [train main loss -1.728209], [lr 0.004857] [batchtime 0.409]
[epoch 90], [iter 32 / 176], [train main loss -1.733390], [lr 0.004857] [batchtime 0.408]
[epoch 90], [iter 33 / 176], [train main loss -1.735431], [lr 0.004857] [batchtime 0.408]
[epoch 90], [iter 34 / 176], [train main loss -1.681059], [lr 0.004857] [batchtime 0.408]
[epoch 90], [iter 35 / 176], [train main loss -1.660886], [lr 0.004857] [batchtime 0.408]
[epoch 90], [iter 36 / 176], [train main loss -1.697837], [lr 0.004857] [batchtime 0.407]
[epoch 90], [iter 37 / 176], [train main loss -1.746000], [lr 0.004857] [batchtime 0.407]
[epoch 90], [iter 38 / 176], [train main loss -1.795430], [lr 0.004857] [batchtime 0.413]
[epoch 90], [iter 39 / 176], [train main loss -1.759133], [lr 0.004857] [batchtime 0.412]
[epoch 90], [iter 40 / 176], [train main loss -1.771386], [lr 0.004857] [batchtime 0.411]
[epoch 90], [iter 41 / 176], [train main loss -1.789576], [lr 0.004857] [batchtime 0.411]
[epoch 90], [iter 42 / 176], [train main loss -1.838684], [lr 0.004857] [batchtime 0.41]
[epoch 90], [iter 43 / 176], [train main loss -1.880367], [lr 0.004857] [batchtime 0.41]
[epoch 90], [iter 44 / 176], [train main loss -1.865254], [lr 0.004857] [batchtime 0.409]
[epoch 90], [iter 45 / 176], [train main loss -1.862451], [lr 0.004857] [batchtime 0.409]
[epoch 90], [iter 46 / 176], [train main loss -1.806977], [lr 0.004857] [batchtime 0.412]
[epoch 90], [iter 47 / 176], [train main loss -1.846592], [lr 0.004857] [batchtime 0.443]
[epoch 90], [iter 48 / 176], [train main loss -1.897041], [lr 0.004857] [batchtime 0.441]
[epoch 90], [iter 49 / 176], [train main loss -1.894770], [lr 0.004857] [batchtime 0.44]
[epoch 90], [iter 50 / 176], [train main loss -1.881003], [lr 0.004857] [batchtime 0.439]
[epoch 90], [iter 51 / 176], [train main loss -1.910968], [lr 0.004857] [batchtime 0.438]
[epoch 90], [iter 52 / 176], [train main loss -1.927246], [lr 0.004857] [batchtime 0.437]
[epoch 90], [iter 53 / 176], [train main loss -1.900888], [lr 0.004857] [batchtime 0.436]
[epoch 90], [iter 54 / 176], [train main loss -1.878636], [lr 0.004857] [batchtime 0.435]
[epoch 90], [iter 55 / 176], [train main loss -1.888796], [lr 0.004857] [batchtime 0.434]
[epoch 90], [iter 56 / 176], [train main loss -1.855360], [lr 0.004857] [batchtime 0.433]
[epoch 90], [iter 57 / 176], [train main loss -1.854078], [lr 0.004857] [batchtime 0.433]
[epoch 90], [iter 58 / 176], [train main loss -1.862927], [lr 0.004857] [batchtime 0.432]
[epoch 90], [iter 59 / 176], [train main loss -1.880053], [lr 0.004857] [batchtime 0.431]
[epoch 90], [iter 60 / 176], [train main loss -1.819179], [lr 0.004857] [batchtime 0.431]
[epoch 90], [iter 61 / 176], [train main loss -1.850455], [lr 0.004857] [batchtime 0.43]
[epoch 90], [iter 62 / 176], [train main loss -1.834746], [lr 0.004857] [batchtime 0.429]
[epoch 90], [iter 63 / 176], [train main loss -1.872963], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 64 / 176], [train main loss -1.865641], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 65 / 176], [train main loss -1.816778], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 66 / 176], [train main loss -1.821247], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 67 / 176], [train main loss -1.827536], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 68 / 176], [train main loss -1.801749], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 69 / 176], [train main loss -1.831901], [lr 0.004857] [batchtime 0.429]
[epoch 90], [iter 70 / 176], [train main loss -1.842510], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 71 / 176], [train main loss -1.873669], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 72 / 176], [train main loss -1.882718], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 73 / 176], [train main loss -1.876919], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 74 / 176], [train main loss -1.910047], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 75 / 176], [train main loss -1.890341], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 76 / 176], [train main loss -1.905075], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 77 / 176], [train main loss -1.908127], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 78 / 176], [train main loss -1.881689], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 79 / 176], [train main loss -1.895017], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 80 / 176], [train main loss -1.929398], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 81 / 176], [train main loss -1.938822], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 82 / 176], [train main loss -1.900685], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 83 / 176], [train main loss -1.878363], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 84 / 176], [train main loss -1.880955], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 85 / 176], [train main loss -1.895413], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 86 / 176], [train main loss -1.909481], [lr 0.004857] [batchtime 0.42]
[epoch 90], [iter 87 / 176], [train main loss -1.888694], [lr 0.004857] [batchtime 0.42]
[epoch 90], [iter 88 / 176], [train main loss -1.871079], [lr 0.004857] [batchtime 0.42]
[epoch 90], [iter 89 / 176], [train main loss -1.873883], [lr 0.004857] [batchtime 0.419]
[epoch 90], [iter 90 / 176], [train main loss -1.884815], [lr 0.004857] [batchtime 0.419]
[epoch 90], [iter 91 / 176], [train main loss -1.891212], [lr 0.004857] [batchtime 0.419]
[epoch 90], [iter 92 / 176], [train main loss -1.889888], [lr 0.004857] [batchtime 0.418]
[epoch 90], [iter 93 / 176], [train main loss -1.871386], [lr 0.004857] [batchtime 0.42]
[epoch 90], [iter 94 / 176], [train main loss -1.855555], [lr 0.004857] [batchtime 0.435]
[epoch 90], [iter 95 / 176], [train main loss -1.862840], [lr 0.004857] [batchtime 0.434]
[epoch 90], [iter 96 / 176], [train main loss -1.888610], [lr 0.004857] [batchtime 0.434]
[epoch 90], [iter 97 / 176], [train main loss -1.866153], [lr 0.004857] [batchtime 0.433]
[epoch 90], [iter 98 / 176], [train main loss -1.886249], [lr 0.004857] [batchtime 0.433]
[epoch 90], [iter 99 / 176], [train main loss -1.868298], [lr 0.004857] [batchtime 0.432]
[epoch 90], [iter 100 / 176], [train main loss -1.889366], [lr 0.004857] [batchtime 0.432]
[epoch 90], [iter 101 / 176], [train main loss -1.901956], [lr 0.004857] [batchtime 0.431]
[epoch 90], [iter 102 / 176], [train main loss -1.938878], [lr 0.004857] [batchtime 0.431]
[epoch 90], [iter 103 / 176], [train main loss -1.941645], [lr 0.004857] [batchtime 0.431]
[epoch 90], [iter 104 / 176], [train main loss -1.926307], [lr 0.004857] [batchtime 0.43]
[epoch 90], [iter 105 / 176], [train main loss -1.939606], [lr 0.004857] [batchtime 0.43]
[epoch 90], [iter 106 / 176], [train main loss -1.943636], [lr 0.004857] [batchtime 0.43]
[epoch 90], [iter 107 / 176], [train main loss -1.970144], [lr 0.004857] [batchtime 0.429]
[epoch 90], [iter 108 / 176], [train main loss -1.967990], [lr 0.004857] [batchtime 0.429]
[epoch 90], [iter 109 / 176], [train main loss -1.950470], [lr 0.004857] [batchtime 0.429]
[epoch 90], [iter 110 / 176], [train main loss -1.965565], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 111 / 176], [train main loss -1.972350], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 112 / 176], [train main loss -1.970341], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 113 / 176], [train main loss -1.977300], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 114 / 176], [train main loss -1.960533], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 115 / 176], [train main loss -1.964748], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 116 / 176], [train main loss -1.962120], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 117 / 176], [train main loss -1.965608], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 118 / 176], [train main loss -1.941615], [lr 0.004857] [batchtime 0.428]
[epoch 90], [iter 119 / 176], [train main loss -1.951197], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 120 / 176], [train main loss -1.969613], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 121 / 176], [train main loss -1.955126], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 122 / 176], [train main loss -1.945801], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 123 / 176], [train main loss -1.954744], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 124 / 176], [train main loss -1.965225], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 125 / 176], [train main loss -1.963495], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 126 / 176], [train main loss -1.968856], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 127 / 176], [train main loss -1.974093], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 128 / 176], [train main loss -1.972622], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 129 / 176], [train main loss -1.968627], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 130 / 176], [train main loss -1.951981], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 131 / 176], [train main loss -1.943840], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 132 / 176], [train main loss -1.957030], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 133 / 176], [train main loss -1.954046], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 134 / 176], [train main loss -1.968004], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 135 / 176], [train main loss -1.953072], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 136 / 176], [train main loss -1.958559], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 137 / 176], [train main loss -1.964914], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 138 / 176], [train main loss -1.952271], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 139 / 176], [train main loss -1.950657], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 140 / 176], [train main loss -1.941705], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 141 / 176], [train main loss -1.948704], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 142 / 176], [train main loss -1.960649], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 143 / 176], [train main loss -1.975890], [lr 0.004857] [batchtime 0.427]
[epoch 90], [iter 144 / 176], [train main loss -1.977669], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 145 / 176], [train main loss -1.978243], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 146 / 176], [train main loss -1.978792], [lr 0.004857] [batchtime 0.426]
[epoch 90], [iter 147 / 176], [train main loss -1.977895], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 148 / 176], [train main loss -1.971529], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 149 / 176], [train main loss -1.978560], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 150 / 176], [train main loss -1.977060], [lr 0.004857] [batchtime 0.425]
[epoch 90], [iter 151 / 176], [train main loss -1.982307], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 152 / 176], [train main loss -1.977431], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 153 / 176], [train main loss -1.981804], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 154 / 176], [train main loss -1.980168], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 155 / 176], [train main loss -1.978553], [lr 0.004857] [batchtime 0.424]
[epoch 90], [iter 156 / 176], [train main loss -1.972135], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 157 / 176], [train main loss -1.978983], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 158 / 176], [train main loss -1.994366], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 159 / 176], [train main loss -1.971510], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 160 / 176], [train main loss -1.962356], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 161 / 176], [train main loss -1.958916], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 162 / 176], [train main loss -1.957301], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 163 / 176], [train main loss -1.938662], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 164 / 176], [train main loss -1.930260], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 165 / 176], [train main loss -1.933586], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 166 / 176], [train main loss -1.933502], [lr 0.004857] [batchtime 0.423]
[epoch 90], [iter 167 / 176], [train main loss -1.925612], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 168 / 176], [train main loss -1.937311], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 169 / 176], [train main loss -1.946213], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 170 / 176], [train main loss -1.945493], [lr 0.004857] [batchtime 0.422]
[epoch 90], [iter 171 / 176], [train main loss -1.941756], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 172 / 176], [train main loss -1.928327], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 173 / 176], [train main loss -1.922154], [lr 0.004857] [batchtime 0.421]
[epoch 90], [iter 174 / 176], [train main loss -1.918522], [lr 0.004857] [batchtime 0.42]
[epoch 90], [iter 175 / 176], [train main loss -1.923600], [lr 0.004857] [batchtime 0.42]
[epoch 90], [iter 176 / 176], [train main loss -1.915995], [lr 0.004857] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.14  35.58   0.02  0.04         0.98      0.96
   1  sidewalk          66.30   5.13   0.28  0.22         0.78      0.82
   2  building          85.28  24.44   0.09  0.08         0.92      0.92
   3  wall              15.45   0.13   3.59  1.88         0.22      0.35
   4  fence             22.41   0.36   2.55  0.91         0.28      0.52
   5  pole              36.26   0.50   1.25  0.51         0.44      0.66
   6  traffic light     11.27   0.02   7.44  0.44         0.12      0.70
   7  traffic sign      16.97   0.10   4.65  0.24         0.18      0.81
   8  vegetation        82.82  11.69   0.06  0.15         0.95      0.87
   9  terrain           37.75   0.35   1.09  0.56         0.48      0.64
  10  sky               93.29   3.73   0.04  0.03         0.96      0.97
  11  person            49.47   1.02   0.50  0.53         0.67      0.66
  12  rider              6.42   0.01  12.71  1.88         0.07      0.35
  13  car               85.11   6.68   0.06  0.12         0.94      0.90
  14  truck              1.89   0.01  51.57  0.42         0.02      0.70
  15  bus               11.76   0.03   1.75  5.76         0.36      0.15
  16  train             23.05   0.09   0.96  2.38         0.51      0.30
  17  motorcycle         2.94   0.00  31.47  1.60         0.03      0.39
  18  bicycle           30.16   0.28   0.41  1.90         0.71      0.34
Mean: 40.67
-----------------------------------------------------------------------------------------------------------
this : [epoch 90], [val loss 0.32550], [acc 0.90152], [acc_cls 0.50634], [mean_iu 0.40670], [fwavacc 0.83260]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 91], [iter 1 / 176], [train main loss -2.708718], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 2 / 176], [train main loss -2.840496], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 3 / 176], [train main loss -2.555772], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 4 / 176], [train main loss -2.254693], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 5 / 176], [train main loss -2.424424], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 6 / 176], [train main loss -2.180471], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 7 / 176], [train main loss -2.327894], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 8 / 176], [train main loss -2.249617], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 9 / 176], [train main loss -2.165841], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 10 / 176], [train main loss -2.159536], [lr 0.004800] [batchtime 0]
[epoch 91], [iter 11 / 176], [train main loss -2.099703], [lr 0.004800] [batchtime 0.384]
[epoch 91], [iter 12 / 176], [train main loss -2.090638], [lr 0.004800] [batchtime 0.395]
[epoch 91], [iter 13 / 176], [train main loss -2.199860], [lr 0.004800] [batchtime 0.398]
[epoch 91], [iter 14 / 176], [train main loss -2.197831], [lr 0.004800] [batchtime 0.398]
[epoch 91], [iter 15 / 176], [train main loss -2.199787], [lr 0.004800] [batchtime 0.398]
[epoch 91], [iter 16 / 176], [train main loss -2.334157], [lr 0.004800] [batchtime 0.399]
[epoch 91], [iter 17 / 176], [train main loss -2.243302], [lr 0.004800] [batchtime 0.399]
[epoch 91], [iter 18 / 176], [train main loss -2.106779], [lr 0.004800] [batchtime 0.4]
[epoch 91], [iter 19 / 176], [train main loss -2.098894], [lr 0.004800] [batchtime 0.4]
[epoch 91], [iter 20 / 176], [train main loss -2.037155], [lr 0.004800] [batchtime 0.401]
[epoch 91], [iter 21 / 176], [train main loss -2.112475], [lr 0.004800] [batchtime 0.401]
[epoch 91], [iter 22 / 176], [train main loss -2.137552], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 23 / 176], [train main loss -2.171280], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 24 / 176], [train main loss -2.138961], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 25 / 176], [train main loss -2.108997], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 26 / 176], [train main loss -2.019009], [lr 0.004800] [batchtime 0.414]
[epoch 91], [iter 27 / 176], [train main loss -2.130648], [lr 0.004800] [batchtime 0.413]
[epoch 91], [iter 28 / 176], [train main loss -2.171734], [lr 0.004800] [batchtime 0.412]
[epoch 91], [iter 29 / 176], [train main loss -2.024456], [lr 0.004800] [batchtime 0.411]
[epoch 91], [iter 30 / 176], [train main loss -2.049648], [lr 0.004800] [batchtime 0.41]
[epoch 91], [iter 31 / 176], [train main loss -2.011976], [lr 0.004800] [batchtime 0.41]
[epoch 91], [iter 32 / 176], [train main loss -1.985730], [lr 0.004800] [batchtime 0.41]
[epoch 91], [iter 33 / 176], [train main loss -2.012788], [lr 0.004800] [batchtime 0.409]
[epoch 91], [iter 34 / 176], [train main loss -1.956850], [lr 0.004800] [batchtime 0.408]
[epoch 91], [iter 35 / 176], [train main loss -1.895807], [lr 0.004800] [batchtime 0.408]
[epoch 91], [iter 36 / 176], [train main loss -1.941894], [lr 0.004800] [batchtime 0.407]
[epoch 91], [iter 37 / 176], [train main loss -1.827882], [lr 0.004800] [batchtime 0.407]
[epoch 91], [iter 38 / 176], [train main loss -1.827026], [lr 0.004800] [batchtime 0.407]
[epoch 91], [iter 39 / 176], [train main loss -1.828036], [lr 0.004800] [batchtime 0.406]
[epoch 91], [iter 40 / 176], [train main loss -1.891383], [lr 0.004800] [batchtime 0.406]
[epoch 91], [iter 41 / 176], [train main loss -1.870519], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 42 / 176], [train main loss -1.837017], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 43 / 176], [train main loss -1.883371], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 44 / 176], [train main loss -1.891745], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 45 / 176], [train main loss -1.834754], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 46 / 176], [train main loss -1.859507], [lr 0.004800] [batchtime 0.405]
[epoch 91], [iter 47 / 176], [train main loss -1.901250], [lr 0.004800] [batchtime 0.424]
[epoch 91], [iter 48 / 176], [train main loss -1.887895], [lr 0.004800] [batchtime 0.428]
[epoch 91], [iter 49 / 176], [train main loss -1.880297], [lr 0.004800] [batchtime 0.427]
[epoch 91], [iter 50 / 176], [train main loss -1.940277], [lr 0.004800] [batchtime 0.426]
[epoch 91], [iter 51 / 176], [train main loss -1.973799], [lr 0.004800] [batchtime 0.425]
[epoch 91], [iter 52 / 176], [train main loss -1.983046], [lr 0.004800] [batchtime 0.425]
[epoch 91], [iter 53 / 176], [train main loss -1.990121], [lr 0.004800] [batchtime 0.424]
[epoch 91], [iter 54 / 176], [train main loss -1.945466], [lr 0.004800] [batchtime 0.423]
[epoch 91], [iter 55 / 176], [train main loss -1.944536], [lr 0.004800] [batchtime 0.423]
[epoch 91], [iter 56 / 176], [train main loss -1.954991], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 57 / 176], [train main loss -1.959061], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 58 / 176], [train main loss -1.966776], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 59 / 176], [train main loss -1.949465], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 60 / 176], [train main loss -1.967199], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 61 / 176], [train main loss -1.983248], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 62 / 176], [train main loss -1.981238], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 63 / 176], [train main loss -1.945720], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 64 / 176], [train main loss -1.952408], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 65 / 176], [train main loss -1.971148], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 66 / 176], [train main loss -1.970600], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 67 / 176], [train main loss -1.928044], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 68 / 176], [train main loss -1.952441], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 69 / 176], [train main loss -1.975808], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 70 / 176], [train main loss -1.978329], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 71 / 176], [train main loss -1.971828], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 72 / 176], [train main loss -1.988205], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 73 / 176], [train main loss -1.990083], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 74 / 176], [train main loss -1.983198], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 75 / 176], [train main loss -2.009992], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 76 / 176], [train main loss -2.001745], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 77 / 176], [train main loss -1.970727], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 78 / 176], [train main loss -1.970936], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 79 / 176], [train main loss -1.986028], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 80 / 176], [train main loss -1.978331], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 81 / 176], [train main loss -1.964035], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 82 / 176], [train main loss -1.960602], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 83 / 176], [train main loss -1.974487], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 84 / 176], [train main loss -1.951690], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 85 / 176], [train main loss -1.960700], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 86 / 176], [train main loss -1.958520], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 87 / 176], [train main loss -1.972967], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 88 / 176], [train main loss -1.992545], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 89 / 176], [train main loss -1.966193], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 90 / 176], [train main loss -1.961462], [lr 0.004800] [batchtime 0.414]
[epoch 91], [iter 91 / 176], [train main loss -1.965554], [lr 0.004800] [batchtime 0.414]
[epoch 91], [iter 92 / 176], [train main loss -1.972439], [lr 0.004800] [batchtime 0.414]
[epoch 91], [iter 93 / 176], [train main loss -1.987802], [lr 0.004800] [batchtime 0.414]
[epoch 91], [iter 94 / 176], [train main loss -1.972739], [lr 0.004800] [batchtime 0.414]
[epoch 91], [iter 95 / 176], [train main loss -1.946057], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 96 / 176], [train main loss -1.947376], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 97 / 176], [train main loss -1.955420], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 98 / 176], [train main loss -1.937366], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 99 / 176], [train main loss -1.941836], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 100 / 176], [train main loss -1.933384], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 101 / 176], [train main loss -1.910208], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 102 / 176], [train main loss -1.912749], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 103 / 176], [train main loss -1.912008], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 104 / 176], [train main loss -1.935414], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 105 / 176], [train main loss -1.955095], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 106 / 176], [train main loss -1.979673], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 107 / 176], [train main loss -1.974757], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 108 / 176], [train main loss -1.976515], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 109 / 176], [train main loss -1.961314], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 110 / 176], [train main loss -1.963695], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 111 / 176], [train main loss -1.945886], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 112 / 176], [train main loss -1.935683], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 113 / 176], [train main loss -1.950638], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 114 / 176], [train main loss -1.973873], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 115 / 176], [train main loss -1.958922], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 116 / 176], [train main loss -1.968168], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 117 / 176], [train main loss -1.952810], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 118 / 176], [train main loss -1.943175], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 119 / 176], [train main loss -1.952725], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 120 / 176], [train main loss -1.946617], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 121 / 176], [train main loss -1.986550], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 122 / 176], [train main loss -1.979609], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 123 / 176], [train main loss -1.964390], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 124 / 176], [train main loss -1.955571], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 125 / 176], [train main loss -1.955140], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 126 / 176], [train main loss -1.942192], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 127 / 176], [train main loss -1.952107], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 128 / 176], [train main loss -1.963255], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 129 / 176], [train main loss -1.949446], [lr 0.004800] [batchtime 0.417]
[epoch 91], [iter 130 / 176], [train main loss -1.947050], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 131 / 176], [train main loss -1.963835], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 132 / 176], [train main loss -1.968555], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 133 / 176], [train main loss -1.969002], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 134 / 176], [train main loss -1.985174], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 135 / 176], [train main loss -1.983340], [lr 0.004800] [batchtime 0.416]
[epoch 91], [iter 136 / 176], [train main loss -1.963632], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 137 / 176], [train main loss -1.955012], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 138 / 176], [train main loss -1.954203], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 139 / 176], [train main loss -1.949630], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 140 / 176], [train main loss -1.975811], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 141 / 176], [train main loss -1.991676], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 142 / 176], [train main loss -2.002698], [lr 0.004800] [batchtime 0.415]
[epoch 91], [iter 143 / 176], [train main loss -2.023820], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 144 / 176], [train main loss -2.016322], [lr 0.004800] [batchtime 0.423]
[epoch 91], [iter 145 / 176], [train main loss -2.009720], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 146 / 176], [train main loss -2.019946], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 147 / 176], [train main loss -2.002817], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 148 / 176], [train main loss -1.999999], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 149 / 176], [train main loss -1.999182], [lr 0.004800] [batchtime 0.422]
[epoch 91], [iter 150 / 176], [train main loss -1.999841], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 151 / 176], [train main loss -2.019041], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 152 / 176], [train main loss -2.034097], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 153 / 176], [train main loss -2.033798], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 154 / 176], [train main loss -2.028534], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 155 / 176], [train main loss -2.029103], [lr 0.004800] [batchtime 0.421]
[epoch 91], [iter 156 / 176], [train main loss -2.025887], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 157 / 176], [train main loss -2.026891], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 158 / 176], [train main loss -2.033994], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 159 / 176], [train main loss -2.029411], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 160 / 176], [train main loss -2.022861], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 161 / 176], [train main loss -2.038097], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 162 / 176], [train main loss -2.036159], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 163 / 176], [train main loss -2.037856], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 164 / 176], [train main loss -2.029826], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 165 / 176], [train main loss -2.036142], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 166 / 176], [train main loss -2.040112], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 167 / 176], [train main loss -2.038294], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 168 / 176], [train main loss -2.038874], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 169 / 176], [train main loss -2.036634], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 170 / 176], [train main loss -2.044647], [lr 0.004800] [batchtime 0.42]
[epoch 91], [iter 171 / 176], [train main loss -2.037448], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 172 / 176], [train main loss -2.047575], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 173 / 176], [train main loss -2.036603], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 174 / 176], [train main loss -2.042274], [lr 0.004800] [batchtime 0.419]
[epoch 91], [iter 175 / 176], [train main loss -2.037738], [lr 0.004800] [batchtime 0.418]
[epoch 91], [iter 176 / 176], [train main loss -2.041512], [lr 0.004800] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.12  34.90    0.04  0.03         0.96      0.97
   1  sidewalk          64.80   5.31    0.24  0.30         0.81      0.77
   2  building          84.75  24.17    0.10  0.08         0.91      0.93
   3  wall              16.57   0.14    3.18  1.86         0.24      0.35
   4  fence             22.52   0.36    2.51  0.93         0.28      0.52
   5  pole              36.76   0.55    1.06  0.66         0.49      0.60
   6  traffic light     11.22   0.02    7.38  0.53         0.12      0.66
   7  traffic sign      16.12   0.09    4.96  0.24         0.17      0.81
   8  vegetation        80.84  11.80    0.05  0.19         0.95      0.84
   9  terrain           38.48   0.39    0.90  0.70         0.53      0.59
  10  sky               93.39   3.76    0.03  0.04         0.97      0.96
  11  person            49.49   0.99    0.55  0.48         0.65      0.68
  12  rider              5.68   0.01   15.04  1.55         0.06      0.39
  13  car               83.20   6.75    0.05  0.15         0.95      0.87
  14  truck              0.66   0.00  150.84  0.33         0.01      0.75
  15  bus               11.05   0.04    1.39  6.66         0.42      0.13
  16  train             14.56   0.03    4.61  1.26         0.18      0.44
  17  motorcycle         2.75   0.00   34.15  1.20         0.03      0.45
  18  bicycle           33.25   0.25    0.58  1.43         0.63      0.41
Mean: 39.96
-----------------------------------------------------------------------------------------------------------
this : [epoch 91], [val loss 0.35764], [acc 0.89547], [acc_cls 0.49208], [mean_iu 0.39960], [fwavacc 0.82280]
best : [epoch 83], [val loss 0.32383], [acc 0.90263], [acc_cls 0.49846], [mean_iu 0.41522], [fwavacc 0.83150]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 92], [iter 1 / 176], [train main loss -2.044692], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 2 / 176], [train main loss -2.600810], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 3 / 176], [train main loss -2.836539], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 4 / 176], [train main loss -2.383161], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 5 / 176], [train main loss -2.785154], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 6 / 176], [train main loss -2.398965], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 7 / 176], [train main loss -2.533214], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 8 / 176], [train main loss -2.431687], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 9 / 176], [train main loss -2.517443], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 10 / 176], [train main loss -2.295845], [lr 0.004743] [batchtime 0]
[epoch 92], [iter 11 / 176], [train main loss -2.224302], [lr 0.004743] [batchtime 0.385]
[epoch 92], [iter 12 / 176], [train main loss -2.175906], [lr 0.004743] [batchtime 0.392]
[epoch 92], [iter 13 / 176], [train main loss -2.308463], [lr 0.004743] [batchtime 0.399]
[epoch 92], [iter 14 / 176], [train main loss -2.402932], [lr 0.004743] [batchtime 0.398]
[epoch 92], [iter 15 / 176], [train main loss -2.370242], [lr 0.004743] [batchtime 0.398]
[epoch 92], [iter 16 / 176], [train main loss -2.173882], [lr 0.004743] [batchtime 0.399]
[epoch 92], [iter 17 / 176], [train main loss -2.177463], [lr 0.004743] [batchtime 0.398]
[epoch 92], [iter 18 / 176], [train main loss -2.262989], [lr 0.004743] [batchtime 0.399]
[epoch 92], [iter 19 / 176], [train main loss -2.265309], [lr 0.004743] [batchtime 0.398]
[epoch 92], [iter 20 / 176], [train main loss -2.143534], [lr 0.004743] [batchtime 0.397]
[epoch 92], [iter 21 / 176], [train main loss -2.152449], [lr 0.004743] [batchtime 0.398]
[epoch 92], [iter 22 / 176], [train main loss -2.204949], [lr 0.004743] [batchtime 0.397]
[epoch 92], [iter 23 / 176], [train main loss -2.097186], [lr 0.004743] [batchtime 0.401]
[epoch 92], [iter 24 / 176], [train main loss -2.004896], [lr 0.004743] [batchtime 0.412]
[epoch 92], [iter 25 / 176], [train main loss -1.891332], [lr 0.004743] [batchtime 0.411]
[epoch 92], [iter 26 / 176], [train main loss -1.864946], [lr 0.004743] [batchtime 0.41]
[epoch 92], [iter 27 / 176], [train main loss -1.975299], [lr 0.004743] [batchtime 0.409]
[epoch 92], [iter 28 / 176], [train main loss -1.972902], [lr 0.004743] [batchtime 0.408]
[epoch 92], [iter 29 / 176], [train main loss -1.958655], [lr 0.004743] [batchtime 0.407]
[epoch 92], [iter 30 / 176], [train main loss -2.136113], [lr 0.004743] [batchtime 0.406]
[epoch 92], [iter 31 / 176], [train main loss -2.059273], [lr 0.004743] [batchtime 0.451]
[epoch 92], [iter 32 / 176], [train main loss -2.108099], [lr 0.004743] [batchtime 0.461]
[epoch 92], [iter 33 / 176], [train main loss -2.058265], [lr 0.004743] [batchtime 0.457]
[epoch 92], [iter 34 / 176], [train main loss -2.077429], [lr 0.004743] [batchtime 0.455]
[epoch 92], [iter 35 / 176], [train main loss -2.065954], [lr 0.004743] [batchtime 0.452]
[epoch 92], [iter 36 / 176], [train main loss -2.016126], [lr 0.004743] [batchtime 0.449]
[epoch 92], [iter 37 / 176], [train main loss -1.971638], [lr 0.004743] [batchtime 0.447]
[epoch 92], [iter 38 / 176], [train main loss -1.987462], [lr 0.004743] [batchtime 0.445]
[epoch 92], [iter 39 / 176], [train main loss -2.000118], [lr 0.004743] [batchtime 0.444]
[epoch 92], [iter 40 / 176], [train main loss -1.946842], [lr 0.004743] [batchtime 0.442]
[epoch 92], [iter 41 / 176], [train main loss -1.994255], [lr 0.004743] [batchtime 0.441]
[epoch 92], [iter 42 / 176], [train main loss -1.952749], [lr 0.004743] [batchtime 0.44]
[epoch 92], [iter 43 / 176], [train main loss -1.960232], [lr 0.004743] [batchtime 0.438]
[epoch 92], [iter 44 / 176], [train main loss -2.029654], [lr 0.004743] [batchtime 0.437]
[epoch 92], [iter 45 / 176], [train main loss -2.084689], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 46 / 176], [train main loss -2.175970], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 47 / 176], [train main loss -2.195806], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 48 / 176], [train main loss -2.204889], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 49 / 176], [train main loss -2.190899], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 50 / 176], [train main loss -2.148959], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 51 / 176], [train main loss -2.111997], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 52 / 176], [train main loss -2.130878], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 53 / 176], [train main loss -2.141692], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 54 / 176], [train main loss -2.148132], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 55 / 176], [train main loss -2.202799], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 56 / 176], [train main loss -2.218332], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 57 / 176], [train main loss -2.219248], [lr 0.004743] [batchtime 0.426]
[epoch 92], [iter 58 / 176], [train main loss -2.162115], [lr 0.004743] [batchtime 0.425]
[epoch 92], [iter 59 / 176], [train main loss -2.183218], [lr 0.004743] [batchtime 0.425]
[epoch 92], [iter 60 / 176], [train main loss -2.233112], [lr 0.004743] [batchtime 0.424]
[epoch 92], [iter 61 / 176], [train main loss -2.218905], [lr 0.004743] [batchtime 0.423]
[epoch 92], [iter 62 / 176], [train main loss -2.201996], [lr 0.004743] [batchtime 0.423]
[epoch 92], [iter 63 / 176], [train main loss -2.230359], [lr 0.004743] [batchtime 0.422]
[epoch 92], [iter 64 / 176], [train main loss -2.242154], [lr 0.004743] [batchtime 0.422]
[epoch 92], [iter 65 / 176], [train main loss -2.228322], [lr 0.004743] [batchtime 0.421]
[epoch 92], [iter 66 / 176], [train main loss -2.225142], [lr 0.004743] [batchtime 0.421]
[epoch 92], [iter 67 / 176], [train main loss -2.209808], [lr 0.004743] [batchtime 0.42]
[epoch 92], [iter 68 / 176], [train main loss -2.243282], [lr 0.004743] [batchtime 0.42]
[epoch 92], [iter 69 / 176], [train main loss -2.202967], [lr 0.004743] [batchtime 0.419]
[epoch 92], [iter 70 / 176], [train main loss -2.217597], [lr 0.004743] [batchtime 0.422]
[epoch 92], [iter 71 / 176], [train main loss -2.217301], [lr 0.004743] [batchtime 0.44]
[epoch 92], [iter 72 / 176], [train main loss -2.189950], [lr 0.004743] [batchtime 0.439]
[epoch 92], [iter 73 / 176], [train main loss -2.176209], [lr 0.004743] [batchtime 0.438]
[epoch 92], [iter 74 / 176], [train main loss -2.169177], [lr 0.004743] [batchtime 0.437]
[epoch 92], [iter 75 / 176], [train main loss -2.188788], [lr 0.004743] [batchtime 0.437]
[epoch 92], [iter 76 / 176], [train main loss -2.159213], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 77 / 176], [train main loss -2.173547], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 78 / 176], [train main loss -2.169358], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 79 / 176], [train main loss -2.168056], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 80 / 176], [train main loss -2.158090], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 81 / 176], [train main loss -2.156593], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 82 / 176], [train main loss -2.147596], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 83 / 176], [train main loss -2.146928], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 84 / 176], [train main loss -2.140965], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 85 / 176], [train main loss -2.161510], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 86 / 176], [train main loss -2.185874], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 87 / 176], [train main loss -2.165332], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 88 / 176], [train main loss -2.153633], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 89 / 176], [train main loss -2.147727], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 90 / 176], [train main loss -2.131298], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 91 / 176], [train main loss -2.133658], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 92 / 176], [train main loss -2.157071], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 93 / 176], [train main loss -2.143649], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 94 / 176], [train main loss -2.138832], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 95 / 176], [train main loss -2.163918], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 96 / 176], [train main loss -2.157907], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 97 / 176], [train main loss -2.143498], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 98 / 176], [train main loss -2.122698], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 99 / 176], [train main loss -2.121622], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 100 / 176], [train main loss -2.146982], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 101 / 176], [train main loss -2.166375], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 102 / 176], [train main loss -2.172285], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 103 / 176], [train main loss -2.163003], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 104 / 176], [train main loss -2.160786], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 105 / 176], [train main loss -2.154132], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 106 / 176], [train main loss -2.132755], [lr 0.004743] [batchtime 0.426]
[epoch 92], [iter 107 / 176], [train main loss -2.153815], [lr 0.004743] [batchtime 0.426]
[epoch 92], [iter 108 / 176], [train main loss -2.188781], [lr 0.004743] [batchtime 0.426]
[epoch 92], [iter 109 / 176], [train main loss -2.191517], [lr 0.004743] [batchtime 0.425]
[epoch 92], [iter 110 / 176], [train main loss -2.173988], [lr 0.004743] [batchtime 0.425]
[epoch 92], [iter 111 / 176], [train main loss -2.158070], [lr 0.004743] [batchtime 0.425]
[epoch 92], [iter 112 / 176], [train main loss -2.141717], [lr 0.004743] [batchtime 0.425]
[epoch 92], [iter 113 / 176], [train main loss -2.136597], [lr 0.004743] [batchtime 0.424]
[epoch 92], [iter 114 / 176], [train main loss -2.121259], [lr 0.004743] [batchtime 0.424]
[epoch 92], [iter 115 / 176], [train main loss -2.111708], [lr 0.004743] [batchtime 0.424]
[epoch 92], [iter 116 / 176], [train main loss -2.087353], [lr 0.004743] [batchtime 0.423]
[epoch 92], [iter 117 / 176], [train main loss -2.068299], [lr 0.004743] [batchtime 0.426]
[epoch 92], [iter 118 / 176], [train main loss -2.073275], [lr 0.004743] [batchtime 0.44]
[epoch 92], [iter 119 / 176], [train main loss -2.062712], [lr 0.004743] [batchtime 0.44]
[epoch 92], [iter 120 / 176], [train main loss -2.067602], [lr 0.004743] [batchtime 0.439]
[epoch 92], [iter 121 / 176], [train main loss -2.067661], [lr 0.004743] [batchtime 0.439]
[epoch 92], [iter 122 / 176], [train main loss -2.051812], [lr 0.004743] [batchtime 0.438]
[epoch 92], [iter 123 / 176], [train main loss -2.058249], [lr 0.004743] [batchtime 0.438]
[epoch 92], [iter 124 / 176], [train main loss -2.063339], [lr 0.004743] [batchtime 0.437]
[epoch 92], [iter 125 / 176], [train main loss -2.047197], [lr 0.004743] [batchtime 0.437]
[epoch 92], [iter 126 / 176], [train main loss -2.049779], [lr 0.004743] [batchtime 0.437]
[epoch 92], [iter 127 / 176], [train main loss -2.044262], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 128 / 176], [train main loss -2.017971], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 129 / 176], [train main loss -2.029235], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 130 / 176], [train main loss -2.022670], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 131 / 176], [train main loss -2.025365], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 132 / 176], [train main loss -2.023821], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 133 / 176], [train main loss -2.015831], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 134 / 176], [train main loss -2.024257], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 135 / 176], [train main loss -2.025300], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 136 / 176], [train main loss -2.052729], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 137 / 176], [train main loss -2.063788], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 138 / 176], [train main loss -2.072442], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 139 / 176], [train main loss -2.068641], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 140 / 176], [train main loss -2.056555], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 141 / 176], [train main loss -2.069060], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 142 / 176], [train main loss -2.077345], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 143 / 176], [train main loss -2.098508], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 144 / 176], [train main loss -2.107454], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 145 / 176], [train main loss -2.112435], [lr 0.004743] [batchtime 0.431]
[epoch 92], [iter 146 / 176], [train main loss -2.113496], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 147 / 176], [train main loss -2.123094], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 148 / 176], [train main loss -2.117430], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 149 / 176], [train main loss -2.098885], [lr 0.004743] [batchtime 0.43]
[epoch 92], [iter 150 / 176], [train main loss -2.110322], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 151 / 176], [train main loss -2.115119], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 152 / 176], [train main loss -2.112845], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 153 / 176], [train main loss -2.106888], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 154 / 176], [train main loss -2.115033], [lr 0.004743] [batchtime 0.429]
[epoch 92], [iter 155 / 176], [train main loss -2.118424], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 156 / 176], [train main loss -2.121669], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 157 / 176], [train main loss -2.124477], [lr 0.004743] [batchtime 0.428]
[epoch 92], [iter 158 / 176], [train main loss -2.124562], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 159 / 176], [train main loss -2.129597], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 160 / 176], [train main loss -2.118974], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 161 / 176], [train main loss -2.120293], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 162 / 176], [train main loss -2.114431], [lr 0.004743] [batchtime 0.426]
[epoch 92], [iter 163 / 176], [train main loss -2.104183], [lr 0.004743] [batchtime 0.427]
[epoch 92], [iter 164 / 176], [train main loss -2.112259], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 165 / 176], [train main loss -2.111386], [lr 0.004743] [batchtime 0.436]
[epoch 92], [iter 166 / 176], [train main loss -2.100787], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 167 / 176], [train main loss -2.098849], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 168 / 176], [train main loss -2.108851], [lr 0.004743] [batchtime 0.435]
[epoch 92], [iter 169 / 176], [train main loss -2.105976], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 170 / 176], [train main loss -2.112083], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 171 / 176], [train main loss -2.108835], [lr 0.004743] [batchtime 0.434]
[epoch 92], [iter 172 / 176], [train main loss -2.112422], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 173 / 176], [train main loss -2.109388], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 174 / 176], [train main loss -2.105322], [lr 0.004743] [batchtime 0.433]
[epoch 92], [iter 175 / 176], [train main loss -2.098148], [lr 0.004743] [batchtime 0.432]
[epoch 92], [iter 176 / 176], [train main loss -2.097478], [lr 0.004743] [batchtime 0.432]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              92.94  34.62   0.05  0.03         0.95      0.97
   1  sidewalk          64.01   5.63   0.17  0.39         0.86      0.72
   2  building          85.61  24.78   0.07  0.10         0.93      0.91
   3  wall              16.88   0.14   3.22  1.71         0.24      0.37
   4  fence             25.17   0.44   1.86  1.11         0.35      0.47
   5  pole              37.30   0.57   0.98  0.70         0.51      0.59
   6  traffic light     11.22   0.02   7.41  0.50         0.12      0.67
   7  traffic sign      16.65   0.10   4.77  0.23         0.17      0.81
   8  vegetation        83.89  11.53   0.07  0.12         0.93      0.89
   9  terrain           37.61   0.34   1.15  0.51         0.47      0.66
  10  sky               93.17   3.75   0.03  0.04         0.97      0.96
  11  person            51.91   1.06   0.45  0.47         0.69      0.68
  12  rider              7.12   0.01  11.63  1.42         0.08      0.41
  13  car               85.73   6.60   0.07  0.10         0.93      0.91
  14  truck              1.06   0.00  92.53  0.42         0.01      0.71
  15  bus               13.04   0.04   1.46  5.21         0.41      0.16
  16  train             33.63   0.09   1.02  0.95         0.50      0.51
  17  motorcycle         2.75   0.00  34.62  0.80         0.03      0.56
  18  bicycle           36.41   0.24   0.62  1.13         0.62      0.47
Mean: 41.90
-----------------------------------------------------------------------------------------------------------
this : [epoch 92], [val loss 0.33651], [acc 0.89973], [acc_cls 0.51321], [mean_iu 0.41901], [fwavacc 0.83067]
best : [epoch 92], [val loss 0.33651], [acc 0.89973], [acc_cls 0.51321], [mean_iu 0.41901], [fwavacc 0.83067]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 93], [iter 1 / 176], [train main loss -3.940279], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 2 / 176], [train main loss -2.201955], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 3 / 176], [train main loss -2.005496], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 4 / 176], [train main loss -2.790535], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 5 / 176], [train main loss -2.117595], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 6 / 176], [train main loss -1.867518], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 7 / 176], [train main loss -1.687174], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 8 / 176], [train main loss -1.406160], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 9 / 176], [train main loss -1.651759], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 10 / 176], [train main loss -1.704072], [lr 0.004686] [batchtime 0]
[epoch 93], [iter 11 / 176], [train main loss -1.654061], [lr 0.004686] [batchtime 0.372]
[epoch 93], [iter 12 / 176], [train main loss -1.620740], [lr 0.004686] [batchtime 0.381]
[epoch 93], [iter 13 / 176], [train main loss -1.490536], [lr 0.004686] [batchtime 0.387]
[epoch 93], [iter 14 / 176], [train main loss -1.582030], [lr 0.004686] [batchtime 0.407]
[epoch 93], [iter 15 / 176], [train main loss -1.799606], [lr 0.004686] [batchtime 0.437]
[epoch 93], [iter 16 / 176], [train main loss -1.938606], [lr 0.004686] [batchtime 0.429]
[epoch 93], [iter 17 / 176], [train main loss -1.742043], [lr 0.004686] [batchtime 0.424]
[epoch 93], [iter 18 / 176], [train main loss -1.727590], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 19 / 176], [train main loss -1.649523], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 20 / 176], [train main loss -1.611155], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 21 / 176], [train main loss -1.654886], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 22 / 176], [train main loss -1.656610], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 23 / 176], [train main loss -1.819921], [lr 0.004686] [batchtime 0.411]
[epoch 93], [iter 24 / 176], [train main loss -1.817591], [lr 0.004686] [batchtime 0.409]
[epoch 93], [iter 25 / 176], [train main loss -1.892600], [lr 0.004686] [batchtime 0.408]
[epoch 93], [iter 26 / 176], [train main loss -1.906671], [lr 0.004686] [batchtime 0.407]
[epoch 93], [iter 27 / 176], [train main loss -1.840221], [lr 0.004686] [batchtime 0.406]
[epoch 93], [iter 28 / 176], [train main loss -1.809044], [lr 0.004686] [batchtime 0.405]
[epoch 93], [iter 29 / 176], [train main loss -1.938946], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 30 / 176], [train main loss -1.923887], [lr 0.004686] [batchtime 0.411]
[epoch 93], [iter 31 / 176], [train main loss -1.858661], [lr 0.004686] [batchtime 0.41]
[epoch 93], [iter 32 / 176], [train main loss -1.720781], [lr 0.004686] [batchtime 0.409]
[epoch 93], [iter 33 / 176], [train main loss -1.814044], [lr 0.004686] [batchtime 0.408]
[epoch 93], [iter 34 / 176], [train main loss -1.775243], [lr 0.004686] [batchtime 0.408]
[epoch 93], [iter 35 / 176], [train main loss -1.822066], [lr 0.004686] [batchtime 0.407]
[epoch 93], [iter 36 / 176], [train main loss -1.881548], [lr 0.004686] [batchtime 0.407]
[epoch 93], [iter 37 / 176], [train main loss -1.877480], [lr 0.004686] [batchtime 0.406]
[epoch 93], [iter 38 / 176], [train main loss -1.938247], [lr 0.004686] [batchtime 0.406]
[epoch 93], [iter 39 / 176], [train main loss -2.005006], [lr 0.004686] [batchtime 0.424]
[epoch 93], [iter 40 / 176], [train main loss -2.016180], [lr 0.004686] [batchtime 0.425]
[epoch 93], [iter 41 / 176], [train main loss -2.008772], [lr 0.004686] [batchtime 0.424]
[epoch 93], [iter 42 / 176], [train main loss -1.974460], [lr 0.004686] [batchtime 0.424]
[epoch 93], [iter 43 / 176], [train main loss -1.973566], [lr 0.004686] [batchtime 0.423]
[epoch 93], [iter 44 / 176], [train main loss -2.052306], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 45 / 176], [train main loss -2.072573], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 46 / 176], [train main loss -2.082054], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 47 / 176], [train main loss -2.104350], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 48 / 176], [train main loss -2.083651], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 49 / 176], [train main loss -2.078984], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 50 / 176], [train main loss -2.057160], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 51 / 176], [train main loss -2.032841], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 52 / 176], [train main loss -2.042115], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 53 / 176], [train main loss -2.038498], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 54 / 176], [train main loss -2.011490], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 55 / 176], [train main loss -1.981222], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 56 / 176], [train main loss -1.931186], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 57 / 176], [train main loss -1.963749], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 58 / 176], [train main loss -1.936662], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 59 / 176], [train main loss -1.932806], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 60 / 176], [train main loss -1.912560], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 61 / 176], [train main loss -1.901704], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 62 / 176], [train main loss -1.865824], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 63 / 176], [train main loss -1.862178], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 64 / 176], [train main loss -1.852227], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 65 / 176], [train main loss -1.903720], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 66 / 176], [train main loss -1.920566], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 67 / 176], [train main loss -1.927769], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 68 / 176], [train main loss -1.970707], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 69 / 176], [train main loss -1.961536], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 70 / 176], [train main loss -1.999078], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 71 / 176], [train main loss -2.034048], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 72 / 176], [train main loss -2.033318], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 73 / 176], [train main loss -2.012164], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 74 / 176], [train main loss -2.011263], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 75 / 176], [train main loss -2.051250], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 76 / 176], [train main loss -2.069252], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 77 / 176], [train main loss -2.099283], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 78 / 176], [train main loss -2.091972], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 79 / 176], [train main loss -2.078978], [lr 0.004686] [batchtime 0.411]
[epoch 93], [iter 80 / 176], [train main loss -2.056086], [lr 0.004686] [batchtime 0.411]
[epoch 93], [iter 81 / 176], [train main loss -2.056211], [lr 0.004686] [batchtime 0.411]
[epoch 93], [iter 82 / 176], [train main loss -2.069209], [lr 0.004686] [batchtime 0.411]
[epoch 93], [iter 83 / 176], [train main loss -2.084308], [lr 0.004686] [batchtime 0.41]
[epoch 93], [iter 84 / 176], [train main loss -2.048259], [lr 0.004686] [batchtime 0.41]
[epoch 93], [iter 85 / 176], [train main loss -2.023486], [lr 0.004686] [batchtime 0.41]
[epoch 93], [iter 86 / 176], [train main loss -2.031489], [lr 0.004686] [batchtime 0.41]
[epoch 93], [iter 87 / 176], [train main loss -2.058676], [lr 0.004686] [batchtime 0.41]
[epoch 93], [iter 88 / 176], [train main loss -2.069111], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 89 / 176], [train main loss -2.065652], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 90 / 176], [train main loss -2.048301], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 91 / 176], [train main loss -2.031274], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 92 / 176], [train main loss -2.038697], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 93 / 176], [train main loss -2.037958], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 94 / 176], [train main loss -2.030116], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 95 / 176], [train main loss -2.044713], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 96 / 176], [train main loss -2.024152], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 97 / 176], [train main loss -2.023107], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 98 / 176], [train main loss -2.013619], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 99 / 176], [train main loss -2.018662], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 100 / 176], [train main loss -2.010305], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 101 / 176], [train main loss -2.014668], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 102 / 176], [train main loss -2.010301], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 103 / 176], [train main loss -2.027971], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 104 / 176], [train main loss -2.037609], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 105 / 176], [train main loss -2.018456], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 106 / 176], [train main loss -2.048861], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 107 / 176], [train main loss -2.050395], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 108 / 176], [train main loss -2.036436], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 109 / 176], [train main loss -2.041510], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 110 / 176], [train main loss -2.053754], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 111 / 176], [train main loss -2.066139], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 112 / 176], [train main loss -2.079582], [lr 0.004686] [batchtime 0.417]
[epoch 93], [iter 113 / 176], [train main loss -2.081953], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 114 / 176], [train main loss -2.077376], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 115 / 176], [train main loss -2.078099], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 116 / 176], [train main loss -2.058333], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 117 / 176], [train main loss -2.035287], [lr 0.004686] [batchtime 0.416]
[epoch 93], [iter 118 / 176], [train main loss -2.023445], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 119 / 176], [train main loss -2.037464], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 120 / 176], [train main loss -2.017442], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 121 / 176], [train main loss -2.002064], [lr 0.004686] [batchtime 0.415]
[epoch 93], [iter 122 / 176], [train main loss -2.013818], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 123 / 176], [train main loss -1.994418], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 124 / 176], [train main loss -1.991291], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 125 / 176], [train main loss -1.977923], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 126 / 176], [train main loss -1.964320], [lr 0.004686] [batchtime 0.414]
[epoch 93], [iter 127 / 176], [train main loss -1.972971], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 128 / 176], [train main loss -1.962368], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 129 / 176], [train main loss -1.965673], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 130 / 176], [train main loss -1.965905], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 131 / 176], [train main loss -1.972831], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 132 / 176], [train main loss -1.995218], [lr 0.004686] [batchtime 0.413]
[epoch 93], [iter 133 / 176], [train main loss -1.989084], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 134 / 176], [train main loss -2.004032], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 135 / 176], [train main loss -1.995778], [lr 0.004686] [batchtime 0.412]
[epoch 93], [iter 136 / 176], [train main loss -2.002100], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 137 / 176], [train main loss -2.020631], [lr 0.004686] [batchtime 0.423]
[epoch 93], [iter 138 / 176], [train main loss -2.026978], [lr 0.004686] [batchtime 0.423]
[epoch 93], [iter 139 / 176], [train main loss -2.018993], [lr 0.004686] [batchtime 0.423]
[epoch 93], [iter 140 / 176], [train main loss -2.018273], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 141 / 176], [train main loss -2.008615], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 142 / 176], [train main loss -2.024788], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 143 / 176], [train main loss -2.020751], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 144 / 176], [train main loss -2.019019], [lr 0.004686] [batchtime 0.422]
[epoch 93], [iter 145 / 176], [train main loss -2.012698], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 146 / 176], [train main loss -2.014471], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 147 / 176], [train main loss -1.998672], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 148 / 176], [train main loss -1.977465], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 149 / 176], [train main loss -1.956116], [lr 0.004686] [batchtime 0.421]
[epoch 93], [iter 150 / 176], [train main loss -1.952434], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 151 / 176], [train main loss -1.939888], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 152 / 176], [train main loss -1.937135], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 153 / 176], [train main loss -1.927132], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 154 / 176], [train main loss -1.911925], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 155 / 176], [train main loss -1.907597], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 156 / 176], [train main loss -1.902720], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 157 / 176], [train main loss -1.891998], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 158 / 176], [train main loss -1.896727], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 159 / 176], [train main loss -1.909226], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 160 / 176], [train main loss -1.906980], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 161 / 176], [train main loss -1.898125], [lr 0.004686] [batchtime 0.42]
[epoch 93], [iter 162 / 176], [train main loss -1.897279], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 163 / 176], [train main loss -1.884489], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 164 / 176], [train main loss -1.887633], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 165 / 176], [train main loss -1.889171], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 166 / 176], [train main loss -1.872103], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 167 / 176], [train main loss -1.864918], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 168 / 176], [train main loss -1.853931], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 169 / 176], [train main loss -1.849103], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 170 / 176], [train main loss -1.828909], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 171 / 176], [train main loss -1.837774], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 172 / 176], [train main loss -1.818591], [lr 0.004686] [batchtime 0.419]
[epoch 93], [iter 173 / 176], [train main loss -1.822352], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 174 / 176], [train main loss -1.836326], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 175 / 176], [train main loss -1.845862], [lr 0.004686] [batchtime 0.418]
[epoch 93], [iter 176 / 176], [train main loss -1.846115], [lr 0.004686] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.02  35.35    0.03  0.04         0.97      0.97
   1  sidewalk          66.13   5.32    0.24  0.27         0.81      0.79
   2  building          84.69  24.13    0.10  0.08         0.91      0.93
   3  wall              17.37   0.14    3.21  1.55         0.24      0.39
   4  fence             22.57   0.35    2.66  0.77         0.27      0.57
   5  pole              36.92   0.61    0.85  0.86         0.54      0.54
   6  traffic light     12.30   0.02    6.59  0.54         0.13      0.65
   7  traffic sign      18.43   0.11    4.14  0.28         0.19      0.78
   8  vegetation        82.02  11.75    0.05  0.17         0.95      0.86
   9  terrain           40.36   0.38    0.94  0.53         0.51      0.65
  10  sky               92.42   3.75    0.03  0.05         0.97      0.95
  11  person            50.82   1.08    0.42  0.55         0.70      0.65
  12  rider              6.30   0.01   13.57  1.30         0.07      0.44
  13  car               84.73   6.69    0.06  0.12         0.95      0.89
  14  truck              0.60   0.00  165.76  0.71         0.01      0.59
  15  bus               14.62   0.04    1.29  4.55         0.44      0.18
  16  train             31.03   0.08    1.38  0.84         0.42      0.54
  17  motorcycle         2.73   0.00   34.89  0.78         0.03      0.56
  18  bicycle           35.05   0.24    0.62  1.23         0.62      0.45
Mean: 41.74
-----------------------------------------------------------------------------------------------------------
this : [epoch 93], [val loss 0.34125], [acc 0.90042], [acc_cls 0.51177], [mean_iu 0.41743], [fwavacc 0.82991]
best : [epoch 92], [val loss 0.33651], [acc 0.89973], [acc_cls 0.51321], [mean_iu 0.41901], [fwavacc 0.83067]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 94], [iter 1 / 176], [train main loss -0.943121], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 2 / 176], [train main loss -0.426409], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 3 / 176], [train main loss -0.603837], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 4 / 176], [train main loss -0.407551], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 5 / 176], [train main loss -0.731880], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 6 / 176], [train main loss -0.873104], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 7 / 176], [train main loss -0.832243], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 8 / 176], [train main loss -1.010794], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 9 / 176], [train main loss -1.039216], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 10 / 176], [train main loss -1.243679], [lr 0.004629] [batchtime 0]
[epoch 94], [iter 11 / 176], [train main loss -1.239376], [lr 0.004629] [batchtime 0.37]
[epoch 94], [iter 12 / 176], [train main loss -1.254616], [lr 0.004629] [batchtime 0.385]
[epoch 94], [iter 13 / 176], [train main loss -1.422725], [lr 0.004629] [batchtime 0.387]
[epoch 94], [iter 14 / 176], [train main loss -1.528975], [lr 0.004629] [batchtime 0.39]
[epoch 94], [iter 15 / 176], [train main loss -1.695067], [lr 0.004629] [batchtime 0.397]
[epoch 94], [iter 16 / 176], [train main loss -1.753706], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 17 / 176], [train main loss -1.714681], [lr 0.004629] [batchtime 0.397]
[epoch 94], [iter 18 / 176], [train main loss -1.844649], [lr 0.004629] [batchtime 0.397]
[epoch 94], [iter 19 / 176], [train main loss -1.746308], [lr 0.004629] [batchtime 0.399]
[epoch 94], [iter 20 / 176], [train main loss -1.669158], [lr 0.004629] [batchtime 0.399]
[epoch 94], [iter 21 / 176], [train main loss -1.818264], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 22 / 176], [train main loss -1.865707], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 23 / 176], [train main loss -1.885064], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 24 / 176], [train main loss -1.830642], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 25 / 176], [train main loss -1.883266], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 26 / 176], [train main loss -1.930480], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 27 / 176], [train main loss -1.980777], [lr 0.004629] [batchtime 0.398]
[epoch 94], [iter 28 / 176], [train main loss -2.024390], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 29 / 176], [train main loss -2.070159], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 30 / 176], [train main loss -2.010753], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 31 / 176], [train main loss -1.980728], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 32 / 176], [train main loss -1.976665], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 33 / 176], [train main loss -1.982830], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 34 / 176], [train main loss -1.985197], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 35 / 176], [train main loss -1.937355], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 36 / 176], [train main loss -1.960298], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 37 / 176], [train main loss -1.980297], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 38 / 176], [train main loss -1.978119], [lr 0.004629] [batchtime 0.402]
[epoch 94], [iter 39 / 176], [train main loss -2.003764], [lr 0.004629] [batchtime 0.401]
[epoch 94], [iter 40 / 176], [train main loss -1.978383], [lr 0.004629] [batchtime 0.407]
[epoch 94], [iter 41 / 176], [train main loss -1.986511], [lr 0.004629] [batchtime 0.407]
[epoch 94], [iter 42 / 176], [train main loss -1.946057], [lr 0.004629] [batchtime 0.406]
[epoch 94], [iter 43 / 176], [train main loss -1.927746], [lr 0.004629] [batchtime 0.406]
[epoch 94], [iter 44 / 176], [train main loss -1.923945], [lr 0.004629] [batchtime 0.406]
[epoch 94], [iter 45 / 176], [train main loss -1.917258], [lr 0.004629] [batchtime 0.405]
[epoch 94], [iter 46 / 176], [train main loss -1.958788], [lr 0.004629] [batchtime 0.405]
[epoch 94], [iter 47 / 176], [train main loss -1.917137], [lr 0.004629] [batchtime 0.405]
[epoch 94], [iter 48 / 176], [train main loss -1.942850], [lr 0.004629] [batchtime 0.405]
[epoch 94], [iter 49 / 176], [train main loss -1.893598], [lr 0.004629] [batchtime 0.405]
[epoch 94], [iter 50 / 176], [train main loss -1.933456], [lr 0.004629] [batchtime 0.405]
[epoch 94], [iter 51 / 176], [train main loss -1.918084], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 52 / 176], [train main loss -1.927950], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 53 / 176], [train main loss -1.975934], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 54 / 176], [train main loss -2.019786], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 55 / 176], [train main loss -1.997266], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 56 / 176], [train main loss -2.009835], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 57 / 176], [train main loss -2.025364], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 58 / 176], [train main loss -1.972176], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 59 / 176], [train main loss -1.938961], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 60 / 176], [train main loss -1.908580], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 61 / 176], [train main loss -1.935502], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 62 / 176], [train main loss -1.951268], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 63 / 176], [train main loss -1.951175], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 64 / 176], [train main loss -1.989857], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 65 / 176], [train main loss -2.004558], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 66 / 176], [train main loss -1.994578], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 67 / 176], [train main loss -2.047782], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 68 / 176], [train main loss -2.067065], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 69 / 176], [train main loss -2.045750], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 70 / 176], [train main loss -2.036060], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 71 / 176], [train main loss -2.049082], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 72 / 176], [train main loss -2.055337], [lr 0.004629] [batchtime 0.404]
[epoch 94], [iter 73 / 176], [train main loss -2.063768], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 74 / 176], [train main loss -2.059580], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 75 / 176], [train main loss -2.075426], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 76 / 176], [train main loss -2.098716], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 77 / 176], [train main loss -2.116170], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 78 / 176], [train main loss -2.111240], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 79 / 176], [train main loss -2.089318], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 80 / 176], [train main loss -2.076587], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 81 / 176], [train main loss -2.099712], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 82 / 176], [train main loss -2.090210], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 83 / 176], [train main loss -2.092686], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 84 / 176], [train main loss -2.072195], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 85 / 176], [train main loss -2.084590], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 86 / 176], [train main loss -2.075590], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 87 / 176], [train main loss -2.053284], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 88 / 176], [train main loss -2.057780], [lr 0.004629] [batchtime 0.403]
[epoch 94], [iter 89 / 176], [train main loss -2.059714], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 90 / 176], [train main loss -2.048421], [lr 0.004629] [batchtime 0.41]
[epoch 94], [iter 91 / 176], [train main loss -2.027622], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 92 / 176], [train main loss -2.050823], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 93 / 176], [train main loss -2.058762], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 94 / 176], [train main loss -2.058588], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 95 / 176], [train main loss -2.027877], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 96 / 176], [train main loss -2.045137], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 97 / 176], [train main loss -2.042371], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 98 / 176], [train main loss -2.033573], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 99 / 176], [train main loss -2.046912], [lr 0.004629] [batchtime 0.409]
[epoch 94], [iter 100 / 176], [train main loss -2.025287], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 101 / 176], [train main loss -2.014325], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 102 / 176], [train main loss -1.994780], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 103 / 176], [train main loss -2.013452], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 104 / 176], [train main loss -1.993126], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 105 / 176], [train main loss -1.982337], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 106 / 176], [train main loss -1.971715], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 107 / 176], [train main loss -1.961474], [lr 0.004629] [batchtime 0.408]
[epoch 94], [iter 108 / 176], [train main loss -1.971174], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 109 / 176], [train main loss -1.983201], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 110 / 176], [train main loss -1.992085], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 111 / 176], [train main loss -1.996732], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 112 / 176], [train main loss -1.987988], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 113 / 176], [train main loss -1.984231], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 114 / 176], [train main loss -1.997655], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 115 / 176], [train main loss -1.993700], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 116 / 176], [train main loss -2.020880], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 117 / 176], [train main loss -2.051280], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 118 / 176], [train main loss -2.027808], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 119 / 176], [train main loss -2.039459], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 120 / 176], [train main loss -2.029893], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 121 / 176], [train main loss -2.029921], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 122 / 176], [train main loss -2.015821], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 123 / 176], [train main loss -2.038510], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 124 / 176], [train main loss -2.045722], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 125 / 176], [train main loss -2.050753], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 126 / 176], [train main loss -2.040443], [lr 0.004629] [batchtime 0.417]
[epoch 94], [iter 127 / 176], [train main loss -2.051682], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 128 / 176], [train main loss -2.057346], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 129 / 176], [train main loss -2.052450], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 130 / 176], [train main loss -2.046039], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 131 / 176], [train main loss -2.035412], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 132 / 176], [train main loss -2.023396], [lr 0.004629] [batchtime 0.416]
[epoch 94], [iter 133 / 176], [train main loss -2.035350], [lr 0.004629] [batchtime 0.415]
[epoch 94], [iter 134 / 176], [train main loss -2.027564], [lr 0.004629] [batchtime 0.415]
[epoch 94], [iter 135 / 176], [train main loss -2.063181], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 136 / 176], [train main loss -2.057704], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 137 / 176], [train main loss -2.059360], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 138 / 176], [train main loss -2.063757], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 139 / 176], [train main loss -2.060166], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 140 / 176], [train main loss -2.073607], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 141 / 176], [train main loss -2.080184], [lr 0.004629] [batchtime 0.421]
[epoch 94], [iter 142 / 176], [train main loss -2.080369], [lr 0.004629] [batchtime 0.421]
[epoch 94], [iter 143 / 176], [train main loss -2.084784], [lr 0.004629] [batchtime 0.421]
[epoch 94], [iter 144 / 176], [train main loss -2.082535], [lr 0.004629] [batchtime 0.421]
[epoch 94], [iter 145 / 176], [train main loss -2.086814], [lr 0.004629] [batchtime 0.421]
[epoch 94], [iter 146 / 176], [train main loss -2.085332], [lr 0.004629] [batchtime 0.42]
[epoch 94], [iter 147 / 176], [train main loss -2.082373], [lr 0.004629] [batchtime 0.42]
[epoch 94], [iter 148 / 176], [train main loss -2.082765], [lr 0.004629] [batchtime 0.42]
[epoch 94], [iter 149 / 176], [train main loss -2.086948], [lr 0.004629] [batchtime 0.42]
[epoch 94], [iter 150 / 176], [train main loss -2.091882], [lr 0.004629] [batchtime 0.42]
[epoch 94], [iter 151 / 176], [train main loss -2.100766], [lr 0.004629] [batchtime 0.42]
[epoch 94], [iter 152 / 176], [train main loss -2.104978], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 153 / 176], [train main loss -2.118545], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 154 / 176], [train main loss -2.116267], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 155 / 176], [train main loss -2.122291], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 156 / 176], [train main loss -2.136378], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 157 / 176], [train main loss -2.130076], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 158 / 176], [train main loss -2.130926], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 159 / 176], [train main loss -2.122864], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 160 / 176], [train main loss -2.126355], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 161 / 176], [train main loss -2.115155], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 162 / 176], [train main loss -2.116785], [lr 0.004629] [batchtime 0.418]
[epoch 94], [iter 163 / 176], [train main loss -2.113960], [lr 0.004629] [batchtime 0.419]
[epoch 94], [iter 164 / 176], [train main loss -2.115716], [lr 0.004629] [batchtime 0.425]
[epoch 94], [iter 165 / 176], [train main loss -2.119574], [lr 0.004629] [batchtime 0.424]
[epoch 94], [iter 166 / 176], [train main loss -2.103438], [lr 0.004629] [batchtime 0.424]
[epoch 94], [iter 167 / 176], [train main loss -2.109427], [lr 0.004629] [batchtime 0.424]
[epoch 94], [iter 168 / 176], [train main loss -2.119534], [lr 0.004629] [batchtime 0.424]
[epoch 94], [iter 169 / 176], [train main loss -2.128467], [lr 0.004629] [batchtime 0.423]
[epoch 94], [iter 170 / 176], [train main loss -2.125216], [lr 0.004629] [batchtime 0.423]
[epoch 94], [iter 171 / 176], [train main loss -2.132002], [lr 0.004629] [batchtime 0.423]
[epoch 94], [iter 172 / 176], [train main loss -2.124555], [lr 0.004629] [batchtime 0.423]
[epoch 94], [iter 173 / 176], [train main loss -2.116239], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 174 / 176], [train main loss -2.112700], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 175 / 176], [train main loss -2.120115], [lr 0.004629] [batchtime 0.422]
[epoch 94], [iter 176 / 176], [train main loss -2.122475], [lr 0.004629] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.31  35.63    0.02  0.04         0.98      0.96
   1  sidewalk          67.14   5.00    0.32  0.17         0.76      0.85
   2  building          85.69  25.15    0.06  0.11         0.95      0.90
   3  wall              18.42   0.15    2.97  1.46         0.25      0.41
   4  fence             21.78   0.32    2.93  0.67         0.25      0.60
   5  pole              37.19   0.52    1.17  0.52         0.46      0.66
   6  traffic light      9.99   0.02    8.61  0.40         0.10      0.72
   7  traffic sign      15.85   0.09    5.09  0.22         0.16      0.82
   8  vegetation        82.48  11.62    0.06  0.15         0.94      0.87
   9  terrain           42.08   0.42    0.74  0.64         0.58      0.61
  10  sky               93.38   3.74    0.04  0.03         0.97      0.97
  11  person            50.52   0.94    0.64  0.34         0.61      0.74
  12  rider              7.11   0.01   11.92  1.15         0.08      0.47
  13  car               85.02   6.62    0.07  0.11         0.94      0.90
  14  truck              0.52   0.00  190.13  0.51         0.01      0.66
  15  bus               15.02   0.05    0.89  4.77         0.53      0.17
  16  train             29.30   0.06    1.93  0.48         0.34      0.67
  17  motorcycle         2.32   0.00   41.74  0.46         0.02      0.69
  18  bicycle           36.87   0.23    0.69  1.02         0.59      0.49
Mean: 41.84
-----------------------------------------------------------------------------------------------------------
this : [epoch 94], [val loss 0.33838], [acc 0.90572], [acc_cls 0.50084], [mean_iu 0.41842], [fwavacc 0.83538]
best : [epoch 92], [val loss 0.33651], [acc 0.89973], [acc_cls 0.51321], [mean_iu 0.41901], [fwavacc 0.83067]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 95], [iter 1 / 176], [train main loss -0.876464], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 2 / 176], [train main loss -1.469370], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 3 / 176], [train main loss -2.538286], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 4 / 176], [train main loss -2.002472], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 5 / 176], [train main loss -2.655987], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 6 / 176], [train main loss -2.683199], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 7 / 176], [train main loss -2.932791], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 8 / 176], [train main loss -3.263762], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 9 / 176], [train main loss -3.212401], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 10 / 176], [train main loss -2.868365], [lr 0.004571] [batchtime 0]
[epoch 95], [iter 11 / 176], [train main loss -2.601684], [lr 0.004571] [batchtime 0.373]
[epoch 95], [iter 12 / 176], [train main loss -2.687315], [lr 0.004571] [batchtime 0.388]
[epoch 95], [iter 13 / 176], [train main loss -2.668482], [lr 0.004571] [batchtime 0.391]
[epoch 95], [iter 14 / 176], [train main loss -2.560906], [lr 0.004571] [batchtime 0.395]
[epoch 95], [iter 15 / 176], [train main loss -2.534998], [lr 0.004571] [batchtime 0.396]
[epoch 95], [iter 16 / 176], [train main loss -2.810955], [lr 0.004571] [batchtime 0.397]
[epoch 95], [iter 17 / 176], [train main loss -2.928091], [lr 0.004571] [batchtime 0.397]
[epoch 95], [iter 18 / 176], [train main loss -2.958357], [lr 0.004571] [batchtime 0.398]
[epoch 95], [iter 19 / 176], [train main loss -2.809618], [lr 0.004571] [batchtime 0.396]
[epoch 95], [iter 20 / 176], [train main loss -2.832037], [lr 0.004571] [batchtime 0.398]
[epoch 95], [iter 21 / 176], [train main loss -2.924414], [lr 0.004571] [batchtime 0.398]
[epoch 95], [iter 22 / 176], [train main loss -2.827170], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 23 / 176], [train main loss -2.710774], [lr 0.004571] [batchtime 0.398]
[epoch 95], [iter 24 / 176], [train main loss -2.642437], [lr 0.004571] [batchtime 0.398]
[epoch 95], [iter 25 / 176], [train main loss -2.562594], [lr 0.004571] [batchtime 0.398]
[epoch 95], [iter 26 / 176], [train main loss -2.463919], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 27 / 176], [train main loss -2.445633], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 28 / 176], [train main loss -2.395636], [lr 0.004571] [batchtime 0.4]
[epoch 95], [iter 29 / 176], [train main loss -2.424505], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 30 / 176], [train main loss -2.349374], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 31 / 176], [train main loss -2.462778], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 32 / 176], [train main loss -2.524826], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 33 / 176], [train main loss -2.529371], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 34 / 176], [train main loss -2.610305], [lr 0.004571] [batchtime 0.399]
[epoch 95], [iter 35 / 176], [train main loss -2.543828], [lr 0.004571] [batchtime 0.4]
[epoch 95], [iter 36 / 176], [train main loss -2.479104], [lr 0.004571] [batchtime 0.4]
[epoch 95], [iter 37 / 176], [train main loss -2.491355], [lr 0.004571] [batchtime 0.405]
[epoch 95], [iter 38 / 176], [train main loss -2.413896], [lr 0.004571] [batchtime 0.456]
[epoch 95], [iter 39 / 176], [train main loss -2.454975], [lr 0.004571] [batchtime 0.454]
[epoch 95], [iter 40 / 176], [train main loss -2.436195], [lr 0.004571] [batchtime 0.452]
[epoch 95], [iter 41 / 176], [train main loss -2.426794], [lr 0.004571] [batchtime 0.45]
[epoch 95], [iter 42 / 176], [train main loss -2.396081], [lr 0.004571] [batchtime 0.448]
[epoch 95], [iter 43 / 176], [train main loss -2.384808], [lr 0.004571] [batchtime 0.446]
[epoch 95], [iter 44 / 176], [train main loss -2.359706], [lr 0.004571] [batchtime 0.445]
[epoch 95], [iter 45 / 176], [train main loss -2.404780], [lr 0.004571] [batchtime 0.444]
[epoch 95], [iter 46 / 176], [train main loss -2.385381], [lr 0.004571] [batchtime 0.443]
[epoch 95], [iter 47 / 176], [train main loss -2.390833], [lr 0.004571] [batchtime 0.442]
[epoch 95], [iter 48 / 176], [train main loss -2.395744], [lr 0.004571] [batchtime 0.45]
[epoch 95], [iter 49 / 176], [train main loss -2.376686], [lr 0.004571] [batchtime 0.449]
[epoch 95], [iter 50 / 176], [train main loss -2.308999], [lr 0.004571] [batchtime 0.447]
[epoch 95], [iter 51 / 176], [train main loss -2.318919], [lr 0.004571] [batchtime 0.446]
[epoch 95], [iter 52 / 176], [train main loss -2.318933], [lr 0.004571] [batchtime 0.445]
[epoch 95], [iter 53 / 176], [train main loss -2.312168], [lr 0.004571] [batchtime 0.444]
[epoch 95], [iter 54 / 176], [train main loss -2.362222], [lr 0.004571] [batchtime 0.443]
[epoch 95], [iter 55 / 176], [train main loss -2.307636], [lr 0.004571] [batchtime 0.442]
[epoch 95], [iter 56 / 176], [train main loss -2.304986], [lr 0.004571] [batchtime 0.441]
[epoch 95], [iter 57 / 176], [train main loss -2.274728], [lr 0.004571] [batchtime 0.44]
[epoch 95], [iter 58 / 176], [train main loss -2.177595], [lr 0.004571] [batchtime 0.439]
[epoch 95], [iter 59 / 176], [train main loss -2.209879], [lr 0.004571] [batchtime 0.438]
[epoch 95], [iter 60 / 176], [train main loss -2.200055], [lr 0.004571] [batchtime 0.437]
[epoch 95], [iter 61 / 176], [train main loss -2.188642], [lr 0.004571] [batchtime 0.437]
[epoch 95], [iter 62 / 176], [train main loss -2.196624], [lr 0.004571] [batchtime 0.436]
[epoch 95], [iter 63 / 176], [train main loss -2.151486], [lr 0.004571] [batchtime 0.435]
[epoch 95], [iter 64 / 176], [train main loss -2.134260], [lr 0.004571] [batchtime 0.434]
[epoch 95], [iter 65 / 176], [train main loss -2.154695], [lr 0.004571] [batchtime 0.434]
[epoch 95], [iter 66 / 176], [train main loss -2.181142], [lr 0.004571] [batchtime 0.433]
[epoch 95], [iter 67 / 176], [train main loss -2.159531], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 68 / 176], [train main loss -2.157051], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 69 / 176], [train main loss -2.176142], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 70 / 176], [train main loss -2.174840], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 71 / 176], [train main loss -2.139026], [lr 0.004571] [batchtime 0.434]
[epoch 95], [iter 72 / 176], [train main loss -2.117288], [lr 0.004571] [batchtime 0.434]
[epoch 95], [iter 73 / 176], [train main loss -2.098472], [lr 0.004571] [batchtime 0.433]
[epoch 95], [iter 74 / 176], [train main loss -2.106393], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 75 / 176], [train main loss -2.117186], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 76 / 176], [train main loss -2.110012], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 77 / 176], [train main loss -2.144072], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 78 / 176], [train main loss -2.135393], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 79 / 176], [train main loss -2.108323], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 80 / 176], [train main loss -2.121543], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 81 / 176], [train main loss -2.109915], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 82 / 176], [train main loss -2.105749], [lr 0.004571] [batchtime 0.436]
[epoch 95], [iter 83 / 176], [train main loss -2.115921], [lr 0.004571] [batchtime 0.443]
[epoch 95], [iter 84 / 176], [train main loss -2.142983], [lr 0.004571] [batchtime 0.443]
[epoch 95], [iter 85 / 176], [train main loss -2.136830], [lr 0.004571] [batchtime 0.442]
[epoch 95], [iter 86 / 176], [train main loss -2.133258], [lr 0.004571] [batchtime 0.441]
[epoch 95], [iter 87 / 176], [train main loss -2.119936], [lr 0.004571] [batchtime 0.441]
[epoch 95], [iter 88 / 176], [train main loss -2.115433], [lr 0.004571] [batchtime 0.44]
[epoch 95], [iter 89 / 176], [train main loss -2.166418], [lr 0.004571] [batchtime 0.44]
[epoch 95], [iter 90 / 176], [train main loss -2.139380], [lr 0.004571] [batchtime 0.439]
[epoch 95], [iter 91 / 176], [train main loss -2.131180], [lr 0.004571] [batchtime 0.439]
[epoch 95], [iter 92 / 176], [train main loss -2.124935], [lr 0.004571] [batchtime 0.438]
[epoch 95], [iter 93 / 176], [train main loss -2.112985], [lr 0.004571] [batchtime 0.438]
[epoch 95], [iter 94 / 176], [train main loss -2.124359], [lr 0.004571] [batchtime 0.438]
[epoch 95], [iter 95 / 176], [train main loss -2.094512], [lr 0.004571] [batchtime 0.437]
[epoch 95], [iter 96 / 176], [train main loss -2.105306], [lr 0.004571] [batchtime 0.437]
[epoch 95], [iter 97 / 176], [train main loss -2.096953], [lr 0.004571] [batchtime 0.436]
[epoch 95], [iter 98 / 176], [train main loss -2.096501], [lr 0.004571] [batchtime 0.436]
[epoch 95], [iter 99 / 176], [train main loss -2.101580], [lr 0.004571] [batchtime 0.436]
[epoch 95], [iter 100 / 176], [train main loss -2.090239], [lr 0.004571] [batchtime 0.435]
[epoch 95], [iter 101 / 176], [train main loss -2.084097], [lr 0.004571] [batchtime 0.435]
[epoch 95], [iter 102 / 176], [train main loss -2.075669], [lr 0.004571] [batchtime 0.434]
[epoch 95], [iter 103 / 176], [train main loss -2.067623], [lr 0.004571] [batchtime 0.434]
[epoch 95], [iter 104 / 176], [train main loss -2.089836], [lr 0.004571] [batchtime 0.433]
[epoch 95], [iter 105 / 176], [train main loss -2.094071], [lr 0.004571] [batchtime 0.433]
[epoch 95], [iter 106 / 176], [train main loss -2.091919], [lr 0.004571] [batchtime 0.433]
[epoch 95], [iter 107 / 176], [train main loss -2.112858], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 108 / 176], [train main loss -2.106879], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 109 / 176], [train main loss -2.117298], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 110 / 176], [train main loss -2.125647], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 111 / 176], [train main loss -2.128125], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 112 / 176], [train main loss -2.142468], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 113 / 176], [train main loss -2.139074], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 114 / 176], [train main loss -2.115280], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 115 / 176], [train main loss -2.098655], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 116 / 176], [train main loss -2.080642], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 117 / 176], [train main loss -2.075362], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 118 / 176], [train main loss -2.087235], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 119 / 176], [train main loss -2.101626], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 120 / 176], [train main loss -2.101055], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 121 / 176], [train main loss -2.102359], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 122 / 176], [train main loss -2.104420], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 123 / 176], [train main loss -2.091795], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 124 / 176], [train main loss -2.102057], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 125 / 176], [train main loss -2.112900], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 126 / 176], [train main loss -2.121976], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 127 / 176], [train main loss -2.134254], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 128 / 176], [train main loss -2.126742], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 129 / 176], [train main loss -2.126420], [lr 0.004571] [batchtime 0.425]
[epoch 95], [iter 130 / 176], [train main loss -2.143255], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 131 / 176], [train main loss -2.135417], [lr 0.004571] [batchtime 0.432]
[epoch 95], [iter 132 / 176], [train main loss -2.167852], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 133 / 176], [train main loss -2.168916], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 134 / 176], [train main loss -2.182870], [lr 0.004571] [batchtime 0.431]
[epoch 95], [iter 135 / 176], [train main loss -2.167485], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 136 / 176], [train main loss -2.165880], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 137 / 176], [train main loss -2.149369], [lr 0.004571] [batchtime 0.43]
[epoch 95], [iter 138 / 176], [train main loss -2.160955], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 139 / 176], [train main loss -2.147551], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 140 / 176], [train main loss -2.134821], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 141 / 176], [train main loss -2.132598], [lr 0.004571] [batchtime 0.429]
[epoch 95], [iter 142 / 176], [train main loss -2.133485], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 143 / 176], [train main loss -2.147725], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 144 / 176], [train main loss -2.150741], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 145 / 176], [train main loss -2.156215], [lr 0.004571] [batchtime 0.428]
[epoch 95], [iter 146 / 176], [train main loss -2.158420], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 147 / 176], [train main loss -2.167777], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 148 / 176], [train main loss -2.143759], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 149 / 176], [train main loss -2.131232], [lr 0.004571] [batchtime 0.427]
[epoch 95], [iter 150 / 176], [train main loss -2.119682], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 151 / 176], [train main loss -2.138259], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 152 / 176], [train main loss -2.129150], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 153 / 176], [train main loss -2.133386], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 154 / 176], [train main loss -2.125859], [lr 0.004571] [batchtime 0.426]
[epoch 95], [iter 155 / 176], [train main loss -2.121153], [lr 0.004571] [batchtime 0.425]
[epoch 95], [iter 156 / 176], [train main loss -2.113084], [lr 0.004571] [batchtime 0.425]
[epoch 95], [iter 157 / 176], [train main loss -2.101462], [lr 0.004571] [batchtime 0.425]
[epoch 95], [iter 158 / 176], [train main loss -2.109812], [lr 0.004571] [batchtime 0.425]
[epoch 95], [iter 159 / 176], [train main loss -2.101769], [lr 0.004571] [batchtime 0.425]
[epoch 95], [iter 160 / 176], [train main loss -2.093488], [lr 0.004571] [batchtime 0.424]
[epoch 95], [iter 161 / 176], [train main loss -2.097486], [lr 0.004571] [batchtime 0.424]
[epoch 95], [iter 162 / 176], [train main loss -2.088363], [lr 0.004571] [batchtime 0.424]
[epoch 95], [iter 163 / 176], [train main loss -2.103595], [lr 0.004571] [batchtime 0.424]
[epoch 95], [iter 164 / 176], [train main loss -2.104861], [lr 0.004571] [batchtime 0.424]
[epoch 95], [iter 165 / 176], [train main loss -2.100587], [lr 0.004571] [batchtime 0.424]
[epoch 95], [iter 166 / 176], [train main loss -2.095331], [lr 0.004571] [batchtime 0.423]
[epoch 95], [iter 167 / 176], [train main loss -2.077043], [lr 0.004571] [batchtime 0.423]
[epoch 95], [iter 168 / 176], [train main loss -2.078769], [lr 0.004571] [batchtime 0.423]
[epoch 95], [iter 169 / 176], [train main loss -2.079264], [lr 0.004571] [batchtime 0.423]
[epoch 95], [iter 170 / 176], [train main loss -2.094745], [lr 0.004571] [batchtime 0.423]
[epoch 95], [iter 171 / 176], [train main loss -2.092525], [lr 0.004571] [batchtime 0.422]
[epoch 95], [iter 172 / 176], [train main loss -2.077211], [lr 0.004571] [batchtime 0.422]
[epoch 95], [iter 173 / 176], [train main loss -2.071045], [lr 0.004571] [batchtime 0.422]
[epoch 95], [iter 174 / 176], [train main loss -2.070163], [lr 0.004571] [batchtime 0.421]
[epoch 95], [iter 175 / 176], [train main loss -2.074188], [lr 0.004571] [batchtime 0.421]
[epoch 95], [iter 176 / 176], [train main loss -2.066756], [lr 0.004571] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              93.54  35.13    0.03  0.03         0.97      0.97
   1  sidewalk          66.10   5.26    0.25  0.26         0.80      0.79
   2  building          86.11  25.13    0.06  0.10         0.95      0.91
   3  wall              17.33   0.15    3.04  1.73         0.25      0.37
   4  fence             24.22   0.38    2.37  0.76         0.30      0.57
   5  pole              37.45   0.54    1.12  0.55         0.47      0.64
   6  traffic light     10.37   0.02    8.21  0.43         0.11      0.70
   7  traffic sign      17.13   0.10    4.58  0.26         0.18      0.79
   8  vegetation        83.49  11.53    0.07  0.13         0.93      0.89
   9  terrain           39.51   0.39    0.90  0.63         0.53      0.61
  10  sky               93.61   3.75    0.03  0.03         0.97      0.97
  11  person            51.61   1.03    0.48  0.45         0.67      0.69
  12  rider              7.16   0.01   11.61  1.36         0.08      0.42
  13  car               85.21   6.65    0.06  0.11         0.94      0.90
  14  truck              0.90   0.00  109.04  0.49         0.01      0.67
  15  bus               14.37   0.04    1.12  4.84         0.47      0.17
  16  train             34.92   0.07    1.47  0.40         0.41      0.72
  17  motorcycle         3.10   0.00   30.51  0.74         0.03      0.57
  18  bicycle           36.64   0.24    0.59  1.14         0.63      0.47
Mean: 42.25
-----------------------------------------------------------------------------------------------------------
this : [epoch 95], [val loss 0.31721], [acc 0.90419], [acc_cls 0.50954], [mean_iu 0.42251], [fwavacc 0.83489]
best : [epoch 95], [val loss 0.31721], [acc 0.90419], [acc_cls 0.50954], [mean_iu 0.42251], [fwavacc 0.83489]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 96], [iter 1 / 176], [train main loss -2.706725], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 2 / 176], [train main loss -1.454319], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 3 / 176], [train main loss -1.748212], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 4 / 176], [train main loss -1.610139], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 5 / 176], [train main loss -1.429334], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 6 / 176], [train main loss -1.543317], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 7 / 176], [train main loss -1.507911], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 8 / 176], [train main loss -1.490536], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 9 / 176], [train main loss -1.669186], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 10 / 176], [train main loss -1.725919], [lr 0.004514] [batchtime 0]
[epoch 96], [iter 11 / 176], [train main loss -1.676327], [lr 0.004514] [batchtime 0.361]
[epoch 96], [iter 12 / 176], [train main loss -1.558303], [lr 0.004514] [batchtime 0.377]
[epoch 96], [iter 13 / 176], [train main loss -1.605031], [lr 0.004514] [batchtime 0.382]
[epoch 96], [iter 14 / 176], [train main loss -1.753942], [lr 0.004514] [batchtime 0.384]
[epoch 96], [iter 15 / 176], [train main loss -1.777805], [lr 0.004514] [batchtime 0.389]
[epoch 96], [iter 16 / 176], [train main loss -1.761599], [lr 0.004514] [batchtime 0.518]
[epoch 96], [iter 17 / 176], [train main loss -1.799847], [lr 0.004514] [batchtime 0.499]
[epoch 96], [iter 18 / 176], [train main loss -1.798960], [lr 0.004514] [batchtime 0.504]
[epoch 96], [iter 19 / 176], [train main loss -1.838672], [lr 0.004514] [batchtime 0.491]
[epoch 96], [iter 20 / 176], [train main loss -1.814587], [lr 0.004514] [batchtime 0.482]
[epoch 96], [iter 21 / 176], [train main loss -1.849811], [lr 0.004514] [batchtime 0.474]
[epoch 96], [iter 22 / 176], [train main loss -1.768875], [lr 0.004514] [batchtime 0.467]
[epoch 96], [iter 23 / 176], [train main loss -1.835023], [lr 0.004514] [batchtime 0.462]
[epoch 96], [iter 24 / 176], [train main loss -1.778055], [lr 0.004514] [batchtime 0.457]
[epoch 96], [iter 25 / 176], [train main loss -1.814613], [lr 0.004514] [batchtime 0.454]
[epoch 96], [iter 26 / 176], [train main loss -1.721464], [lr 0.004514] [batchtime 0.45]
[epoch 96], [iter 27 / 176], [train main loss -1.797640], [lr 0.004514] [batchtime 0.447]
[epoch 96], [iter 28 / 176], [train main loss -1.833916], [lr 0.004514] [batchtime 0.444]
[epoch 96], [iter 29 / 176], [train main loss -1.865544], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 30 / 176], [train main loss -1.965879], [lr 0.004514] [batchtime 0.508]
[epoch 96], [iter 31 / 176], [train main loss -1.946565], [lr 0.004514] [batchtime 0.502]
[epoch 96], [iter 32 / 176], [train main loss -1.899330], [lr 0.004514] [batchtime 0.497]
[epoch 96], [iter 33 / 176], [train main loss -1.865415], [lr 0.004514] [batchtime 0.492]
[epoch 96], [iter 34 / 176], [train main loss -1.872322], [lr 0.004514] [batchtime 0.488]
[epoch 96], [iter 35 / 176], [train main loss -1.884076], [lr 0.004514] [batchtime 0.485]
[epoch 96], [iter 36 / 176], [train main loss -1.943997], [lr 0.004514] [batchtime 0.481]
[epoch 96], [iter 37 / 176], [train main loss -1.949421], [lr 0.004514] [batchtime 0.478]
[epoch 96], [iter 38 / 176], [train main loss -1.878795], [lr 0.004514] [batchtime 0.476]
[epoch 96], [iter 39 / 176], [train main loss -1.903215], [lr 0.004514] [batchtime 0.473]
[epoch 96], [iter 40 / 176], [train main loss -1.897203], [lr 0.004514] [batchtime 0.471]
[epoch 96], [iter 41 / 176], [train main loss -1.856678], [lr 0.004514] [batchtime 0.469]
[epoch 96], [iter 42 / 176], [train main loss -1.898246], [lr 0.004514] [batchtime 0.467]
[epoch 96], [iter 43 / 176], [train main loss -1.877893], [lr 0.004514] [batchtime 0.465]
[epoch 96], [iter 44 / 176], [train main loss -1.882945], [lr 0.004514] [batchtime 0.463]
[epoch 96], [iter 45 / 176], [train main loss -1.929864], [lr 0.004514] [batchtime 0.461]
[epoch 96], [iter 46 / 176], [train main loss -1.899277], [lr 0.004514] [batchtime 0.459]
[epoch 96], [iter 47 / 176], [train main loss -1.880964], [lr 0.004514] [batchtime 0.458]
[epoch 96], [iter 48 / 176], [train main loss -1.885031], [lr 0.004514] [batchtime 0.456]
[epoch 96], [iter 49 / 176], [train main loss -1.869512], [lr 0.004514] [batchtime 0.455]
[epoch 96], [iter 50 / 176], [train main loss -1.857742], [lr 0.004514] [batchtime 0.454]
[epoch 96], [iter 51 / 176], [train main loss -1.836391], [lr 0.004514] [batchtime 0.452]
[epoch 96], [iter 52 / 176], [train main loss -1.811586], [lr 0.004514] [batchtime 0.456]
[epoch 96], [iter 53 / 176], [train main loss -1.816678], [lr 0.004514] [batchtime 0.454]
[epoch 96], [iter 54 / 176], [train main loss -1.814552], [lr 0.004514] [batchtime 0.453]
[epoch 96], [iter 55 / 176], [train main loss -1.793399], [lr 0.004514] [batchtime 0.451]
[epoch 96], [iter 56 / 176], [train main loss -1.777357], [lr 0.004514] [batchtime 0.45]
[epoch 96], [iter 57 / 176], [train main loss -1.789783], [lr 0.004514] [batchtime 0.449]
[epoch 96], [iter 58 / 176], [train main loss -1.854271], [lr 0.004514] [batchtime 0.448]
[epoch 96], [iter 59 / 176], [train main loss -1.819474], [lr 0.004514] [batchtime 0.447]
[epoch 96], [iter 60 / 176], [train main loss -1.845904], [lr 0.004514] [batchtime 0.445]
[epoch 96], [iter 61 / 176], [train main loss -1.854171], [lr 0.004514] [batchtime 0.444]
[epoch 96], [iter 62 / 176], [train main loss -1.848703], [lr 0.004514] [batchtime 0.443]
[epoch 96], [iter 63 / 176], [train main loss -1.799059], [lr 0.004514] [batchtime 0.443]
[epoch 96], [iter 64 / 176], [train main loss -1.837237], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 65 / 176], [train main loss -1.826430], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 66 / 176], [train main loss -1.819957], [lr 0.004514] [batchtime 0.44]
[epoch 96], [iter 67 / 176], [train main loss -1.853102], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 68 / 176], [train main loss -1.857201], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 69 / 176], [train main loss -1.814788], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 70 / 176], [train main loss -1.791765], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 71 / 176], [train main loss -1.776251], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 72 / 176], [train main loss -1.779846], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 73 / 176], [train main loss -1.802820], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 74 / 176], [train main loss -1.783206], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 75 / 176], [train main loss -1.788098], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 76 / 176], [train main loss -1.808118], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 77 / 176], [train main loss -1.802345], [lr 0.004514] [batchtime 0.456]
[epoch 96], [iter 78 / 176], [train main loss -1.796890], [lr 0.004514] [batchtime 0.454]
[epoch 96], [iter 79 / 176], [train main loss -1.790171], [lr 0.004514] [batchtime 0.453]
[epoch 96], [iter 80 / 176], [train main loss -1.800038], [lr 0.004514] [batchtime 0.453]
[epoch 96], [iter 81 / 176], [train main loss -1.866821], [lr 0.004514] [batchtime 0.452]
[epoch 96], [iter 82 / 176], [train main loss -1.888569], [lr 0.004514] [batchtime 0.451]
[epoch 96], [iter 83 / 176], [train main loss -1.882629], [lr 0.004514] [batchtime 0.45]
[epoch 96], [iter 84 / 176], [train main loss -1.853435], [lr 0.004514] [batchtime 0.45]
[epoch 96], [iter 85 / 176], [train main loss -1.832854], [lr 0.004514] [batchtime 0.449]
[epoch 96], [iter 86 / 176], [train main loss -1.858032], [lr 0.004514] [batchtime 0.448]
[epoch 96], [iter 87 / 176], [train main loss -1.901682], [lr 0.004514] [batchtime 0.448]
[epoch 96], [iter 88 / 176], [train main loss -1.907655], [lr 0.004514] [batchtime 0.447]
[epoch 96], [iter 89 / 176], [train main loss -1.869281], [lr 0.004514] [batchtime 0.446]
[epoch 96], [iter 90 / 176], [train main loss -1.850416], [lr 0.004514] [batchtime 0.446]
[epoch 96], [iter 91 / 176], [train main loss -1.877155], [lr 0.004514] [batchtime 0.445]
[epoch 96], [iter 92 / 176], [train main loss -1.904719], [lr 0.004514] [batchtime 0.445]
[epoch 96], [iter 93 / 176], [train main loss -1.876024], [lr 0.004514] [batchtime 0.444]
[epoch 96], [iter 94 / 176], [train main loss -1.912563], [lr 0.004514] [batchtime 0.443]
[epoch 96], [iter 95 / 176], [train main loss -1.917308], [lr 0.004514] [batchtime 0.443]
[epoch 96], [iter 96 / 176], [train main loss -1.900202], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 97 / 176], [train main loss -1.894132], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 98 / 176], [train main loss -1.929964], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 99 / 176], [train main loss -1.930106], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 100 / 176], [train main loss -1.938475], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 101 / 176], [train main loss -1.944158], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 102 / 176], [train main loss -1.926603], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 103 / 176], [train main loss -1.924501], [lr 0.004514] [batchtime 0.44]
[epoch 96], [iter 104 / 176], [train main loss -1.945167], [lr 0.004514] [batchtime 0.44]
[epoch 96], [iter 105 / 176], [train main loss -1.953702], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 106 / 176], [train main loss -1.962214], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 107 / 176], [train main loss -1.950511], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 108 / 176], [train main loss -1.953590], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 109 / 176], [train main loss -1.943200], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 110 / 176], [train main loss -1.948339], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 111 / 176], [train main loss -1.960047], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 112 / 176], [train main loss -1.930840], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 113 / 176], [train main loss -1.972752], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 114 / 176], [train main loss -1.952921], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 115 / 176], [train main loss -1.947184], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 116 / 176], [train main loss -1.943614], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 117 / 176], [train main loss -1.912813], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 118 / 176], [train main loss -1.922799], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 119 / 176], [train main loss -1.949055], [lr 0.004514] [batchtime 0.433]
[epoch 96], [iter 120 / 176], [train main loss -1.957110], [lr 0.004514] [batchtime 0.433]
[epoch 96], [iter 121 / 176], [train main loss -1.956451], [lr 0.004514] [batchtime 0.433]
[epoch 96], [iter 122 / 176], [train main loss -1.959015], [lr 0.004514] [batchtime 0.432]
[epoch 96], [iter 123 / 176], [train main loss -1.947120], [lr 0.004514] [batchtime 0.444]
[epoch 96], [iter 124 / 176], [train main loss -1.933481], [lr 0.004514] [batchtime 0.443]
[epoch 96], [iter 125 / 176], [train main loss -1.930604], [lr 0.004514] [batchtime 0.443]
[epoch 96], [iter 126 / 176], [train main loss -1.945328], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 127 / 176], [train main loss -1.938349], [lr 0.004514] [batchtime 0.442]
[epoch 96], [iter 128 / 176], [train main loss -1.940156], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 129 / 176], [train main loss -1.939860], [lr 0.004514] [batchtime 0.441]
[epoch 96], [iter 130 / 176], [train main loss -1.924648], [lr 0.004514] [batchtime 0.44]
[epoch 96], [iter 131 / 176], [train main loss -1.911829], [lr 0.004514] [batchtime 0.44]
[epoch 96], [iter 132 / 176], [train main loss -1.910030], [lr 0.004514] [batchtime 0.44]
[epoch 96], [iter 133 / 176], [train main loss -1.916341], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 134 / 176], [train main loss -1.918491], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 135 / 176], [train main loss -1.905290], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 136 / 176], [train main loss -1.931181], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 137 / 176], [train main loss -1.954216], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 138 / 176], [train main loss -1.943320], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 139 / 176], [train main loss -1.941103], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 140 / 176], [train main loss -1.934067], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 141 / 176], [train main loss -1.912132], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 142 / 176], [train main loss -1.936891], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 143 / 176], [train main loss -1.923864], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 144 / 176], [train main loss -1.930902], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 145 / 176], [train main loss -1.930506], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 146 / 176], [train main loss -1.930554], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 147 / 176], [train main loss -1.935217], [lr 0.004514] [batchtime 0.436]
[epoch 96], [iter 148 / 176], [train main loss -1.958053], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 149 / 176], [train main loss -1.974025], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 150 / 176], [train main loss -1.983322], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 151 / 176], [train main loss -1.973425], [lr 0.004514] [batchtime 0.435]
[epoch 96], [iter 152 / 176], [train main loss -1.966220], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 153 / 176], [train main loss -1.947470], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 154 / 176], [train main loss -1.936122], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 155 / 176], [train main loss -1.939788], [lr 0.004514] [batchtime 0.434]
[epoch 96], [iter 156 / 176], [train main loss -1.931364], [lr 0.004514] [batchtime 0.433]
[epoch 96], [iter 157 / 176], [train main loss -1.934591], [lr 0.004514] [batchtime 0.433]
[epoch 96], [iter 158 / 176], [train main loss -1.942907], [lr 0.004514] [batchtime 0.433]
[epoch 96], [iter 159 / 176], [train main loss -1.951528], [lr 0.004514] [batchtime 0.432]
[epoch 96], [iter 160 / 176], [train main loss -1.947148], [lr 0.004514] [batchtime 0.432]
[epoch 96], [iter 161 / 176], [train main loss -1.956016], [lr 0.004514] [batchtime 0.432]
[epoch 96], [iter 162 / 176], [train main loss -1.961172], [lr 0.004514] [batchtime 0.432]
[epoch 96], [iter 163 / 176], [train main loss -1.952703], [lr 0.004514] [batchtime 0.432]
[epoch 96], [iter 164 / 176], [train main loss -1.952850], [lr 0.004514] [batchtime 0.431]
[epoch 96], [iter 165 / 176], [train main loss -1.966477], [lr 0.004514] [batchtime 0.431]
[epoch 96], [iter 166 / 176], [train main loss -1.968338], [lr 0.004514] [batchtime 0.431]
[epoch 96], [iter 167 / 176], [train main loss -1.958387], [lr 0.004514] [batchtime 0.431]
[epoch 96], [iter 168 / 176], [train main loss -1.954439], [lr 0.004514] [batchtime 0.43]
[epoch 96], [iter 169 / 176], [train main loss -1.950127], [lr 0.004514] [batchtime 0.43]
[epoch 96], [iter 170 / 176], [train main loss -1.952256], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 171 / 176], [train main loss -1.960563], [lr 0.004514] [batchtime 0.439]
[epoch 96], [iter 172 / 176], [train main loss -1.954609], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 173 / 176], [train main loss -1.947110], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 174 / 176], [train main loss -1.962640], [lr 0.004514] [batchtime 0.438]
[epoch 96], [iter 175 / 176], [train main loss -1.959505], [lr 0.004514] [batchtime 0.437]
[epoch 96], [iter 176 / 176], [train main loss -1.954638], [lr 0.004514] [batchtime 0.437]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.09  35.43   0.03  0.04         0.97      0.96
   1  sidewalk          67.13   5.20   0.27  0.22         0.79      0.82
   2  building          85.34  24.89   0.07  0.10         0.94      0.91
   3  wall              16.63   0.14   3.30  1.71         0.23      0.37
   4  fence             21.86   0.33   2.87  0.71         0.26      0.59
   5  pole              36.94   0.53   1.13  0.58         0.47      0.63
   6  traffic light     13.33   0.02   5.95  0.56         0.14      0.64
   7  traffic sign      19.96   0.12   3.72  0.29         0.21      0.78
   8  vegetation        82.42  11.57   0.07  0.15         0.94      0.87
   9  terrain           42.46   0.41   0.79  0.57         0.56      0.64
  10  sky               93.23   3.75   0.03  0.04         0.97      0.96
  11  person            49.88   0.95   0.62  0.38         0.62      0.72
  12  rider              7.39   0.01  11.11  1.42         0.08      0.41
  13  car               84.83   6.64   0.06  0.11         0.94      0.90
  14  truck              1.10   0.00  89.52  0.70         0.01      0.59
  15  bus               14.11   0.03   1.81  4.28         0.36      0.19
  16  train             39.08   0.10   0.83  0.73         0.55      0.58
  17  motorcycle         2.83   0.00  33.53  0.87         0.03      0.54
  18  bicycle           35.02   0.26   0.51  1.35         0.66      0.43
Mean: 42.51
-----------------------------------------------------------------------------------------------------------
this : [epoch 96], [val loss 0.33281], [acc 0.90388], [acc_cls 0.51186], [mean_iu 0.42507], [fwavacc 0.83357]
best : [epoch 96], [val loss 0.33281], [acc 0.90388], [acc_cls 0.51186], [mean_iu 0.42507], [fwavacc 0.83357]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 97], [iter 1 / 176], [train main loss -2.947731], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 2 / 176], [train main loss -1.861148], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 3 / 176], [train main loss -2.779928], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 4 / 176], [train main loss -2.556946], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 5 / 176], [train main loss -2.454223], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 6 / 176], [train main loss -2.777732], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 7 / 176], [train main loss -2.530390], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 8 / 176], [train main loss -2.451402], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 9 / 176], [train main loss -2.300939], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 10 / 176], [train main loss -2.146302], [lr 0.004457] [batchtime 0]
[epoch 97], [iter 11 / 176], [train main loss -2.543230], [lr 0.004457] [batchtime 0.372]
[epoch 97], [iter 12 / 176], [train main loss -2.593838], [lr 0.004457] [batchtime 0.38]
[epoch 97], [iter 13 / 176], [train main loss -2.405330], [lr 0.004457] [batchtime 0.382]
[epoch 97], [iter 14 / 176], [train main loss -2.537631], [lr 0.004457] [batchtime 0.383]
[epoch 97], [iter 15 / 176], [train main loss -2.617113], [lr 0.004457] [batchtime 0.387]
[epoch 97], [iter 16 / 176], [train main loss -2.689489], [lr 0.004457] [batchtime 0.388]
[epoch 97], [iter 17 / 176], [train main loss -2.606661], [lr 0.004457] [batchtime 0.39]
[epoch 97], [iter 18 / 176], [train main loss -2.538164], [lr 0.004457] [batchtime 0.39]
[epoch 97], [iter 19 / 176], [train main loss -2.555219], [lr 0.004457] [batchtime 0.391]
[epoch 97], [iter 20 / 176], [train main loss -2.550383], [lr 0.004457] [batchtime 0.399]
[epoch 97], [iter 21 / 176], [train main loss -2.527021], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 22 / 176], [train main loss -2.446476], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 23 / 176], [train main loss -2.463297], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 24 / 176], [train main loss -2.461066], [lr 0.004457] [batchtime 0.409]
[epoch 97], [iter 25 / 176], [train main loss -2.493437], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 26 / 176], [train main loss -2.555654], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 27 / 176], [train main loss -2.471838], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 28 / 176], [train main loss -2.427731], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 29 / 176], [train main loss -2.480880], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 30 / 176], [train main loss -2.476565], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 31 / 176], [train main loss -2.470418], [lr 0.004457] [batchtime 0.404]
[epoch 97], [iter 32 / 176], [train main loss -2.541069], [lr 0.004457] [batchtime 0.404]
[epoch 97], [iter 33 / 176], [train main loss -2.453175], [lr 0.004457] [batchtime 0.403]
[epoch 97], [iter 34 / 176], [train main loss -2.346514], [lr 0.004457] [batchtime 0.403]
[epoch 97], [iter 35 / 176], [train main loss -2.304387], [lr 0.004457] [batchtime 0.402]
[epoch 97], [iter 36 / 176], [train main loss -2.269507], [lr 0.004457] [batchtime 0.402]
[epoch 97], [iter 37 / 176], [train main loss -2.174887], [lr 0.004457] [batchtime 0.401]
[epoch 97], [iter 38 / 176], [train main loss -2.136407], [lr 0.004457] [batchtime 0.401]
[epoch 97], [iter 39 / 176], [train main loss -2.129869], [lr 0.004457] [batchtime 0.401]
[epoch 97], [iter 40 / 176], [train main loss -2.138045], [lr 0.004457] [batchtime 0.401]
[epoch 97], [iter 41 / 176], [train main loss -2.159194], [lr 0.004457] [batchtime 0.4]
[epoch 97], [iter 42 / 176], [train main loss -2.147749], [lr 0.004457] [batchtime 0.4]
[epoch 97], [iter 43 / 176], [train main loss -2.164971], [lr 0.004457] [batchtime 0.4]
[epoch 97], [iter 44 / 176], [train main loss -2.145507], [lr 0.004457] [batchtime 0.399]
[epoch 97], [iter 45 / 176], [train main loss -2.156172], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 46 / 176], [train main loss -2.134399], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 47 / 176], [train main loss -2.165289], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 48 / 176], [train main loss -2.156348], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 49 / 176], [train main loss -2.120363], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 50 / 176], [train main loss -2.059364], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 51 / 176], [train main loss -2.076014], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 52 / 176], [train main loss -2.070114], [lr 0.004457] [batchtime 0.41]
[epoch 97], [iter 53 / 176], [train main loss -2.048888], [lr 0.004457] [batchtime 0.41]
[epoch 97], [iter 54 / 176], [train main loss -2.052853], [lr 0.004457] [batchtime 0.41]
[epoch 97], [iter 55 / 176], [train main loss -2.020873], [lr 0.004457] [batchtime 0.409]
[epoch 97], [iter 56 / 176], [train main loss -1.998672], [lr 0.004457] [batchtime 0.409]
[epoch 97], [iter 57 / 176], [train main loss -2.025795], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 58 / 176], [train main loss -2.044390], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 59 / 176], [train main loss -2.038459], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 60 / 176], [train main loss -2.003464], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 61 / 176], [train main loss -1.997449], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 62 / 176], [train main loss -1.993237], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 63 / 176], [train main loss -2.005974], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 64 / 176], [train main loss -1.992688], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 65 / 176], [train main loss -2.010840], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 66 / 176], [train main loss -2.054960], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 67 / 176], [train main loss -2.037781], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 68 / 176], [train main loss -2.017153], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 69 / 176], [train main loss -2.003819], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 70 / 176], [train main loss -1.983934], [lr 0.004457] [batchtime 0.41]
[epoch 97], [iter 71 / 176], [train main loss -1.954750], [lr 0.004457] [batchtime 0.409]
[epoch 97], [iter 72 / 176], [train main loss -1.946699], [lr 0.004457] [batchtime 0.409]
[epoch 97], [iter 73 / 176], [train main loss -1.945932], [lr 0.004457] [batchtime 0.409]
[epoch 97], [iter 74 / 176], [train main loss -1.946846], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 75 / 176], [train main loss -1.967634], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 76 / 176], [train main loss -2.025859], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 77 / 176], [train main loss -2.035846], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 78 / 176], [train main loss -2.048598], [lr 0.004457] [batchtime 0.408]
[epoch 97], [iter 79 / 176], [train main loss -2.038784], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 80 / 176], [train main loss -2.041106], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 81 / 176], [train main loss -2.073329], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 82 / 176], [train main loss -2.048793], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 83 / 176], [train main loss -2.028633], [lr 0.004457] [batchtime 0.407]
[epoch 97], [iter 84 / 176], [train main loss -2.035683], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 85 / 176], [train main loss -2.048781], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 86 / 176], [train main loss -2.064957], [lr 0.004457] [batchtime 0.406]
[epoch 97], [iter 87 / 176], [train main loss -2.074876], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 88 / 176], [train main loss -2.079945], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 89 / 176], [train main loss -2.082428], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 90 / 176], [train main loss -2.078982], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 91 / 176], [train main loss -2.087366], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 92 / 176], [train main loss -2.080450], [lr 0.004457] [batchtime 0.405]
[epoch 97], [iter 93 / 176], [train main loss -2.079940], [lr 0.004457] [batchtime 0.404]
[epoch 97], [iter 94 / 176], [train main loss -2.070043], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 95 / 176], [train main loss -2.066396], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 96 / 176], [train main loss -2.066253], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 97 / 176], [train main loss -2.036746], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 98 / 176], [train main loss -2.049310], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 99 / 176], [train main loss -2.057700], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 100 / 176], [train main loss -2.053451], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 101 / 176], [train main loss -2.035614], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 102 / 176], [train main loss -2.033991], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 103 / 176], [train main loss -2.046574], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 104 / 176], [train main loss -2.042269], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 105 / 176], [train main loss -2.051821], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 106 / 176], [train main loss -2.074811], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 107 / 176], [train main loss -2.084084], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 108 / 176], [train main loss -2.079183], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 109 / 176], [train main loss -2.057019], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 110 / 176], [train main loss -2.068964], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 111 / 176], [train main loss -2.094894], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 112 / 176], [train main loss -2.114093], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 113 / 176], [train main loss -2.118864], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 114 / 176], [train main loss -2.103605], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 115 / 176], [train main loss -2.130281], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 116 / 176], [train main loss -2.103982], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 117 / 176], [train main loss -2.098505], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 118 / 176], [train main loss -2.102648], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 119 / 176], [train main loss -2.111623], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 120 / 176], [train main loss -2.104574], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 121 / 176], [train main loss -2.102334], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 122 / 176], [train main loss -2.094324], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 123 / 176], [train main loss -2.101202], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 124 / 176], [train main loss -2.122397], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 125 / 176], [train main loss -2.133368], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 126 / 176], [train main loss -2.119138], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 127 / 176], [train main loss -2.129089], [lr 0.004457] [batchtime 0.413]
[epoch 97], [iter 128 / 176], [train main loss -2.121762], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 129 / 176], [train main loss -2.111327], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 130 / 176], [train main loss -2.137072], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 131 / 176], [train main loss -2.122601], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 132 / 176], [train main loss -2.107872], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 133 / 176], [train main loss -2.142094], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 134 / 176], [train main loss -2.142865], [lr 0.004457] [batchtime 0.412]
[epoch 97], [iter 135 / 176], [train main loss -2.146189], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 136 / 176], [train main loss -2.142219], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 137 / 176], [train main loss -2.142874], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 138 / 176], [train main loss -2.146607], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 139 / 176], [train main loss -2.154071], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 140 / 176], [train main loss -2.143461], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 141 / 176], [train main loss -2.117101], [lr 0.004457] [batchtime 0.411]
[epoch 97], [iter 142 / 176], [train main loss -2.105254], [lr 0.004457] [batchtime 0.419]
[epoch 97], [iter 143 / 176], [train main loss -2.103817], [lr 0.004457] [batchtime 0.419]
[epoch 97], [iter 144 / 176], [train main loss -2.097360], [lr 0.004457] [batchtime 0.419]
[epoch 97], [iter 145 / 176], [train main loss -2.103526], [lr 0.004457] [batchtime 0.419]
[epoch 97], [iter 146 / 176], [train main loss -2.123093], [lr 0.004457] [batchtime 0.419]
[epoch 97], [iter 147 / 176], [train main loss -2.122181], [lr 0.004457] [batchtime 0.418]
[epoch 97], [iter 148 / 176], [train main loss -2.104001], [lr 0.004457] [batchtime 0.418]
[epoch 97], [iter 149 / 176], [train main loss -2.105653], [lr 0.004457] [batchtime 0.418]
[epoch 97], [iter 150 / 176], [train main loss -2.112696], [lr 0.004457] [batchtime 0.418]
[epoch 97], [iter 151 / 176], [train main loss -2.130041], [lr 0.004457] [batchtime 0.418]
[epoch 97], [iter 152 / 176], [train main loss -2.129937], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 153 / 176], [train main loss -2.135369], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 154 / 176], [train main loss -2.134686], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 155 / 176], [train main loss -2.132925], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 156 / 176], [train main loss -2.138502], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 157 / 176], [train main loss -2.142384], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 158 / 176], [train main loss -2.155231], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 159 / 176], [train main loss -2.147230], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 160 / 176], [train main loss -2.148911], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 161 / 176], [train main loss -2.130573], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 162 / 176], [train main loss -2.132954], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 163 / 176], [train main loss -2.123866], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 164 / 176], [train main loss -2.123735], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 165 / 176], [train main loss -2.126911], [lr 0.004457] [batchtime 0.417]
[epoch 97], [iter 166 / 176], [train main loss -2.131570], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 167 / 176], [train main loss -2.136328], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 168 / 176], [train main loss -2.136172], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 169 / 176], [train main loss -2.145905], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 170 / 176], [train main loss -2.145515], [lr 0.004457] [batchtime 0.416]
[epoch 97], [iter 171 / 176], [train main loss -2.160111], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 172 / 176], [train main loss -2.139772], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 173 / 176], [train main loss -2.154753], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 174 / 176], [train main loss -2.144168], [lr 0.004457] [batchtime 0.415]
[epoch 97], [iter 175 / 176], [train main loss -2.149510], [lr 0.004457] [batchtime 0.414]
[epoch 97], [iter 176 / 176], [train main loss -2.151998], [lr 0.004457] [batchtime 0.414]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.39  35.28   0.03  0.03         0.97      0.97
   1  sidewalk          68.59   5.48   0.20  0.26         0.83      0.80
   2  building          85.86  25.15   0.06  0.11         0.95      0.90
   3  wall              16.91   0.14   3.24  1.67         0.24      0.37
   4  fence             21.82   0.32   2.95  0.63         0.25      0.61
   5  pole              37.19   0.55   1.07  0.62         0.48      0.62
   6  traffic light     14.31   0.02   5.34  0.65         0.16      0.61
   7  traffic sign      20.52   0.12   3.58  0.30         0.22      0.77
   8  vegetation        83.83  11.42   0.08  0.11         0.92      0.90
   9  terrain           39.15   0.38   0.94  0.61         0.51      0.62
  10  sky               93.19   3.75   0.03  0.04         0.97      0.96
  11  person            50.09   0.94   0.64  0.36         0.61      0.74
  12  rider             11.22   0.01   6.42  1.49         0.13      0.40
  13  car               84.88   6.71   0.05  0.12         0.95      0.89
  14  truck              2.23   0.01  43.22  0.71         0.02      0.58
  15  bus               15.39   0.03   1.70  3.79         0.37      0.21
  16  train             39.04   0.09   1.02  0.55         0.50      0.65
  17  motorcycle         3.43   0.00  27.49  0.70         0.04      0.59
  18  bicycle           34.55   0.25   0.56  1.34         0.64      0.43
Mean: 42.98
-----------------------------------------------------------------------------------------------------------
this : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 98], [iter 1 / 176], [train main loss 2.445625], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 2 / 176], [train main loss 0.950813], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 3 / 176], [train main loss 0.252232], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 4 / 176], [train main loss -0.295554], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 5 / 176], [train main loss -0.228799], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 6 / 176], [train main loss -0.354958], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 7 / 176], [train main loss -0.700988], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 8 / 176], [train main loss -0.761869], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 9 / 176], [train main loss -0.856776], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 10 / 176], [train main loss -1.066675], [lr 0.004400] [batchtime 0]
[epoch 98], [iter 11 / 176], [train main loss -1.414213], [lr 0.004400] [batchtime 0.366]
[epoch 98], [iter 12 / 176], [train main loss -1.509381], [lr 0.004400] [batchtime 0.382]
[epoch 98], [iter 13 / 176], [train main loss -1.474687], [lr 0.004400] [batchtime 0.389]
[epoch 98], [iter 14 / 176], [train main loss -1.717863], [lr 0.004400] [batchtime 0.394]
[epoch 98], [iter 15 / 176], [train main loss -1.786450], [lr 0.004400] [batchtime 0.398]
[epoch 98], [iter 16 / 176], [train main loss -1.729986], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 17 / 176], [train main loss -1.640166], [lr 0.004400] [batchtime 0.43]
[epoch 98], [iter 18 / 176], [train main loss -1.792685], [lr 0.004400] [batchtime 0.427]
[epoch 98], [iter 19 / 176], [train main loss -1.792359], [lr 0.004400] [batchtime 0.423]
[epoch 98], [iter 20 / 176], [train main loss -1.686108], [lr 0.004400] [batchtime 0.419]
[epoch 98], [iter 21 / 176], [train main loss -1.667485], [lr 0.004400] [batchtime 0.418]
[epoch 98], [iter 22 / 176], [train main loss -1.628239], [lr 0.004400] [batchtime 0.416]
[epoch 98], [iter 23 / 176], [train main loss -1.660287], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 24 / 176], [train main loss -1.674728], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 25 / 176], [train main loss -1.648090], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 26 / 176], [train main loss -1.800146], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 27 / 176], [train main loss -1.818841], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 28 / 176], [train main loss -1.840951], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 29 / 176], [train main loss -1.765631], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 30 / 176], [train main loss -1.686019], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 31 / 176], [train main loss -1.663091], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 32 / 176], [train main loss -1.710265], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 33 / 176], [train main loss -1.736484], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 34 / 176], [train main loss -1.707316], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 35 / 176], [train main loss -1.742637], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 36 / 176], [train main loss -1.753058], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 37 / 176], [train main loss -1.744357], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 38 / 176], [train main loss -1.757201], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 39 / 176], [train main loss -1.686867], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 40 / 176], [train main loss -1.702711], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 41 / 176], [train main loss -1.746000], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 42 / 176], [train main loss -1.739206], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 43 / 176], [train main loss -1.742038], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 44 / 176], [train main loss -1.752460], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 45 / 176], [train main loss -1.752725], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 46 / 176], [train main loss -1.762555], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 47 / 176], [train main loss -1.726827], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 48 / 176], [train main loss -1.751676], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 49 / 176], [train main loss -1.736534], [lr 0.004400] [batchtime 0.404]
[epoch 98], [iter 50 / 176], [train main loss -1.735922], [lr 0.004400] [batchtime 0.404]
[epoch 98], [iter 51 / 176], [train main loss -1.763057], [lr 0.004400] [batchtime 0.404]
[epoch 98], [iter 52 / 176], [train main loss -1.837051], [lr 0.004400] [batchtime 0.404]
[epoch 98], [iter 53 / 176], [train main loss -1.802410], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 54 / 176], [train main loss -1.793691], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 55 / 176], [train main loss -1.775565], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 56 / 176], [train main loss -1.777241], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 57 / 176], [train main loss -1.735813], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 58 / 176], [train main loss -1.734186], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 59 / 176], [train main loss -1.770511], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 60 / 176], [train main loss -1.810668], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 61 / 176], [train main loss -1.793887], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 62 / 176], [train main loss -1.792921], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 63 / 176], [train main loss -1.825634], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 64 / 176], [train main loss -1.828063], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 65 / 176], [train main loss -1.844832], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 66 / 176], [train main loss -1.846716], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 67 / 176], [train main loss -1.844113], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 68 / 176], [train main loss -1.834661], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 69 / 176], [train main loss -1.794024], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 70 / 176], [train main loss -1.777313], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 71 / 176], [train main loss -1.765798], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 72 / 176], [train main loss -1.752432], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 73 / 176], [train main loss -1.726704], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 74 / 176], [train main loss -1.731994], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 75 / 176], [train main loss -1.742655], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 76 / 176], [train main loss -1.755291], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 77 / 176], [train main loss -1.770691], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 78 / 176], [train main loss -1.787743], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 79 / 176], [train main loss -1.795066], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 80 / 176], [train main loss -1.796806], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 81 / 176], [train main loss -1.796065], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 82 / 176], [train main loss -1.830598], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 83 / 176], [train main loss -1.824836], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 84 / 176], [train main loss -1.841423], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 85 / 176], [train main loss -1.841530], [lr 0.004400] [batchtime 0.406]
[epoch 98], [iter 86 / 176], [train main loss -1.844382], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 87 / 176], [train main loss -1.857468], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 88 / 176], [train main loss -1.862774], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 89 / 176], [train main loss -1.877099], [lr 0.004400] [batchtime 0.405]
[epoch 98], [iter 90 / 176], [train main loss -1.871544], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 91 / 176], [train main loss -1.909144], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 92 / 176], [train main loss -1.913488], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 93 / 176], [train main loss -1.918528], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 94 / 176], [train main loss -1.898304], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 95 / 176], [train main loss -1.899953], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 96 / 176], [train main loss -1.900709], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 97 / 176], [train main loss -1.891663], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 98 / 176], [train main loss -1.890275], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 99 / 176], [train main loss -1.879574], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 100 / 176], [train main loss -1.898627], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 101 / 176], [train main loss -1.902327], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 102 / 176], [train main loss -1.922256], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 103 / 176], [train main loss -1.929312], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 104 / 176], [train main loss -1.893750], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 105 / 176], [train main loss -1.865818], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 106 / 176], [train main loss -1.851564], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 107 / 176], [train main loss -1.859973], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 108 / 176], [train main loss -1.859305], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 109 / 176], [train main loss -1.858741], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 110 / 176], [train main loss -1.850787], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 111 / 176], [train main loss -1.860380], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 112 / 176], [train main loss -1.847336], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 113 / 176], [train main loss -1.854705], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 114 / 176], [train main loss -1.870692], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 115 / 176], [train main loss -1.871637], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 116 / 176], [train main loss -1.850843], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 117 / 176], [train main loss -1.840805], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 118 / 176], [train main loss -1.842989], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 119 / 176], [train main loss -1.872156], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 120 / 176], [train main loss -1.837134], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 121 / 176], [train main loss -1.838301], [lr 0.004400] [batchtime 0.41]
[epoch 98], [iter 122 / 176], [train main loss -1.841108], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 123 / 176], [train main loss -1.854466], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 124 / 176], [train main loss -1.854468], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 125 / 176], [train main loss -1.848416], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 126 / 176], [train main loss -1.860996], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 127 / 176], [train main loss -1.867156], [lr 0.004400] [batchtime 0.409]
[epoch 98], [iter 128 / 176], [train main loss -1.846387], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 129 / 176], [train main loss -1.848932], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 130 / 176], [train main loss -1.854668], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 131 / 176], [train main loss -1.848102], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 132 / 176], [train main loss -1.842250], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 133 / 176], [train main loss -1.858444], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 134 / 176], [train main loss -1.870266], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 135 / 176], [train main loss -1.891595], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 136 / 176], [train main loss -1.891271], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 137 / 176], [train main loss -1.916317], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 138 / 176], [train main loss -1.927883], [lr 0.004400] [batchtime 0.407]
[epoch 98], [iter 139 / 176], [train main loss -1.927926], [lr 0.004400] [batchtime 0.408]
[epoch 98], [iter 140 / 176], [train main loss -1.921626], [lr 0.004400] [batchtime 0.415]
[epoch 98], [iter 141 / 176], [train main loss -1.925911], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 142 / 176], [train main loss -1.927579], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 143 / 176], [train main loss -1.926976], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 144 / 176], [train main loss -1.925774], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 145 / 176], [train main loss -1.932335], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 146 / 176], [train main loss -1.943826], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 147 / 176], [train main loss -1.930931], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 148 / 176], [train main loss -1.909878], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 149 / 176], [train main loss -1.918851], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 150 / 176], [train main loss -1.914465], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 151 / 176], [train main loss -1.907057], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 152 / 176], [train main loss -1.904659], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 153 / 176], [train main loss -1.905722], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 154 / 176], [train main loss -1.905353], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 155 / 176], [train main loss -1.902573], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 156 / 176], [train main loss -1.908761], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 157 / 176], [train main loss -1.926316], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 158 / 176], [train main loss -1.911993], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 159 / 176], [train main loss -1.910746], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 160 / 176], [train main loss -1.923422], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 161 / 176], [train main loss -1.913146], [lr 0.004400] [batchtime 0.411]
[epoch 98], [iter 162 / 176], [train main loss -1.924077], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 163 / 176], [train main loss -1.931433], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 164 / 176], [train main loss -1.933644], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 165 / 176], [train main loss -1.947209], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 166 / 176], [train main loss -1.946801], [lr 0.004400] [batchtime 0.414]
[epoch 98], [iter 167 / 176], [train main loss -1.953588], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 168 / 176], [train main loss -1.953394], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 169 / 176], [train main loss -1.966325], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 170 / 176], [train main loss -1.967768], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 171 / 176], [train main loss -1.965532], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 172 / 176], [train main loss -1.975581], [lr 0.004400] [batchtime 0.413]
[epoch 98], [iter 173 / 176], [train main loss -1.993073], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 174 / 176], [train main loss -2.011832], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 175 / 176], [train main loss -2.016583], [lr 0.004400] [batchtime 0.412]
[epoch 98], [iter 176 / 176], [train main loss -2.010867], [lr 0.004400] [batchtime 0.412]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.35  35.67   0.02  0.04         0.98      0.96
   1  sidewalk          67.22   5.07   0.30  0.19         0.77      0.84
   2  building          83.51  25.69   0.03  0.16         0.97      0.86
   3  wall              17.04   0.13   3.49  1.38         0.22      0.42
   4  fence             18.70   0.26   3.88  0.47         0.20      0.68
   5  pole              32.66   0.44   1.61  0.45         0.38      0.69
   6  traffic light      7.71   0.01  11.65  0.32         0.08      0.76
   7  traffic sign      14.84   0.09   5.50  0.23         0.15      0.81
   8  vegetation        83.42  11.02   0.12  0.08         0.89      0.93
   9  terrain           39.06   0.36   1.06  0.50         0.49      0.67
  10  sky               93.31   3.78   0.02  0.05         0.98      0.96
  11  person            45.73   0.82   0.87  0.32         0.54      0.76
  12  rider              4.19   0.00  21.75  1.13         0.04      0.47
  13  car               84.63   6.66   0.06  0.12         0.94      0.89
  14  truck              1.11   0.00  88.67  0.83         0.01      0.55
  15  bus               14.82   0.02   2.52  3.23         0.28      0.24
  16  train             36.52   0.08   1.34  0.40         0.43      0.72
  17  motorcycle         2.12   0.00  45.70  0.49         0.02      0.67
  18  bicycle           36.39   0.21   0.83  0.92         0.55      0.52
Mean: 40.91
-----------------------------------------------------------------------------------------------------------
this : [epoch 98], [val loss 0.36588], [acc 0.90318], [acc_cls 0.46969], [mean_iu 0.40911], [fwavacc 0.82867]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 99], [iter 1 / 176], [train main loss -4.313803], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 2 / 176], [train main loss -3.602885], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 3 / 176], [train main loss -3.972345], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 4 / 176], [train main loss -4.225043], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 5 / 176], [train main loss -3.807223], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 6 / 176], [train main loss -3.196036], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 7 / 176], [train main loss -3.200246], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 8 / 176], [train main loss -2.923194], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 9 / 176], [train main loss -2.600869], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 10 / 176], [train main loss -2.273023], [lr 0.004343] [batchtime 0]
[epoch 99], [iter 11 / 176], [train main loss -2.175346], [lr 0.004343] [batchtime 0.365]
[epoch 99], [iter 12 / 176], [train main loss -2.092669], [lr 0.004343] [batchtime 0.379]
[epoch 99], [iter 13 / 176], [train main loss -1.956969], [lr 0.004343] [batchtime 0.381]
[epoch 99], [iter 14 / 176], [train main loss -2.110876], [lr 0.004343] [batchtime 0.386]
[epoch 99], [iter 15 / 176], [train main loss -2.094014], [lr 0.004343] [batchtime 0.389]
[epoch 99], [iter 16 / 176], [train main loss -1.950989], [lr 0.004343] [batchtime 0.391]
[epoch 99], [iter 17 / 176], [train main loss -1.997690], [lr 0.004343] [batchtime 0.391]
[epoch 99], [iter 18 / 176], [train main loss -1.963191], [lr 0.004343] [batchtime 0.391]
[epoch 99], [iter 19 / 176], [train main loss -1.895086], [lr 0.004343] [batchtime 0.392]
[epoch 99], [iter 20 / 176], [train main loss -1.678471], [lr 0.004343] [batchtime 0.393]
[epoch 99], [iter 21 / 176], [train main loss -1.763060], [lr 0.004343] [batchtime 0.393]
[epoch 99], [iter 22 / 176], [train main loss -1.750123], [lr 0.004343] [batchtime 0.399]
[epoch 99], [iter 23 / 176], [train main loss -1.689886], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 24 / 176], [train main loss -1.714158], [lr 0.004343] [batchtime 0.411]
[epoch 99], [iter 25 / 176], [train main loss -1.694500], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 26 / 176], [train main loss -1.657222], [lr 0.004343] [batchtime 0.41]
[epoch 99], [iter 27 / 176], [train main loss -1.716891], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 28 / 176], [train main loss -1.736140], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 29 / 176], [train main loss -1.827153], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 30 / 176], [train main loss -1.736155], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 31 / 176], [train main loss -1.708060], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 32 / 176], [train main loss -1.751714], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 33 / 176], [train main loss -1.850823], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 34 / 176], [train main loss -1.796474], [lr 0.004343] [batchtime 0.405]
[epoch 99], [iter 35 / 176], [train main loss -1.823062], [lr 0.004343] [batchtime 0.405]
[epoch 99], [iter 36 / 176], [train main loss -1.860370], [lr 0.004343] [batchtime 0.405]
[epoch 99], [iter 37 / 176], [train main loss -1.829866], [lr 0.004343] [batchtime 0.405]
[epoch 99], [iter 38 / 176], [train main loss -1.874273], [lr 0.004343] [batchtime 0.405]
[epoch 99], [iter 39 / 176], [train main loss -1.834242], [lr 0.004343] [batchtime 0.405]
[epoch 99], [iter 40 / 176], [train main loss -1.797178], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 41 / 176], [train main loss -1.849379], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 42 / 176], [train main loss -1.840843], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 43 / 176], [train main loss -1.780188], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 44 / 176], [train main loss -1.860056], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 45 / 176], [train main loss -1.827713], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 46 / 176], [train main loss -1.864963], [lr 0.004343] [batchtime 0.404]
[epoch 99], [iter 47 / 176], [train main loss -1.857936], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 48 / 176], [train main loss -1.895791], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 49 / 176], [train main loss -1.886309], [lr 0.004343] [batchtime 0.411]
[epoch 99], [iter 50 / 176], [train main loss -1.855523], [lr 0.004343] [batchtime 0.411]
[epoch 99], [iter 51 / 176], [train main loss -1.844492], [lr 0.004343] [batchtime 0.41]
[epoch 99], [iter 52 / 176], [train main loss -1.824223], [lr 0.004343] [batchtime 0.41]
[epoch 99], [iter 53 / 176], [train main loss -1.821362], [lr 0.004343] [batchtime 0.41]
[epoch 99], [iter 54 / 176], [train main loss -1.826159], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 55 / 176], [train main loss -1.871771], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 56 / 176], [train main loss -1.893379], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 57 / 176], [train main loss -1.915891], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 58 / 176], [train main loss -1.892185], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 59 / 176], [train main loss -1.917555], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 60 / 176], [train main loss -1.943502], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 61 / 176], [train main loss -1.933499], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 62 / 176], [train main loss -1.936968], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 63 / 176], [train main loss -1.962812], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 64 / 176], [train main loss -1.939153], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 65 / 176], [train main loss -1.957698], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 66 / 176], [train main loss -1.963350], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 67 / 176], [train main loss -1.951984], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 68 / 176], [train main loss -1.968559], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 69 / 176], [train main loss -1.984088], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 70 / 176], [train main loss -1.961795], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 71 / 176], [train main loss -1.977554], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 72 / 176], [train main loss -2.023053], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 73 / 176], [train main loss -2.021352], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 74 / 176], [train main loss -2.036656], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 75 / 176], [train main loss -2.035303], [lr 0.004343] [batchtime 0.409]
[epoch 99], [iter 76 / 176], [train main loss -2.009209], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 77 / 176], [train main loss -2.016773], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 78 / 176], [train main loss -2.012022], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 79 / 176], [train main loss -1.996856], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 80 / 176], [train main loss -1.953890], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 81 / 176], [train main loss -1.945988], [lr 0.004343] [batchtime 0.408]
[epoch 99], [iter 82 / 176], [train main loss -1.962000], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 83 / 176], [train main loss -1.982141], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 84 / 176], [train main loss -1.965982], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 85 / 176], [train main loss -1.968094], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 86 / 176], [train main loss -1.966839], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 87 / 176], [train main loss -1.978789], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 88 / 176], [train main loss -1.986383], [lr 0.004343] [batchtime 0.407]
[epoch 99], [iter 89 / 176], [train main loss -1.954199], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 90 / 176], [train main loss -1.936030], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 91 / 176], [train main loss -1.943127], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 92 / 176], [train main loss -1.923333], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 93 / 176], [train main loss -1.950883], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 94 / 176], [train main loss -1.951684], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 95 / 176], [train main loss -1.952512], [lr 0.004343] [batchtime 0.406]
[epoch 99], [iter 96 / 176], [train main loss -1.979985], [lr 0.004343] [batchtime 0.417]
[epoch 99], [iter 97 / 176], [train main loss -1.989978], [lr 0.004343] [batchtime 0.419]
[epoch 99], [iter 98 / 176], [train main loss -1.995329], [lr 0.004343] [batchtime 0.418]
[epoch 99], [iter 99 / 176], [train main loss -1.988975], [lr 0.004343] [batchtime 0.418]
[epoch 99], [iter 100 / 176], [train main loss -1.999690], [lr 0.004343] [batchtime 0.418]
[epoch 99], [iter 101 / 176], [train main loss -2.005279], [lr 0.004343] [batchtime 0.417]
[epoch 99], [iter 102 / 176], [train main loss -2.012138], [lr 0.004343] [batchtime 0.417]
[epoch 99], [iter 103 / 176], [train main loss -1.997965], [lr 0.004343] [batchtime 0.417]
[epoch 99], [iter 104 / 176], [train main loss -2.002158], [lr 0.004343] [batchtime 0.416]
[epoch 99], [iter 105 / 176], [train main loss -2.002763], [lr 0.004343] [batchtime 0.416]
[epoch 99], [iter 106 / 176], [train main loss -1.995113], [lr 0.004343] [batchtime 0.416]
[epoch 99], [iter 107 / 176], [train main loss -2.004129], [lr 0.004343] [batchtime 0.416]
[epoch 99], [iter 108 / 176], [train main loss -1.985099], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 109 / 176], [train main loss -1.990113], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 110 / 176], [train main loss -1.981509], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 111 / 176], [train main loss -1.979912], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 112 / 176], [train main loss -1.974141], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 113 / 176], [train main loss -1.981208], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 114 / 176], [train main loss -1.980601], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 115 / 176], [train main loss -1.988568], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 116 / 176], [train main loss -1.966244], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 117 / 176], [train main loss -1.962324], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 118 / 176], [train main loss -1.965523], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 119 / 176], [train main loss -1.979584], [lr 0.004343] [batchtime 0.416]
[epoch 99], [iter 120 / 176], [train main loss -1.977414], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 121 / 176], [train main loss -1.959120], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 122 / 176], [train main loss -1.962738], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 123 / 176], [train main loss -1.958613], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 124 / 176], [train main loss -1.961229], [lr 0.004343] [batchtime 0.415]
[epoch 99], [iter 125 / 176], [train main loss -1.958643], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 126 / 176], [train main loss -1.947813], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 127 / 176], [train main loss -1.962784], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 128 / 176], [train main loss -1.973901], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 129 / 176], [train main loss -1.954852], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 130 / 176], [train main loss -1.950990], [lr 0.004343] [batchtime 0.414]
[epoch 99], [iter 131 / 176], [train main loss -1.942767], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 132 / 176], [train main loss -1.916896], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 133 / 176], [train main loss -1.897860], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 134 / 176], [train main loss -1.888439], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 135 / 176], [train main loss -1.895409], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 136 / 176], [train main loss -1.888757], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 137 / 176], [train main loss -1.889556], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 138 / 176], [train main loss -1.880743], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 139 / 176], [train main loss -1.890093], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 140 / 176], [train main loss -1.888392], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 141 / 176], [train main loss -1.878728], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 142 / 176], [train main loss -1.879525], [lr 0.004343] [batchtime 0.412]
[epoch 99], [iter 143 / 176], [train main loss -1.859333], [lr 0.004343] [batchtime 0.413]
[epoch 99], [iter 144 / 176], [train main loss -1.878241], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 145 / 176], [train main loss -1.896094], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 146 / 176], [train main loss -1.909178], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 147 / 176], [train main loss -1.921796], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 148 / 176], [train main loss -1.925246], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 149 / 176], [train main loss -1.913806], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 150 / 176], [train main loss -1.907752], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 151 / 176], [train main loss -1.916191], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 152 / 176], [train main loss -1.908879], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 153 / 176], [train main loss -1.917315], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 154 / 176], [train main loss -1.920422], [lr 0.004343] [batchtime 0.422]
[epoch 99], [iter 155 / 176], [train main loss -1.914743], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 156 / 176], [train main loss -1.895787], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 157 / 176], [train main loss -1.889007], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 158 / 176], [train main loss -1.896096], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 159 / 176], [train main loss -1.897256], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 160 / 176], [train main loss -1.899477], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 161 / 176], [train main loss -1.888446], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 162 / 176], [train main loss -1.894045], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 163 / 176], [train main loss -1.903278], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 164 / 176], [train main loss -1.915371], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 165 / 176], [train main loss -1.920130], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 166 / 176], [train main loss -1.927194], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 167 / 176], [train main loss -1.936712], [lr 0.004343] [batchtime 0.421]
[epoch 99], [iter 168 / 176], [train main loss -1.935822], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 169 / 176], [train main loss -1.914339], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 170 / 176], [train main loss -1.913864], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 171 / 176], [train main loss -1.919014], [lr 0.004343] [batchtime 0.42]
[epoch 99], [iter 172 / 176], [train main loss -1.934814], [lr 0.004343] [batchtime 0.419]
[epoch 99], [iter 173 / 176], [train main loss -1.921255], [lr 0.004343] [batchtime 0.419]
[epoch 99], [iter 174 / 176], [train main loss -1.937413], [lr 0.004343] [batchtime 0.419]
[epoch 99], [iter 175 / 176], [train main loss -1.938887], [lr 0.004343] [batchtime 0.418]
[epoch 99], [iter 176 / 176], [train main loss -1.934120], [lr 0.004343] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.61  35.60    0.02  0.04         0.98      0.97
   1  sidewalk          68.45   5.26    0.25  0.21         0.80      0.83
   2  building          85.64  24.92    0.07  0.10         0.94      0.91
   3  wall              17.94   0.14    3.08  1.49         0.24      0.40
   4  fence             21.01   0.31    3.16  0.60         0.24      0.63
   5  pole              38.23   0.56    1.04  0.58         0.49      0.63
   6  traffic light     16.32   0.03    4.34  0.79         0.19      0.56
   7  traffic sign      20.54   0.12    3.60  0.27         0.22      0.79
   8  vegetation        82.84  11.60    0.07  0.14         0.94      0.88
   9  terrain           39.55   0.37    0.97  0.56         0.51      0.64
  10  sky               93.22   3.76    0.03  0.04         0.97      0.96
  11  person            52.17   1.02    0.50  0.42         0.67      0.70
  12  rider              6.12   0.01   13.94  1.39         0.07      0.42
  13  car               86.03   6.65    0.06  0.10         0.94      0.91
  14  truck              0.77   0.00  129.44  0.23         0.01      0.82
  15  bus               15.00   0.04    1.24  4.43         0.45      0.18
  16  train             32.84   0.07    1.60  0.44         0.38      0.69
  17  motorcycle         2.88   0.00   33.10  0.61         0.03      0.62
  18  bicycle           36.61   0.25    0.55  1.18         0.64      0.46
Mean: 42.67
-----------------------------------------------------------------------------------------------------------
this : [epoch 99], [val loss 0.32262], [acc 0.90726], [acc_cls 0.51063], [mean_iu 0.42673], [fwavacc 0.83876]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 100], [iter 1 / 176], [train main loss -4.125009], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 2 / 176], [train main loss -3.117836], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 3 / 176], [train main loss -2.907705], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 4 / 176], [train main loss -2.726726], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 5 / 176], [train main loss -2.344473], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 6 / 176], [train main loss -2.311923], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 7 / 176], [train main loss -2.044702], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 8 / 176], [train main loss -1.677994], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 9 / 176], [train main loss -1.997814], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 10 / 176], [train main loss -2.147862], [lr 0.004286] [batchtime 0]
[epoch 100], [iter 11 / 176], [train main loss -1.903540], [lr 0.004286] [batchtime 0.368]
[epoch 100], [iter 12 / 176], [train main loss -2.163078], [lr 0.004286] [batchtime 0.385]
[epoch 100], [iter 13 / 176], [train main loss -2.097320], [lr 0.004286] [batchtime 0.39]
[epoch 100], [iter 14 / 176], [train main loss -2.068425], [lr 0.004286] [batchtime 0.389]
[epoch 100], [iter 15 / 176], [train main loss -2.064803], [lr 0.004286] [batchtime 0.392]
[epoch 100], [iter 16 / 176], [train main loss -1.897521], [lr 0.004286] [batchtime 0.397]
[epoch 100], [iter 17 / 176], [train main loss -1.835911], [lr 0.004286] [batchtime 0.396]
[epoch 100], [iter 18 / 176], [train main loss -1.947645], [lr 0.004286] [batchtime 0.398]
[epoch 100], [iter 19 / 176], [train main loss -1.804562], [lr 0.004286] [batchtime 0.399]
[epoch 100], [iter 20 / 176], [train main loss -1.735495], [lr 0.004286] [batchtime 0.398]
[epoch 100], [iter 21 / 176], [train main loss -1.619960], [lr 0.004286] [batchtime 0.398]
[epoch 100], [iter 22 / 176], [train main loss -1.650456], [lr 0.004286] [batchtime 0.397]
[epoch 100], [iter 23 / 176], [train main loss -1.558486], [lr 0.004286] [batchtime 0.398]
[epoch 100], [iter 24 / 176], [train main loss -1.703270], [lr 0.004286] [batchtime 0.398]
[epoch 100], [iter 25 / 176], [train main loss -1.611937], [lr 0.004286] [batchtime 0.399]
[epoch 100], [iter 26 / 176], [train main loss -1.612224], [lr 0.004286] [batchtime 0.409]
[epoch 100], [iter 27 / 176], [train main loss -1.655205], [lr 0.004286] [batchtime 0.408]
[epoch 100], [iter 28 / 176], [train main loss -1.670546], [lr 0.004286] [batchtime 0.407]
[epoch 100], [iter 29 / 176], [train main loss -1.576566], [lr 0.004286] [batchtime 0.407]
[epoch 100], [iter 30 / 176], [train main loss -1.563540], [lr 0.004286] [batchtime 0.407]
[epoch 100], [iter 31 / 176], [train main loss -1.600469], [lr 0.004286] [batchtime 0.406]
[epoch 100], [iter 32 / 176], [train main loss -1.584005], [lr 0.004286] [batchtime 0.406]
[epoch 100], [iter 33 / 176], [train main loss -1.611876], [lr 0.004286] [batchtime 0.406]
[epoch 100], [iter 34 / 176], [train main loss -1.639954], [lr 0.004286] [batchtime 0.405]
[epoch 100], [iter 35 / 176], [train main loss -1.660935], [lr 0.004286] [batchtime 0.405]
[epoch 100], [iter 36 / 176], [train main loss -1.734581], [lr 0.004286] [batchtime 0.404]
[epoch 100], [iter 37 / 176], [train main loss -1.688394], [lr 0.004286] [batchtime 0.404]
[epoch 100], [iter 38 / 176], [train main loss -1.693186], [lr 0.004286] [batchtime 0.404]
[epoch 100], [iter 39 / 176], [train main loss -1.676169], [lr 0.004286] [batchtime 0.404]
[epoch 100], [iter 40 / 176], [train main loss -1.624783], [lr 0.004286] [batchtime 0.403]
[epoch 100], [iter 41 / 176], [train main loss -1.644808], [lr 0.004286] [batchtime 0.403]
[epoch 100], [iter 42 / 176], [train main loss -1.730058], [lr 0.004286] [batchtime 0.403]
[epoch 100], [iter 43 / 176], [train main loss -1.716293], [lr 0.004286] [batchtime 0.403]
[epoch 100], [iter 44 / 176], [train main loss -1.731287], [lr 0.004286] [batchtime 0.403]
[epoch 100], [iter 45 / 176], [train main loss -1.709268], [lr 0.004286] [batchtime 0.402]
[epoch 100], [iter 46 / 176], [train main loss -1.744611], [lr 0.004286] [batchtime 0.402]
[epoch 100], [iter 47 / 176], [train main loss -1.792384], [lr 0.004286] [batchtime 0.402]
[epoch 100], [iter 48 / 176], [train main loss -1.850773], [lr 0.004286] [batchtime 0.402]
[epoch 100], [iter 49 / 176], [train main loss -1.868042], [lr 0.004286] [batchtime 0.402]
[epoch 100], [iter 50 / 176], [train main loss -1.900183], [lr 0.004286] [batchtime 0.415]
[epoch 100], [iter 51 / 176], [train main loss -1.896639], [lr 0.004286] [batchtime 0.417]
[epoch 100], [iter 52 / 176], [train main loss -1.883833], [lr 0.004286] [batchtime 0.416]
[epoch 100], [iter 53 / 176], [train main loss -1.881605], [lr 0.004286] [batchtime 0.416]
[epoch 100], [iter 54 / 176], [train main loss -1.857426], [lr 0.004286] [batchtime 0.415]
[epoch 100], [iter 55 / 176], [train main loss -1.861664], [lr 0.004286] [batchtime 0.415]
[epoch 100], [iter 56 / 176], [train main loss -1.856516], [lr 0.004286] [batchtime 0.414]
[epoch 100], [iter 57 / 176], [train main loss -1.813997], [lr 0.004286] [batchtime 0.414]
[epoch 100], [iter 58 / 176], [train main loss -1.769033], [lr 0.004286] [batchtime 0.414]
[epoch 100], [iter 59 / 176], [train main loss -1.766407], [lr 0.004286] [batchtime 0.414]
[epoch 100], [iter 60 / 176], [train main loss -1.794449], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 61 / 176], [train main loss -1.754597], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 62 / 176], [train main loss -1.792692], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 63 / 176], [train main loss -1.792115], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 64 / 176], [train main loss -1.749846], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 65 / 176], [train main loss -1.733148], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 66 / 176], [train main loss -1.731426], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 67 / 176], [train main loss -1.690729], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 68 / 176], [train main loss -1.672393], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 69 / 176], [train main loss -1.702953], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 70 / 176], [train main loss -1.665331], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 71 / 176], [train main loss -1.675022], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 72 / 176], [train main loss -1.725331], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 73 / 176], [train main loss -1.764281], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 74 / 176], [train main loss -1.770779], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 75 / 176], [train main loss -1.793583], [lr 0.004286] [batchtime 0.414]
[epoch 100], [iter 76 / 176], [train main loss -1.781547], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 77 / 176], [train main loss -1.739384], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 78 / 176], [train main loss -1.739456], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 79 / 176], [train main loss -1.758965], [lr 0.004286] [batchtime 0.413]
[epoch 100], [iter 80 / 176], [train main loss -1.743220], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 81 / 176], [train main loss -1.732233], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 82 / 176], [train main loss -1.723489], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 83 / 176], [train main loss -1.726399], [lr 0.004286] [batchtime 0.412]
[epoch 100], [iter 84 / 176], [train main loss -1.713754], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 85 / 176], [train main loss -1.679116], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 86 / 176], [train main loss -1.674407], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 87 / 176], [train main loss -1.700829], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 88 / 176], [train main loss -1.696032], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 89 / 176], [train main loss -1.717512], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 90 / 176], [train main loss -1.682181], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 91 / 176], [train main loss -1.688932], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 92 / 176], [train main loss -1.662018], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 93 / 176], [train main loss -1.670012], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 94 / 176], [train main loss -1.642457], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 95 / 176], [train main loss -1.634404], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 96 / 176], [train main loss -1.626788], [lr 0.004286] [batchtime 0.41]
[epoch 100], [iter 97 / 176], [train main loss -1.648735], [lr 0.004286] [batchtime 0.409]
[epoch 100], [iter 98 / 176], [train main loss -1.637223], [lr 0.004286] [batchtime 0.411]
[epoch 100], [iter 99 / 176], [train main loss -1.644610], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 100 / 176], [train main loss -1.654581], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 101 / 176], [train main loss -1.672580], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 102 / 176], [train main loss -1.663256], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 103 / 176], [train main loss -1.664342], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 104 / 176], [train main loss -1.660477], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 105 / 176], [train main loss -1.653406], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 106 / 176], [train main loss -1.642397], [lr 0.004286] [batchtime 0.424]
[epoch 100], [iter 107 / 176], [train main loss -1.644663], [lr 0.004286] [batchtime 0.424]
[epoch 100], [iter 108 / 176], [train main loss -1.655179], [lr 0.004286] [batchtime 0.424]
[epoch 100], [iter 109 / 176], [train main loss -1.663643], [lr 0.004286] [batchtime 0.424]
[epoch 100], [iter 110 / 176], [train main loss -1.671304], [lr 0.004286] [batchtime 0.423]
[epoch 100], [iter 111 / 176], [train main loss -1.669255], [lr 0.004286] [batchtime 0.423]
[epoch 100], [iter 112 / 176], [train main loss -1.667152], [lr 0.004286] [batchtime 0.423]
[epoch 100], [iter 113 / 176], [train main loss -1.677928], [lr 0.004286] [batchtime 0.423]
[epoch 100], [iter 114 / 176], [train main loss -1.680607], [lr 0.004286] [batchtime 0.422]
[epoch 100], [iter 115 / 176], [train main loss -1.674883], [lr 0.004286] [batchtime 0.422]
[epoch 100], [iter 116 / 176], [train main loss -1.699645], [lr 0.004286] [batchtime 0.422]
[epoch 100], [iter 117 / 176], [train main loss -1.713657], [lr 0.004286] [batchtime 0.422]
[epoch 100], [iter 118 / 176], [train main loss -1.706508], [lr 0.004286] [batchtime 0.421]
[epoch 100], [iter 119 / 176], [train main loss -1.699774], [lr 0.004286] [batchtime 0.431]
[epoch 100], [iter 120 / 176], [train main loss -1.740435], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 121 / 176], [train main loss -1.750795], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 122 / 176], [train main loss -1.774761], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 123 / 176], [train main loss -1.757278], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 124 / 176], [train main loss -1.750684], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 125 / 176], [train main loss -1.776353], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 126 / 176], [train main loss -1.774058], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 127 / 176], [train main loss -1.774661], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 128 / 176], [train main loss -1.792478], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 129 / 176], [train main loss -1.798098], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 130 / 176], [train main loss -1.796627], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 131 / 176], [train main loss -1.791860], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 132 / 176], [train main loss -1.792535], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 133 / 176], [train main loss -1.796333], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 134 / 176], [train main loss -1.790271], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 135 / 176], [train main loss -1.790763], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 136 / 176], [train main loss -1.797945], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 137 / 176], [train main loss -1.795331], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 138 / 176], [train main loss -1.768361], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 139 / 176], [train main loss -1.792783], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 140 / 176], [train main loss -1.812533], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 141 / 176], [train main loss -1.813273], [lr 0.004286] [batchtime 0.425]
[epoch 100], [iter 142 / 176], [train main loss -1.836200], [lr 0.004286] [batchtime 0.426]
[epoch 100], [iter 143 / 176], [train main loss -1.837229], [lr 0.004286] [batchtime 0.435]
[epoch 100], [iter 144 / 176], [train main loss -1.827106], [lr 0.004286] [batchtime 0.434]
[epoch 100], [iter 145 / 176], [train main loss -1.833612], [lr 0.004286] [batchtime 0.434]
[epoch 100], [iter 146 / 176], [train main loss -1.827611], [lr 0.004286] [batchtime 0.434]
[epoch 100], [iter 147 / 176], [train main loss -1.832308], [lr 0.004286] [batchtime 0.433]
[epoch 100], [iter 148 / 176], [train main loss -1.834679], [lr 0.004286] [batchtime 0.433]
[epoch 100], [iter 149 / 176], [train main loss -1.832880], [lr 0.004286] [batchtime 0.433]
[epoch 100], [iter 150 / 176], [train main loss -1.822643], [lr 0.004286] [batchtime 0.432]
[epoch 100], [iter 151 / 176], [train main loss -1.817392], [lr 0.004286] [batchtime 0.432]
[epoch 100], [iter 152 / 176], [train main loss -1.811054], [lr 0.004286] [batchtime 0.432]
[epoch 100], [iter 153 / 176], [train main loss -1.817004], [lr 0.004286] [batchtime 0.432]
[epoch 100], [iter 154 / 176], [train main loss -1.825035], [lr 0.004286] [batchtime 0.431]
[epoch 100], [iter 155 / 176], [train main loss -1.811249], [lr 0.004286] [batchtime 0.431]
[epoch 100], [iter 156 / 176], [train main loss -1.796720], [lr 0.004286] [batchtime 0.431]
[epoch 100], [iter 157 / 176], [train main loss -1.815744], [lr 0.004286] [batchtime 0.431]
[epoch 100], [iter 158 / 176], [train main loss -1.823777], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 159 / 176], [train main loss -1.829389], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 160 / 176], [train main loss -1.821260], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 161 / 176], [train main loss -1.815281], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 162 / 176], [train main loss -1.808212], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 163 / 176], [train main loss -1.826863], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 164 / 176], [train main loss -1.840319], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 165 / 176], [train main loss -1.840294], [lr 0.004286] [batchtime 0.43]
[epoch 100], [iter 166 / 176], [train main loss -1.831688], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 167 / 176], [train main loss -1.839689], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 168 / 176], [train main loss -1.826370], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 169 / 176], [train main loss -1.819741], [lr 0.004286] [batchtime 0.429]
[epoch 100], [iter 170 / 176], [train main loss -1.823123], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 171 / 176], [train main loss -1.839798], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 172 / 176], [train main loss -1.839823], [lr 0.004286] [batchtime 0.428]
[epoch 100], [iter 173 / 176], [train main loss -1.832887], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 174 / 176], [train main loss -1.847207], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 175 / 176], [train main loss -1.844122], [lr 0.004286] [batchtime 0.427]
[epoch 100], [iter 176 / 176], [train main loss -1.845328], [lr 0.004286] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.32  35.60   0.02  0.04         0.98      0.96
   1  sidewalk          67.58   5.12   0.29  0.19         0.78      0.84
   2  building          85.77  25.03   0.06  0.10         0.94      0.91
   3  wall              16.47   0.13   3.52  1.55         0.22      0.39
   4  fence             25.47   0.40   2.14  0.79         0.32      0.56
   5  pole              37.36   0.53   1.16  0.52         0.46      0.66
   6  traffic light     13.58   0.02   5.84  0.53         0.15      0.66
   7  traffic sign      18.50   0.11   4.18  0.22         0.19      0.82
   8  vegetation        83.28  11.61   0.06  0.14         0.94      0.88
   9  terrain           39.66   0.37   1.00  0.52         0.50      0.66
  10  sky               93.47   3.74   0.04  0.03         0.97      0.97
  11  person            51.06   0.97   0.58  0.38         0.63      0.73
  12  rider              6.03   0.01  14.54  1.04         0.06      0.49
  13  car               85.39   6.69   0.06  0.11         0.95      0.90
  14  truck              2.27   0.01  42.32  0.64         0.02      0.61
  15  bus               15.85   0.04   1.32  3.99         0.43      0.20
  16  train             34.25   0.09   1.07  0.84         0.48      0.54
  17  motorcycle         2.74   0.00  35.05  0.47         0.03      0.68
  18  bicycle           36.82   0.24   0.63  1.08         0.61      0.48
Mean: 42.62
-----------------------------------------------------------------------------------------------------------
this : [epoch 100], [val loss 0.31683], [acc 0.90689], [acc_cls 0.50863], [mean_iu 0.42625], [fwavacc 0.83781]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 101], [iter 1 / 176], [train main loss -2.525942], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 2 / 176], [train main loss -2.924939], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 3 / 176], [train main loss -3.017708], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 4 / 176], [train main loss -3.289816], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 5 / 176], [train main loss -2.748598], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 6 / 176], [train main loss -2.414966], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 7 / 176], [train main loss -2.388775], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 8 / 176], [train main loss -2.524654], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 9 / 176], [train main loss -2.700403], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 10 / 176], [train main loss -2.482568], [lr 0.004229] [batchtime 0]
[epoch 101], [iter 11 / 176], [train main loss -2.803529], [lr 0.004229] [batchtime 0.364]
[epoch 101], [iter 12 / 176], [train main loss -2.614855], [lr 0.004229] [batchtime 0.38]
[epoch 101], [iter 13 / 176], [train main loss -2.524719], [lr 0.004229] [batchtime 0.386]
[epoch 101], [iter 14 / 176], [train main loss -2.548501], [lr 0.004229] [batchtime 0.387]
[epoch 101], [iter 15 / 176], [train main loss -2.402328], [lr 0.004229] [batchtime 0.389]
[epoch 101], [iter 16 / 176], [train main loss -2.372330], [lr 0.004229] [batchtime 0.389]
[epoch 101], [iter 17 / 176], [train main loss -2.275295], [lr 0.004229] [batchtime 0.389]
[epoch 101], [iter 18 / 176], [train main loss -2.275789], [lr 0.004229] [batchtime 0.389]
[epoch 101], [iter 19 / 176], [train main loss -2.175604], [lr 0.004229] [batchtime 0.39]
[epoch 101], [iter 20 / 176], [train main loss -2.099827], [lr 0.004229] [batchtime 0.391]
[epoch 101], [iter 21 / 176], [train main loss -2.105266], [lr 0.004229] [batchtime 0.39]
[epoch 101], [iter 22 / 176], [train main loss -2.109383], [lr 0.004229] [batchtime 0.395]
[epoch 101], [iter 23 / 176], [train main loss -2.123680], [lr 0.004229] [batchtime 0.406]
[epoch 101], [iter 24 / 176], [train main loss -2.210169], [lr 0.004229] [batchtime 0.404]
[epoch 101], [iter 25 / 176], [train main loss -2.179354], [lr 0.004229] [batchtime 0.403]
[epoch 101], [iter 26 / 176], [train main loss -2.168811], [lr 0.004229] [batchtime 0.402]
[epoch 101], [iter 27 / 176], [train main loss -2.070027], [lr 0.004229] [batchtime 0.402]
[epoch 101], [iter 28 / 176], [train main loss -2.108412], [lr 0.004229] [batchtime 0.401]
[epoch 101], [iter 29 / 176], [train main loss -1.983459], [lr 0.004229] [batchtime 0.401]
[epoch 101], [iter 30 / 176], [train main loss -2.032877], [lr 0.004229] [batchtime 0.401]
[epoch 101], [iter 31 / 176], [train main loss -2.011985], [lr 0.004229] [batchtime 0.4]
[epoch 101], [iter 32 / 176], [train main loss -2.170948], [lr 0.004229] [batchtime 0.4]
[epoch 101], [iter 33 / 176], [train main loss -2.133090], [lr 0.004229] [batchtime 0.4]
[epoch 101], [iter 34 / 176], [train main loss -2.100926], [lr 0.004229] [batchtime 0.4]
[epoch 101], [iter 35 / 176], [train main loss -2.136659], [lr 0.004229] [batchtime 0.4]
[epoch 101], [iter 36 / 176], [train main loss -2.107747], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 37 / 176], [train main loss -2.039579], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 38 / 176], [train main loss -2.079308], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 39 / 176], [train main loss -2.092401], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 40 / 176], [train main loss -2.122753], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 41 / 176], [train main loss -2.115588], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 42 / 176], [train main loss -2.111964], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 43 / 176], [train main loss -2.097870], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 44 / 176], [train main loss -2.112474], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 45 / 176], [train main loss -2.087466], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 46 / 176], [train main loss -2.076939], [lr 0.004229] [batchtime 0.399]
[epoch 101], [iter 47 / 176], [train main loss -2.078423], [lr 0.004229] [batchtime 0.402]
[epoch 101], [iter 48 / 176], [train main loss -2.098691], [lr 0.004229] [batchtime 0.437]
[epoch 101], [iter 49 / 176], [train main loss -2.087454], [lr 0.004229] [batchtime 0.436]
[epoch 101], [iter 50 / 176], [train main loss -2.041003], [lr 0.004229] [batchtime 0.435]
[epoch 101], [iter 51 / 176], [train main loss -2.035641], [lr 0.004229] [batchtime 0.433]
[epoch 101], [iter 52 / 176], [train main loss -2.011662], [lr 0.004229] [batchtime 0.433]
[epoch 101], [iter 53 / 176], [train main loss -1.976777], [lr 0.004229] [batchtime 0.432]
[epoch 101], [iter 54 / 176], [train main loss -2.006430], [lr 0.004229] [batchtime 0.435]
[epoch 101], [iter 55 / 176], [train main loss -2.037270], [lr 0.004229] [batchtime 0.434]
[epoch 101], [iter 56 / 176], [train main loss -2.037881], [lr 0.004229] [batchtime 0.433]
[epoch 101], [iter 57 / 176], [train main loss -2.009057], [lr 0.004229] [batchtime 0.432]
[epoch 101], [iter 58 / 176], [train main loss -1.985412], [lr 0.004229] [batchtime 0.431]
[epoch 101], [iter 59 / 176], [train main loss -2.026326], [lr 0.004229] [batchtime 0.43]
[epoch 101], [iter 60 / 176], [train main loss -2.054990], [lr 0.004229] [batchtime 0.43]
[epoch 101], [iter 61 / 176], [train main loss -2.051096], [lr 0.004229] [batchtime 0.429]
[epoch 101], [iter 62 / 176], [train main loss -2.066332], [lr 0.004229] [batchtime 0.428]
[epoch 101], [iter 63 / 176], [train main loss -2.095018], [lr 0.004229] [batchtime 0.428]
[epoch 101], [iter 64 / 176], [train main loss -2.072799], [lr 0.004229] [batchtime 0.427]
[epoch 101], [iter 65 / 176], [train main loss -2.064807], [lr 0.004229] [batchtime 0.426]
[epoch 101], [iter 66 / 176], [train main loss -2.066692], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 67 / 176], [train main loss -2.050803], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 68 / 176], [train main loss -2.027731], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 69 / 176], [train main loss -2.027390], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 70 / 176], [train main loss -2.057390], [lr 0.004229] [batchtime 0.426]
[epoch 101], [iter 71 / 176], [train main loss -2.085995], [lr 0.004229] [batchtime 0.426]
[epoch 101], [iter 72 / 176], [train main loss -2.144146], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 73 / 176], [train main loss -2.109736], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 74 / 176], [train main loss -2.071565], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 75 / 176], [train main loss -2.059941], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 76 / 176], [train main loss -2.066680], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 77 / 176], [train main loss -2.109552], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 78 / 176], [train main loss -2.117293], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 79 / 176], [train main loss -2.109459], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 80 / 176], [train main loss -2.132225], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 81 / 176], [train main loss -2.109817], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 82 / 176], [train main loss -2.119205], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 83 / 176], [train main loss -2.122394], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 84 / 176], [train main loss -2.133933], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 85 / 176], [train main loss -2.115562], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 86 / 176], [train main loss -2.097968], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 87 / 176], [train main loss -2.090902], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 88 / 176], [train main loss -2.094551], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 89 / 176], [train main loss -2.093630], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 90 / 176], [train main loss -2.090849], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 91 / 176], [train main loss -2.074215], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 92 / 176], [train main loss -2.070784], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 93 / 176], [train main loss -2.088557], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 94 / 176], [train main loss -2.080191], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 95 / 176], [train main loss -2.053910], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 96 / 176], [train main loss -2.044300], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 97 / 176], [train main loss -2.052196], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 98 / 176], [train main loss -2.087035], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 99 / 176], [train main loss -2.095625], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 100 / 176], [train main loss -2.055193], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 101 / 176], [train main loss -2.052062], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 102 / 176], [train main loss -2.065044], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 103 / 176], [train main loss -2.080855], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 104 / 176], [train main loss -2.060907], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 105 / 176], [train main loss -2.086170], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 106 / 176], [train main loss -2.081443], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 107 / 176], [train main loss -2.086336], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 108 / 176], [train main loss -2.085619], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 109 / 176], [train main loss -2.071450], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 110 / 176], [train main loss -2.054223], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 111 / 176], [train main loss -2.027309], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 112 / 176], [train main loss -2.033655], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 113 / 176], [train main loss -2.028020], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 114 / 176], [train main loss -2.011277], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 115 / 176], [train main loss -2.012696], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 116 / 176], [train main loss -2.011709], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 117 / 176], [train main loss -1.996858], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 118 / 176], [train main loss -1.993293], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 119 / 176], [train main loss -2.001803], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 120 / 176], [train main loss -2.001291], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 121 / 176], [train main loss -1.984470], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 122 / 176], [train main loss -1.959201], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 123 / 176], [train main loss -1.968565], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 124 / 176], [train main loss -1.964513], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 125 / 176], [train main loss -1.971208], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 126 / 176], [train main loss -1.949796], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 127 / 176], [train main loss -1.959782], [lr 0.004229] [batchtime 0.418]
[epoch 101], [iter 128 / 176], [train main loss -1.948354], [lr 0.004229] [batchtime 0.417]
[epoch 101], [iter 129 / 176], [train main loss -1.948917], [lr 0.004229] [batchtime 0.417]
[epoch 101], [iter 130 / 176], [train main loss -1.942928], [lr 0.004229] [batchtime 0.417]
[epoch 101], [iter 131 / 176], [train main loss -1.945000], [lr 0.004229] [batchtime 0.417]
[epoch 101], [iter 132 / 176], [train main loss -1.956092], [lr 0.004229] [batchtime 0.417]
[epoch 101], [iter 133 / 176], [train main loss -1.953492], [lr 0.004229] [batchtime 0.417]
[epoch 101], [iter 134 / 176], [train main loss -1.935310], [lr 0.004229] [batchtime 0.416]
[epoch 101], [iter 135 / 176], [train main loss -1.936113], [lr 0.004229] [batchtime 0.416]
[epoch 101], [iter 136 / 176], [train main loss -1.946856], [lr 0.004229] [batchtime 0.416]
[epoch 101], [iter 137 / 176], [train main loss -1.929477], [lr 0.004229] [batchtime 0.416]
[epoch 101], [iter 138 / 176], [train main loss -1.933319], [lr 0.004229] [batchtime 0.416]
[epoch 101], [iter 139 / 176], [train main loss -1.926964], [lr 0.004229] [batchtime 0.415]
[epoch 101], [iter 140 / 176], [train main loss -1.911250], [lr 0.004229] [batchtime 0.415]
[epoch 101], [iter 141 / 176], [train main loss -1.906766], [lr 0.004229] [batchtime 0.415]
[epoch 101], [iter 142 / 176], [train main loss -1.907724], [lr 0.004229] [batchtime 0.416]
[epoch 101], [iter 143 / 176], [train main loss -1.916268], [lr 0.004229] [batchtime 0.426]
[epoch 101], [iter 144 / 176], [train main loss -1.910293], [lr 0.004229] [batchtime 0.426]
[epoch 101], [iter 145 / 176], [train main loss -1.897037], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 146 / 176], [train main loss -1.906514], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 147 / 176], [train main loss -1.929840], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 148 / 176], [train main loss -1.935429], [lr 0.004229] [batchtime 0.425]
[epoch 101], [iter 149 / 176], [train main loss -1.952851], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 150 / 176], [train main loss -1.954656], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 151 / 176], [train main loss -1.954440], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 152 / 176], [train main loss -1.951598], [lr 0.004229] [batchtime 0.424]
[epoch 101], [iter 153 / 176], [train main loss -1.948138], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 154 / 176], [train main loss -1.946912], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 155 / 176], [train main loss -1.956660], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 156 / 176], [train main loss -1.942914], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 157 / 176], [train main loss -1.946551], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 158 / 176], [train main loss -1.942336], [lr 0.004229] [batchtime 0.423]
[epoch 101], [iter 159 / 176], [train main loss -1.958644], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 160 / 176], [train main loss -1.972415], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 161 / 176], [train main loss -1.967911], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 162 / 176], [train main loss -1.967215], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 163 / 176], [train main loss -1.964717], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 164 / 176], [train main loss -1.957973], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 165 / 176], [train main loss -1.983299], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 166 / 176], [train main loss -1.988610], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 167 / 176], [train main loss -1.985625], [lr 0.004229] [batchtime 0.422]
[epoch 101], [iter 168 / 176], [train main loss -1.975238], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 169 / 176], [train main loss -1.979976], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 170 / 176], [train main loss -1.999058], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 171 / 176], [train main loss -2.004234], [lr 0.004229] [batchtime 0.421]
[epoch 101], [iter 172 / 176], [train main loss -2.021293], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 173 / 176], [train main loss -2.008926], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 174 / 176], [train main loss -1.995764], [lr 0.004229] [batchtime 0.42]
[epoch 101], [iter 175 / 176], [train main loss -1.996885], [lr 0.004229] [batchtime 0.419]
[epoch 101], [iter 176 / 176], [train main loss -1.995518], [lr 0.004229] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.11  35.78    0.02  0.05         0.98      0.96
   1  sidewalk          65.67   4.92    0.34  0.18         0.75      0.84
   2  building          86.26  24.88    0.07  0.09         0.94      0.92
   3  wall              18.35   0.14    3.08  1.38         0.25      0.42
   4  fence             23.74   0.36    2.50  0.71         0.29      0.58
   5  pole              38.38   0.57    1.00  0.61         0.50      0.62
   6  traffic light     14.93   0.02    5.24  0.45         0.16      0.69
   7  traffic sign      19.87   0.12    3.79  0.24         0.21      0.81
   8  vegetation        83.96  11.59    0.07  0.12         0.94      0.89
   9  terrain           38.84   0.35    1.12  0.46         0.47      0.69
  10  sky               93.52   3.78    0.02  0.04         0.98      0.96
  11  person            51.56   1.01    0.52  0.42         0.66      0.71
  12  rider             11.16   0.01    6.30  1.66         0.14      0.38
  13  car               84.41   6.74    0.05  0.14         0.95      0.88
  14  truck              0.64   0.00  154.68  0.34         0.01      0.75
  15  bus               11.39   0.04    1.42  6.36         0.41      0.14
  16  train              7.30   0.01   11.56  1.14         0.08      0.47
  17  motorcycle         4.66   0.01   19.39  1.05         0.05      0.49
  18  bicycle           34.61   0.26    0.50  1.39         0.67      0.42
Mean: 41.23
-----------------------------------------------------------------------------------------------------------
this : [epoch 101], [val loss 0.32621], [acc 0.90594], [acc_cls 0.49558], [mean_iu 0.41229], [fwavacc 0.83677]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 102], [iter 1 / 176], [train main loss -2.899596], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 2 / 176], [train main loss -2.487863], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 3 / 176], [train main loss -2.398613], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 4 / 176], [train main loss -2.116305], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 5 / 176], [train main loss -2.163451], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 6 / 176], [train main loss -2.105630], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 7 / 176], [train main loss -2.230332], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 8 / 176], [train main loss -2.216186], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 9 / 176], [train main loss -2.209166], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 10 / 176], [train main loss -2.156356], [lr 0.004171] [batchtime 0]
[epoch 102], [iter 11 / 176], [train main loss -2.118309], [lr 0.004171] [batchtime 0.375]
[epoch 102], [iter 12 / 176], [train main loss -2.118995], [lr 0.004171] [batchtime 0.384]
[epoch 102], [iter 13 / 176], [train main loss -1.979693], [lr 0.004171] [batchtime 0.389]
[epoch 102], [iter 14 / 176], [train main loss -2.064615], [lr 0.004171] [batchtime 0.391]
[epoch 102], [iter 15 / 176], [train main loss -2.071087], [lr 0.004171] [batchtime 0.392]
[epoch 102], [iter 16 / 176], [train main loss -2.091996], [lr 0.004171] [batchtime 0.392]
[epoch 102], [iter 17 / 176], [train main loss -1.971488], [lr 0.004171] [batchtime 0.392]
[epoch 102], [iter 18 / 176], [train main loss -1.917128], [lr 0.004171] [batchtime 0.394]
[epoch 102], [iter 19 / 176], [train main loss -1.968486], [lr 0.004171] [batchtime 0.395]
[epoch 102], [iter 20 / 176], [train main loss -1.932177], [lr 0.004171] [batchtime 0.396]
[epoch 102], [iter 21 / 176], [train main loss -1.859971], [lr 0.004171] [batchtime 0.395]
[epoch 102], [iter 22 / 176], [train main loss -1.891985], [lr 0.004171] [batchtime 0.395]
[epoch 102], [iter 23 / 176], [train main loss -1.914627], [lr 0.004171] [batchtime 0.403]
[epoch 102], [iter 24 / 176], [train main loss -1.969246], [lr 0.004171] [batchtime 0.415]
[epoch 102], [iter 25 / 176], [train main loss -2.034470], [lr 0.004171] [batchtime 0.413]
[epoch 102], [iter 26 / 176], [train main loss -2.027585], [lr 0.004171] [batchtime 0.412]
[epoch 102], [iter 27 / 176], [train main loss -2.018460], [lr 0.004171] [batchtime 0.411]
[epoch 102], [iter 28 / 176], [train main loss -1.956838], [lr 0.004171] [batchtime 0.41]
[epoch 102], [iter 29 / 176], [train main loss -1.838196], [lr 0.004171] [batchtime 0.41]
[epoch 102], [iter 30 / 176], [train main loss -1.751971], [lr 0.004171] [batchtime 0.41]
[epoch 102], [iter 31 / 176], [train main loss -1.787932], [lr 0.004171] [batchtime 0.409]
[epoch 102], [iter 32 / 176], [train main loss -1.778604], [lr 0.004171] [batchtime 0.408]
[epoch 102], [iter 33 / 176], [train main loss -1.762805], [lr 0.004171] [batchtime 0.407]
[epoch 102], [iter 34 / 176], [train main loss -1.822297], [lr 0.004171] [batchtime 0.407]
[epoch 102], [iter 35 / 176], [train main loss -1.885353], [lr 0.004171] [batchtime 0.407]
[epoch 102], [iter 36 / 176], [train main loss -1.922308], [lr 0.004171] [batchtime 0.406]
[epoch 102], [iter 37 / 176], [train main loss -1.893401], [lr 0.004171] [batchtime 0.406]
[epoch 102], [iter 38 / 176], [train main loss -1.972867], [lr 0.004171] [batchtime 0.405]
[epoch 102], [iter 39 / 176], [train main loss -1.949304], [lr 0.004171] [batchtime 0.405]
[epoch 102], [iter 40 / 176], [train main loss -1.912099], [lr 0.004171] [batchtime 0.405]
[epoch 102], [iter 41 / 176], [train main loss -1.899986], [lr 0.004171] [batchtime 0.404]
[epoch 102], [iter 42 / 176], [train main loss -2.003892], [lr 0.004171] [batchtime 0.404]
[epoch 102], [iter 43 / 176], [train main loss -2.022459], [lr 0.004171] [batchtime 0.404]
[epoch 102], [iter 44 / 176], [train main loss -2.023212], [lr 0.004171] [batchtime 0.404]
[epoch 102], [iter 45 / 176], [train main loss -2.065077], [lr 0.004171] [batchtime 0.404]
[epoch 102], [iter 46 / 176], [train main loss -2.045641], [lr 0.004171] [batchtime 0.404]
[epoch 102], [iter 47 / 176], [train main loss -2.022704], [lr 0.004171] [batchtime 0.41]
[epoch 102], [iter 48 / 176], [train main loss -2.015668], [lr 0.004171] [batchtime 0.448]
[epoch 102], [iter 49 / 176], [train main loss -1.996586], [lr 0.004171] [batchtime 0.446]
[epoch 102], [iter 50 / 176], [train main loss -2.018021], [lr 0.004171] [batchtime 0.444]
[epoch 102], [iter 51 / 176], [train main loss -2.014981], [lr 0.004171] [batchtime 0.443]
[epoch 102], [iter 52 / 176], [train main loss -2.011641], [lr 0.004171] [batchtime 0.442]
[epoch 102], [iter 53 / 176], [train main loss -2.029069], [lr 0.004171] [batchtime 0.441]
[epoch 102], [iter 54 / 176], [train main loss -2.022117], [lr 0.004171] [batchtime 0.44]
[epoch 102], [iter 55 / 176], [train main loss -2.027158], [lr 0.004171] [batchtime 0.439]
[epoch 102], [iter 56 / 176], [train main loss -2.040200], [lr 0.004171] [batchtime 0.438]
[epoch 102], [iter 57 / 176], [train main loss -2.029849], [lr 0.004171] [batchtime 0.437]
[epoch 102], [iter 58 / 176], [train main loss -2.003706], [lr 0.004171] [batchtime 0.436]
[epoch 102], [iter 59 / 176], [train main loss -2.010793], [lr 0.004171] [batchtime 0.435]
[epoch 102], [iter 60 / 176], [train main loss -2.003959], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 61 / 176], [train main loss -2.021969], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 62 / 176], [train main loss -2.038180], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 63 / 176], [train main loss -2.012569], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 64 / 176], [train main loss -2.017842], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 65 / 176], [train main loss -2.045857], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 66 / 176], [train main loss -2.088594], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 67 / 176], [train main loss -2.119494], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 68 / 176], [train main loss -2.104661], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 69 / 176], [train main loss -2.106535], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 70 / 176], [train main loss -2.117154], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 71 / 176], [train main loss -2.105664], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 72 / 176], [train main loss -2.107639], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 73 / 176], [train main loss -2.128872], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 74 / 176], [train main loss -2.130474], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 75 / 176], [train main loss -2.162659], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 76 / 176], [train main loss -2.193726], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 77 / 176], [train main loss -2.271420], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 78 / 176], [train main loss -2.242107], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 79 / 176], [train main loss -2.229884], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 80 / 176], [train main loss -2.236764], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 81 / 176], [train main loss -2.215046], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 82 / 176], [train main loss -2.225213], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 83 / 176], [train main loss -2.234119], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 84 / 176], [train main loss -2.202839], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 85 / 176], [train main loss -2.215440], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 86 / 176], [train main loss -2.230972], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 87 / 176], [train main loss -2.227314], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 88 / 176], [train main loss -2.222536], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 89 / 176], [train main loss -2.220194], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 90 / 176], [train main loss -2.233281], [lr 0.004171] [batchtime 0.423]
[epoch 102], [iter 91 / 176], [train main loss -2.224318], [lr 0.004171] [batchtime 0.423]
[epoch 102], [iter 92 / 176], [train main loss -2.200426], [lr 0.004171] [batchtime 0.422]
[epoch 102], [iter 93 / 176], [train main loss -2.203592], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 94 / 176], [train main loss -2.202309], [lr 0.004171] [batchtime 0.438]
[epoch 102], [iter 95 / 176], [train main loss -2.197873], [lr 0.004171] [batchtime 0.438]
[epoch 102], [iter 96 / 176], [train main loss -2.174104], [lr 0.004171] [batchtime 0.437]
[epoch 102], [iter 97 / 176], [train main loss -2.184483], [lr 0.004171] [batchtime 0.437]
[epoch 102], [iter 98 / 176], [train main loss -2.160933], [lr 0.004171] [batchtime 0.436]
[epoch 102], [iter 99 / 176], [train main loss -2.158662], [lr 0.004171] [batchtime 0.436]
[epoch 102], [iter 100 / 176], [train main loss -2.167115], [lr 0.004171] [batchtime 0.435]
[epoch 102], [iter 101 / 176], [train main loss -2.189300], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 102 / 176], [train main loss -2.184092], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 103 / 176], [train main loss -2.165968], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 104 / 176], [train main loss -2.194554], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 105 / 176], [train main loss -2.217138], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 106 / 176], [train main loss -2.206768], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 107 / 176], [train main loss -2.226332], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 108 / 176], [train main loss -2.218069], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 109 / 176], [train main loss -2.190384], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 110 / 176], [train main loss -2.188726], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 111 / 176], [train main loss -2.182205], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 112 / 176], [train main loss -2.180011], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 113 / 176], [train main loss -2.192144], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 114 / 176], [train main loss -2.210350], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 115 / 176], [train main loss -2.190286], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 116 / 176], [train main loss -2.202515], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 117 / 176], [train main loss -2.189753], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 118 / 176], [train main loss -2.182440], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 119 / 176], [train main loss -2.160357], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 120 / 176], [train main loss -2.173606], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 121 / 176], [train main loss -2.163912], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 122 / 176], [train main loss -2.165291], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 123 / 176], [train main loss -2.169740], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 124 / 176], [train main loss -2.152144], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 125 / 176], [train main loss -2.131080], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 126 / 176], [train main loss -2.114458], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 127 / 176], [train main loss -2.101349], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 128 / 176], [train main loss -2.094809], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 129 / 176], [train main loss -2.085546], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 130 / 176], [train main loss -2.081227], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 131 / 176], [train main loss -2.092947], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 132 / 176], [train main loss -2.088403], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 133 / 176], [train main loss -2.089463], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 134 / 176], [train main loss -2.092920], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 135 / 176], [train main loss -2.103329], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 136 / 176], [train main loss -2.127715], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 137 / 176], [train main loss -2.130777], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 138 / 176], [train main loss -2.133232], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 139 / 176], [train main loss -2.148310], [lr 0.004171] [batchtime 0.424]
[epoch 102], [iter 140 / 176], [train main loss -2.151743], [lr 0.004171] [batchtime 0.425]
[epoch 102], [iter 141 / 176], [train main loss -2.182017], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 142 / 176], [train main loss -2.183936], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 143 / 176], [train main loss -2.183032], [lr 0.004171] [batchtime 0.434]
[epoch 102], [iter 144 / 176], [train main loss -2.186943], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 145 / 176], [train main loss -2.190523], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 146 / 176], [train main loss -2.194764], [lr 0.004171] [batchtime 0.433]
[epoch 102], [iter 147 / 176], [train main loss -2.192264], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 148 / 176], [train main loss -2.193915], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 149 / 176], [train main loss -2.196115], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 150 / 176], [train main loss -2.193627], [lr 0.004171] [batchtime 0.432]
[epoch 102], [iter 151 / 176], [train main loss -2.196433], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 152 / 176], [train main loss -2.200773], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 153 / 176], [train main loss -2.184920], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 154 / 176], [train main loss -2.197330], [lr 0.004171] [batchtime 0.431]
[epoch 102], [iter 155 / 176], [train main loss -2.196403], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 156 / 176], [train main loss -2.190292], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 157 / 176], [train main loss -2.199964], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 158 / 176], [train main loss -2.190168], [lr 0.004171] [batchtime 0.43]
[epoch 102], [iter 159 / 176], [train main loss -2.171311], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 160 / 176], [train main loss -2.180718], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 161 / 176], [train main loss -2.178546], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 162 / 176], [train main loss -2.165476], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 163 / 176], [train main loss -2.164834], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 164 / 176], [train main loss -2.147400], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 165 / 176], [train main loss -2.130642], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 166 / 176], [train main loss -2.122767], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 167 / 176], [train main loss -2.132196], [lr 0.004171] [batchtime 0.429]
[epoch 102], [iter 168 / 176], [train main loss -2.125145], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 169 / 176], [train main loss -2.129706], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 170 / 176], [train main loss -2.135262], [lr 0.004171] [batchtime 0.428]
[epoch 102], [iter 171 / 176], [train main loss -2.130096], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 172 / 176], [train main loss -2.149022], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 173 / 176], [train main loss -2.138641], [lr 0.004171] [batchtime 0.427]
[epoch 102], [iter 174 / 176], [train main loss -2.139999], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 175 / 176], [train main loss -2.138990], [lr 0.004171] [batchtime 0.426]
[epoch 102], [iter 176 / 176], [train main loss -2.143401], [lr 0.004171] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.60  35.17   0.03  0.02         0.97      0.98
   1  sidewalk          70.04   5.65   0.17  0.26         0.86      0.79
   2  building          85.12  24.92   0.07  0.11         0.94      0.90
   3  wall              16.59   0.13   3.53  1.50         0.22      0.40
   4  fence             23.70   0.35   2.60  0.62         0.28      0.62
   5  pole              36.43   0.50   1.26  0.49         0.44      0.67
   6  traffic light     11.94   0.02   6.86  0.52         0.13      0.66
   7  traffic sign      17.41   0.10   4.54  0.21         0.18      0.83
   8  vegetation        81.85  11.70   0.06  0.17         0.95      0.86
   9  terrain           38.53   0.34   1.15  0.44         0.46      0.69
  10  sky               93.01   3.79   0.02  0.05         0.98      0.95
  11  person            46.58   0.83   0.85  0.30         0.54      0.77
  12  rider             11.62   0.01   6.24  1.37         0.14      0.42
  13  car               85.09   6.63   0.07  0.11         0.94      0.90
  14  truck              1.72   0.01  56.49  0.81         0.02      0.55
  15  bus               13.76   0.02   3.08  3.19         0.25      0.24
  16  train             38.78   0.09   0.91  0.67         0.52      0.60
  17  motorcycle         3.31   0.00  28.43  0.77         0.03      0.57
  18  bicycle           34.88   0.26   0.48  1.39         0.68      0.42
Mean: 42.37
-----------------------------------------------------------------------------------------------------------
this : [epoch 102], [val loss 0.33118], [acc 0.90543], [acc_cls 0.50084], [mean_iu 0.42366], [fwavacc 0.83541]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 103], [iter 1 / 176], [train main loss -2.803327], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 2 / 176], [train main loss -2.692410], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 3 / 176], [train main loss -3.756600], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 4 / 176], [train main loss -3.910257], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 5 / 176], [train main loss -3.398155], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 6 / 176], [train main loss -3.199935], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 7 / 176], [train main loss -3.166922], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 8 / 176], [train main loss -3.155572], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 9 / 176], [train main loss -3.075525], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 10 / 176], [train main loss -2.968524], [lr 0.004114] [batchtime 0]
[epoch 103], [iter 11 / 176], [train main loss -2.551589], [lr 0.004114] [batchtime 0.365]
[epoch 103], [iter 12 / 176], [train main loss -2.617270], [lr 0.004114] [batchtime 0.376]
[epoch 103], [iter 13 / 176], [train main loss -2.622369], [lr 0.004114] [batchtime 0.382]
[epoch 103], [iter 14 / 176], [train main loss -2.581150], [lr 0.004114] [batchtime 0.384]
[epoch 103], [iter 15 / 176], [train main loss -2.536685], [lr 0.004114] [batchtime 0.386]
[epoch 103], [iter 16 / 176], [train main loss -2.549746], [lr 0.004114] [batchtime 0.387]
[epoch 103], [iter 17 / 176], [train main loss -2.452656], [lr 0.004114] [batchtime 0.388]
[epoch 103], [iter 18 / 176], [train main loss -2.419810], [lr 0.004114] [batchtime 0.389]
[epoch 103], [iter 19 / 176], [train main loss -2.486688], [lr 0.004114] [batchtime 0.388]
[epoch 103], [iter 20 / 176], [train main loss -2.444442], [lr 0.004114] [batchtime 0.401]
[epoch 103], [iter 21 / 176], [train main loss -2.609267], [lr 0.004114] [batchtime 0.401]
[epoch 103], [iter 22 / 176], [train main loss -2.485748], [lr 0.004114] [batchtime 0.402]
[epoch 103], [iter 23 / 176], [train main loss -2.476647], [lr 0.004114] [batchtime 0.401]
[epoch 103], [iter 24 / 176], [train main loss -2.378303], [lr 0.004114] [batchtime 0.401]
[epoch 103], [iter 25 / 176], [train main loss -2.344009], [lr 0.004114] [batchtime 0.4]
[epoch 103], [iter 26 / 176], [train main loss -2.351098], [lr 0.004114] [batchtime 0.399]
[epoch 103], [iter 27 / 176], [train main loss -2.351408], [lr 0.004114] [batchtime 0.399]
[epoch 103], [iter 28 / 176], [train main loss -2.267214], [lr 0.004114] [batchtime 0.399]
[epoch 103], [iter 29 / 176], [train main loss -2.148699], [lr 0.004114] [batchtime 0.399]
[epoch 103], [iter 30 / 176], [train main loss -2.137618], [lr 0.004114] [batchtime 0.399]
[epoch 103], [iter 31 / 176], [train main loss -2.070107], [lr 0.004114] [batchtime 0.398]
[epoch 103], [iter 32 / 176], [train main loss -2.177325], [lr 0.004114] [batchtime 0.398]
[epoch 103], [iter 33 / 176], [train main loss -2.248676], [lr 0.004114] [batchtime 0.489]
[epoch 103], [iter 34 / 176], [train main loss -2.232655], [lr 0.004114] [batchtime 0.494]
[epoch 103], [iter 35 / 176], [train main loss -2.172576], [lr 0.004114] [batchtime 0.489]
[epoch 103], [iter 36 / 176], [train main loss -2.175945], [lr 0.004114] [batchtime 0.485]
[epoch 103], [iter 37 / 176], [train main loss -2.208630], [lr 0.004114] [batchtime 0.482]
[epoch 103], [iter 38 / 176], [train main loss -2.270322], [lr 0.004114] [batchtime 0.479]
[epoch 103], [iter 39 / 176], [train main loss -2.319766], [lr 0.004114] [batchtime 0.476]
[epoch 103], [iter 40 / 176], [train main loss -2.343739], [lr 0.004114] [batchtime 0.473]
[epoch 103], [iter 41 / 176], [train main loss -2.347392], [lr 0.004114] [batchtime 0.471]
[epoch 103], [iter 42 / 176], [train main loss -2.372662], [lr 0.004114] [batchtime 0.469]
[epoch 103], [iter 43 / 176], [train main loss -2.408777], [lr 0.004114] [batchtime 0.466]
[epoch 103], [iter 44 / 176], [train main loss -2.477799], [lr 0.004114] [batchtime 0.464]
[epoch 103], [iter 45 / 176], [train main loss -2.451868], [lr 0.004114] [batchtime 0.462]
[epoch 103], [iter 46 / 176], [train main loss -2.437309], [lr 0.004114] [batchtime 0.46]
[epoch 103], [iter 47 / 176], [train main loss -2.400506], [lr 0.004114] [batchtime 0.458]
[epoch 103], [iter 48 / 176], [train main loss -2.408302], [lr 0.004114] [batchtime 0.457]
[epoch 103], [iter 49 / 176], [train main loss -2.404814], [lr 0.004114] [batchtime 0.455]
[epoch 103], [iter 50 / 176], [train main loss -2.453257], [lr 0.004114] [batchtime 0.454]
[epoch 103], [iter 51 / 176], [train main loss -2.435944], [lr 0.004114] [batchtime 0.452]
[epoch 103], [iter 52 / 176], [train main loss -2.408403], [lr 0.004114] [batchtime 0.451]
[epoch 103], [iter 53 / 176], [train main loss -2.356604], [lr 0.004114] [batchtime 0.45]
[epoch 103], [iter 54 / 176], [train main loss -2.349146], [lr 0.004114] [batchtime 0.449]
[epoch 103], [iter 55 / 176], [train main loss -2.331393], [lr 0.004114] [batchtime 0.448]
[epoch 103], [iter 56 / 176], [train main loss -2.348879], [lr 0.004114] [batchtime 0.447]
[epoch 103], [iter 57 / 176], [train main loss -2.338133], [lr 0.004114] [batchtime 0.446]
[epoch 103], [iter 58 / 176], [train main loss -2.337129], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 59 / 176], [train main loss -2.372363], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 60 / 176], [train main loss -2.377147], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 61 / 176], [train main loss -2.314643], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 62 / 176], [train main loss -2.337077], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 63 / 176], [train main loss -2.310614], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 64 / 176], [train main loss -2.305239], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 65 / 176], [train main loss -2.309043], [lr 0.004114] [batchtime 0.46]
[epoch 103], [iter 66 / 176], [train main loss -2.328375], [lr 0.004114] [batchtime 0.458]
[epoch 103], [iter 67 / 176], [train main loss -2.336414], [lr 0.004114] [batchtime 0.457]
[epoch 103], [iter 68 / 176], [train main loss -2.352070], [lr 0.004114] [batchtime 0.455]
[epoch 103], [iter 69 / 176], [train main loss -2.339262], [lr 0.004114] [batchtime 0.454]
[epoch 103], [iter 70 / 176], [train main loss -2.341342], [lr 0.004114] [batchtime 0.453]
[epoch 103], [iter 71 / 176], [train main loss -2.344303], [lr 0.004114] [batchtime 0.452]
[epoch 103], [iter 72 / 176], [train main loss -2.342521], [lr 0.004114] [batchtime 0.452]
[epoch 103], [iter 73 / 176], [train main loss -2.332419], [lr 0.004114] [batchtime 0.451]
[epoch 103], [iter 74 / 176], [train main loss -2.383280], [lr 0.004114] [batchtime 0.45]
[epoch 103], [iter 75 / 176], [train main loss -2.358697], [lr 0.004114] [batchtime 0.449]
[epoch 103], [iter 76 / 176], [train main loss -2.363523], [lr 0.004114] [batchtime 0.448]
[epoch 103], [iter 77 / 176], [train main loss -2.286059], [lr 0.004114] [batchtime 0.447]
[epoch 103], [iter 78 / 176], [train main loss -2.282740], [lr 0.004114] [batchtime 0.447]
[epoch 103], [iter 79 / 176], [train main loss -2.272696], [lr 0.004114] [batchtime 0.446]
[epoch 103], [iter 80 / 176], [train main loss -2.281311], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 81 / 176], [train main loss -2.301285], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 82 / 176], [train main loss -2.311082], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 83 / 176], [train main loss -2.293747], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 84 / 176], [train main loss -2.274255], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 85 / 176], [train main loss -2.264546], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 86 / 176], [train main loss -2.253865], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 87 / 176], [train main loss -2.250740], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 88 / 176], [train main loss -2.257996], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 89 / 176], [train main loss -2.238098], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 90 / 176], [train main loss -2.233249], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 91 / 176], [train main loss -2.237403], [lr 0.004114] [batchtime 0.438]
[epoch 103], [iter 92 / 176], [train main loss -2.234134], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 93 / 176], [train main loss -2.206030], [lr 0.004114] [batchtime 0.45]
[epoch 103], [iter 94 / 176], [train main loss -2.202335], [lr 0.004114] [batchtime 0.449]
[epoch 103], [iter 95 / 176], [train main loss -2.211652], [lr 0.004114] [batchtime 0.449]
[epoch 103], [iter 96 / 176], [train main loss -2.226707], [lr 0.004114] [batchtime 0.448]
[epoch 103], [iter 97 / 176], [train main loss -2.249661], [lr 0.004114] [batchtime 0.447]
[epoch 103], [iter 98 / 176], [train main loss -2.237395], [lr 0.004114] [batchtime 0.447]
[epoch 103], [iter 99 / 176], [train main loss -2.260015], [lr 0.004114] [batchtime 0.446]
[epoch 103], [iter 100 / 176], [train main loss -2.274600], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 101 / 176], [train main loss -2.283512], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 102 / 176], [train main loss -2.270379], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 103 / 176], [train main loss -2.255806], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 104 / 176], [train main loss -2.237483], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 105 / 176], [train main loss -2.236749], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 106 / 176], [train main loss -2.217801], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 107 / 176], [train main loss -2.190604], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 108 / 176], [train main loss -2.196096], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 109 / 176], [train main loss -2.180855], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 110 / 176], [train main loss -2.171779], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 111 / 176], [train main loss -2.173928], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 112 / 176], [train main loss -2.177712], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 113 / 176], [train main loss -2.193031], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 114 / 176], [train main loss -2.194164], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 115 / 176], [train main loss -2.190035], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 116 / 176], [train main loss -2.208196], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 117 / 176], [train main loss -2.212642], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 118 / 176], [train main loss -2.209113], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 119 / 176], [train main loss -2.189226], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 120 / 176], [train main loss -2.195524], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 121 / 176], [train main loss -2.171128], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 122 / 176], [train main loss -2.153833], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 123 / 176], [train main loss -2.147664], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 124 / 176], [train main loss -2.160019], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 125 / 176], [train main loss -2.137433], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 126 / 176], [train main loss -2.129584], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 127 / 176], [train main loss -2.135445], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 128 / 176], [train main loss -2.149227], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 129 / 176], [train main loss -2.142471], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 130 / 176], [train main loss -2.161936], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 131 / 176], [train main loss -2.147549], [lr 0.004114] [batchtime 0.438]
[epoch 103], [iter 132 / 176], [train main loss -2.148442], [lr 0.004114] [batchtime 0.438]
[epoch 103], [iter 133 / 176], [train main loss -2.123520], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 134 / 176], [train main loss -2.114284], [lr 0.004114] [batchtime 0.446]
[epoch 103], [iter 135 / 176], [train main loss -2.103150], [lr 0.004114] [batchtime 0.446]
[epoch 103], [iter 136 / 176], [train main loss -2.101033], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 137 / 176], [train main loss -2.098959], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 138 / 176], [train main loss -2.117809], [lr 0.004114] [batchtime 0.445]
[epoch 103], [iter 139 / 176], [train main loss -2.111571], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 140 / 176], [train main loss -2.107785], [lr 0.004114] [batchtime 0.444]
[epoch 103], [iter 141 / 176], [train main loss -2.090597], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 142 / 176], [train main loss -2.085504], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 143 / 176], [train main loss -2.092754], [lr 0.004114] [batchtime 0.443]
[epoch 103], [iter 144 / 176], [train main loss -2.091041], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 145 / 176], [train main loss -2.107323], [lr 0.004114] [batchtime 0.442]
[epoch 103], [iter 146 / 176], [train main loss -2.114553], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 147 / 176], [train main loss -2.107732], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 148 / 176], [train main loss -2.108843], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 149 / 176], [train main loss -2.085975], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 150 / 176], [train main loss -2.084506], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 151 / 176], [train main loss -2.081378], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 152 / 176], [train main loss -2.088063], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 153 / 176], [train main loss -2.095011], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 154 / 176], [train main loss -2.103779], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 155 / 176], [train main loss -2.123985], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 156 / 176], [train main loss -2.104737], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 157 / 176], [train main loss -2.119297], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 158 / 176], [train main loss -2.122419], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 159 / 176], [train main loss -2.112760], [lr 0.004114] [batchtime 0.441]
[epoch 103], [iter 160 / 176], [train main loss -2.114143], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 161 / 176], [train main loss -2.107438], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 162 / 176], [train main loss -2.112829], [lr 0.004114] [batchtime 0.44]
[epoch 103], [iter 163 / 176], [train main loss -2.105603], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 164 / 176], [train main loss -2.124357], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 165 / 176], [train main loss -2.120069], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 166 / 176], [train main loss -2.134564], [lr 0.004114] [batchtime 0.439]
[epoch 103], [iter 167 / 176], [train main loss -2.124217], [lr 0.004114] [batchtime 0.438]
[epoch 103], [iter 168 / 176], [train main loss -2.110193], [lr 0.004114] [batchtime 0.438]
[epoch 103], [iter 169 / 176], [train main loss -2.094946], [lr 0.004114] [batchtime 0.438]
[epoch 103], [iter 170 / 176], [train main loss -2.108869], [lr 0.004114] [batchtime 0.437]
[epoch 103], [iter 171 / 176], [train main loss -2.119209], [lr 0.004114] [batchtime 0.437]
[epoch 103], [iter 172 / 176], [train main loss -2.099440], [lr 0.004114] [batchtime 0.437]
[epoch 103], [iter 173 / 176], [train main loss -2.103790], [lr 0.004114] [batchtime 0.436]
[epoch 103], [iter 174 / 176], [train main loss -2.093985], [lr 0.004114] [batchtime 0.436]
[epoch 103], [iter 175 / 176], [train main loss -2.091334], [lr 0.004114] [batchtime 0.436]
[epoch 103], [iter 176 / 176], [train main loss -2.096313], [lr 0.004114] [batchtime 0.435]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.40  35.58   0.02  0.04         0.98      0.96
   1  sidewalk          67.20   5.21   0.26  0.22         0.79      0.82
   2  building          85.98  25.09   0.06  0.10         0.94      0.91
   3  wall              16.85   0.14   3.31  1.62         0.23      0.38
   4  fence             22.89   0.34   2.79  0.58         0.26      0.63
   5  pole              37.35   0.53   1.13  0.55         0.47      0.65
   6  traffic light     14.30   0.02   5.40  0.59         0.16      0.63
   7  traffic sign      18.74   0.11   4.11  0.23         0.20      0.82
   8  vegetation        84.12  11.50   0.07  0.11         0.93      0.90
   9  terrain           38.89   0.35   1.07  0.50         0.48      0.67
  10  sky               93.30   3.76   0.03  0.04         0.97      0.96
  11  person            51.30   1.02   0.51  0.44         0.66      0.69
  12  rider              5.86   0.01  14.90  1.17         0.06      0.46
  13  car               85.77   6.70   0.06  0.11         0.95      0.90
  14  truck              2.33   0.01  41.32  0.51         0.02      0.66
  15  bus               14.98   0.03   1.78  3.90         0.36      0.20
  16  train             36.85   0.11   0.70  1.01         0.59      0.50
  17  motorcycle         2.21   0.00  43.48  0.71         0.02      0.59
  18  bicycle           35.51   0.26   0.52  1.30         0.66      0.43
Mean: 42.57
-----------------------------------------------------------------------------------------------------------
this : [epoch 103], [val loss 0.32141], [acc 0.90757], [acc_cls 0.51264], [mean_iu 0.42571], [fwavacc 0.83934]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 104], [iter 1 / 176], [train main loss -2.485534], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 2 / 176], [train main loss -0.731720], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 3 / 176], [train main loss -0.861072], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 4 / 176], [train main loss -1.173732], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 5 / 176], [train main loss -1.012101], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 6 / 176], [train main loss -1.192532], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 7 / 176], [train main loss -1.159851], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 8 / 176], [train main loss -1.307875], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 9 / 176], [train main loss -1.324244], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 10 / 176], [train main loss -1.382168], [lr 0.004057] [batchtime 0]
[epoch 104], [iter 11 / 176], [train main loss -1.163986], [lr 0.004057] [batchtime 2.79]
[epoch 104], [iter 12 / 176], [train main loss -1.392145], [lr 0.004057] [batchtime 1.65]
[epoch 104], [iter 13 / 176], [train main loss -1.307476], [lr 0.004057] [batchtime 1.23]
[epoch 104], [iter 14 / 176], [train main loss -1.432838], [lr 0.004057] [batchtime 1.02]
[epoch 104], [iter 15 / 176], [train main loss -1.492825], [lr 0.004057] [batchtime 0.893]
[epoch 104], [iter 16 / 176], [train main loss -1.390957], [lr 0.004057] [batchtime 0.81]
[epoch 104], [iter 17 / 176], [train main loss -1.380174], [lr 0.004057] [batchtime 0.75]
[epoch 104], [iter 18 / 176], [train main loss -1.397417], [lr 0.004057] [batchtime 0.721]
[epoch 104], [iter 19 / 176], [train main loss -1.496651], [lr 0.004057] [batchtime 0.685]
[epoch 104], [iter 20 / 176], [train main loss -1.414154], [lr 0.004057] [batchtime 0.66]
[epoch 104], [iter 21 / 176], [train main loss -1.532210], [lr 0.004057] [batchtime 0.731]
[epoch 104], [iter 22 / 176], [train main loss -1.619552], [lr 0.004057] [batchtime 0.701]
[epoch 104], [iter 23 / 176], [train main loss -1.620478], [lr 0.004057] [batchtime 0.677]
[epoch 104], [iter 24 / 176], [train main loss -1.722294], [lr 0.004057] [batchtime 0.659]
[epoch 104], [iter 25 / 176], [train main loss -1.678677], [lr 0.004057] [batchtime 0.954]
[epoch 104], [iter 26 / 176], [train main loss -1.699210], [lr 0.004057] [batchtime 0.919]
[epoch 104], [iter 27 / 176], [train main loss -1.655804], [lr 0.004057] [batchtime 0.888]
[epoch 104], [iter 28 / 176], [train main loss -1.616377], [lr 0.004057] [batchtime 0.86]
[epoch 104], [iter 29 / 176], [train main loss -1.659923], [lr 0.004057] [batchtime 0.835]
[epoch 104], [iter 30 / 176], [train main loss -1.638952], [lr 0.004057] [batchtime 0.813]
[epoch 104], [iter 31 / 176], [train main loss -1.596100], [lr 0.004057] [batchtime 0.793]
[epoch 104], [iter 32 / 176], [train main loss -1.602840], [lr 0.004057] [batchtime 0.776]
[epoch 104], [iter 33 / 176], [train main loss -1.630312], [lr 0.004057] [batchtime 0.76]
[epoch 104], [iter 34 / 176], [train main loss -1.660002], [lr 0.004057] [batchtime 0.744]
[epoch 104], [iter 35 / 176], [train main loss -1.653332], [lr 0.004057] [batchtime 0.731]
[epoch 104], [iter 36 / 176], [train main loss -1.590606], [lr 0.004057] [batchtime 0.717]
[epoch 104], [iter 37 / 176], [train main loss -1.503114], [lr 0.004057] [batchtime 0.706]
[epoch 104], [iter 38 / 176], [train main loss -1.456913], [lr 0.004057] [batchtime 0.695]
[epoch 104], [iter 39 / 176], [train main loss -1.478865], [lr 0.004057] [batchtime 0.685]
[epoch 104], [iter 40 / 176], [train main loss -1.475024], [lr 0.004057] [batchtime 0.675]
[epoch 104], [iter 41 / 176], [train main loss -1.485274], [lr 0.004057] [batchtime 0.666]
[epoch 104], [iter 42 / 176], [train main loss -1.554361], [lr 0.004057] [batchtime 0.658]
[epoch 104], [iter 43 / 176], [train main loss -1.579464], [lr 0.004057] [batchtime 0.65]
[epoch 104], [iter 44 / 176], [train main loss -1.540267], [lr 0.004057] [batchtime 0.642]
[epoch 104], [iter 45 / 176], [train main loss -1.521649], [lr 0.004057] [batchtime 0.636]
[epoch 104], [iter 46 / 176], [train main loss -1.530139], [lr 0.004057] [batchtime 0.634]
[epoch 104], [iter 47 / 176], [train main loss -1.553417], [lr 0.004057] [batchtime 0.627]
[epoch 104], [iter 48 / 176], [train main loss -1.569685], [lr 0.004057] [batchtime 0.621]
[epoch 104], [iter 49 / 176], [train main loss -1.612965], [lr 0.004057] [batchtime 0.615]
[epoch 104], [iter 50 / 176], [train main loss -1.611951], [lr 0.004057] [batchtime 0.609]
[epoch 104], [iter 51 / 176], [train main loss -1.632650], [lr 0.004057] [batchtime 0.604]
[epoch 104], [iter 52 / 176], [train main loss -1.618342], [lr 0.004057] [batchtime 0.598]
[epoch 104], [iter 53 / 176], [train main loss -1.665407], [lr 0.004057] [batchtime 0.594]
[epoch 104], [iter 54 / 176], [train main loss -1.644875], [lr 0.004057] [batchtime 0.589]
[epoch 104], [iter 55 / 176], [train main loss -1.629983], [lr 0.004057] [batchtime 0.585]
[epoch 104], [iter 56 / 176], [train main loss -1.602134], [lr 0.004057] [batchtime 0.581]
[epoch 104], [iter 57 / 176], [train main loss -1.569590], [lr 0.004057] [batchtime 0.576]
[epoch 104], [iter 58 / 176], [train main loss -1.535204], [lr 0.004057] [batchtime 0.573]
[epoch 104], [iter 59 / 176], [train main loss -1.564072], [lr 0.004057] [batchtime 0.569]
[epoch 104], [iter 60 / 176], [train main loss -1.553713], [lr 0.004057] [batchtime 0.565]
[epoch 104], [iter 61 / 176], [train main loss -1.529757], [lr 0.004057] [batchtime 0.562]
[epoch 104], [iter 62 / 176], [train main loss -1.586865], [lr 0.004057] [batchtime 0.559]
[epoch 104], [iter 63 / 176], [train main loss -1.577526], [lr 0.004057] [batchtime 0.556]
[epoch 104], [iter 64 / 176], [train main loss -1.612502], [lr 0.004057] [batchtime 0.553]
[epoch 104], [iter 65 / 176], [train main loss -1.641688], [lr 0.004057] [batchtime 0.55]
[epoch 104], [iter 66 / 176], [train main loss -1.642557], [lr 0.004057] [batchtime 0.547]
[epoch 104], [iter 67 / 176], [train main loss -1.627696], [lr 0.004057] [batchtime 0.545]
[epoch 104], [iter 68 / 176], [train main loss -1.659209], [lr 0.004057] [batchtime 0.542]
[epoch 104], [iter 69 / 176], [train main loss -1.657497], [lr 0.004057] [batchtime 0.54]
[epoch 104], [iter 70 / 176], [train main loss -1.691878], [lr 0.004057] [batchtime 0.557]
[epoch 104], [iter 71 / 176], [train main loss -1.704167], [lr 0.004057] [batchtime 0.558]
[epoch 104], [iter 72 / 176], [train main loss -1.735708], [lr 0.004057] [batchtime 0.556]
[epoch 104], [iter 73 / 176], [train main loss -1.729485], [lr 0.004057] [batchtime 0.553]
[epoch 104], [iter 74 / 176], [train main loss -1.739652], [lr 0.004057] [batchtime 0.55]
[epoch 104], [iter 75 / 176], [train main loss -1.730022], [lr 0.004057] [batchtime 0.548]
[epoch 104], [iter 76 / 176], [train main loss -1.743080], [lr 0.004057] [batchtime 0.546]
[epoch 104], [iter 77 / 176], [train main loss -1.723965], [lr 0.004057] [batchtime 0.543]
[epoch 104], [iter 78 / 176], [train main loss -1.739734], [lr 0.004057] [batchtime 0.541]
[epoch 104], [iter 79 / 176], [train main loss -1.689533], [lr 0.004057] [batchtime 0.539]
[epoch 104], [iter 80 / 176], [train main loss -1.687239], [lr 0.004057] [batchtime 0.537]
[epoch 104], [iter 81 / 176], [train main loss -1.719181], [lr 0.004057] [batchtime 0.535]
[epoch 104], [iter 82 / 176], [train main loss -1.711253], [lr 0.004057] [batchtime 0.533]
[epoch 104], [iter 83 / 176], [train main loss -1.712585], [lr 0.004057] [batchtime 0.531]
[epoch 104], [iter 84 / 176], [train main loss -1.722151], [lr 0.004057] [batchtime 0.529]
[epoch 104], [iter 85 / 176], [train main loss -1.718398], [lr 0.004057] [batchtime 0.527]
[epoch 104], [iter 86 / 176], [train main loss -1.718884], [lr 0.004057] [batchtime 0.525]
[epoch 104], [iter 87 / 176], [train main loss -1.689518], [lr 0.004057] [batchtime 0.524]
[epoch 104], [iter 88 / 176], [train main loss -1.705574], [lr 0.004057] [batchtime 0.522]
[epoch 104], [iter 89 / 176], [train main loss -1.733998], [lr 0.004057] [batchtime 0.52]
[epoch 104], [iter 90 / 176], [train main loss -1.729766], [lr 0.004057] [batchtime 0.519]
[epoch 104], [iter 91 / 176], [train main loss -1.738984], [lr 0.004057] [batchtime 0.517]
[epoch 104], [iter 92 / 176], [train main loss -1.748141], [lr 0.004057] [batchtime 0.517]
[epoch 104], [iter 93 / 176], [train main loss -1.746118], [lr 0.004057] [batchtime 0.517]
[epoch 104], [iter 94 / 176], [train main loss -1.762482], [lr 0.004057] [batchtime 0.516]
[epoch 104], [iter 95 / 176], [train main loss -1.772246], [lr 0.004057] [batchtime 0.514]
[epoch 104], [iter 96 / 176], [train main loss -1.778321], [lr 0.004057] [batchtime 0.513]
[epoch 104], [iter 97 / 176], [train main loss -1.772927], [lr 0.004057] [batchtime 0.511]
[epoch 104], [iter 98 / 176], [train main loss -1.775031], [lr 0.004057] [batchtime 0.51]
[epoch 104], [iter 99 / 176], [train main loss -1.756080], [lr 0.004057] [batchtime 0.508]
[epoch 104], [iter 100 / 176], [train main loss -1.750033], [lr 0.004057] [batchtime 0.507]
[epoch 104], [iter 101 / 176], [train main loss -1.773845], [lr 0.004057] [batchtime 0.506]
[epoch 104], [iter 102 / 176], [train main loss -1.788195], [lr 0.004057] [batchtime 0.505]
[epoch 104], [iter 103 / 176], [train main loss -1.794260], [lr 0.004057] [batchtime 0.504]
[epoch 104], [iter 104 / 176], [train main loss -1.794266], [lr 0.004057] [batchtime 0.503]
[epoch 104], [iter 105 / 176], [train main loss -1.802126], [lr 0.004057] [batchtime 0.501]
[epoch 104], [iter 106 / 176], [train main loss -1.797873], [lr 0.004057] [batchtime 0.5]
[epoch 104], [iter 107 / 176], [train main loss -1.792479], [lr 0.004057] [batchtime 0.499]
[epoch 104], [iter 108 / 176], [train main loss -1.772218], [lr 0.004057] [batchtime 0.498]
[epoch 104], [iter 109 / 176], [train main loss -1.778390], [lr 0.004057] [batchtime 0.497]
[epoch 104], [iter 110 / 176], [train main loss -1.771034], [lr 0.004057] [batchtime 0.496]
[epoch 104], [iter 111 / 176], [train main loss -1.766885], [lr 0.004057] [batchtime 0.495]
[epoch 104], [iter 112 / 176], [train main loss -1.759600], [lr 0.004057] [batchtime 0.494]
[epoch 104], [iter 113 / 176], [train main loss -1.747164], [lr 0.004057] [batchtime 0.493]
[epoch 104], [iter 114 / 176], [train main loss -1.740588], [lr 0.004057] [batchtime 0.492]
[epoch 104], [iter 115 / 176], [train main loss -1.712735], [lr 0.004057] [batchtime 0.491]
[epoch 104], [iter 116 / 176], [train main loss -1.725066], [lr 0.004057] [batchtime 0.49]
[epoch 104], [iter 117 / 176], [train main loss -1.728183], [lr 0.004057] [batchtime 0.499]
[epoch 104], [iter 118 / 176], [train main loss -1.738239], [lr 0.004057] [batchtime 0.499]
[epoch 104], [iter 119 / 176], [train main loss -1.747770], [lr 0.004057] [batchtime 0.497]
[epoch 104], [iter 120 / 176], [train main loss -1.751595], [lr 0.004057] [batchtime 0.496]
[epoch 104], [iter 121 / 176], [train main loss -1.770008], [lr 0.004057] [batchtime 0.496]
[epoch 104], [iter 122 / 176], [train main loss -1.777298], [lr 0.004057] [batchtime 0.495]
[epoch 104], [iter 123 / 176], [train main loss -1.770677], [lr 0.004057] [batchtime 0.494]
[epoch 104], [iter 124 / 176], [train main loss -1.782589], [lr 0.004057] [batchtime 0.493]
[epoch 104], [iter 125 / 176], [train main loss -1.808691], [lr 0.004057] [batchtime 0.492]
[epoch 104], [iter 126 / 176], [train main loss -1.809852], [lr 0.004057] [batchtime 0.491]
[epoch 104], [iter 127 / 176], [train main loss -1.815759], [lr 0.004057] [batchtime 0.49]
[epoch 104], [iter 128 / 176], [train main loss -1.812301], [lr 0.004057] [batchtime 0.49]
[epoch 104], [iter 129 / 176], [train main loss -1.799927], [lr 0.004057] [batchtime 0.489]
[epoch 104], [iter 130 / 176], [train main loss -1.824020], [lr 0.004057] [batchtime 0.488]
[epoch 104], [iter 131 / 176], [train main loss -1.849955], [lr 0.004057] [batchtime 0.487]
[epoch 104], [iter 132 / 176], [train main loss -1.868871], [lr 0.004057] [batchtime 0.487]
[epoch 104], [iter 133 / 176], [train main loss -1.877339], [lr 0.004057] [batchtime 0.486]
[epoch 104], [iter 134 / 176], [train main loss -1.861298], [lr 0.004057] [batchtime 0.485]
[epoch 104], [iter 135 / 176], [train main loss -1.860940], [lr 0.004057] [batchtime 0.484]
[epoch 104], [iter 136 / 176], [train main loss -1.860134], [lr 0.004057] [batchtime 0.484]
[epoch 104], [iter 137 / 176], [train main loss -1.875718], [lr 0.004057] [batchtime 0.483]
[epoch 104], [iter 138 / 176], [train main loss -1.886053], [lr 0.004057] [batchtime 0.482]
[epoch 104], [iter 139 / 176], [train main loss -1.886148], [lr 0.004057] [batchtime 0.483]
[epoch 104], [iter 140 / 176], [train main loss -1.893127], [lr 0.004057] [batchtime 0.484]
[epoch 104], [iter 141 / 176], [train main loss -1.898209], [lr 0.004057] [batchtime 0.483]
[epoch 104], [iter 142 / 176], [train main loss -1.883307], [lr 0.004057] [batchtime 0.488]
[epoch 104], [iter 143 / 176], [train main loss -1.862836], [lr 0.004057] [batchtime 0.487]
[epoch 104], [iter 144 / 176], [train main loss -1.868158], [lr 0.004057] [batchtime 0.486]
[epoch 104], [iter 145 / 176], [train main loss -1.841597], [lr 0.004057] [batchtime 0.487]
[epoch 104], [iter 146 / 176], [train main loss -1.854377], [lr 0.004057] [batchtime 0.486]
[epoch 104], [iter 147 / 176], [train main loss -1.873141], [lr 0.004057] [batchtime 0.485]
[epoch 104], [iter 148 / 176], [train main loss -1.908771], [lr 0.004057] [batchtime 0.485]
[epoch 104], [iter 149 / 176], [train main loss -1.910690], [lr 0.004057] [batchtime 0.484]
[epoch 104], [iter 150 / 176], [train main loss -1.905753], [lr 0.004057] [batchtime 0.483]
[epoch 104], [iter 151 / 176], [train main loss -1.906768], [lr 0.004057] [batchtime 0.483]
[epoch 104], [iter 152 / 176], [train main loss -1.916021], [lr 0.004057] [batchtime 0.482]
[epoch 104], [iter 153 / 176], [train main loss -1.900487], [lr 0.004057] [batchtime 0.482]
[epoch 104], [iter 154 / 176], [train main loss -1.902103], [lr 0.004057] [batchtime 0.481]
[epoch 104], [iter 155 / 176], [train main loss -1.901317], [lr 0.004057] [batchtime 0.48]
[epoch 104], [iter 156 / 176], [train main loss -1.898240], [lr 0.004057] [batchtime 0.48]
[epoch 104], [iter 157 / 176], [train main loss -1.902153], [lr 0.004057] [batchtime 0.479]
[epoch 104], [iter 158 / 176], [train main loss -1.913003], [lr 0.004057] [batchtime 0.479]
[epoch 104], [iter 159 / 176], [train main loss -1.922597], [lr 0.004057] [batchtime 0.478]
[epoch 104], [iter 160 / 176], [train main loss -1.930611], [lr 0.004057] [batchtime 0.477]
[epoch 104], [iter 161 / 176], [train main loss -1.926249], [lr 0.004057] [batchtime 0.477]
[epoch 104], [iter 162 / 176], [train main loss -1.946067], [lr 0.004057] [batchtime 0.481]
[epoch 104], [iter 163 / 176], [train main loss -1.949838], [lr 0.004057] [batchtime 0.481]
[epoch 104], [iter 164 / 176], [train main loss -1.941058], [lr 0.004057] [batchtime 0.48]
[epoch 104], [iter 165 / 176], [train main loss -1.954739], [lr 0.004057] [batchtime 0.48]
[epoch 104], [iter 166 / 176], [train main loss -1.948285], [lr 0.004057] [batchtime 0.479]
[epoch 104], [iter 167 / 176], [train main loss -1.968349], [lr 0.004057] [batchtime 0.478]
[epoch 104], [iter 168 / 176], [train main loss -1.967849], [lr 0.004057] [batchtime 0.478]
[epoch 104], [iter 169 / 176], [train main loss -1.967110], [lr 0.004057] [batchtime 0.477]
[epoch 104], [iter 170 / 176], [train main loss -1.962340], [lr 0.004057] [batchtime 0.477]
[epoch 104], [iter 171 / 176], [train main loss -1.967927], [lr 0.004057] [batchtime 0.476]
[epoch 104], [iter 172 / 176], [train main loss -1.953442], [lr 0.004057] [batchtime 0.475]
[epoch 104], [iter 173 / 176], [train main loss -1.959676], [lr 0.004057] [batchtime 0.475]
[epoch 104], [iter 174 / 176], [train main loss -1.951442], [lr 0.004057] [batchtime 0.474]
[epoch 104], [iter 175 / 176], [train main loss -1.939396], [lr 0.004057] [batchtime 0.474]
[epoch 104], [iter 176 / 176], [train main loss -1.938568], [lr 0.004057] [batchtime 0.473]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.48  35.64   0.02  0.04         0.98      0.96
   1  sidewalk          67.64   5.17   0.28  0.20         0.78      0.83
   2  building          86.03  25.41   0.05  0.12         0.96      0.90
   3  wall              17.90   0.16   2.71  1.88         0.27      0.35
   4  fence             26.91   0.46   1.75  0.96         0.36      0.51
   5  pole              37.24   0.54   1.12  0.57         0.47      0.64
   6  traffic light      9.97   0.02   8.77  0.26         0.10      0.80
   7  traffic sign      20.42   0.12   3.67  0.23         0.21      0.81
   8  vegetation        84.45  11.18   0.11  0.08         0.90      0.93
   9  terrain           40.91   0.40   0.83  0.61         0.55      0.62
  10  sky               93.79   3.74   0.04  0.03         0.97      0.97
  11  person            51.17   0.95   0.61  0.34         0.62      0.74
  12  rider              4.20   0.00  21.87  0.93         0.04      0.52
  13  car               86.20   6.62   0.07  0.09         0.94      0.92
  14  truck              1.32   0.00  74.56  0.47         0.01      0.68
  15  bus               15.34   0.03   1.52  4.00         0.40      0.20
  16  train             37.93   0.09   0.90  0.74         0.53      0.57
  17  motorcycle         2.23   0.00  43.25  0.62         0.02      0.62
  18  bicycle           34.74   0.27   0.43  1.45         0.70      0.41
Mean: 42.78
-----------------------------------------------------------------------------------------------------------
this : [epoch 104], [val loss 0.32667], [acc 0.90798], [acc_cls 0.51655], [mean_iu 0.42783], [fwavacc 0.84162]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 105], [iter 1 / 176], [train main loss -1.468088], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 2 / 176], [train main loss -2.058810], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 3 / 176], [train main loss -1.821042], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 4 / 176], [train main loss -1.868437], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 5 / 176], [train main loss -2.241722], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 6 / 176], [train main loss -2.163945], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 7 / 176], [train main loss -2.222215], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 8 / 176], [train main loss -2.282002], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 9 / 176], [train main loss -2.515292], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 10 / 176], [train main loss -2.407275], [lr 0.004000] [batchtime 0]
[epoch 105], [iter 11 / 176], [train main loss -2.392218], [lr 0.004000] [batchtime 0.372]
[epoch 105], [iter 12 / 176], [train main loss -2.269725], [lr 0.004000] [batchtime 0.393]
[epoch 105], [iter 13 / 176], [train main loss -2.190223], [lr 0.004000] [batchtime 0.394]
[epoch 105], [iter 14 / 176], [train main loss -2.347958], [lr 0.004000] [batchtime 0.393]
[epoch 105], [iter 15 / 176], [train main loss -2.264483], [lr 0.004000] [batchtime 0.393]
[epoch 105], [iter 16 / 176], [train main loss -2.203285], [lr 0.004000] [batchtime 0.393]
[epoch 105], [iter 17 / 176], [train main loss -2.244189], [lr 0.004000] [batchtime 0.394]
[epoch 105], [iter 18 / 176], [train main loss -2.237244], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 19 / 176], [train main loss -2.103104], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 20 / 176], [train main loss -2.113410], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 21 / 176], [train main loss -2.147929], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 22 / 176], [train main loss -2.130711], [lr 0.004000] [batchtime 0.4]
[epoch 105], [iter 23 / 176], [train main loss -2.069406], [lr 0.004000] [batchtime 0.399]
[epoch 105], [iter 24 / 176], [train main loss -2.074618], [lr 0.004000] [batchtime 0.399]
[epoch 105], [iter 25 / 176], [train main loss -2.098327], [lr 0.004000] [batchtime 0.398]
[epoch 105], [iter 26 / 176], [train main loss -2.134587], [lr 0.004000] [batchtime 0.398]
[epoch 105], [iter 27 / 176], [train main loss -2.108818], [lr 0.004000] [batchtime 0.398]
[epoch 105], [iter 28 / 176], [train main loss -2.018579], [lr 0.004000] [batchtime 0.398]
[epoch 105], [iter 29 / 176], [train main loss -2.024207], [lr 0.004000] [batchtime 0.397]
[epoch 105], [iter 30 / 176], [train main loss -2.050192], [lr 0.004000] [batchtime 0.397]
[epoch 105], [iter 31 / 176], [train main loss -1.992317], [lr 0.004000] [batchtime 0.397]
[epoch 105], [iter 32 / 176], [train main loss -1.980498], [lr 0.004000] [batchtime 0.397]
[epoch 105], [iter 33 / 176], [train main loss -2.052440], [lr 0.004000] [batchtime 0.397]
[epoch 105], [iter 34 / 176], [train main loss -2.061485], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 35 / 176], [train main loss -2.140704], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 36 / 176], [train main loss -2.200664], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 37 / 176], [train main loss -2.267834], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 38 / 176], [train main loss -2.313425], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 39 / 176], [train main loss -2.311744], [lr 0.004000] [batchtime 0.396]
[epoch 105], [iter 40 / 176], [train main loss -2.288870], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 41 / 176], [train main loss -2.285183], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 42 / 176], [train main loss -2.345336], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 43 / 176], [train main loss -2.342239], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 44 / 176], [train main loss -2.272560], [lr 0.004000] [batchtime 0.395]
[epoch 105], [iter 45 / 176], [train main loss -2.347986], [lr 0.004000] [batchtime 0.398]
[epoch 105], [iter 46 / 176], [train main loss -2.304722], [lr 0.004000] [batchtime 0.408]
[epoch 105], [iter 47 / 176], [train main loss -2.269056], [lr 0.004000] [batchtime 0.408]
[epoch 105], [iter 48 / 176], [train main loss -2.294162], [lr 0.004000] [batchtime 0.407]
[epoch 105], [iter 49 / 176], [train main loss -2.273707], [lr 0.004000] [batchtime 0.407]
[epoch 105], [iter 50 / 176], [train main loss -2.216124], [lr 0.004000] [batchtime 0.406]
[epoch 105], [iter 51 / 176], [train main loss -2.239993], [lr 0.004000] [batchtime 0.406]
[epoch 105], [iter 52 / 176], [train main loss -2.264026], [lr 0.004000] [batchtime 0.405]
[epoch 105], [iter 53 / 176], [train main loss -2.293948], [lr 0.004000] [batchtime 0.405]
[epoch 105], [iter 54 / 176], [train main loss -2.251972], [lr 0.004000] [batchtime 0.405]
[epoch 105], [iter 55 / 176], [train main loss -2.246717], [lr 0.004000] [batchtime 0.404]
[epoch 105], [iter 56 / 176], [train main loss -2.236573], [lr 0.004000] [batchtime 0.404]
[epoch 105], [iter 57 / 176], [train main loss -2.216950], [lr 0.004000] [batchtime 0.404]
[epoch 105], [iter 58 / 176], [train main loss -2.261300], [lr 0.004000] [batchtime 0.404]
[epoch 105], [iter 59 / 176], [train main loss -2.195046], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 60 / 176], [train main loss -2.183316], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 61 / 176], [train main loss -2.188273], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 62 / 176], [train main loss -2.150179], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 63 / 176], [train main loss -2.160861], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 64 / 176], [train main loss -2.219315], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 65 / 176], [train main loss -2.250217], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 66 / 176], [train main loss -2.213366], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 67 / 176], [train main loss -2.198659], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 68 / 176], [train main loss -2.161906], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 69 / 176], [train main loss -2.144936], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 70 / 176], [train main loss -2.140122], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 71 / 176], [train main loss -2.127281], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 72 / 176], [train main loss -2.142701], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 73 / 176], [train main loss -2.143803], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 74 / 176], [train main loss -2.127251], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 75 / 176], [train main loss -2.147707], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 76 / 176], [train main loss -2.120415], [lr 0.004000] [batchtime 0.403]
[epoch 105], [iter 77 / 176], [train main loss -2.157463], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 78 / 176], [train main loss -2.161437], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 79 / 176], [train main loss -2.125928], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 80 / 176], [train main loss -2.098961], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 81 / 176], [train main loss -2.066493], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 82 / 176], [train main loss -2.065617], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 83 / 176], [train main loss -2.086868], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 84 / 176], [train main loss -2.095596], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 85 / 176], [train main loss -2.105135], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 86 / 176], [train main loss -2.119381], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 87 / 176], [train main loss -2.100287], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 88 / 176], [train main loss -2.118501], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 89 / 176], [train main loss -2.109561], [lr 0.004000] [batchtime 0.401]
[epoch 105], [iter 90 / 176], [train main loss -2.126318], [lr 0.004000] [batchtime 0.4]
[epoch 105], [iter 91 / 176], [train main loss -2.123042], [lr 0.004000] [batchtime 0.4]
[epoch 105], [iter 92 / 176], [train main loss -2.102196], [lr 0.004000] [batchtime 0.4]
[epoch 105], [iter 93 / 176], [train main loss -2.105638], [lr 0.004000] [batchtime 0.4]
[epoch 105], [iter 94 / 176], [train main loss -2.112809], [lr 0.004000] [batchtime 0.4]
[epoch 105], [iter 95 / 176], [train main loss -2.124933], [lr 0.004000] [batchtime 0.402]
[epoch 105], [iter 96 / 176], [train main loss -2.100281], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 97 / 176], [train main loss -2.108060], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 98 / 176], [train main loss -2.077703], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 99 / 176], [train main loss -2.099917], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 100 / 176], [train main loss -2.096675], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 101 / 176], [train main loss -2.098783], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 102 / 176], [train main loss -2.107082], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 103 / 176], [train main loss -2.111558], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 104 / 176], [train main loss -2.130328], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 105 / 176], [train main loss -2.116066], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 106 / 176], [train main loss -2.101288], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 107 / 176], [train main loss -2.109530], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 108 / 176], [train main loss -2.082162], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 109 / 176], [train main loss -2.079379], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 110 / 176], [train main loss -2.080290], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 111 / 176], [train main loss -2.070673], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 112 / 176], [train main loss -2.057004], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 113 / 176], [train main loss -2.056278], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 114 / 176], [train main loss -2.048369], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 115 / 176], [train main loss -2.024451], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 116 / 176], [train main loss -2.001378], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 117 / 176], [train main loss -1.991975], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 118 / 176], [train main loss -1.986649], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 119 / 176], [train main loss -1.959083], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 120 / 176], [train main loss -1.962047], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 121 / 176], [train main loss -1.954925], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 122 / 176], [train main loss -1.973158], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 123 / 176], [train main loss -1.954312], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 124 / 176], [train main loss -1.970500], [lr 0.004000] [batchtime 0.411]
[epoch 105], [iter 125 / 176], [train main loss -1.963467], [lr 0.004000] [batchtime 0.41]
[epoch 105], [iter 126 / 176], [train main loss -1.968792], [lr 0.004000] [batchtime 0.41]
[epoch 105], [iter 127 / 176], [train main loss -1.943413], [lr 0.004000] [batchtime 0.41]
[epoch 105], [iter 128 / 176], [train main loss -1.954049], [lr 0.004000] [batchtime 0.41]
[epoch 105], [iter 129 / 176], [train main loss -1.965887], [lr 0.004000] [batchtime 0.41]
[epoch 105], [iter 130 / 176], [train main loss -1.969931], [lr 0.004000] [batchtime 0.41]
[epoch 105], [iter 131 / 176], [train main loss -1.979579], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 132 / 176], [train main loss -1.985397], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 133 / 176], [train main loss -1.982791], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 134 / 176], [train main loss -1.993089], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 135 / 176], [train main loss -1.985961], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 136 / 176], [train main loss -1.979942], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 137 / 176], [train main loss -1.981511], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 138 / 176], [train main loss -1.978171], [lr 0.004000] [batchtime 0.409]
[epoch 105], [iter 139 / 176], [train main loss -1.984694], [lr 0.004000] [batchtime 0.408]
[epoch 105], [iter 140 / 176], [train main loss -2.001248], [lr 0.004000] [batchtime 0.408]
[epoch 105], [iter 141 / 176], [train main loss -2.014955], [lr 0.004000] [batchtime 0.408]
[epoch 105], [iter 142 / 176], [train main loss -2.009005], [lr 0.004000] [batchtime 0.408]
[epoch 105], [iter 143 / 176], [train main loss -2.018152], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 144 / 176], [train main loss -2.010172], [lr 0.004000] [batchtime 0.417]
[epoch 105], [iter 145 / 176], [train main loss -2.013034], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 146 / 176], [train main loss -2.002548], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 147 / 176], [train main loss -2.012846], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 148 / 176], [train main loss -2.004659], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 149 / 176], [train main loss -1.984188], [lr 0.004000] [batchtime 0.416]
[epoch 105], [iter 150 / 176], [train main loss -1.983939], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 151 / 176], [train main loss -1.983810], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 152 / 176], [train main loss -1.976391], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 153 / 176], [train main loss -1.973267], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 154 / 176], [train main loss -1.975555], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 155 / 176], [train main loss -1.970856], [lr 0.004000] [batchtime 0.415]
[epoch 105], [iter 156 / 176], [train main loss -1.948099], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 157 / 176], [train main loss -1.963097], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 158 / 176], [train main loss -1.981426], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 159 / 176], [train main loss -1.974988], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 160 / 176], [train main loss -1.968634], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 161 / 176], [train main loss -1.977804], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 162 / 176], [train main loss -1.976722], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 163 / 176], [train main loss -1.986857], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 164 / 176], [train main loss -1.990009], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 165 / 176], [train main loss -1.991536], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 166 / 176], [train main loss -2.014940], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 167 / 176], [train main loss -2.010664], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 168 / 176], [train main loss -2.005792], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 169 / 176], [train main loss -2.003148], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 170 / 176], [train main loss -2.010333], [lr 0.004000] [batchtime 0.414]
[epoch 105], [iter 171 / 176], [train main loss -2.016506], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 172 / 176], [train main loss -2.028441], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 173 / 176], [train main loss -2.023055], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 174 / 176], [train main loss -2.023639], [lr 0.004000] [batchtime 0.413]
[epoch 105], [iter 175 / 176], [train main loss -2.029298], [lr 0.004000] [batchtime 0.412]
[epoch 105], [iter 176 / 176], [train main loss -2.032771], [lr 0.004000] [batchtime 0.412]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.48  35.50    0.02  0.03         0.98      0.97
   1  sidewalk          68.47   5.20    0.27  0.19         0.79      0.84
   2  building          85.97  24.89    0.07  0.10         0.94      0.91
   3  wall              19.33   0.17    2.54  1.64         0.28      0.38
   4  fence             24.81   0.38    2.34  0.70         0.30      0.59
   5  pole              37.55   0.53    1.14  0.52         0.47      0.66
   6  traffic light     13.45   0.02    6.03  0.41         0.14      0.71
   7  traffic sign      23.38   0.14    3.00  0.28         0.25      0.78
   8  vegetation        82.86  11.68    0.06  0.15         0.94      0.87
   9  terrain           40.67   0.38    0.91  0.55         0.52      0.65
  10  sky               93.66   3.77    0.03  0.04         0.97      0.96
  11  person            52.27   1.05    0.47  0.45         0.68      0.69
  12  rider              4.76   0.00   19.15  0.85         0.05      0.54
  13  car               85.54   6.66    0.06  0.11         0.94      0.90
  14  truck              0.67   0.00  148.49  0.50         0.01      0.67
  15  bus               13.59   0.03    1.52  4.84         0.40      0.17
  16  train             28.35   0.06    1.94  0.59         0.34      0.63
  17  motorcycle         3.21   0.00   29.50  0.66         0.03      0.60
  18  bicycle           35.90   0.25    0.53  1.26         0.65      0.44
Mean: 42.58
-----------------------------------------------------------------------------------------------------------
this : [epoch 105], [val loss 0.31233], [acc 0.90737], [acc_cls 0.51005], [mean_iu 0.42575], [fwavacc 0.83962]
best : [epoch 97], [val loss 0.32199], [acc 0.90677], [acc_cls 0.51393], [mean_iu 0.42977], [fwavacc 0.83869]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 106], [iter 1 / 176], [train main loss -2.943152], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 2 / 176], [train main loss -1.977722], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 3 / 176], [train main loss -2.707081], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 4 / 176], [train main loss -2.001375], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 5 / 176], [train main loss -1.876479], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 6 / 176], [train main loss -1.971989], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 7 / 176], [train main loss -2.082757], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 8 / 176], [train main loss -2.126402], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 9 / 176], [train main loss -2.034500], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 10 / 176], [train main loss -2.122731], [lr 0.003943] [batchtime 0]
[epoch 106], [iter 11 / 176], [train main loss -2.049945], [lr 0.003943] [batchtime 0.375]
[epoch 106], [iter 12 / 176], [train main loss -1.897700], [lr 0.003943] [batchtime 0.388]
[epoch 106], [iter 13 / 176], [train main loss -1.700426], [lr 0.003943] [batchtime 0.4]
[epoch 106], [iter 14 / 176], [train main loss -1.648839], [lr 0.003943] [batchtime 0.4]
[epoch 106], [iter 15 / 176], [train main loss -1.531977], [lr 0.003943] [batchtime 0.401]
[epoch 106], [iter 16 / 176], [train main loss -1.623910], [lr 0.003943] [batchtime 0.401]
[epoch 106], [iter 17 / 176], [train main loss -1.496205], [lr 0.003943] [batchtime 0.401]
[epoch 106], [iter 18 / 176], [train main loss -1.513215], [lr 0.003943] [batchtime 0.4]
[epoch 106], [iter 19 / 176], [train main loss -1.659091], [lr 0.003943] [batchtime 0.4]
[epoch 106], [iter 20 / 176], [train main loss -1.587983], [lr 0.003943] [batchtime 0.401]
[epoch 106], [iter 21 / 176], [train main loss -1.643227], [lr 0.003943] [batchtime 0.41]
[epoch 106], [iter 22 / 176], [train main loss -1.604049], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 23 / 176], [train main loss -1.724425], [lr 0.003943] [batchtime 0.419]
[epoch 106], [iter 24 / 176], [train main loss -1.649128], [lr 0.003943] [batchtime 0.418]
[epoch 106], [iter 25 / 176], [train main loss -1.715106], [lr 0.003943] [batchtime 0.417]
[epoch 106], [iter 26 / 176], [train main loss -1.760510], [lr 0.003943] [batchtime 0.415]
[epoch 106], [iter 27 / 176], [train main loss -1.715012], [lr 0.003943] [batchtime 0.414]
[epoch 106], [iter 28 / 176], [train main loss -1.696244], [lr 0.003943] [batchtime 0.413]
[epoch 106], [iter 29 / 176], [train main loss -1.680408], [lr 0.003943] [batchtime 0.412]
[epoch 106], [iter 30 / 176], [train main loss -1.761430], [lr 0.003943] [batchtime 0.412]
[epoch 106], [iter 31 / 176], [train main loss -1.726408], [lr 0.003943] [batchtime 0.412]
[epoch 106], [iter 32 / 176], [train main loss -1.756182], [lr 0.003943] [batchtime 0.411]
[epoch 106], [iter 33 / 176], [train main loss -1.744798], [lr 0.003943] [batchtime 0.411]
[epoch 106], [iter 34 / 176], [train main loss -1.722652], [lr 0.003943] [batchtime 0.411]
[epoch 106], [iter 35 / 176], [train main loss -1.772901], [lr 0.003943] [batchtime 0.41]
[epoch 106], [iter 36 / 176], [train main loss -1.740932], [lr 0.003943] [batchtime 0.41]
[epoch 106], [iter 37 / 176], [train main loss -1.755413], [lr 0.003943] [batchtime 0.41]
[epoch 106], [iter 38 / 176], [train main loss -1.715789], [lr 0.003943] [batchtime 0.409]
[epoch 106], [iter 39 / 176], [train main loss -1.734085], [lr 0.003943] [batchtime 0.409]
[epoch 106], [iter 40 / 176], [train main loss -1.691117], [lr 0.003943] [batchtime 0.409]
[epoch 106], [iter 41 / 176], [train main loss -1.708040], [lr 0.003943] [batchtime 0.409]
[epoch 106], [iter 42 / 176], [train main loss -1.572038], [lr 0.003943] [batchtime 0.409]
[epoch 106], [iter 43 / 176], [train main loss -1.518545], [lr 0.003943] [batchtime 0.408]
[epoch 106], [iter 44 / 176], [train main loss -1.545844], [lr 0.003943] [batchtime 0.408]
[epoch 106], [iter 45 / 176], [train main loss -1.632342], [lr 0.003943] [batchtime 0.412]
[epoch 106], [iter 46 / 176], [train main loss -1.631434], [lr 0.003943] [batchtime 0.446]
[epoch 106], [iter 47 / 176], [train main loss -1.665722], [lr 0.003943] [batchtime 0.444]
[epoch 106], [iter 48 / 176], [train main loss -1.689315], [lr 0.003943] [batchtime 0.443]
[epoch 106], [iter 49 / 176], [train main loss -1.674803], [lr 0.003943] [batchtime 0.441]
[epoch 106], [iter 50 / 176], [train main loss -1.687883], [lr 0.003943] [batchtime 0.44]
[epoch 106], [iter 51 / 176], [train main loss -1.653182], [lr 0.003943] [batchtime 0.439]
[epoch 106], [iter 52 / 176], [train main loss -1.712038], [lr 0.003943] [batchtime 0.438]
[epoch 106], [iter 53 / 176], [train main loss -1.708552], [lr 0.003943] [batchtime 0.437]
[epoch 106], [iter 54 / 176], [train main loss -1.682870], [lr 0.003943] [batchtime 0.436]
[epoch 106], [iter 55 / 176], [train main loss -1.661371], [lr 0.003943] [batchtime 0.435]
[epoch 106], [iter 56 / 176], [train main loss -1.700086], [lr 0.003943] [batchtime 0.434]
[epoch 106], [iter 57 / 176], [train main loss -1.696549], [lr 0.003943] [batchtime 0.434]
[epoch 106], [iter 58 / 176], [train main loss -1.733187], [lr 0.003943] [batchtime 0.433]
[epoch 106], [iter 59 / 176], [train main loss -1.752532], [lr 0.003943] [batchtime 0.432]
[epoch 106], [iter 60 / 176], [train main loss -1.747533], [lr 0.003943] [batchtime 0.431]
[epoch 106], [iter 61 / 176], [train main loss -1.769980], [lr 0.003943] [batchtime 0.431]
[epoch 106], [iter 62 / 176], [train main loss -1.743378], [lr 0.003943] [batchtime 0.43]
[epoch 106], [iter 63 / 176], [train main loss -1.750889], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 64 / 176], [train main loss -1.725658], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 65 / 176], [train main loss -1.767461], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 66 / 176], [train main loss -1.760327], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 67 / 176], [train main loss -1.773847], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 68 / 176], [train main loss -1.743788], [lr 0.003943] [batchtime 0.43]
[epoch 106], [iter 69 / 176], [train main loss -1.782431], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 70 / 176], [train main loss -1.763821], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 71 / 176], [train main loss -1.739839], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 72 / 176], [train main loss -1.698402], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 73 / 176], [train main loss -1.719019], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 74 / 176], [train main loss -1.697137], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 75 / 176], [train main loss -1.719073], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 76 / 176], [train main loss -1.781804], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 77 / 176], [train main loss -1.761751], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 78 / 176], [train main loss -1.772319], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 79 / 176], [train main loss -1.765034], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 80 / 176], [train main loss -1.787449], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 81 / 176], [train main loss -1.786282], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 82 / 176], [train main loss -1.799444], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 83 / 176], [train main loss -1.809910], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 84 / 176], [train main loss -1.797576], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 85 / 176], [train main loss -1.826878], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 86 / 176], [train main loss -1.809040], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 87 / 176], [train main loss -1.787772], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 88 / 176], [train main loss -1.769785], [lr 0.003943] [batchtime 0.42]
[epoch 106], [iter 89 / 176], [train main loss -1.757994], [lr 0.003943] [batchtime 0.42]
[epoch 106], [iter 90 / 176], [train main loss -1.780923], [lr 0.003943] [batchtime 0.42]
[epoch 106], [iter 91 / 176], [train main loss -1.809878], [lr 0.003943] [batchtime 0.419]
[epoch 106], [iter 92 / 176], [train main loss -1.831599], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 93 / 176], [train main loss -1.831587], [lr 0.003943] [batchtime 0.435]
[epoch 106], [iter 94 / 176], [train main loss -1.831293], [lr 0.003943] [batchtime 0.435]
[epoch 106], [iter 95 / 176], [train main loss -1.843312], [lr 0.003943] [batchtime 0.434]
[epoch 106], [iter 96 / 176], [train main loss -1.846038], [lr 0.003943] [batchtime 0.434]
[epoch 106], [iter 97 / 176], [train main loss -1.872666], [lr 0.003943] [batchtime 0.433]
[epoch 106], [iter 98 / 176], [train main loss -1.892257], [lr 0.003943] [batchtime 0.433]
[epoch 106], [iter 99 / 176], [train main loss -1.891737], [lr 0.003943] [batchtime 0.432]
[epoch 106], [iter 100 / 176], [train main loss -1.904821], [lr 0.003943] [batchtime 0.432]
[epoch 106], [iter 101 / 176], [train main loss -1.884892], [lr 0.003943] [batchtime 0.431]
[epoch 106], [iter 102 / 176], [train main loss -1.886073], [lr 0.003943] [batchtime 0.431]
[epoch 106], [iter 103 / 176], [train main loss -1.875247], [lr 0.003943] [batchtime 0.431]
[epoch 106], [iter 104 / 176], [train main loss -1.849352], [lr 0.003943] [batchtime 0.43]
[epoch 106], [iter 105 / 176], [train main loss -1.842001], [lr 0.003943] [batchtime 0.43]
[epoch 106], [iter 106 / 176], [train main loss -1.796598], [lr 0.003943] [batchtime 0.43]
[epoch 106], [iter 107 / 176], [train main loss -1.793110], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 108 / 176], [train main loss -1.787976], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 109 / 176], [train main loss -1.793232], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 110 / 176], [train main loss -1.789238], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 111 / 176], [train main loss -1.808778], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 112 / 176], [train main loss -1.821006], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 113 / 176], [train main loss -1.827601], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 114 / 176], [train main loss -1.824800], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 115 / 176], [train main loss -1.823635], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 116 / 176], [train main loss -1.834835], [lr 0.003943] [batchtime 0.429]
[epoch 106], [iter 117 / 176], [train main loss -1.854261], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 118 / 176], [train main loss -1.854040], [lr 0.003943] [batchtime 0.428]
[epoch 106], [iter 119 / 176], [train main loss -1.841839], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 120 / 176], [train main loss -1.858828], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 121 / 176], [train main loss -1.850252], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 122 / 176], [train main loss -1.855885], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 123 / 176], [train main loss -1.871564], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 124 / 176], [train main loss -1.879358], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 125 / 176], [train main loss -1.882394], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 126 / 176], [train main loss -1.902905], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 127 / 176], [train main loss -1.888215], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 128 / 176], [train main loss -1.883219], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 129 / 176], [train main loss -1.891024], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 130 / 176], [train main loss -1.889857], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 131 / 176], [train main loss -1.881786], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 132 / 176], [train main loss -1.888506], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 133 / 176], [train main loss -1.889152], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 134 / 176], [train main loss -1.877626], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 135 / 176], [train main loss -1.871693], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 136 / 176], [train main loss -1.873971], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 137 / 176], [train main loss -1.868278], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 138 / 176], [train main loss -1.854741], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 139 / 176], [train main loss -1.858092], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 140 / 176], [train main loss -1.868309], [lr 0.003943] [batchtime 0.427]
[epoch 106], [iter 141 / 176], [train main loss -1.888441], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 142 / 176], [train main loss -1.875606], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 143 / 176], [train main loss -1.882441], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 144 / 176], [train main loss -1.882814], [lr 0.003943] [batchtime 0.426]
[epoch 106], [iter 145 / 176], [train main loss -1.878585], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 146 / 176], [train main loss -1.888313], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 147 / 176], [train main loss -1.897419], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 148 / 176], [train main loss -1.889294], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 149 / 176], [train main loss -1.872130], [lr 0.003943] [batchtime 0.425]
[epoch 106], [iter 150 / 176], [train main loss -1.880614], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 151 / 176], [train main loss -1.893778], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 152 / 176], [train main loss -1.893842], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 153 / 176], [train main loss -1.883858], [lr 0.003943] [batchtime 0.424]
[epoch 106], [iter 154 / 176], [train main loss -1.878928], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 155 / 176], [train main loss -1.889146], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 156 / 176], [train main loss -1.889647], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 157 / 176], [train main loss -1.882246], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 158 / 176], [train main loss -1.890421], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 159 / 176], [train main loss -1.881917], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 160 / 176], [train main loss -1.892145], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 161 / 176], [train main loss -1.901648], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 162 / 176], [train main loss -1.902560], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 163 / 176], [train main loss -1.907202], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 164 / 176], [train main loss -1.909753], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 165 / 176], [train main loss -1.911436], [lr 0.003943] [batchtime 0.423]
[epoch 106], [iter 166 / 176], [train main loss -1.924428], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 167 / 176], [train main loss -1.906581], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 168 / 176], [train main loss -1.918549], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 169 / 176], [train main loss -1.919033], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 170 / 176], [train main loss -1.905925], [lr 0.003943] [batchtime 0.422]
[epoch 106], [iter 171 / 176], [train main loss -1.914924], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 172 / 176], [train main loss -1.933821], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 173 / 176], [train main loss -1.941549], [lr 0.003943] [batchtime 0.421]
[epoch 106], [iter 174 / 176], [train main loss -1.938345], [lr 0.003943] [batchtime 0.42]
[epoch 106], [iter 175 / 176], [train main loss -1.935742], [lr 0.003943] [batchtime 0.42]
[epoch 106], [iter 176 / 176], [train main loss -1.953287], [lr 0.003943] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.17  35.16   0.03  0.03         0.97      0.97
   1  sidewalk          68.15   5.50   0.20  0.27         0.83      0.79
   2  building          86.20  25.15   0.06  0.10         0.95      0.91
   3  wall              17.77   0.15   2.82  1.81         0.26      0.36
   4  fence             23.79   0.36   2.48  0.72         0.29      0.58
   5  pole              38.06   0.57   1.00  0.63         0.50      0.61
   6  traffic light     12.87   0.02   6.40  0.37         0.14      0.73
   7  traffic sign      22.47   0.13   3.19  0.27         0.24      0.79
   8  vegetation        83.89  11.55   0.07  0.12         0.93      0.89
   9  terrain           39.29   0.37   1.00  0.54         0.50      0.65
  10  sky               93.44   3.76   0.03  0.04         0.97      0.96
  11  person            51.69   0.97   0.57  0.36         0.64      0.73
  12  rider              7.21   0.01  11.98  0.89         0.08      0.53
  13  car               85.59   6.63   0.07  0.10         0.94      0.91
  14  truck              1.79   0.01  54.16  0.61         0.02      0.62
  15  bus               15.09   0.03   1.84  3.79         0.35      0.21
  16  train             42.32   0.10   0.74  0.62         0.57      0.62
  17  motorcycle         2.99   0.00  31.84  0.63         0.03      0.61
  18  bicycle           37.26   0.26   0.51  1.17         0.66      0.46
Mean: 43.37
-----------------------------------------------------------------------------------------------------------
this : [epoch 106], [val loss 0.31181], [acc 0.90736], [acc_cls 0.51904], [mean_iu 0.43370], [fwavacc 0.84003]
best : [epoch 106], [val loss 0.31181], [acc 0.90736], [acc_cls 0.51904], [mean_iu 0.43370], [fwavacc 0.84003]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 107], [iter 1 / 176], [train main loss -3.119903], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 2 / 176], [train main loss -5.312672], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 3 / 176], [train main loss -4.077114], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 4 / 176], [train main loss -3.062728], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 5 / 176], [train main loss -3.072847], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 6 / 176], [train main loss -2.895618], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 7 / 176], [train main loss -2.922858], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 8 / 176], [train main loss -2.847791], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 9 / 176], [train main loss -2.711625], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 10 / 176], [train main loss -2.723305], [lr 0.003886] [batchtime 0]
[epoch 107], [iter 11 / 176], [train main loss -2.989430], [lr 0.003886] [batchtime 0.382]
[epoch 107], [iter 12 / 176], [train main loss -2.956905], [lr 0.003886] [batchtime 0.39]
[epoch 107], [iter 13 / 176], [train main loss -2.938337], [lr 0.003886] [batchtime 0.39]
[epoch 107], [iter 14 / 176], [train main loss -2.870798], [lr 0.003886] [batchtime 0.39]
[epoch 107], [iter 15 / 176], [train main loss -2.756237], [lr 0.003886] [batchtime 0.392]
[epoch 107], [iter 16 / 176], [train main loss -2.814328], [lr 0.003886] [batchtime 0.417]
[epoch 107], [iter 17 / 176], [train main loss -2.832953], [lr 0.003886] [batchtime 0.439]
[epoch 107], [iter 18 / 176], [train main loss -2.827804], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 19 / 176], [train main loss -2.747026], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 20 / 176], [train main loss -2.783953], [lr 0.003886] [batchtime 0.426]
[epoch 107], [iter 21 / 176], [train main loss -2.694172], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 22 / 176], [train main loss -2.695534], [lr 0.003886] [batchtime 0.42]
[epoch 107], [iter 23 / 176], [train main loss -2.613885], [lr 0.003886] [batchtime 0.418]
[epoch 107], [iter 24 / 176], [train main loss -2.480150], [lr 0.003886] [batchtime 0.417]
[epoch 107], [iter 25 / 176], [train main loss -2.428720], [lr 0.003886] [batchtime 0.416]
[epoch 107], [iter 26 / 176], [train main loss -2.490834], [lr 0.003886] [batchtime 0.415]
[epoch 107], [iter 27 / 176], [train main loss -2.457869], [lr 0.003886] [batchtime 0.414]
[epoch 107], [iter 28 / 176], [train main loss -2.554581], [lr 0.003886] [batchtime 0.413]
[epoch 107], [iter 29 / 176], [train main loss -2.506548], [lr 0.003886] [batchtime 0.412]
[epoch 107], [iter 30 / 176], [train main loss -2.492594], [lr 0.003886] [batchtime 0.411]
[epoch 107], [iter 31 / 176], [train main loss -2.503962], [lr 0.003886] [batchtime 0.41]
[epoch 107], [iter 32 / 176], [train main loss -2.542828], [lr 0.003886] [batchtime 0.41]
[epoch 107], [iter 33 / 176], [train main loss -2.452027], [lr 0.003886] [batchtime 0.41]
[epoch 107], [iter 34 / 176], [train main loss -2.464541], [lr 0.003886] [batchtime 0.409]
[epoch 107], [iter 35 / 176], [train main loss -2.504748], [lr 0.003886] [batchtime 0.409]
[epoch 107], [iter 36 / 176], [train main loss -2.540293], [lr 0.003886] [batchtime 0.408]
[epoch 107], [iter 37 / 176], [train main loss -2.518465], [lr 0.003886] [batchtime 0.408]
[epoch 107], [iter 38 / 176], [train main loss -2.461761], [lr 0.003886] [batchtime 0.407]
[epoch 107], [iter 39 / 176], [train main loss -2.471102], [lr 0.003886] [batchtime 0.407]
[epoch 107], [iter 40 / 176], [train main loss -2.492399], [lr 0.003886] [batchtime 0.411]
[epoch 107], [iter 41 / 176], [train main loss -2.482864], [lr 0.003886] [batchtime 0.451]
[epoch 107], [iter 42 / 176], [train main loss -2.522438], [lr 0.003886] [batchtime 0.449]
[epoch 107], [iter 43 / 176], [train main loss -2.437669], [lr 0.003886] [batchtime 0.447]
[epoch 107], [iter 44 / 176], [train main loss -2.451018], [lr 0.003886] [batchtime 0.446]
[epoch 107], [iter 45 / 176], [train main loss -2.409618], [lr 0.003886] [batchtime 0.444]
[epoch 107], [iter 46 / 176], [train main loss -2.391345], [lr 0.003886] [batchtime 0.443]
[epoch 107], [iter 47 / 176], [train main loss -2.397823], [lr 0.003886] [batchtime 0.441]
[epoch 107], [iter 48 / 176], [train main loss -2.395576], [lr 0.003886] [batchtime 0.44]
[epoch 107], [iter 49 / 176], [train main loss -2.397272], [lr 0.003886] [batchtime 0.439]
[epoch 107], [iter 50 / 176], [train main loss -2.416180], [lr 0.003886] [batchtime 0.438]
[epoch 107], [iter 51 / 176], [train main loss -2.365141], [lr 0.003886] [batchtime 0.437]
[epoch 107], [iter 52 / 176], [train main loss -2.354987], [lr 0.003886] [batchtime 0.436]
[epoch 107], [iter 53 / 176], [train main loss -2.317330], [lr 0.003886] [batchtime 0.435]
[epoch 107], [iter 54 / 176], [train main loss -2.327757], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 55 / 176], [train main loss -2.357691], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 56 / 176], [train main loss -2.397884], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 57 / 176], [train main loss -2.386417], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 58 / 176], [train main loss -2.412206], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 59 / 176], [train main loss -2.391325], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 60 / 176], [train main loss -2.402497], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 61 / 176], [train main loss -2.379455], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 62 / 176], [train main loss -2.383436], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 63 / 176], [train main loss -2.346333], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 64 / 176], [train main loss -2.351652], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 65 / 176], [train main loss -2.345802], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 66 / 176], [train main loss -2.309413], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 67 / 176], [train main loss -2.318985], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 68 / 176], [train main loss -2.284639], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 69 / 176], [train main loss -2.278172], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 70 / 176], [train main loss -2.280151], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 71 / 176], [train main loss -2.241894], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 72 / 176], [train main loss -2.245003], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 73 / 176], [train main loss -2.251392], [lr 0.003886] [batchtime 0.426]
[epoch 107], [iter 74 / 176], [train main loss -2.255390], [lr 0.003886] [batchtime 0.426]
[epoch 107], [iter 75 / 176], [train main loss -2.265457], [lr 0.003886] [batchtime 0.425]
[epoch 107], [iter 76 / 176], [train main loss -2.282622], [lr 0.003886] [batchtime 0.425]
[epoch 107], [iter 77 / 176], [train main loss -2.272394], [lr 0.003886] [batchtime 0.424]
[epoch 107], [iter 78 / 176], [train main loss -2.296063], [lr 0.003886] [batchtime 0.424]
[epoch 107], [iter 79 / 176], [train main loss -2.277778], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 80 / 176], [train main loss -2.302039], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 81 / 176], [train main loss -2.310284], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 82 / 176], [train main loss -2.350620], [lr 0.003886] [batchtime 0.422]
[epoch 107], [iter 83 / 176], [train main loss -2.396333], [lr 0.003886] [batchtime 0.422]
[epoch 107], [iter 84 / 176], [train main loss -2.374805], [lr 0.003886] [batchtime 0.421]
[epoch 107], [iter 85 / 176], [train main loss -2.369868], [lr 0.003886] [batchtime 0.421]
[epoch 107], [iter 86 / 176], [train main loss -2.341270], [lr 0.003886] [batchtime 0.421]
[epoch 107], [iter 87 / 176], [train main loss -2.361965], [lr 0.003886] [batchtime 0.436]
[epoch 107], [iter 88 / 176], [train main loss -2.370408], [lr 0.003886] [batchtime 0.438]
[epoch 107], [iter 89 / 176], [train main loss -2.369043], [lr 0.003886] [batchtime 0.437]
[epoch 107], [iter 90 / 176], [train main loss -2.351358], [lr 0.003886] [batchtime 0.436]
[epoch 107], [iter 91 / 176], [train main loss -2.314962], [lr 0.003886] [batchtime 0.436]
[epoch 107], [iter 92 / 176], [train main loss -2.278131], [lr 0.003886] [batchtime 0.435]
[epoch 107], [iter 93 / 176], [train main loss -2.283898], [lr 0.003886] [batchtime 0.435]
[epoch 107], [iter 94 / 176], [train main loss -2.261403], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 95 / 176], [train main loss -2.264811], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 96 / 176], [train main loss -2.248891], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 97 / 176], [train main loss -2.257740], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 98 / 176], [train main loss -2.251554], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 99 / 176], [train main loss -2.243433], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 100 / 176], [train main loss -2.245929], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 101 / 176], [train main loss -2.225153], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 102 / 176], [train main loss -2.258806], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 103 / 176], [train main loss -2.262029], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 104 / 176], [train main loss -2.240178], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 105 / 176], [train main loss -2.253311], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 106 / 176], [train main loss -2.247450], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 107 / 176], [train main loss -2.235425], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 108 / 176], [train main loss -2.236036], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 109 / 176], [train main loss -2.244148], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 110 / 176], [train main loss -2.240922], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 111 / 176], [train main loss -2.242573], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 112 / 176], [train main loss -2.233775], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 113 / 176], [train main loss -2.234194], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 114 / 176], [train main loss -2.224241], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 115 / 176], [train main loss -2.201137], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 116 / 176], [train main loss -2.194772], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 117 / 176], [train main loss -2.191910], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 118 / 176], [train main loss -2.176692], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 119 / 176], [train main loss -2.178283], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 120 / 176], [train main loss -2.159546], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 121 / 176], [train main loss -2.146849], [lr 0.003886] [batchtime 0.426]
[epoch 107], [iter 122 / 176], [train main loss -2.145966], [lr 0.003886] [batchtime 0.426]
[epoch 107], [iter 123 / 176], [train main loss -2.142308], [lr 0.003886] [batchtime 0.426]
[epoch 107], [iter 124 / 176], [train main loss -2.162985], [lr 0.003886] [batchtime 0.425]
[epoch 107], [iter 125 / 176], [train main loss -2.157704], [lr 0.003886] [batchtime 0.425]
[epoch 107], [iter 126 / 176], [train main loss -2.149324], [lr 0.003886] [batchtime 0.425]
[epoch 107], [iter 127 / 176], [train main loss -2.161549], [lr 0.003886] [batchtime 0.424]
[epoch 107], [iter 128 / 176], [train main loss -2.161062], [lr 0.003886] [batchtime 0.424]
[epoch 107], [iter 129 / 176], [train main loss -2.166118], [lr 0.003886] [batchtime 0.424]
[epoch 107], [iter 130 / 176], [train main loss -2.159246], [lr 0.003886] [batchtime 0.424]
[epoch 107], [iter 131 / 176], [train main loss -2.156883], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 132 / 176], [train main loss -2.122661], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 133 / 176], [train main loss -2.121836], [lr 0.003886] [batchtime 0.423]
[epoch 107], [iter 134 / 176], [train main loss -2.109791], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 135 / 176], [train main loss -2.123232], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 136 / 176], [train main loss -2.125247], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 137 / 176], [train main loss -2.127065], [lr 0.003886] [batchtime 0.435]
[epoch 107], [iter 138 / 176], [train main loss -2.126148], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 139 / 176], [train main loss -2.116183], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 140 / 176], [train main loss -2.114196], [lr 0.003886] [batchtime 0.434]
[epoch 107], [iter 141 / 176], [train main loss -2.129665], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 142 / 176], [train main loss -2.133865], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 143 / 176], [train main loss -2.116468], [lr 0.003886] [batchtime 0.433]
[epoch 107], [iter 144 / 176], [train main loss -2.090221], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 145 / 176], [train main loss -2.081251], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 146 / 176], [train main loss -2.066755], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 147 / 176], [train main loss -2.073241], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 148 / 176], [train main loss -2.069634], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 149 / 176], [train main loss -2.072440], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 150 / 176], [train main loss -2.070785], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 151 / 176], [train main loss -2.065491], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 152 / 176], [train main loss -2.070518], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 153 / 176], [train main loss -2.064203], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 154 / 176], [train main loss -2.081080], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 155 / 176], [train main loss -2.083798], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 156 / 176], [train main loss -2.077568], [lr 0.003886] [batchtime 0.432]
[epoch 107], [iter 157 / 176], [train main loss -2.061336], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 158 / 176], [train main loss -2.053194], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 159 / 176], [train main loss -2.046887], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 160 / 176], [train main loss -2.042346], [lr 0.003886] [batchtime 0.431]
[epoch 107], [iter 161 / 176], [train main loss -2.025683], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 162 / 176], [train main loss -2.044857], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 163 / 176], [train main loss -2.055772], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 164 / 176], [train main loss -2.053271], [lr 0.003886] [batchtime 0.43]
[epoch 107], [iter 165 / 176], [train main loss -2.044980], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 166 / 176], [train main loss -2.042309], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 167 / 176], [train main loss -2.039430], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 168 / 176], [train main loss -2.046923], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 169 / 176], [train main loss -2.051497], [lr 0.003886] [batchtime 0.429]
[epoch 107], [iter 170 / 176], [train main loss -2.081627], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 171 / 176], [train main loss -2.085022], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 172 / 176], [train main loss -2.074856], [lr 0.003886] [batchtime 0.428]
[epoch 107], [iter 173 / 176], [train main loss -2.071128], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 174 / 176], [train main loss -2.085222], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 175 / 176], [train main loss -2.090418], [lr 0.003886] [batchtime 0.427]
[epoch 107], [iter 176 / 176], [train main loss -2.093557], [lr 0.003886] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.18  35.37   0.03  0.03         0.97      0.97
   1  sidewalk          67.58   5.36   0.23  0.25         0.81      0.80
   2  building          86.19  24.78   0.07  0.09         0.93      0.92
   3  wall              15.79   0.12   4.09  1.24         0.20      0.45
   4  fence             25.40   0.39   2.23  0.71         0.31      0.59
   5  pole              38.50   0.57   0.99  0.60         0.50      0.62
   6  traffic light     16.93   0.03   4.31  0.59         0.19      0.63
   7  traffic sign      22.35   0.13   3.22  0.25         0.24      0.80
   8  vegetation        83.91  11.58   0.07  0.12         0.94      0.89
   9  terrain           39.39   0.38   0.95  0.59         0.51      0.63
  10  sky               93.19   3.76   0.03  0.04         0.97      0.96
  11  person            52.58   1.08   0.42  0.48         0.70      0.68
  12  rider              6.91   0.01  12.19  1.28         0.08      0.44
  13  car               85.40   6.73   0.05  0.12         0.95      0.89
  14  truck              1.98   0.01  48.79  0.70         0.02      0.59
  15  bus               13.72   0.03   1.64  4.65         0.38      0.18
  16  train             34.05   0.09   0.93  1.01         0.52      0.50
  17  motorcycle         5.03   0.01  18.21  0.66         0.05      0.60
  18  bicycle           35.78   0.27   0.45  1.35         0.69      0.43
Mean: 43.10
-----------------------------------------------------------------------------------------------------------
this : [epoch 107], [val loss 0.30427], [acc 0.90697], [acc_cls 0.52437], [mean_iu 0.43099], [fwavacc 0.83962]
best : [epoch 106], [val loss 0.31181], [acc 0.90736], [acc_cls 0.51904], [mean_iu 0.43370], [fwavacc 0.84003]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 108], [iter 1 / 176], [train main loss -1.305634], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 2 / 176], [train main loss -1.610698], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 3 / 176], [train main loss -2.324457], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 4 / 176], [train main loss -2.142787], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 5 / 176], [train main loss -1.826470], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 6 / 176], [train main loss -1.703129], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 7 / 176], [train main loss -2.006259], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 8 / 176], [train main loss -2.307133], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 9 / 176], [train main loss -2.386180], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 10 / 176], [train main loss -1.888649], [lr 0.003829] [batchtime 0]
[epoch 108], [iter 11 / 176], [train main loss -1.623715], [lr 0.003829] [batchtime 0.383]
[epoch 108], [iter 12 / 176], [train main loss -1.647325], [lr 0.003829] [batchtime 0.393]
[epoch 108], [iter 13 / 176], [train main loss -1.818497], [lr 0.003829] [batchtime 0.395]
[epoch 108], [iter 14 / 176], [train main loss -1.831249], [lr 0.003829] [batchtime 0.398]
[epoch 108], [iter 15 / 176], [train main loss -2.006969], [lr 0.003829] [batchtime 0.396]
[epoch 108], [iter 16 / 176], [train main loss -2.136595], [lr 0.003829] [batchtime 0.396]
[epoch 108], [iter 17 / 176], [train main loss -2.154663], [lr 0.003829] [batchtime 0.398]
[epoch 108], [iter 18 / 176], [train main loss -2.180886], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 19 / 176], [train main loss -2.169720], [lr 0.003829] [batchtime 0.398]
[epoch 108], [iter 20 / 176], [train main loss -2.193233], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 21 / 176], [train main loss -2.085338], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 22 / 176], [train main loss -2.157148], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 23 / 176], [train main loss -2.141015], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 24 / 176], [train main loss -2.153738], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 25 / 176], [train main loss -2.045206], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 26 / 176], [train main loss -2.023895], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 27 / 176], [train main loss -2.031859], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 28 / 176], [train main loss -2.005035], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 29 / 176], [train main loss -1.984263], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 30 / 176], [train main loss -1.891142], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 31 / 176], [train main loss -1.945339], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 32 / 176], [train main loss -1.876638], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 33 / 176], [train main loss -1.863555], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 34 / 176], [train main loss -1.849632], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 35 / 176], [train main loss -1.825487], [lr 0.003829] [batchtime 0.4]
[epoch 108], [iter 36 / 176], [train main loss -1.867767], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 37 / 176], [train main loss -1.839861], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 38 / 176], [train main loss -1.870556], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 39 / 176], [train main loss -1.856366], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 40 / 176], [train main loss -1.833164], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 41 / 176], [train main loss -1.832319], [lr 0.003829] [batchtime 0.399]
[epoch 108], [iter 42 / 176], [train main loss -1.824614], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 43 / 176], [train main loss -1.799802], [lr 0.003829] [batchtime 0.417]
[epoch 108], [iter 44 / 176], [train main loss -1.812893], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 45 / 176], [train main loss -1.837767], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 46 / 176], [train main loss -1.869285], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 47 / 176], [train main loss -1.924048], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 48 / 176], [train main loss -1.932118], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 49 / 176], [train main loss -1.890985], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 50 / 176], [train main loss -1.893468], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 51 / 176], [train main loss -1.946148], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 52 / 176], [train main loss -1.945904], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 53 / 176], [train main loss -1.965644], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 54 / 176], [train main loss -1.976805], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 55 / 176], [train main loss -1.976340], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 56 / 176], [train main loss -2.026402], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 57 / 176], [train main loss -2.009510], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 58 / 176], [train main loss -2.010045], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 59 / 176], [train main loss -1.977928], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 60 / 176], [train main loss -1.970735], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 61 / 176], [train main loss -1.952879], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 62 / 176], [train main loss -1.970214], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 63 / 176], [train main loss -1.950506], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 64 / 176], [train main loss -1.935031], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 65 / 176], [train main loss -1.911035], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 66 / 176], [train main loss -1.903520], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 67 / 176], [train main loss -1.898690], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 68 / 176], [train main loss -1.924683], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 69 / 176], [train main loss -1.970266], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 70 / 176], [train main loss -1.955767], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 71 / 176], [train main loss -1.990581], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 72 / 176], [train main loss -1.932517], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 73 / 176], [train main loss -1.930894], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 74 / 176], [train main loss -1.952598], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 75 / 176], [train main loss -1.941919], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 76 / 176], [train main loss -1.972402], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 77 / 176], [train main loss -1.980230], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 78 / 176], [train main loss -2.009041], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 79 / 176], [train main loss -2.025018], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 80 / 176], [train main loss -2.077136], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 81 / 176], [train main loss -2.060162], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 82 / 176], [train main loss -2.067518], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 83 / 176], [train main loss -2.107070], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 84 / 176], [train main loss -2.108637], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 85 / 176], [train main loss -2.106867], [lr 0.003829] [batchtime 0.405]
[epoch 108], [iter 86 / 176], [train main loss -2.108387], [lr 0.003829] [batchtime 0.405]
[epoch 108], [iter 87 / 176], [train main loss -2.110726], [lr 0.003829] [batchtime 0.405]
[epoch 108], [iter 88 / 176], [train main loss -2.122787], [lr 0.003829] [batchtime 0.405]
[epoch 108], [iter 89 / 176], [train main loss -2.137578], [lr 0.003829] [batchtime 0.405]
[epoch 108], [iter 90 / 176], [train main loss -2.133509], [lr 0.003829] [batchtime 0.405]
[epoch 108], [iter 91 / 176], [train main loss -2.115186], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 92 / 176], [train main loss -2.099528], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 93 / 176], [train main loss -2.104261], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 94 / 176], [train main loss -2.111426], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 95 / 176], [train main loss -2.104370], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 96 / 176], [train main loss -2.107977], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 97 / 176], [train main loss -2.086180], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 98 / 176], [train main loss -2.105929], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 99 / 176], [train main loss -2.111961], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 100 / 176], [train main loss -2.103927], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 101 / 176], [train main loss -2.104876], [lr 0.003829] [batchtime 0.411]
[epoch 108], [iter 102 / 176], [train main loss -2.090534], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 103 / 176], [train main loss -2.106649], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 104 / 176], [train main loss -2.100450], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 105 / 176], [train main loss -2.131307], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 106 / 176], [train main loss -2.113115], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 107 / 176], [train main loss -2.093130], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 108 / 176], [train main loss -2.093853], [lr 0.003829] [batchtime 0.41]
[epoch 108], [iter 109 / 176], [train main loss -2.094583], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 110 / 176], [train main loss -2.107893], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 111 / 176], [train main loss -2.115551], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 112 / 176], [train main loss -2.125820], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 113 / 176], [train main loss -2.123206], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 114 / 176], [train main loss -2.115178], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 115 / 176], [train main loss -2.120910], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 116 / 176], [train main loss -2.127554], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 117 / 176], [train main loss -2.139516], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 118 / 176], [train main loss -2.127485], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 119 / 176], [train main loss -2.118170], [lr 0.003829] [batchtime 0.409]
[epoch 108], [iter 120 / 176], [train main loss -2.101870], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 121 / 176], [train main loss -2.111753], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 122 / 176], [train main loss -2.106457], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 123 / 176], [train main loss -2.083283], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 124 / 176], [train main loss -2.075238], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 125 / 176], [train main loss -2.063467], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 126 / 176], [train main loss -2.074665], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 127 / 176], [train main loss -2.056775], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 128 / 176], [train main loss -2.068371], [lr 0.003829] [batchtime 0.408]
[epoch 108], [iter 129 / 176], [train main loss -2.062387], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 130 / 176], [train main loss -2.070102], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 131 / 176], [train main loss -2.055488], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 132 / 176], [train main loss -2.037806], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 133 / 176], [train main loss -2.059339], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 134 / 176], [train main loss -2.057618], [lr 0.003829] [batchtime 0.407]
[epoch 108], [iter 135 / 176], [train main loss -2.043006], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 136 / 176], [train main loss -2.054391], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 137 / 176], [train main loss -2.035299], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 138 / 176], [train main loss -2.034848], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 139 / 176], [train main loss -2.043113], [lr 0.003829] [batchtime 0.406]
[epoch 108], [iter 140 / 176], [train main loss -2.021881], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 141 / 176], [train main loss -2.029880], [lr 0.003829] [batchtime 0.418]
[epoch 108], [iter 142 / 176], [train main loss -2.032515], [lr 0.003829] [batchtime 0.418]
[epoch 108], [iter 143 / 176], [train main loss -2.029767], [lr 0.003829] [batchtime 0.417]
[epoch 108], [iter 144 / 176], [train main loss -2.020884], [lr 0.003829] [batchtime 0.417]
[epoch 108], [iter 145 / 176], [train main loss -2.050812], [lr 0.003829] [batchtime 0.417]
[epoch 108], [iter 146 / 176], [train main loss -2.047477], [lr 0.003829] [batchtime 0.417]
[epoch 108], [iter 147 / 176], [train main loss -2.064893], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 148 / 176], [train main loss -2.072540], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 149 / 176], [train main loss -2.060750], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 150 / 176], [train main loss -2.066806], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 151 / 176], [train main loss -2.084977], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 152 / 176], [train main loss -2.088574], [lr 0.003829] [batchtime 0.416]
[epoch 108], [iter 153 / 176], [train main loss -2.078711], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 154 / 176], [train main loss -2.095420], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 155 / 176], [train main loss -2.100832], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 156 / 176], [train main loss -2.108954], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 157 / 176], [train main loss -2.106491], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 158 / 176], [train main loss -2.099131], [lr 0.003829] [batchtime 0.415]
[epoch 108], [iter 159 / 176], [train main loss -2.102194], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 160 / 176], [train main loss -2.101807], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 161 / 176], [train main loss -2.099143], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 162 / 176], [train main loss -2.096401], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 163 / 176], [train main loss -2.092037], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 164 / 176], [train main loss -2.083621], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 165 / 176], [train main loss -2.091173], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 166 / 176], [train main loss -2.087934], [lr 0.003829] [batchtime 0.414]
[epoch 108], [iter 167 / 176], [train main loss -2.100707], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 168 / 176], [train main loss -2.101623], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 169 / 176], [train main loss -2.100101], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 170 / 176], [train main loss -2.087491], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 171 / 176], [train main loss -2.096139], [lr 0.003829] [batchtime 0.413]
[epoch 108], [iter 172 / 176], [train main loss -2.095544], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 173 / 176], [train main loss -2.102266], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 174 / 176], [train main loss -2.092889], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 175 / 176], [train main loss -2.081069], [lr 0.003829] [batchtime 0.412]
[epoch 108], [iter 176 / 176], [train main loss -2.072189], [lr 0.003829] [batchtime 0.411]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.26  35.77   0.02  0.04         0.98      0.96
   1  sidewalk          66.80   4.98   0.32  0.17         0.76      0.85
   2  building          86.22  25.07   0.06  0.10         0.94      0.91
   3  wall              17.61   0.15   3.03  1.65         0.25      0.38
   4  fence             24.16   0.36   2.49  0.65         0.29      0.60
   5  pole              38.44   0.55   1.05  0.55         0.49      0.64
   6  traffic light     13.31   0.02   6.12  0.39         0.14      0.72
   7  traffic sign      19.74   0.12   3.83  0.24         0.21      0.81
   8  vegetation        83.64  11.63   0.06  0.13         0.94      0.88
   9  terrain           39.75   0.38   0.96  0.56         0.51      0.64
  10  sky               93.64   3.75   0.03  0.03         0.97      0.97
  11  person            51.40   0.96   0.60  0.35         0.63      0.74
  12  rider             10.92   0.01   7.07  1.08         0.12      0.48
  13  car               85.74   6.66   0.06  0.10         0.94      0.91
  14  truck              2.25   0.01  42.97  0.50         0.02      0.67
  15  bus               15.44   0.05   0.92  4.56         0.52      0.18
  16  train             29.81   0.07   1.73  0.62         0.37      0.62
  17  motorcycle         3.28   0.00  28.89  0.55         0.03      0.64
  18  bicycle           37.69   0.25   0.58  1.07         0.63      0.48
Mean: 42.85
-----------------------------------------------------------------------------------------------------------
this : [epoch 108], [val loss 0.32231], [acc 0.90782], [acc_cls 0.51266], [mean_iu 0.42849], [fwavacc 0.83918]
best : [epoch 106], [val loss 0.31181], [acc 0.90736], [acc_cls 0.51904], [mean_iu 0.43370], [fwavacc 0.84003]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 109], [iter 1 / 176], [train main loss -1.503184], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 2 / 176], [train main loss -1.978730], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 3 / 176], [train main loss -1.629718], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 4 / 176], [train main loss -2.233608], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 5 / 176], [train main loss -1.928238], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 6 / 176], [train main loss -2.140610], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 7 / 176], [train main loss -1.696223], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 8 / 176], [train main loss -1.829837], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 9 / 176], [train main loss -2.085813], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 10 / 176], [train main loss -2.089544], [lr 0.003771] [batchtime 0]
[epoch 109], [iter 11 / 176], [train main loss -2.086827], [lr 0.003771] [batchtime 0.36]
[epoch 109], [iter 12 / 176], [train main loss -2.076764], [lr 0.003771] [batchtime 0.38]
[epoch 109], [iter 13 / 176], [train main loss -2.127988], [lr 0.003771] [batchtime 0.387]
[epoch 109], [iter 14 / 176], [train main loss -1.936132], [lr 0.003771] [batchtime 0.389]
[epoch 109], [iter 15 / 176], [train main loss -1.947747], [lr 0.003771] [batchtime 0.39]
[epoch 109], [iter 16 / 176], [train main loss -2.002935], [lr 0.003771] [batchtime 0.392]
[epoch 109], [iter 17 / 176], [train main loss -1.979778], [lr 0.003771] [batchtime 0.392]
[epoch 109], [iter 18 / 176], [train main loss -1.984192], [lr 0.003771] [batchtime 0.394]
[epoch 109], [iter 19 / 176], [train main loss -1.856442], [lr 0.003771] [batchtime 0.397]
[epoch 109], [iter 20 / 176], [train main loss -1.864492], [lr 0.003771] [batchtime 0.398]
[epoch 109], [iter 21 / 176], [train main loss -1.878282], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 22 / 176], [train main loss -1.889937], [lr 0.003771] [batchtime 0.398]
[epoch 109], [iter 23 / 176], [train main loss -2.069959], [lr 0.003771] [batchtime 0.398]
[epoch 109], [iter 24 / 176], [train main loss -2.037884], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 25 / 176], [train main loss -1.979408], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 26 / 176], [train main loss -2.036894], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 27 / 176], [train main loss -2.004409], [lr 0.003771] [batchtime 0.398]
[epoch 109], [iter 28 / 176], [train main loss -2.012546], [lr 0.003771] [batchtime 0.398]
[epoch 109], [iter 29 / 176], [train main loss -1.917001], [lr 0.003771] [batchtime 0.398]
[epoch 109], [iter 30 / 176], [train main loss -1.847421], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 31 / 176], [train main loss -1.853619], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 32 / 176], [train main loss -1.919565], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 33 / 176], [train main loss -1.903026], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 34 / 176], [train main loss -2.061076], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 35 / 176], [train main loss -1.988097], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 36 / 176], [train main loss -1.940529], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 37 / 176], [train main loss -1.895262], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 38 / 176], [train main loss -1.967174], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 39 / 176], [train main loss -1.894070], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 40 / 176], [train main loss -1.933971], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 41 / 176], [train main loss -1.953036], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 42 / 176], [train main loss -1.968411], [lr 0.003771] [batchtime 0.399]
[epoch 109], [iter 43 / 176], [train main loss -1.996923], [lr 0.003771] [batchtime 0.405]
[epoch 109], [iter 44 / 176], [train main loss -2.017025], [lr 0.003771] [batchtime 0.443]
[epoch 109], [iter 45 / 176], [train main loss -2.001134], [lr 0.003771] [batchtime 0.441]
[epoch 109], [iter 46 / 176], [train main loss -1.963156], [lr 0.003771] [batchtime 0.44]
[epoch 109], [iter 47 / 176], [train main loss -2.009459], [lr 0.003771] [batchtime 0.438]
[epoch 109], [iter 48 / 176], [train main loss -2.018055], [lr 0.003771] [batchtime 0.437]
[epoch 109], [iter 49 / 176], [train main loss -1.967828], [lr 0.003771] [batchtime 0.437]
[epoch 109], [iter 50 / 176], [train main loss -1.995329], [lr 0.003771] [batchtime 0.436]
[epoch 109], [iter 51 / 176], [train main loss -2.045619], [lr 0.003771] [batchtime 0.435]
[epoch 109], [iter 52 / 176], [train main loss -2.035976], [lr 0.003771] [batchtime 0.434]
[epoch 109], [iter 53 / 176], [train main loss -2.077443], [lr 0.003771] [batchtime 0.433]
[epoch 109], [iter 54 / 176], [train main loss -2.116593], [lr 0.003771] [batchtime 0.432]
[epoch 109], [iter 55 / 176], [train main loss -2.169556], [lr 0.003771] [batchtime 0.431]
[epoch 109], [iter 56 / 176], [train main loss -2.181592], [lr 0.003771] [batchtime 0.431]
[epoch 109], [iter 57 / 176], [train main loss -2.220752], [lr 0.003771] [batchtime 0.43]
[epoch 109], [iter 58 / 176], [train main loss -2.225908], [lr 0.003771] [batchtime 0.429]
[epoch 109], [iter 59 / 176], [train main loss -2.175725], [lr 0.003771] [batchtime 0.429]
[epoch 109], [iter 60 / 176], [train main loss -2.223253], [lr 0.003771] [batchtime 0.428]
[epoch 109], [iter 61 / 176], [train main loss -2.228630], [lr 0.003771] [batchtime 0.428]
[epoch 109], [iter 62 / 176], [train main loss -2.224415], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 63 / 176], [train main loss -2.198609], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 64 / 176], [train main loss -2.194853], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 65 / 176], [train main loss -2.181460], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 66 / 176], [train main loss -2.213516], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 67 / 176], [train main loss -2.176736], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 68 / 176], [train main loss -2.158928], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 69 / 176], [train main loss -2.179501], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 70 / 176], [train main loss -2.120343], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 71 / 176], [train main loss -2.125787], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 72 / 176], [train main loss -2.140488], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 73 / 176], [train main loss -2.158135], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 74 / 176], [train main loss -2.126213], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 75 / 176], [train main loss -2.150668], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 76 / 176], [train main loss -2.184293], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 77 / 176], [train main loss -2.196176], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 78 / 176], [train main loss -2.204870], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 79 / 176], [train main loss -2.177715], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 80 / 176], [train main loss -2.198959], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 81 / 176], [train main loss -2.220835], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 82 / 176], [train main loss -2.221764], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 83 / 176], [train main loss -2.235360], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 84 / 176], [train main loss -2.306775], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 85 / 176], [train main loss -2.297715], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 86 / 176], [train main loss -2.281584], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 87 / 176], [train main loss -2.255614], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 88 / 176], [train main loss -2.234320], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 89 / 176], [train main loss -2.223980], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 90 / 176], [train main loss -2.194953], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 91 / 176], [train main loss -2.196177], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 92 / 176], [train main loss -2.178142], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 93 / 176], [train main loss -2.184232], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 94 / 176], [train main loss -2.188730], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 95 / 176], [train main loss -2.169995], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 96 / 176], [train main loss -2.182274], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 97 / 176], [train main loss -2.186617], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 98 / 176], [train main loss -2.179865], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 99 / 176], [train main loss -2.175052], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 100 / 176], [train main loss -2.149448], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 101 / 176], [train main loss -2.133760], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 102 / 176], [train main loss -2.133481], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 103 / 176], [train main loss -2.128820], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 104 / 176], [train main loss -2.105138], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 105 / 176], [train main loss -2.106103], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 106 / 176], [train main loss -2.099977], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 107 / 176], [train main loss -2.096885], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 108 / 176], [train main loss -2.123183], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 109 / 176], [train main loss -2.146241], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 110 / 176], [train main loss -2.142191], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 111 / 176], [train main loss -2.139218], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 112 / 176], [train main loss -2.152678], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 113 / 176], [train main loss -2.175835], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 114 / 176], [train main loss -2.168894], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 115 / 176], [train main loss -2.175479], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 116 / 176], [train main loss -2.155153], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 117 / 176], [train main loss -2.162674], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 118 / 176], [train main loss -2.147356], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 119 / 176], [train main loss -2.136702], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 120 / 176], [train main loss -2.098620], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 121 / 176], [train main loss -2.097148], [lr 0.003771] [batchtime 0.42]
[epoch 109], [iter 122 / 176], [train main loss -2.102608], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 123 / 176], [train main loss -2.081496], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 124 / 176], [train main loss -2.097362], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 125 / 176], [train main loss -2.090144], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 126 / 176], [train main loss -2.078571], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 127 / 176], [train main loss -2.079064], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 128 / 176], [train main loss -2.050128], [lr 0.003771] [batchtime 0.419]
[epoch 109], [iter 129 / 176], [train main loss -2.052846], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 130 / 176], [train main loss -2.046176], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 131 / 176], [train main loss -2.050559], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 132 / 176], [train main loss -2.061277], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 133 / 176], [train main loss -2.075147], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 134 / 176], [train main loss -2.065856], [lr 0.003771] [batchtime 0.417]
[epoch 109], [iter 135 / 176], [train main loss -2.066684], [lr 0.003771] [batchtime 0.417]
[epoch 109], [iter 136 / 176], [train main loss -2.061380], [lr 0.003771] [batchtime 0.417]
[epoch 109], [iter 137 / 176], [train main loss -2.042023], [lr 0.003771] [batchtime 0.417]
[epoch 109], [iter 138 / 176], [train main loss -2.041324], [lr 0.003771] [batchtime 0.418]
[epoch 109], [iter 139 / 176], [train main loss -2.023635], [lr 0.003771] [batchtime 0.428]
[epoch 109], [iter 140 / 176], [train main loss -2.054714], [lr 0.003771] [batchtime 0.428]
[epoch 109], [iter 141 / 176], [train main loss -2.082108], [lr 0.003771] [batchtime 0.428]
[epoch 109], [iter 142 / 176], [train main loss -2.074182], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 143 / 176], [train main loss -2.067434], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 144 / 176], [train main loss -2.067394], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 145 / 176], [train main loss -2.076590], [lr 0.003771] [batchtime 0.427]
[epoch 109], [iter 146 / 176], [train main loss -2.069818], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 147 / 176], [train main loss -2.065980], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 148 / 176], [train main loss -2.060916], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 149 / 176], [train main loss -2.058994], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 150 / 176], [train main loss -2.057466], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 151 / 176], [train main loss -2.064963], [lr 0.003771] [batchtime 0.426]
[epoch 109], [iter 152 / 176], [train main loss -2.065687], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 153 / 176], [train main loss -2.070825], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 154 / 176], [train main loss -2.082633], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 155 / 176], [train main loss -2.075649], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 156 / 176], [train main loss -2.077156], [lr 0.003771] [batchtime 0.425]
[epoch 109], [iter 157 / 176], [train main loss -2.073343], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 158 / 176], [train main loss -2.067182], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 159 / 176], [train main loss -2.068043], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 160 / 176], [train main loss -2.062965], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 161 / 176], [train main loss -2.073755], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 162 / 176], [train main loss -2.070254], [lr 0.003771] [batchtime 0.424]
[epoch 109], [iter 163 / 176], [train main loss -2.071811], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 164 / 176], [train main loss -2.071625], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 165 / 176], [train main loss -2.071822], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 166 / 176], [train main loss -2.078557], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 167 / 176], [train main loss -2.078468], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 168 / 176], [train main loss -2.073371], [lr 0.003771] [batchtime 0.423]
[epoch 109], [iter 169 / 176], [train main loss -2.078994], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 170 / 176], [train main loss -2.067667], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 171 / 176], [train main loss -2.089937], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 172 / 176], [train main loss -2.074769], [lr 0.003771] [batchtime 0.422]
[epoch 109], [iter 173 / 176], [train main loss -2.089762], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 174 / 176], [train main loss -2.088726], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 175 / 176], [train main loss -2.092660], [lr 0.003771] [batchtime 0.421]
[epoch 109], [iter 176 / 176], [train main loss -2.078576], [lr 0.003771] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.83  35.53    0.02  0.03         0.98      0.97
   1  sidewalk          69.99   5.40    0.22  0.21         0.82      0.83
   2  building          85.80  25.17    0.06  0.11         0.95      0.90
   3  wall              15.95   0.12    4.02  1.25         0.20      0.44
   4  fence             23.57   0.35    2.68  0.57         0.27      0.64
   5  pole              37.62   0.53    1.16  0.50         0.46      0.67
   6  traffic light     14.53   0.02    5.50  0.39         0.15      0.72
   7  traffic sign      18.74   0.11    4.15  0.19         0.19      0.84
   8  vegetation        83.33  11.64    0.06  0.14         0.94      0.88
   9  terrain           39.89   0.37    0.97  0.54         0.51      0.65
  10  sky               93.69   3.71    0.04  0.02         0.96      0.98
  11  person            51.77   0.98    0.56  0.37         0.64      0.73
  12  rider              8.70   0.01    9.54  0.96         0.09      0.51
  13  car               86.25   6.63    0.07  0.09         0.94      0.92
  14  truck              0.87   0.00  113.57  0.54         0.01      0.65
  15  bus               16.51   0.04    1.23  3.83         0.45      0.21
  16  train             38.31   0.08    1.29  0.32         0.44      0.76
  17  motorcycle         2.94   0.00   32.63  0.41         0.03      0.71
  18  bicycle           35.72   0.27    0.43  1.37         0.70      0.42
Mean: 43.11
-----------------------------------------------------------------------------------------------------------
this : [epoch 109], [val loss 0.32288], [acc 0.90955], [acc_cls 0.51217], [mean_iu 0.43106], [fwavacc 0.84202]
best : [epoch 106], [val loss 0.31181], [acc 0.90736], [acc_cls 0.51904], [mean_iu 0.43370], [fwavacc 0.84003]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 110], [iter 1 / 176], [train main loss -1.049366], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 2 / 176], [train main loss -2.390839], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 3 / 176], [train main loss -2.619298], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 4 / 176], [train main loss -2.603602], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 5 / 176], [train main loss -2.732031], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 6 / 176], [train main loss -2.340844], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 7 / 176], [train main loss -2.279488], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 8 / 176], [train main loss -2.545828], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 9 / 176], [train main loss -2.792468], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 10 / 176], [train main loss -3.053324], [lr 0.003714] [batchtime 0]
[epoch 110], [iter 11 / 176], [train main loss -2.802352], [lr 0.003714] [batchtime 0.367]
[epoch 110], [iter 12 / 176], [train main loss -2.815531], [lr 0.003714] [batchtime 0.387]
[epoch 110], [iter 13 / 176], [train main loss -2.816100], [lr 0.003714] [batchtime 0.395]
[epoch 110], [iter 14 / 176], [train main loss -2.591506], [lr 0.003714] [batchtime 0.394]
[epoch 110], [iter 15 / 176], [train main loss -2.332372], [lr 0.003714] [batchtime 0.399]
[epoch 110], [iter 16 / 176], [train main loss -2.460461], [lr 0.003714] [batchtime 0.398]
[epoch 110], [iter 17 / 176], [train main loss -2.397970], [lr 0.003714] [batchtime 0.4]
[epoch 110], [iter 18 / 176], [train main loss -2.443868], [lr 0.003714] [batchtime 0.401]
[epoch 110], [iter 19 / 176], [train main loss -2.381969], [lr 0.003714] [batchtime 0.402]
[epoch 110], [iter 20 / 176], [train main loss -2.425785], [lr 0.003714] [batchtime 0.401]
[epoch 110], [iter 21 / 176], [train main loss -2.504825], [lr 0.003714] [batchtime 0.404]
[epoch 110], [iter 22 / 176], [train main loss -2.489130], [lr 0.003714] [batchtime 0.404]
[epoch 110], [iter 23 / 176], [train main loss -2.479871], [lr 0.003714] [batchtime 0.403]
[epoch 110], [iter 24 / 176], [train main loss -2.523743], [lr 0.003714] [batchtime 0.404]
[epoch 110], [iter 25 / 176], [train main loss -2.394764], [lr 0.003714] [batchtime 0.404]
[epoch 110], [iter 26 / 176], [train main loss -2.248142], [lr 0.003714] [batchtime 0.405]
[epoch 110], [iter 27 / 176], [train main loss -2.186433], [lr 0.003714] [batchtime 0.405]
[epoch 110], [iter 28 / 176], [train main loss -2.196337], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 29 / 176], [train main loss -2.256192], [lr 0.003714] [batchtime 0.407]
[epoch 110], [iter 30 / 176], [train main loss -2.315240], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 31 / 176], [train main loss -2.239330], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 32 / 176], [train main loss -2.190909], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 33 / 176], [train main loss -2.224226], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 34 / 176], [train main loss -2.283262], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 35 / 176], [train main loss -2.243720], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 36 / 176], [train main loss -2.204816], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 37 / 176], [train main loss -2.226275], [lr 0.003714] [batchtime 0.405]
[epoch 110], [iter 38 / 176], [train main loss -2.281857], [lr 0.003714] [batchtime 0.405]
[epoch 110], [iter 39 / 176], [train main loss -2.229646], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 40 / 176], [train main loss -2.304493], [lr 0.003714] [batchtime 0.406]
[epoch 110], [iter 41 / 176], [train main loss -2.254414], [lr 0.003714] [batchtime 0.443]
[epoch 110], [iter 42 / 176], [train main loss -2.297382], [lr 0.003714] [batchtime 0.446]
[epoch 110], [iter 43 / 176], [train main loss -2.367601], [lr 0.003714] [batchtime 0.445]
[epoch 110], [iter 44 / 176], [train main loss -2.358908], [lr 0.003714] [batchtime 0.443]
[epoch 110], [iter 45 / 176], [train main loss -2.335963], [lr 0.003714] [batchtime 0.442]
[epoch 110], [iter 46 / 176], [train main loss -2.410955], [lr 0.003714] [batchtime 0.441]
[epoch 110], [iter 47 / 176], [train main loss -2.425587], [lr 0.003714] [batchtime 0.44]
[epoch 110], [iter 48 / 176], [train main loss -2.473304], [lr 0.003714] [batchtime 0.439]
[epoch 110], [iter 49 / 176], [train main loss -2.445107], [lr 0.003714] [batchtime 0.438]
[epoch 110], [iter 50 / 176], [train main loss -2.453383], [lr 0.003714] [batchtime 0.438]
[epoch 110], [iter 51 / 176], [train main loss -2.442332], [lr 0.003714] [batchtime 0.437]
[epoch 110], [iter 52 / 176], [train main loss -2.440197], [lr 0.003714] [batchtime 0.436]
[epoch 110], [iter 53 / 176], [train main loss -2.400695], [lr 0.003714] [batchtime 0.435]
[epoch 110], [iter 54 / 176], [train main loss -2.397374], [lr 0.003714] [batchtime 0.434]
[epoch 110], [iter 55 / 176], [train main loss -2.464460], [lr 0.003714] [batchtime 0.433]
[epoch 110], [iter 56 / 176], [train main loss -2.438107], [lr 0.003714] [batchtime 0.433]
[epoch 110], [iter 57 / 176], [train main loss -2.409568], [lr 0.003714] [batchtime 0.432]
[epoch 110], [iter 58 / 176], [train main loss -2.404692], [lr 0.003714] [batchtime 0.432]
[epoch 110], [iter 59 / 176], [train main loss -2.350719], [lr 0.003714] [batchtime 0.431]
[epoch 110], [iter 60 / 176], [train main loss -2.342477], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 61 / 176], [train main loss -2.306939], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 62 / 176], [train main loss -2.331477], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 63 / 176], [train main loss -2.338345], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 64 / 176], [train main loss -2.327359], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 65 / 176], [train main loss -2.337572], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 66 / 176], [train main loss -2.360896], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 67 / 176], [train main loss -2.348740], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 68 / 176], [train main loss -2.350349], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 69 / 176], [train main loss -2.329596], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 70 / 176], [train main loss -2.322077], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 71 / 176], [train main loss -2.285239], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 72 / 176], [train main loss -2.263538], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 73 / 176], [train main loss -2.267281], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 74 / 176], [train main loss -2.236874], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 75 / 176], [train main loss -2.206129], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 76 / 176], [train main loss -2.184493], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 77 / 176], [train main loss -2.177384], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 78 / 176], [train main loss -2.190906], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 79 / 176], [train main loss -2.190915], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 80 / 176], [train main loss -2.177124], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 81 / 176], [train main loss -2.145297], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 82 / 176], [train main loss -2.166434], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 83 / 176], [train main loss -2.131699], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 84 / 176], [train main loss -2.119399], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 85 / 176], [train main loss -2.110088], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 86 / 176], [train main loss -2.108704], [lr 0.003714] [batchtime 0.419]
[epoch 110], [iter 87 / 176], [train main loss -2.130420], [lr 0.003714] [batchtime 0.419]
[epoch 110], [iter 88 / 176], [train main loss -2.118823], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 89 / 176], [train main loss -2.108180], [lr 0.003714] [batchtime 0.431]
[epoch 110], [iter 90 / 176], [train main loss -2.118696], [lr 0.003714] [batchtime 0.431]
[epoch 110], [iter 91 / 176], [train main loss -2.118524], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 92 / 176], [train main loss -2.113300], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 93 / 176], [train main loss -2.124644], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 94 / 176], [train main loss -2.152678], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 95 / 176], [train main loss -2.142016], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 96 / 176], [train main loss -2.154318], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 97 / 176], [train main loss -2.156149], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 98 / 176], [train main loss -2.175069], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 99 / 176], [train main loss -2.183959], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 100 / 176], [train main loss -2.197629], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 101 / 176], [train main loss -2.199333], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 102 / 176], [train main loss -2.199792], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 103 / 176], [train main loss -2.210900], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 104 / 176], [train main loss -2.233450], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 105 / 176], [train main loss -2.239863], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 106 / 176], [train main loss -2.251712], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 107 / 176], [train main loss -2.229448], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 108 / 176], [train main loss -2.210914], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 109 / 176], [train main loss -2.210390], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 110 / 176], [train main loss -2.214158], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 111 / 176], [train main loss -2.212326], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 112 / 176], [train main loss -2.197443], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 113 / 176], [train main loss -2.185624], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 114 / 176], [train main loss -2.169978], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 115 / 176], [train main loss -2.190087], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 116 / 176], [train main loss -2.197664], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 117 / 176], [train main loss -2.174260], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 118 / 176], [train main loss -2.183743], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 119 / 176], [train main loss -2.168594], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 120 / 176], [train main loss -2.177704], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 121 / 176], [train main loss -2.171086], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 122 / 176], [train main loss -2.172266], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 123 / 176], [train main loss -2.159802], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 124 / 176], [train main loss -2.174185], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 125 / 176], [train main loss -2.169147], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 126 / 176], [train main loss -2.182409], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 127 / 176], [train main loss -2.153616], [lr 0.003714] [batchtime 0.421]
[epoch 110], [iter 128 / 176], [train main loss -2.151908], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 129 / 176], [train main loss -2.147683], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 130 / 176], [train main loss -2.140868], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 131 / 176], [train main loss -2.110206], [lr 0.003714] [batchtime 0.42]
[epoch 110], [iter 132 / 176], [train main loss -2.116347], [lr 0.003714] [batchtime 0.419]
[epoch 110], [iter 133 / 176], [train main loss -2.114499], [lr 0.003714] [batchtime 0.419]
[epoch 110], [iter 134 / 176], [train main loss -2.129709], [lr 0.003714] [batchtime 0.419]
[epoch 110], [iter 135 / 176], [train main loss -2.140089], [lr 0.003714] [batchtime 0.419]
[epoch 110], [iter 136 / 176], [train main loss -2.133394], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 137 / 176], [train main loss -2.145224], [lr 0.003714] [batchtime 0.431]
[epoch 110], [iter 138 / 176], [train main loss -2.140372], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 139 / 176], [train main loss -2.144799], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 140 / 176], [train main loss -2.135325], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 141 / 176], [train main loss -2.126503], [lr 0.003714] [batchtime 0.43]
[epoch 110], [iter 142 / 176], [train main loss -2.113497], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 143 / 176], [train main loss -2.107540], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 144 / 176], [train main loss -2.107734], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 145 / 176], [train main loss -2.107444], [lr 0.003714] [batchtime 0.429]
[epoch 110], [iter 146 / 176], [train main loss -2.090108], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 147 / 176], [train main loss -2.100944], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 148 / 176], [train main loss -2.130150], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 149 / 176], [train main loss -2.125261], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 150 / 176], [train main loss -2.109721], [lr 0.003714] [batchtime 0.428]
[epoch 110], [iter 151 / 176], [train main loss -2.128772], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 152 / 176], [train main loss -2.129374], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 153 / 176], [train main loss -2.134569], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 154 / 176], [train main loss -2.122941], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 155 / 176], [train main loss -2.124240], [lr 0.003714] [batchtime 0.427]
[epoch 110], [iter 156 / 176], [train main loss -2.123674], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 157 / 176], [train main loss -2.125619], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 158 / 176], [train main loss -2.132963], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 159 / 176], [train main loss -2.109845], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 160 / 176], [train main loss -2.125982], [lr 0.003714] [batchtime 0.426]
[epoch 110], [iter 161 / 176], [train main loss -2.118276], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 162 / 176], [train main loss -2.119242], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 163 / 176], [train main loss -2.115601], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 164 / 176], [train main loss -2.103069], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 165 / 176], [train main loss -2.098685], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 166 / 176], [train main loss -2.093436], [lr 0.003714] [batchtime 0.425]
[epoch 110], [iter 167 / 176], [train main loss -2.072265], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 168 / 176], [train main loss -2.071858], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 169 / 176], [train main loss -2.072524], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 170 / 176], [train main loss -2.075110], [lr 0.003714] [batchtime 0.424]
[epoch 110], [iter 171 / 176], [train main loss -2.087713], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 172 / 176], [train main loss -2.077427], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 173 / 176], [train main loss -2.085160], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 174 / 176], [train main loss -2.086250], [lr 0.003714] [batchtime 0.423]
[epoch 110], [iter 175 / 176], [train main loss -2.084448], [lr 0.003714] [batchtime 0.422]
[epoch 110], [iter 176 / 176], [train main loss -2.077967], [lr 0.003714] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.47  35.52    0.02  0.03         0.98      0.97
   1  sidewalk          68.74   5.23    0.26  0.19         0.79      0.84
   2  building          86.12  24.97    0.06  0.10         0.94      0.91
   3  wall              19.21   0.18    2.33  1.88         0.30      0.35
   4  fence             26.98   0.46    1.76  0.95         0.36      0.51
   5  pole              38.28   0.56    1.04  0.57         0.49      0.64
   6  traffic light     14.67   0.02    5.34  0.48         0.16      0.68
   7  traffic sign      21.82   0.13    3.30  0.28         0.23      0.78
   8  vegetation        84.02  11.53    0.07  0.12         0.93      0.89
   9  terrain           41.30   0.42    0.76  0.66         0.57      0.60
  10  sky               93.34   3.76    0.03  0.04         0.97      0.96
  11  person            52.16   0.98    0.56  0.36         0.64      0.74
  12  rider              5.60   0.01   15.97  0.88         0.06      0.53
  13  car               85.18   6.63    0.07  0.11         0.94      0.90
  14  truck              0.83   0.00  118.39  0.62         0.01      0.62
  15  bus               13.76   0.05    0.83  5.44         0.55      0.16
  16  train             28.50   0.07    1.71  0.80         0.37      0.55
  17  motorcycle         3.11   0.00   30.80  0.36         0.03      0.74
  18  bicycle           38.19   0.25    0.57  1.05         0.64      0.49
Mean: 42.96
-----------------------------------------------------------------------------------------------------------
this : [epoch 110], [val loss 0.31369], [acc 0.90763], [acc_cls 0.52388], [mean_iu 0.42962], [fwavacc 0.84160]
best : [epoch 106], [val loss 0.31181], [acc 0.90736], [acc_cls 0.51904], [mean_iu 0.43370], [fwavacc 0.84003]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 111], [iter 1 / 176], [train main loss -5.633644], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 2 / 176], [train main loss -4.056670], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 3 / 176], [train main loss -4.301378], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 4 / 176], [train main loss -3.858665], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 5 / 176], [train main loss -3.121438], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 6 / 176], [train main loss -2.967400], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 7 / 176], [train main loss -3.052084], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 8 / 176], [train main loss -2.879104], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 9 / 176], [train main loss -2.597383], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 10 / 176], [train main loss -2.531233], [lr 0.003657] [batchtime 0]
[epoch 111], [iter 11 / 176], [train main loss -2.503439], [lr 0.003657] [batchtime 0.364]
[epoch 111], [iter 12 / 176], [train main loss -2.464309], [lr 0.003657] [batchtime 0.382]
[epoch 111], [iter 13 / 176], [train main loss -2.492160], [lr 0.003657] [batchtime 0.389]
[epoch 111], [iter 14 / 176], [train main loss -2.420986], [lr 0.003657] [batchtime 0.391]
[epoch 111], [iter 15 / 176], [train main loss -2.427177], [lr 0.003657] [batchtime 0.394]
[epoch 111], [iter 16 / 176], [train main loss -2.473113], [lr 0.003657] [batchtime 0.394]
[epoch 111], [iter 17 / 176], [train main loss -2.428300], [lr 0.003657] [batchtime 0.395]
[epoch 111], [iter 18 / 176], [train main loss -2.427039], [lr 0.003657] [batchtime 0.395]
[epoch 111], [iter 19 / 176], [train main loss -2.386121], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 20 / 176], [train main loss -2.448701], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 21 / 176], [train main loss -2.338935], [lr 0.003657] [batchtime 0.395]
[epoch 111], [iter 22 / 176], [train main loss -2.367269], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 23 / 176], [train main loss -2.378492], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 24 / 176], [train main loss -2.345830], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 25 / 176], [train main loss -2.303353], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 26 / 176], [train main loss -2.299860], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 27 / 176], [train main loss -2.318655], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 28 / 176], [train main loss -2.352245], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 29 / 176], [train main loss -2.402939], [lr 0.003657] [batchtime 0.397]
[epoch 111], [iter 30 / 176], [train main loss -2.490891], [lr 0.003657] [batchtime 0.397]
[epoch 111], [iter 31 / 176], [train main loss -2.620261], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 32 / 176], [train main loss -2.502262], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 33 / 176], [train main loss -2.478119], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 34 / 176], [train main loss -2.445284], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 35 / 176], [train main loss -2.515052], [lr 0.003657] [batchtime 0.396]
[epoch 111], [iter 36 / 176], [train main loss -2.487223], [lr 0.003657] [batchtime 0.397]
[epoch 111], [iter 37 / 176], [train main loss -2.417562], [lr 0.003657] [batchtime 0.397]
[epoch 111], [iter 38 / 176], [train main loss -2.362933], [lr 0.003657] [batchtime 0.397]
[epoch 111], [iter 39 / 176], [train main loss -2.401142], [lr 0.003657] [batchtime 0.397]
[epoch 111], [iter 40 / 176], [train main loss -2.378870], [lr 0.003657] [batchtime 0.403]
[epoch 111], [iter 41 / 176], [train main loss -2.359875], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 42 / 176], [train main loss -2.360730], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 43 / 176], [train main loss -2.346936], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 44 / 176], [train main loss -2.406278], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 45 / 176], [train main loss -2.417555], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 46 / 176], [train main loss -2.400875], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 47 / 176], [train main loss -2.371919], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 48 / 176], [train main loss -2.355060], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 49 / 176], [train main loss -2.392394], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 50 / 176], [train main loss -2.406829], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 51 / 176], [train main loss -2.362343], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 52 / 176], [train main loss -2.331999], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 53 / 176], [train main loss -2.367011], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 54 / 176], [train main loss -2.332904], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 55 / 176], [train main loss -2.331199], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 56 / 176], [train main loss -2.322664], [lr 0.003657] [batchtime 0.416]
[epoch 111], [iter 57 / 176], [train main loss -2.312424], [lr 0.003657] [batchtime 0.416]
[epoch 111], [iter 58 / 176], [train main loss -2.295342], [lr 0.003657] [batchtime 0.416]
[epoch 111], [iter 59 / 176], [train main loss -2.291051], [lr 0.003657] [batchtime 0.416]
[epoch 111], [iter 60 / 176], [train main loss -2.253241], [lr 0.003657] [batchtime 0.415]
[epoch 111], [iter 61 / 176], [train main loss -2.248200], [lr 0.003657] [batchtime 0.415]
[epoch 111], [iter 62 / 176], [train main loss -2.262657], [lr 0.003657] [batchtime 0.414]
[epoch 111], [iter 63 / 176], [train main loss -2.231824], [lr 0.003657] [batchtime 0.414]
[epoch 111], [iter 64 / 176], [train main loss -2.268249], [lr 0.003657] [batchtime 0.414]
[epoch 111], [iter 65 / 176], [train main loss -2.268578], [lr 0.003657] [batchtime 0.413]
[epoch 111], [iter 66 / 176], [train main loss -2.276863], [lr 0.003657] [batchtime 0.413]
[epoch 111], [iter 67 / 176], [train main loss -2.240087], [lr 0.003657] [batchtime 0.413]
[epoch 111], [iter 68 / 176], [train main loss -2.239708], [lr 0.003657] [batchtime 0.413]
[epoch 111], [iter 69 / 176], [train main loss -2.242159], [lr 0.003657] [batchtime 0.412]
[epoch 111], [iter 70 / 176], [train main loss -2.237207], [lr 0.003657] [batchtime 0.412]
[epoch 111], [iter 71 / 176], [train main loss -2.219862], [lr 0.003657] [batchtime 0.412]
[epoch 111], [iter 72 / 176], [train main loss -2.188982], [lr 0.003657] [batchtime 0.412]
[epoch 111], [iter 73 / 176], [train main loss -2.149215], [lr 0.003657] [batchtime 0.411]
[epoch 111], [iter 74 / 176], [train main loss -2.149295], [lr 0.003657] [batchtime 0.411]
[epoch 111], [iter 75 / 176], [train main loss -2.126217], [lr 0.003657] [batchtime 0.411]
[epoch 111], [iter 76 / 176], [train main loss -2.153687], [lr 0.003657] [batchtime 0.41]
[epoch 111], [iter 77 / 176], [train main loss -2.176951], [lr 0.003657] [batchtime 0.41]
[epoch 111], [iter 78 / 176], [train main loss -2.165786], [lr 0.003657] [batchtime 0.41]
[epoch 111], [iter 79 / 176], [train main loss -2.150145], [lr 0.003657] [batchtime 0.41]
[epoch 111], [iter 80 / 176], [train main loss -2.155013], [lr 0.003657] [batchtime 0.409]
[epoch 111], [iter 81 / 176], [train main loss -2.171258], [lr 0.003657] [batchtime 0.409]
[epoch 111], [iter 82 / 176], [train main loss -2.187434], [lr 0.003657] [batchtime 0.409]
[epoch 111], [iter 83 / 176], [train main loss -2.185423], [lr 0.003657] [batchtime 0.409]
[epoch 111], [iter 84 / 176], [train main loss -2.195978], [lr 0.003657] [batchtime 0.409]
[epoch 111], [iter 85 / 176], [train main loss -2.194319], [lr 0.003657] [batchtime 0.409]
[epoch 111], [iter 86 / 176], [train main loss -2.183438], [lr 0.003657] [batchtime 0.408]
[epoch 111], [iter 87 / 176], [train main loss -2.207346], [lr 0.003657] [batchtime 0.408]
[epoch 111], [iter 88 / 176], [train main loss -2.199634], [lr 0.003657] [batchtime 0.408]
[epoch 111], [iter 89 / 176], [train main loss -2.205696], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 90 / 176], [train main loss -2.207970], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 91 / 176], [train main loss -2.221979], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 92 / 176], [train main loss -2.219801], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 93 / 176], [train main loss -2.206243], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 94 / 176], [train main loss -2.209415], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 95 / 176], [train main loss -2.195163], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 96 / 176], [train main loss -2.192424], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 97 / 176], [train main loss -2.183690], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 98 / 176], [train main loss -2.187438], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 99 / 176], [train main loss -2.196027], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 100 / 176], [train main loss -2.197440], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 101 / 176], [train main loss -2.214844], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 102 / 176], [train main loss -2.234688], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 103 / 176], [train main loss -2.242698], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 104 / 176], [train main loss -2.228839], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 105 / 176], [train main loss -2.209061], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 106 / 176], [train main loss -2.178747], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 107 / 176], [train main loss -2.187445], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 108 / 176], [train main loss -2.204347], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 109 / 176], [train main loss -2.192202], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 110 / 176], [train main loss -2.165247], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 111 / 176], [train main loss -2.190158], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 112 / 176], [train main loss -2.167909], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 113 / 176], [train main loss -2.171361], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 114 / 176], [train main loss -2.153089], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 115 / 176], [train main loss -2.184144], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 116 / 176], [train main loss -2.220789], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 117 / 176], [train main loss -2.207658], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 118 / 176], [train main loss -2.212855], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 119 / 176], [train main loss -2.232212], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 120 / 176], [train main loss -2.227294], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 121 / 176], [train main loss -2.231439], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 122 / 176], [train main loss -2.231387], [lr 0.003657] [batchtime 0.419]
[epoch 111], [iter 123 / 176], [train main loss -2.238179], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 124 / 176], [train main loss -2.209971], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 125 / 176], [train main loss -2.192320], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 126 / 176], [train main loss -2.172525], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 127 / 176], [train main loss -2.180069], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 128 / 176], [train main loss -2.186280], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 129 / 176], [train main loss -2.183426], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 130 / 176], [train main loss -2.197348], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 131 / 176], [train main loss -2.196060], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 132 / 176], [train main loss -2.195717], [lr 0.003657] [batchtime 0.417]
[epoch 111], [iter 133 / 176], [train main loss -2.212213], [lr 0.003657] [batchtime 0.416]
[epoch 111], [iter 134 / 176], [train main loss -2.211014], [lr 0.003657] [batchtime 0.416]
[epoch 111], [iter 135 / 176], [train main loss -2.215760], [lr 0.003657] [batchtime 0.418]
[epoch 111], [iter 136 / 176], [train main loss -2.220674], [lr 0.003657] [batchtime 0.429]
[epoch 111], [iter 137 / 176], [train main loss -2.207889], [lr 0.003657] [batchtime 0.428]
[epoch 111], [iter 138 / 176], [train main loss -2.192020], [lr 0.003657] [batchtime 0.428]
[epoch 111], [iter 139 / 176], [train main loss -2.194186], [lr 0.003657] [batchtime 0.428]
[epoch 111], [iter 140 / 176], [train main loss -2.215883], [lr 0.003657] [batchtime 0.427]
[epoch 111], [iter 141 / 176], [train main loss -2.230635], [lr 0.003657] [batchtime 0.427]
[epoch 111], [iter 142 / 176], [train main loss -2.224860], [lr 0.003657] [batchtime 0.427]
[epoch 111], [iter 143 / 176], [train main loss -2.223340], [lr 0.003657] [batchtime 0.427]
[epoch 111], [iter 144 / 176], [train main loss -2.219590], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 145 / 176], [train main loss -2.205968], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 146 / 176], [train main loss -2.204481], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 147 / 176], [train main loss -2.199555], [lr 0.003657] [batchtime 0.426]
[epoch 111], [iter 148 / 176], [train main loss -2.198464], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 149 / 176], [train main loss -2.200289], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 150 / 176], [train main loss -2.207197], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 151 / 176], [train main loss -2.187572], [lr 0.003657] [batchtime 0.425]
[epoch 111], [iter 152 / 176], [train main loss -2.207482], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 153 / 176], [train main loss -2.191026], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 154 / 176], [train main loss -2.172107], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 155 / 176], [train main loss -2.170174], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 156 / 176], [train main loss -2.158533], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 157 / 176], [train main loss -2.138294], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 158 / 176], [train main loss -2.133724], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 159 / 176], [train main loss -2.133267], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 160 / 176], [train main loss -2.146222], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 161 / 176], [train main loss -2.149502], [lr 0.003657] [batchtime 0.424]
[epoch 111], [iter 162 / 176], [train main loss -2.151467], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 163 / 176], [train main loss -2.164801], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 164 / 176], [train main loss -2.163499], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 165 / 176], [train main loss -2.182560], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 166 / 176], [train main loss -2.190419], [lr 0.003657] [batchtime 0.423]
[epoch 111], [iter 167 / 176], [train main loss -2.193444], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 168 / 176], [train main loss -2.187820], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 169 / 176], [train main loss -2.185669], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 170 / 176], [train main loss -2.186493], [lr 0.003657] [batchtime 0.422]
[epoch 111], [iter 171 / 176], [train main loss -2.197647], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 172 / 176], [train main loss -2.205287], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 173 / 176], [train main loss -2.183803], [lr 0.003657] [batchtime 0.421]
[epoch 111], [iter 174 / 176], [train main loss -2.189561], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 175 / 176], [train main loss -2.187808], [lr 0.003657] [batchtime 0.42]
[epoch 111], [iter 176 / 176], [train main loss -2.169093], [lr 0.003657] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.33  35.29   0.03  0.03         0.97      0.97
   1  sidewalk          68.40   5.48   0.20  0.26         0.83      0.79
   2  building          85.94  25.31   0.05  0.11         0.95      0.90
   3  wall              18.28   0.14   3.22  1.25         0.24      0.44
   4  fence             24.21   0.36   2.55  0.58         0.28      0.63
   5  pole              38.53   0.56   1.01  0.58         0.50      0.63
   6  traffic light     15.20   0.03   4.89  0.69         0.17      0.59
   7  traffic sign      20.52   0.12   3.64  0.23         0.22      0.81
   8  vegetation        84.05  11.47   0.08  0.11         0.93      0.90
   9  terrain           37.42   0.33   1.21  0.46         0.45      0.68
  10  sky               93.74   3.74   0.04  0.03         0.97      0.97
  11  person            49.88   0.91   0.68  0.33         0.60      0.75
  12  rider              9.75   0.01   8.17  1.08         0.11      0.48
  13  car               85.60   6.66   0.06  0.11         0.94      0.90
  14  truck              1.95   0.01  49.55  0.83         0.02      0.55
  15  bus               16.88   0.04   1.02  3.90         0.49      0.20
  16  train             39.18   0.09   1.02  0.53         0.50      0.65
  17  motorcycle         3.72   0.00  25.23  0.62         0.04      0.62
  18  bicycle           37.27   0.25   0.53  1.15         0.65      0.47
Mean: 43.41
-----------------------------------------------------------------------------------------------------------
this : [epoch 111], [val loss 0.31590], [acc 0.90812], [acc_cls 0.51829], [mean_iu 0.43413], [fwavacc 0.84006]
best : [epoch 111], [val loss 0.31590], [acc 0.90812], [acc_cls 0.51829], [mean_iu 0.43413], [fwavacc 0.84006]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 112], [iter 1 / 176], [train main loss -6.090794], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 2 / 176], [train main loss -3.613560], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 3 / 176], [train main loss -2.652449], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 4 / 176], [train main loss -1.797394], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 5 / 176], [train main loss -2.270738], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 6 / 176], [train main loss -2.262808], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 7 / 176], [train main loss -2.126212], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 8 / 176], [train main loss -2.173942], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 9 / 176], [train main loss -1.973865], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 10 / 176], [train main loss -2.083360], [lr 0.003600] [batchtime 0]
[epoch 112], [iter 11 / 176], [train main loss -2.083051], [lr 0.003600] [batchtime 0.362]
[epoch 112], [iter 12 / 176], [train main loss -1.989714], [lr 0.003600] [batchtime 0.378]
[epoch 112], [iter 13 / 176], [train main loss -2.035420], [lr 0.003600] [batchtime 0.385]
[epoch 112], [iter 14 / 176], [train main loss -2.158530], [lr 0.003600] [batchtime 0.389]
[epoch 112], [iter 15 / 176], [train main loss -2.209037], [lr 0.003600] [batchtime 0.391]
[epoch 112], [iter 16 / 176], [train main loss -2.058057], [lr 0.003600] [batchtime 0.393]
[epoch 112], [iter 17 / 176], [train main loss -2.021696], [lr 0.003600] [batchtime 0.393]
[epoch 112], [iter 18 / 176], [train main loss -1.967084], [lr 0.003600] [batchtime 0.393]
[epoch 112], [iter 19 / 176], [train main loss -2.166766], [lr 0.003600] [batchtime 0.394]
[epoch 112], [iter 20 / 176], [train main loss -2.148818], [lr 0.003600] [batchtime 0.394]
[epoch 112], [iter 21 / 176], [train main loss -2.110712], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 22 / 176], [train main loss -2.272999], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 23 / 176], [train main loss -2.207275], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 24 / 176], [train main loss -2.298110], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 25 / 176], [train main loss -2.225861], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 26 / 176], [train main loss -2.379671], [lr 0.003600] [batchtime 0.396]
[epoch 112], [iter 27 / 176], [train main loss -2.318767], [lr 0.003600] [batchtime 0.396]
[epoch 112], [iter 28 / 176], [train main loss -2.255471], [lr 0.003600] [batchtime 0.396]
[epoch 112], [iter 29 / 176], [train main loss -2.125563], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 30 / 176], [train main loss -2.113432], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 31 / 176], [train main loss -2.048047], [lr 0.003600] [batchtime 0.395]
[epoch 112], [iter 32 / 176], [train main loss -2.048533], [lr 0.003600] [batchtime 0.396]
[epoch 112], [iter 33 / 176], [train main loss -2.077307], [lr 0.003600] [batchtime 0.396]
[epoch 112], [iter 34 / 176], [train main loss -2.040975], [lr 0.003600] [batchtime 0.396]
[epoch 112], [iter 35 / 176], [train main loss -2.007042], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 36 / 176], [train main loss -2.064898], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 37 / 176], [train main loss -2.018256], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 38 / 176], [train main loss -2.023040], [lr 0.003600] [batchtime 0.404]
[epoch 112], [iter 39 / 176], [train main loss -2.028938], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 40 / 176], [train main loss -2.052306], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 41 / 176], [train main loss -1.992799], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 42 / 176], [train main loss -1.958369], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 43 / 176], [train main loss -1.965549], [lr 0.003600] [batchtime 0.403]
[epoch 112], [iter 44 / 176], [train main loss -1.960774], [lr 0.003600] [batchtime 0.402]
[epoch 112], [iter 45 / 176], [train main loss -1.958880], [lr 0.003600] [batchtime 0.402]
[epoch 112], [iter 46 / 176], [train main loss -1.984895], [lr 0.003600] [batchtime 0.402]
[epoch 112], [iter 47 / 176], [train main loss -1.953571], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 48 / 176], [train main loss -1.928365], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 49 / 176], [train main loss -1.936837], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 50 / 176], [train main loss -1.959302], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 51 / 176], [train main loss -1.938327], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 52 / 176], [train main loss -1.899354], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 53 / 176], [train main loss -1.883535], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 54 / 176], [train main loss -1.913192], [lr 0.003600] [batchtime 0.401]
[epoch 112], [iter 55 / 176], [train main loss -1.890987], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 56 / 176], [train main loss -1.902133], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 57 / 176], [train main loss -1.913721], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 58 / 176], [train main loss -1.954507], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 59 / 176], [train main loss -1.977470], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 60 / 176], [train main loss -1.983060], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 61 / 176], [train main loss -1.996149], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 62 / 176], [train main loss -2.001005], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 63 / 176], [train main loss -2.008538], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 64 / 176], [train main loss -2.001015], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 65 / 176], [train main loss -2.035831], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 66 / 176], [train main loss -2.021956], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 67 / 176], [train main loss -2.002898], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 68 / 176], [train main loss -1.981229], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 69 / 176], [train main loss -1.970098], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 70 / 176], [train main loss -1.980431], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 71 / 176], [train main loss -1.988586], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 72 / 176], [train main loss -1.987320], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 73 / 176], [train main loss -2.006035], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 74 / 176], [train main loss -2.006299], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 75 / 176], [train main loss -2.005427], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 76 / 176], [train main loss -2.021127], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 77 / 176], [train main loss -1.998504], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 78 / 176], [train main loss -1.995934], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 79 / 176], [train main loss -1.949823], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 80 / 176], [train main loss -1.962807], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 81 / 176], [train main loss -1.922664], [lr 0.003600] [batchtime 0.4]
[epoch 112], [iter 82 / 176], [train main loss -1.916936], [lr 0.003600] [batchtime 0.399]
[epoch 112], [iter 83 / 176], [train main loss -1.938483], [lr 0.003600] [batchtime 0.399]
[epoch 112], [iter 84 / 176], [train main loss -1.966429], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 85 / 176], [train main loss -1.966601], [lr 0.003600] [batchtime 0.411]
[epoch 112], [iter 86 / 176], [train main loss -1.979016], [lr 0.003600] [batchtime 0.411]
[epoch 112], [iter 87 / 176], [train main loss -1.960211], [lr 0.003600] [batchtime 0.411]
[epoch 112], [iter 88 / 176], [train main loss -1.973746], [lr 0.003600] [batchtime 0.41]
[epoch 112], [iter 89 / 176], [train main loss -1.965186], [lr 0.003600] [batchtime 0.41]
[epoch 112], [iter 90 / 176], [train main loss -1.954639], [lr 0.003600] [batchtime 0.41]
[epoch 112], [iter 91 / 176], [train main loss -1.955888], [lr 0.003600] [batchtime 0.41]
[epoch 112], [iter 92 / 176], [train main loss -1.959557], [lr 0.003600] [batchtime 0.41]
[epoch 112], [iter 93 / 176], [train main loss -1.994599], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 94 / 176], [train main loss -2.008597], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 95 / 176], [train main loss -2.008997], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 96 / 176], [train main loss -2.008858], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 97 / 176], [train main loss -2.028561], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 98 / 176], [train main loss -2.018948], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 99 / 176], [train main loss -2.006452], [lr 0.003600] [batchtime 0.409]
[epoch 112], [iter 100 / 176], [train main loss -2.011938], [lr 0.003600] [batchtime 0.408]
[epoch 112], [iter 101 / 176], [train main loss -1.987684], [lr 0.003600] [batchtime 0.408]
[epoch 112], [iter 102 / 176], [train main loss -1.977237], [lr 0.003600] [batchtime 0.408]
[epoch 112], [iter 103 / 176], [train main loss -1.967705], [lr 0.003600] [batchtime 0.408]
[epoch 112], [iter 104 / 176], [train main loss -1.960788], [lr 0.003600] [batchtime 0.408]
[epoch 112], [iter 105 / 176], [train main loss -1.933198], [lr 0.003600] [batchtime 0.408]
[epoch 112], [iter 106 / 176], [train main loss -1.939292], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 107 / 176], [train main loss -1.961225], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 108 / 176], [train main loss -1.975955], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 109 / 176], [train main loss -1.973949], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 110 / 176], [train main loss -1.989015], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 111 / 176], [train main loss -2.008351], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 112 / 176], [train main loss -1.967575], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 113 / 176], [train main loss -1.961866], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 114 / 176], [train main loss -1.946952], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 115 / 176], [train main loss -1.967380], [lr 0.003600] [batchtime 0.407]
[epoch 112], [iter 116 / 176], [train main loss -1.971517], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 117 / 176], [train main loss -1.991963], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 118 / 176], [train main loss -2.001825], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 119 / 176], [train main loss -2.028722], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 120 / 176], [train main loss -2.022417], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 121 / 176], [train main loss -2.030304], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 122 / 176], [train main loss -2.009838], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 123 / 176], [train main loss -2.020332], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 124 / 176], [train main loss -2.025645], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 125 / 176], [train main loss -2.025625], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 126 / 176], [train main loss -2.035530], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 127 / 176], [train main loss -2.049231], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 128 / 176], [train main loss -2.022352], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 129 / 176], [train main loss -2.039262], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 130 / 176], [train main loss -2.027134], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 131 / 176], [train main loss -2.027340], [lr 0.003600] [batchtime 0.405]
[epoch 112], [iter 132 / 176], [train main loss -2.028410], [lr 0.003600] [batchtime 0.406]
[epoch 112], [iter 133 / 176], [train main loss -2.030089], [lr 0.003600] [batchtime 0.418]
[epoch 112], [iter 134 / 176], [train main loss -2.050967], [lr 0.003600] [batchtime 0.418]
[epoch 112], [iter 135 / 176], [train main loss -2.054197], [lr 0.003600] [batchtime 0.417]
[epoch 112], [iter 136 / 176], [train main loss -2.042159], [lr 0.003600] [batchtime 0.417]
[epoch 112], [iter 137 / 176], [train main loss -2.029604], [lr 0.003600] [batchtime 0.417]
[epoch 112], [iter 138 / 176], [train main loss -2.014785], [lr 0.003600] [batchtime 0.417]
[epoch 112], [iter 139 / 176], [train main loss -2.016571], [lr 0.003600] [batchtime 0.417]
[epoch 112], [iter 140 / 176], [train main loss -2.033991], [lr 0.003600] [batchtime 0.417]
[epoch 112], [iter 141 / 176], [train main loss -2.039888], [lr 0.003600] [batchtime 0.416]
[epoch 112], [iter 142 / 176], [train main loss -2.044283], [lr 0.003600] [batchtime 0.416]
[epoch 112], [iter 143 / 176], [train main loss -2.047967], [lr 0.003600] [batchtime 0.416]
[epoch 112], [iter 144 / 176], [train main loss -2.039399], [lr 0.003600] [batchtime 0.416]
[epoch 112], [iter 145 / 176], [train main loss -2.031180], [lr 0.003600] [batchtime 0.416]
[epoch 112], [iter 146 / 176], [train main loss -2.028777], [lr 0.003600] [batchtime 0.416]
[epoch 112], [iter 147 / 176], [train main loss -2.023191], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 148 / 176], [train main loss -2.028640], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 149 / 176], [train main loss -2.056792], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 150 / 176], [train main loss -2.057407], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 151 / 176], [train main loss -2.053967], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 152 / 176], [train main loss -2.063618], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 153 / 176], [train main loss -2.071843], [lr 0.003600] [batchtime 0.415]
[epoch 112], [iter 154 / 176], [train main loss -2.071147], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 155 / 176], [train main loss -2.077386], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 156 / 176], [train main loss -2.079197], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 157 / 176], [train main loss -2.086156], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 158 / 176], [train main loss -2.085180], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 159 / 176], [train main loss -2.080698], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 160 / 176], [train main loss -2.066728], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 161 / 176], [train main loss -2.076561], [lr 0.003600] [batchtime 0.414]
[epoch 112], [iter 162 / 176], [train main loss -2.082649], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 163 / 176], [train main loss -2.084415], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 164 / 176], [train main loss -2.088430], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 165 / 176], [train main loss -2.086710], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 166 / 176], [train main loss -2.087870], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 167 / 176], [train main loss -2.093666], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 168 / 176], [train main loss -2.091116], [lr 0.003600] [batchtime 0.413]
[epoch 112], [iter 169 / 176], [train main loss -2.088558], [lr 0.003600] [batchtime 0.412]
[epoch 112], [iter 170 / 176], [train main loss -2.089892], [lr 0.003600] [batchtime 0.412]
[epoch 112], [iter 171 / 176], [train main loss -2.103994], [lr 0.003600] [batchtime 0.412]
[epoch 112], [iter 172 / 176], [train main loss -2.097487], [lr 0.003600] [batchtime 0.412]
[epoch 112], [iter 173 / 176], [train main loss -2.109712], [lr 0.003600] [batchtime 0.412]
[epoch 112], [iter 174 / 176], [train main loss -2.106147], [lr 0.003600] [batchtime 0.411]
[epoch 112], [iter 175 / 176], [train main loss -2.115952], [lr 0.003600] [batchtime 0.411]
[epoch 112], [iter 176 / 176], [train main loss -2.134567], [lr 0.003600] [batchtime 0.411]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.89  35.46   0.03  0.03         0.98      0.97
   1  sidewalk          70.19   5.52   0.19  0.23         0.84      0.81
   2  building          86.33  24.69   0.08  0.08         0.93      0.92
   3  wall              18.02   0.16   2.67  1.88         0.27      0.35
   4  fence             24.88   0.40   2.19  0.83         0.31      0.55
   5  pole              38.81   0.58   0.97  0.60         0.51      0.62
   6  traffic light     16.65   0.03   4.20  0.80         0.19      0.55
   7  traffic sign      24.68   0.15   2.78  0.27         0.26      0.79
   8  vegetation        83.71  11.59   0.07  0.13         0.94      0.89
   9  terrain           38.95   0.38   0.92  0.64         0.52      0.61
  10  sky               93.76   3.76   0.03  0.04         0.97      0.96
  11  person            54.28   1.09   0.41  0.44         0.71      0.70
  12  rider              8.33   0.01  10.02  0.99         0.09      0.50
  13  car               85.66   6.75   0.05  0.12         0.95      0.89
  14  truck              1.80   0.01  53.68  0.74         0.02      0.57
  15  bus               14.52   0.03   1.61  4.27         0.38      0.19
  16  train             38.01   0.10   0.79  0.85         0.56      0.54
  17  motorcycle         2.76   0.00  34.63  0.56         0.03      0.64
  18  bicycle           38.00   0.26   0.47  1.16         0.68      0.46
Mean: 43.91
-----------------------------------------------------------------------------------------------------------
this : [epoch 112], [val loss 0.29958], [acc 0.90965], [acc_cls 0.53392], [mean_iu 0.43907], [fwavacc 0.84506]
best : [epoch 112], [val loss 0.29958], [acc 0.90965], [acc_cls 0.53392], [mean_iu 0.43907], [fwavacc 0.84506]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 113], [iter 1 / 176], [train main loss -3.972265], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 2 / 176], [train main loss -3.695320], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 3 / 176], [train main loss -2.879548], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 4 / 176], [train main loss -3.159392], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 5 / 176], [train main loss -3.204402], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 6 / 176], [train main loss -3.249246], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 7 / 176], [train main loss -3.078259], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 8 / 176], [train main loss -2.779570], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 9 / 176], [train main loss -2.672531], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 10 / 176], [train main loss -2.594015], [lr 0.003543] [batchtime 0]
[epoch 113], [iter 11 / 176], [train main loss -2.800924], [lr 0.003543] [batchtime 0.382]
[epoch 113], [iter 12 / 176], [train main loss -2.904452], [lr 0.003543] [batchtime 0.391]
[epoch 113], [iter 13 / 176], [train main loss -2.987573], [lr 0.003543] [batchtime 0.395]
[epoch 113], [iter 14 / 176], [train main loss -2.933505], [lr 0.003543] [batchtime 0.396]
[epoch 113], [iter 15 / 176], [train main loss -2.929234], [lr 0.003543] [batchtime 0.396]
[epoch 113], [iter 16 / 176], [train main loss -2.949691], [lr 0.003543] [batchtime 0.397]
[epoch 113], [iter 17 / 176], [train main loss -2.979599], [lr 0.003543] [batchtime 0.397]
[epoch 113], [iter 18 / 176], [train main loss -3.005902], [lr 0.003543] [batchtime 0.399]
[epoch 113], [iter 19 / 176], [train main loss -2.982159], [lr 0.003543] [batchtime 0.399]
[epoch 113], [iter 20 / 176], [train main loss -2.923605], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 21 / 176], [train main loss -2.792995], [lr 0.003543] [batchtime 0.397]
[epoch 113], [iter 22 / 176], [train main loss -2.646942], [lr 0.003543] [batchtime 0.396]
[epoch 113], [iter 23 / 176], [train main loss -2.564491], [lr 0.003543] [batchtime 0.397]
[epoch 113], [iter 24 / 176], [train main loss -2.598424], [lr 0.003543] [batchtime 0.397]
[epoch 113], [iter 25 / 176], [train main loss -2.607799], [lr 0.003543] [batchtime 0.399]
[epoch 113], [iter 26 / 176], [train main loss -2.542883], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 27 / 176], [train main loss -2.642829], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 28 / 176], [train main loss -2.648041], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 29 / 176], [train main loss -2.584375], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 30 / 176], [train main loss -2.565560], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 31 / 176], [train main loss -2.639489], [lr 0.003543] [batchtime 0.398]
[epoch 113], [iter 32 / 176], [train main loss -2.664155], [lr 0.003543] [batchtime 0.399]
[epoch 113], [iter 33 / 176], [train main loss -2.671300], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 34 / 176], [train main loss -2.665427], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 35 / 176], [train main loss -2.790848], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 36 / 176], [train main loss -2.818009], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 37 / 176], [train main loss -2.771050], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 38 / 176], [train main loss -2.703488], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 39 / 176], [train main loss -2.741667], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 40 / 176], [train main loss -2.739818], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 41 / 176], [train main loss -2.728020], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 42 / 176], [train main loss -2.676635], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 43 / 176], [train main loss -2.694477], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 44 / 176], [train main loss -2.705564], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 45 / 176], [train main loss -2.673755], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 46 / 176], [train main loss -2.655553], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 47 / 176], [train main loss -2.612041], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 48 / 176], [train main loss -2.580369], [lr 0.003543] [batchtime 0.412]
[epoch 113], [iter 49 / 176], [train main loss -2.558625], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 50 / 176], [train main loss -2.546183], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 51 / 176], [train main loss -2.513602], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 52 / 176], [train main loss -2.528725], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 53 / 176], [train main loss -2.500887], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 54 / 176], [train main loss -2.477543], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 55 / 176], [train main loss -2.464294], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 56 / 176], [train main loss -2.439946], [lr 0.003543] [batchtime 0.409]
[epoch 113], [iter 57 / 176], [train main loss -2.452862], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 58 / 176], [train main loss -2.420982], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 59 / 176], [train main loss -2.398188], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 60 / 176], [train main loss -2.460799], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 61 / 176], [train main loss -2.467502], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 62 / 176], [train main loss -2.469118], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 63 / 176], [train main loss -2.483514], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 64 / 176], [train main loss -2.468857], [lr 0.003543] [batchtime 0.412]
[epoch 113], [iter 65 / 176], [train main loss -2.506119], [lr 0.003543] [batchtime 0.412]
[epoch 113], [iter 66 / 176], [train main loss -2.467824], [lr 0.003543] [batchtime 0.412]
[epoch 113], [iter 67 / 176], [train main loss -2.476834], [lr 0.003543] [batchtime 0.412]
[epoch 113], [iter 68 / 176], [train main loss -2.493058], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 69 / 176], [train main loss -2.513558], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 70 / 176], [train main loss -2.516710], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 71 / 176], [train main loss -2.536477], [lr 0.003543] [batchtime 0.411]
[epoch 113], [iter 72 / 176], [train main loss -2.515744], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 73 / 176], [train main loss -2.520772], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 74 / 176], [train main loss -2.501681], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 75 / 176], [train main loss -2.494100], [lr 0.003543] [batchtime 0.41]
[epoch 113], [iter 76 / 176], [train main loss -2.499904], [lr 0.003543] [batchtime 0.409]
[epoch 113], [iter 77 / 176], [train main loss -2.469194], [lr 0.003543] [batchtime 0.409]
[epoch 113], [iter 78 / 176], [train main loss -2.468255], [lr 0.003543] [batchtime 0.409]
[epoch 113], [iter 79 / 176], [train main loss -2.450837], [lr 0.003543] [batchtime 0.409]
[epoch 113], [iter 80 / 176], [train main loss -2.421951], [lr 0.003543] [batchtime 0.409]
[epoch 113], [iter 81 / 176], [train main loss -2.443725], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 82 / 176], [train main loss -2.413684], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 83 / 176], [train main loss -2.427410], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 84 / 176], [train main loss -2.423485], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 85 / 176], [train main loss -2.419982], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 86 / 176], [train main loss -2.407619], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 87 / 176], [train main loss -2.392317], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 88 / 176], [train main loss -2.384399], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 89 / 176], [train main loss -2.383092], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 90 / 176], [train main loss -2.374328], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 91 / 176], [train main loss -2.374943], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 92 / 176], [train main loss -2.381157], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 93 / 176], [train main loss -2.394996], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 94 / 176], [train main loss -2.395290], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 95 / 176], [train main loss -2.388888], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 96 / 176], [train main loss -2.378293], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 97 / 176], [train main loss -2.360078], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 98 / 176], [train main loss -2.376372], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 99 / 176], [train main loss -2.351980], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 100 / 176], [train main loss -2.363929], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 101 / 176], [train main loss -2.374766], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 102 / 176], [train main loss -2.390980], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 103 / 176], [train main loss -2.406571], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 104 / 176], [train main loss -2.397616], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 105 / 176], [train main loss -2.386369], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 106 / 176], [train main loss -2.355092], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 107 / 176], [train main loss -2.362585], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 108 / 176], [train main loss -2.381703], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 109 / 176], [train main loss -2.378671], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 110 / 176], [train main loss -2.390506], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 111 / 176], [train main loss -2.390799], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 112 / 176], [train main loss -2.368701], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 113 / 176], [train main loss -2.347689], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 114 / 176], [train main loss -2.330156], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 115 / 176], [train main loss -2.323893], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 116 / 176], [train main loss -2.307423], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 117 / 176], [train main loss -2.310086], [lr 0.003543] [batchtime 0.415]
[epoch 113], [iter 118 / 176], [train main loss -2.316477], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 119 / 176], [train main loss -2.291159], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 120 / 176], [train main loss -2.287083], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 121 / 176], [train main loss -2.306544], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 122 / 176], [train main loss -2.313294], [lr 0.003543] [batchtime 0.414]
[epoch 113], [iter 123 / 176], [train main loss -2.303041], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 124 / 176], [train main loss -2.309655], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 125 / 176], [train main loss -2.318513], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 126 / 176], [train main loss -2.305605], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 127 / 176], [train main loss -2.292114], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 128 / 176], [train main loss -2.296294], [lr 0.003543] [batchtime 0.413]
[epoch 113], [iter 129 / 176], [train main loss -2.298228], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 130 / 176], [train main loss -2.303207], [lr 0.003543] [batchtime 0.425]
[epoch 113], [iter 131 / 176], [train main loss -2.288622], [lr 0.003543] [batchtime 0.425]
[epoch 113], [iter 132 / 176], [train main loss -2.291564], [lr 0.003543] [batchtime 0.424]
[epoch 113], [iter 133 / 176], [train main loss -2.312595], [lr 0.003543] [batchtime 0.424]
[epoch 113], [iter 134 / 176], [train main loss -2.291841], [lr 0.003543] [batchtime 0.424]
[epoch 113], [iter 135 / 176], [train main loss -2.297294], [lr 0.003543] [batchtime 0.424]
[epoch 113], [iter 136 / 176], [train main loss -2.299331], [lr 0.003543] [batchtime 0.424]
[epoch 113], [iter 137 / 176], [train main loss -2.314159], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 138 / 176], [train main loss -2.324092], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 139 / 176], [train main loss -2.323005], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 140 / 176], [train main loss -2.319389], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 141 / 176], [train main loss -2.314099], [lr 0.003543] [batchtime 0.423]
[epoch 113], [iter 142 / 176], [train main loss -2.310578], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 143 / 176], [train main loss -2.304514], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 144 / 176], [train main loss -2.304305], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 145 / 176], [train main loss -2.319636], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 146 / 176], [train main loss -2.311052], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 147 / 176], [train main loss -2.324503], [lr 0.003543] [batchtime 0.422]
[epoch 113], [iter 148 / 176], [train main loss -2.321752], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 149 / 176], [train main loss -2.327594], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 150 / 176], [train main loss -2.329931], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 151 / 176], [train main loss -2.325055], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 152 / 176], [train main loss -2.333039], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 153 / 176], [train main loss -2.344160], [lr 0.003543] [batchtime 0.421]
[epoch 113], [iter 154 / 176], [train main loss -2.361335], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 155 / 176], [train main loss -2.379862], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 156 / 176], [train main loss -2.379358], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 157 / 176], [train main loss -2.364690], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 158 / 176], [train main loss -2.363203], [lr 0.003543] [batchtime 0.42]
[epoch 113], [iter 159 / 176], [train main loss -2.359576], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 160 / 176], [train main loss -2.343683], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 161 / 176], [train main loss -2.341473], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 162 / 176], [train main loss -2.350822], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 163 / 176], [train main loss -2.360280], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 164 / 176], [train main loss -2.368379], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 165 / 176], [train main loss -2.365627], [lr 0.003543] [batchtime 0.419]
[epoch 113], [iter 166 / 176], [train main loss -2.373220], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 167 / 176], [train main loss -2.361787], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 168 / 176], [train main loss -2.375059], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 169 / 176], [train main loss -2.388765], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 170 / 176], [train main loss -2.386281], [lr 0.003543] [batchtime 0.418]
[epoch 113], [iter 171 / 176], [train main loss -2.386173], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 172 / 176], [train main loss -2.398629], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 173 / 176], [train main loss -2.404450], [lr 0.003543] [batchtime 0.417]
[epoch 113], [iter 174 / 176], [train main loss -2.407747], [lr 0.003543] [batchtime 0.416]
[epoch 113], [iter 175 / 176], [train main loss -2.401080], [lr 0.003543] [batchtime 0.426]
[epoch 113], [iter 176 / 176], [train main loss -2.407966], [lr 0.003543] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.45  35.68   0.02  0.04         0.98      0.96
   1  sidewalk          68.11   5.11   0.29  0.18         0.77      0.85
   2  building          86.03  25.34   0.05  0.11         0.95      0.90
   3  wall              16.35   0.12   3.88  1.24         0.21      0.45
   4  fence             25.95   0.40   2.18  0.67         0.31      0.60
   5  pole              38.39   0.55   1.07  0.54         0.48      0.65
   6  traffic light     15.87   0.03   4.74  0.57         0.17      0.64
   7  traffic sign      19.55   0.11   3.89  0.23         0.20      0.82
   8  vegetation        84.03  11.41   0.08  0.11         0.92      0.90
   9  terrain           39.44   0.35   1.08  0.45         0.48      0.69
  10  sky               93.61   3.75   0.03  0.03         0.97      0.97
  11  person            52.88   1.02   0.50  0.39         0.66      0.72
  12  rider              9.41   0.01   8.44  1.19         0.11      0.46
  13  car               85.81   6.67   0.06  0.10         0.94      0.91
  14  truck              2.04   0.01  47.51  0.59         0.02      0.63
  15  bus               15.77   0.04   1.45  3.89         0.41      0.20
  16  train             36.85   0.10   0.87  0.85         0.54      0.54
  17  motorcycle         4.57   0.01  20.18  0.71         0.05      0.59
  18  bicycle           38.10   0.25   0.55  1.08         0.65      0.48
Mean: 43.54
-----------------------------------------------------------------------------------------------------------
this : [epoch 113], [val loss 0.32217], [acc 0.90939], [acc_cls 0.51756], [mean_iu 0.43537], [fwavacc 0.84125]
best : [epoch 112], [val loss 0.29958], [acc 0.90965], [acc_cls 0.53392], [mean_iu 0.43907], [fwavacc 0.84506]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 114], [iter 1 / 176], [train main loss -1.129189], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 2 / 176], [train main loss -2.280881], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 3 / 176], [train main loss -2.833577], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 4 / 176], [train main loss -2.282452], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 5 / 176], [train main loss -2.236414], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 6 / 176], [train main loss -2.329259], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 7 / 176], [train main loss -2.256222], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 8 / 176], [train main loss -2.325749], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 9 / 176], [train main loss -2.375492], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 10 / 176], [train main loss -2.039033], [lr 0.003486] [batchtime 0]
[epoch 114], [iter 11 / 176], [train main loss -2.067143], [lr 0.003486] [batchtime 0.364]
[epoch 114], [iter 12 / 176], [train main loss -2.206383], [lr 0.003486] [batchtime 0.379]
[epoch 114], [iter 13 / 176], [train main loss -2.174789], [lr 0.003486] [batchtime 0.386]
[epoch 114], [iter 14 / 176], [train main loss -2.381358], [lr 0.003486] [batchtime 0.391]
[epoch 114], [iter 15 / 176], [train main loss -2.328772], [lr 0.003486] [batchtime 0.391]
[epoch 114], [iter 16 / 176], [train main loss -2.247218], [lr 0.003486] [batchtime 0.394]
[epoch 114], [iter 17 / 176], [train main loss -2.210735], [lr 0.003486] [batchtime 0.393]
[epoch 114], [iter 18 / 176], [train main loss -2.169162], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 19 / 176], [train main loss -2.135459], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 20 / 176], [train main loss -2.206974], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 21 / 176], [train main loss -2.244968], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 22 / 176], [train main loss -2.291528], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 23 / 176], [train main loss -2.362181], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 24 / 176], [train main loss -2.304461], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 25 / 176], [train main loss -2.265805], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 26 / 176], [train main loss -2.186064], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 27 / 176], [train main loss -2.265342], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 28 / 176], [train main loss -2.262840], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 29 / 176], [train main loss -2.355143], [lr 0.003486] [batchtime 0.395]
[epoch 114], [iter 30 / 176], [train main loss -2.367881], [lr 0.003486] [batchtime 0.396]
[epoch 114], [iter 31 / 176], [train main loss -2.408358], [lr 0.003486] [batchtime 0.404]
[epoch 114], [iter 32 / 176], [train main loss -2.370193], [lr 0.003486] [batchtime 0.469]
[epoch 114], [iter 33 / 176], [train main loss -2.382945], [lr 0.003486] [batchtime 0.465]
[epoch 114], [iter 34 / 176], [train main loss -2.393789], [lr 0.003486] [batchtime 0.462]
[epoch 114], [iter 35 / 176], [train main loss -2.404185], [lr 0.003486] [batchtime 0.46]
[epoch 114], [iter 36 / 176], [train main loss -2.469235], [lr 0.003486] [batchtime 0.457]
[epoch 114], [iter 37 / 176], [train main loss -2.449317], [lr 0.003486] [batchtime 0.454]
[epoch 114], [iter 38 / 176], [train main loss -2.457678], [lr 0.003486] [batchtime 0.453]
[epoch 114], [iter 39 / 176], [train main loss -2.422354], [lr 0.003486] [batchtime 0.451]
[epoch 114], [iter 40 / 176], [train main loss -2.346539], [lr 0.003486] [batchtime 0.449]
[epoch 114], [iter 41 / 176], [train main loss -2.340931], [lr 0.003486] [batchtime 0.448]
[epoch 114], [iter 42 / 176], [train main loss -2.349857], [lr 0.003486] [batchtime 0.446]
[epoch 114], [iter 43 / 176], [train main loss -2.395502], [lr 0.003486] [batchtime 0.445]
[epoch 114], [iter 44 / 176], [train main loss -2.351098], [lr 0.003486] [batchtime 0.443]
[epoch 114], [iter 45 / 176], [train main loss -2.405105], [lr 0.003486] [batchtime 0.442]
[epoch 114], [iter 46 / 176], [train main loss -2.423997], [lr 0.003486] [batchtime 0.441]
[epoch 114], [iter 47 / 176], [train main loss -2.447274], [lr 0.003486] [batchtime 0.439]
[epoch 114], [iter 48 / 176], [train main loss -2.397100], [lr 0.003486] [batchtime 0.439]
[epoch 114], [iter 49 / 176], [train main loss -2.374205], [lr 0.003486] [batchtime 0.438]
[epoch 114], [iter 50 / 176], [train main loss -2.367495], [lr 0.003486] [batchtime 0.437]
[epoch 114], [iter 51 / 176], [train main loss -2.333884], [lr 0.003486] [batchtime 0.436]
[epoch 114], [iter 52 / 176], [train main loss -2.395121], [lr 0.003486] [batchtime 0.435]
[epoch 114], [iter 53 / 176], [train main loss -2.389925], [lr 0.003486] [batchtime 0.434]
[epoch 114], [iter 54 / 176], [train main loss -2.372498], [lr 0.003486] [batchtime 0.433]
[epoch 114], [iter 55 / 176], [train main loss -2.385152], [lr 0.003486] [batchtime 0.432]
[epoch 114], [iter 56 / 176], [train main loss -2.392203], [lr 0.003486] [batchtime 0.432]
[epoch 114], [iter 57 / 176], [train main loss -2.355064], [lr 0.003486] [batchtime 0.431]
[epoch 114], [iter 58 / 176], [train main loss -2.309850], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 59 / 176], [train main loss -2.285507], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 60 / 176], [train main loss -2.255778], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 61 / 176], [train main loss -2.279800], [lr 0.003486] [batchtime 0.428]
[epoch 114], [iter 62 / 176], [train main loss -2.269689], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 63 / 176], [train main loss -2.281625], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 64 / 176], [train main loss -2.221136], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 65 / 176], [train main loss -2.205568], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 66 / 176], [train main loss -2.226526], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 67 / 176], [train main loss -2.206674], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 68 / 176], [train main loss -2.226698], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 69 / 176], [train main loss -2.230567], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 70 / 176], [train main loss -2.233756], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 71 / 176], [train main loss -2.209533], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 72 / 176], [train main loss -2.216787], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 73 / 176], [train main loss -2.197249], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 74 / 176], [train main loss -2.211441], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 75 / 176], [train main loss -2.248107], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 76 / 176], [train main loss -2.280967], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 77 / 176], [train main loss -2.269555], [lr 0.003486] [batchtime 0.42]
[epoch 114], [iter 78 / 176], [train main loss -2.246510], [lr 0.003486] [batchtime 0.439]
[epoch 114], [iter 79 / 176], [train main loss -2.203090], [lr 0.003486] [batchtime 0.441]
[epoch 114], [iter 80 / 176], [train main loss -2.191077], [lr 0.003486] [batchtime 0.44]
[epoch 114], [iter 81 / 176], [train main loss -2.215983], [lr 0.003486] [batchtime 0.439]
[epoch 114], [iter 82 / 176], [train main loss -2.231967], [lr 0.003486] [batchtime 0.438]
[epoch 114], [iter 83 / 176], [train main loss -2.216839], [lr 0.003486] [batchtime 0.438]
[epoch 114], [iter 84 / 176], [train main loss -2.233140], [lr 0.003486] [batchtime 0.437]
[epoch 114], [iter 85 / 176], [train main loss -2.236283], [lr 0.003486] [batchtime 0.436]
[epoch 114], [iter 86 / 176], [train main loss -2.241324], [lr 0.003486] [batchtime 0.436]
[epoch 114], [iter 87 / 176], [train main loss -2.206859], [lr 0.003486] [batchtime 0.435]
[epoch 114], [iter 88 / 176], [train main loss -2.195798], [lr 0.003486] [batchtime 0.435]
[epoch 114], [iter 89 / 176], [train main loss -2.228056], [lr 0.003486] [batchtime 0.434]
[epoch 114], [iter 90 / 176], [train main loss -2.249101], [lr 0.003486] [batchtime 0.434]
[epoch 114], [iter 91 / 176], [train main loss -2.247720], [lr 0.003486] [batchtime 0.433]
[epoch 114], [iter 92 / 176], [train main loss -2.242899], [lr 0.003486] [batchtime 0.433]
[epoch 114], [iter 93 / 176], [train main loss -2.239904], [lr 0.003486] [batchtime 0.432]
[epoch 114], [iter 94 / 176], [train main loss -2.249616], [lr 0.003486] [batchtime 0.432]
[epoch 114], [iter 95 / 176], [train main loss -2.270905], [lr 0.003486] [batchtime 0.431]
[epoch 114], [iter 96 / 176], [train main loss -2.282319], [lr 0.003486] [batchtime 0.431]
[epoch 114], [iter 97 / 176], [train main loss -2.279102], [lr 0.003486] [batchtime 0.431]
[epoch 114], [iter 98 / 176], [train main loss -2.259682], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 99 / 176], [train main loss -2.220290], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 100 / 176], [train main loss -2.180606], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 101 / 176], [train main loss -2.166535], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 102 / 176], [train main loss -2.151607], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 103 / 176], [train main loss -2.140850], [lr 0.003486] [batchtime 0.428]
[epoch 114], [iter 104 / 176], [train main loss -2.151507], [lr 0.003486] [batchtime 0.428]
[epoch 114], [iter 105 / 176], [train main loss -2.155950], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 106 / 176], [train main loss -2.153576], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 107 / 176], [train main loss -2.148612], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 108 / 176], [train main loss -2.152725], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 109 / 176], [train main loss -2.147082], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 110 / 176], [train main loss -2.132487], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 111 / 176], [train main loss -2.124498], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 112 / 176], [train main loss -2.124363], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 113 / 176], [train main loss -2.127535], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 114 / 176], [train main loss -2.133324], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 115 / 176], [train main loss -2.127808], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 116 / 176], [train main loss -2.125973], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 117 / 176], [train main loss -2.139411], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 118 / 176], [train main loss -2.136190], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 119 / 176], [train main loss -2.136965], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 120 / 176], [train main loss -2.147874], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 121 / 176], [train main loss -2.151540], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 122 / 176], [train main loss -2.155510], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 123 / 176], [train main loss -2.153887], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 124 / 176], [train main loss -2.161246], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 125 / 176], [train main loss -2.169621], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 126 / 176], [train main loss -2.151264], [lr 0.003486] [batchtime 0.431]
[epoch 114], [iter 127 / 176], [train main loss -2.152359], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 128 / 176], [train main loss -2.164696], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 129 / 176], [train main loss -2.161799], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 130 / 176], [train main loss -2.159834], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 131 / 176], [train main loss -2.165454], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 132 / 176], [train main loss -2.163368], [lr 0.003486] [batchtime 0.429]
[epoch 114], [iter 133 / 176], [train main loss -2.166712], [lr 0.003486] [batchtime 0.428]
[epoch 114], [iter 134 / 176], [train main loss -2.147380], [lr 0.003486] [batchtime 0.428]
[epoch 114], [iter 135 / 176], [train main loss -2.134066], [lr 0.003486] [batchtime 0.428]
[epoch 114], [iter 136 / 176], [train main loss -2.131294], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 137 / 176], [train main loss -2.122015], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 138 / 176], [train main loss -2.109394], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 139 / 176], [train main loss -2.116858], [lr 0.003486] [batchtime 0.427]
[epoch 114], [iter 140 / 176], [train main loss -2.109210], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 141 / 176], [train main loss -2.131111], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 142 / 176], [train main loss -2.118069], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 143 / 176], [train main loss -2.100544], [lr 0.003486] [batchtime 0.426]
[epoch 114], [iter 144 / 176], [train main loss -2.105697], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 145 / 176], [train main loss -2.096769], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 146 / 176], [train main loss -2.109600], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 147 / 176], [train main loss -2.110930], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 148 / 176], [train main loss -2.120035], [lr 0.003486] [batchtime 0.425]
[epoch 114], [iter 149 / 176], [train main loss -2.136587], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 150 / 176], [train main loss -2.134464], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 151 / 176], [train main loss -2.135233], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 152 / 176], [train main loss -2.133872], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 153 / 176], [train main loss -2.141965], [lr 0.003486] [batchtime 0.424]
[epoch 114], [iter 154 / 176], [train main loss -2.149223], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 155 / 176], [train main loss -2.154306], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 156 / 176], [train main loss -2.156256], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 157 / 176], [train main loss -2.148327], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 158 / 176], [train main loss -2.148044], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 159 / 176], [train main loss -2.145371], [lr 0.003486] [batchtime 0.423]
[epoch 114], [iter 160 / 176], [train main loss -2.141793], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 161 / 176], [train main loss -2.143278], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 162 / 176], [train main loss -2.154534], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 163 / 176], [train main loss -2.140544], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 164 / 176], [train main loss -2.127682], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 165 / 176], [train main loss -2.130522], [lr 0.003486] [batchtime 0.422]
[epoch 114], [iter 166 / 176], [train main loss -2.111319], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 167 / 176], [train main loss -2.105702], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 168 / 176], [train main loss -2.106551], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 169 / 176], [train main loss -2.109433], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 170 / 176], [train main loss -2.113596], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 171 / 176], [train main loss -2.123261], [lr 0.003486] [batchtime 0.42]
[epoch 114], [iter 172 / 176], [train main loss -2.124012], [lr 0.003486] [batchtime 0.42]
[epoch 114], [iter 173 / 176], [train main loss -2.136267], [lr 0.003486] [batchtime 0.421]
[epoch 114], [iter 174 / 176], [train main loss -2.126142], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 175 / 176], [train main loss -2.115230], [lr 0.003486] [batchtime 0.43]
[epoch 114], [iter 176 / 176], [train main loss -2.105203], [lr 0.003486] [batchtime 0.43]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.50  35.52   0.02  0.03         0.98      0.97
   1  sidewalk          68.43   5.32   0.24  0.22         0.81      0.82
   2  building          86.08  24.66   0.08  0.08         0.93      0.92
   3  wall              16.36   0.13   3.49  1.62         0.22      0.38
   4  fence             22.26   0.33   2.91  0.59         0.26      0.63
   5  pole              39.28   0.57   0.99  0.56         0.50      0.64
   6  traffic light     13.78   0.02   5.85  0.41         0.15      0.71
   7  traffic sign      23.61   0.14   2.97  0.26         0.25      0.79
   8  vegetation        83.03  11.71   0.06  0.15         0.95      0.87
   9  terrain           39.31   0.38   0.91  0.63         0.52      0.61
  10  sky               93.51   3.75   0.03  0.04         0.97      0.97
  11  person            52.94   1.04   0.48  0.41         0.68      0.71
  12  rider             15.33   0.02   4.08  1.44         0.20      0.41
  13  car               84.60   6.75   0.05  0.13         0.95      0.88
  14  truck              1.90   0.01  50.66  0.84         0.02      0.54
  15  bus               13.23   0.04   1.40  5.15         0.42      0.16
  16  train             25.68   0.07   1.61  1.28         0.38      0.44
  17  motorcycle         6.20   0.01  14.30  0.83         0.07      0.55
  18  bicycle           37.19   0.25   0.54  1.15         0.65      0.47
Mean: 43.01
-----------------------------------------------------------------------------------------------------------
this : [epoch 114], [val loss 0.31855], [acc 0.90708], [acc_cls 0.52034], [mean_iu 0.43012], [fwavacc 0.83932]
best : [epoch 112], [val loss 0.29958], [acc 0.90965], [acc_cls 0.53392], [mean_iu 0.43907], [fwavacc 0.84506]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 115], [iter 1 / 176], [train main loss -3.303222], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 2 / 176], [train main loss -2.613001], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 3 / 176], [train main loss -1.755405], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 4 / 176], [train main loss -1.591854], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 5 / 176], [train main loss -2.111560], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 6 / 176], [train main loss -1.945997], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 7 / 176], [train main loss -2.201977], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 8 / 176], [train main loss -2.338098], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 9 / 176], [train main loss -2.093379], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 10 / 176], [train main loss -2.163878], [lr 0.003429] [batchtime 0]
[epoch 115], [iter 11 / 176], [train main loss -2.352247], [lr 0.003429] [batchtime 0.372]
[epoch 115], [iter 12 / 176], [train main loss -2.109509], [lr 0.003429] [batchtime 0.393]
[epoch 115], [iter 13 / 176], [train main loss -2.153056], [lr 0.003429] [batchtime 0.394]
[epoch 115], [iter 14 / 176], [train main loss -2.210139], [lr 0.003429] [batchtime 0.396]
[epoch 115], [iter 15 / 176], [train main loss -2.267851], [lr 0.003429] [batchtime 0.398]
[epoch 115], [iter 16 / 176], [train main loss -2.091197], [lr 0.003429] [batchtime 0.398]
[epoch 115], [iter 17 / 176], [train main loss -2.155017], [lr 0.003429] [batchtime 0.4]
[epoch 115], [iter 18 / 176], [train main loss -2.400338], [lr 0.003429] [batchtime 0.401]
[epoch 115], [iter 19 / 176], [train main loss -2.258724], [lr 0.003429] [batchtime 0.401]
[epoch 115], [iter 20 / 176], [train main loss -2.358450], [lr 0.003429] [batchtime 0.401]
[epoch 115], [iter 21 / 176], [train main loss -2.327229], [lr 0.003429] [batchtime 0.402]
[epoch 115], [iter 22 / 176], [train main loss -2.402873], [lr 0.003429] [batchtime 0.401]
[epoch 115], [iter 23 / 176], [train main loss -2.295833], [lr 0.003429] [batchtime 0.402]
[epoch 115], [iter 24 / 176], [train main loss -2.308132], [lr 0.003429] [batchtime 0.402]
[epoch 115], [iter 25 / 176], [train main loss -2.236297], [lr 0.003429] [batchtime 0.402]
[epoch 115], [iter 26 / 176], [train main loss -2.103270], [lr 0.003429] [batchtime 0.403]
[epoch 115], [iter 27 / 176], [train main loss -2.085372], [lr 0.003429] [batchtime 0.403]
[epoch 115], [iter 28 / 176], [train main loss -2.016574], [lr 0.003429] [batchtime 0.413]
[epoch 115], [iter 29 / 176], [train main loss -1.949901], [lr 0.003429] [batchtime 0.464]
[epoch 115], [iter 30 / 176], [train main loss -2.017630], [lr 0.003429] [batchtime 0.46]
[epoch 115], [iter 31 / 176], [train main loss -1.981366], [lr 0.003429] [batchtime 0.457]
[epoch 115], [iter 32 / 176], [train main loss -1.881893], [lr 0.003429] [batchtime 0.454]
[epoch 115], [iter 33 / 176], [train main loss -1.913153], [lr 0.003429] [batchtime 0.451]
[epoch 115], [iter 34 / 176], [train main loss -2.018017], [lr 0.003429] [batchtime 0.449]
[epoch 115], [iter 35 / 176], [train main loss -2.120975], [lr 0.003429] [batchtime 0.448]
[epoch 115], [iter 36 / 176], [train main loss -2.153490], [lr 0.003429] [batchtime 0.446]
[epoch 115], [iter 37 / 176], [train main loss -2.192678], [lr 0.003429] [batchtime 0.444]
[epoch 115], [iter 38 / 176], [train main loss -2.253387], [lr 0.003429] [batchtime 0.442]
[epoch 115], [iter 39 / 176], [train main loss -2.210705], [lr 0.003429] [batchtime 0.441]
[epoch 115], [iter 40 / 176], [train main loss -2.204377], [lr 0.003429] [batchtime 0.44]
[epoch 115], [iter 41 / 176], [train main loss -2.190648], [lr 0.003429] [batchtime 0.438]
[epoch 115], [iter 42 / 176], [train main loss -2.152957], [lr 0.003429] [batchtime 0.437]
[epoch 115], [iter 43 / 176], [train main loss -2.130230], [lr 0.003429] [batchtime 0.436]
[epoch 115], [iter 44 / 176], [train main loss -2.107574], [lr 0.003429] [batchtime 0.435]
[epoch 115], [iter 45 / 176], [train main loss -2.129571], [lr 0.003429] [batchtime 0.434]
[epoch 115], [iter 46 / 176], [train main loss -2.174326], [lr 0.003429] [batchtime 0.433]
[epoch 115], [iter 47 / 176], [train main loss -2.132374], [lr 0.003429] [batchtime 0.433]
[epoch 115], [iter 48 / 176], [train main loss -2.090623], [lr 0.003429] [batchtime 0.432]
[epoch 115], [iter 49 / 176], [train main loss -2.085396], [lr 0.003429] [batchtime 0.431]
[epoch 115], [iter 50 / 176], [train main loss -2.079476], [lr 0.003429] [batchtime 0.43]
[epoch 115], [iter 51 / 176], [train main loss -2.030753], [lr 0.003429] [batchtime 0.43]
[epoch 115], [iter 52 / 176], [train main loss -2.003659], [lr 0.003429] [batchtime 0.429]
[epoch 115], [iter 53 / 176], [train main loss -2.002089], [lr 0.003429] [batchtime 0.428]
[epoch 115], [iter 54 / 176], [train main loss -1.982357], [lr 0.003429] [batchtime 0.428]
[epoch 115], [iter 55 / 176], [train main loss -1.981451], [lr 0.003429] [batchtime 0.427]
[epoch 115], [iter 56 / 176], [train main loss -2.032151], [lr 0.003429] [batchtime 0.427]
[epoch 115], [iter 57 / 176], [train main loss -2.011442], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 58 / 176], [train main loss -2.057642], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 59 / 176], [train main loss -2.056100], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 60 / 176], [train main loss -2.032130], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 61 / 176], [train main loss -2.022247], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 62 / 176], [train main loss -2.007002], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 63 / 176], [train main loss -2.008662], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 64 / 176], [train main loss -2.006206], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 65 / 176], [train main loss -1.984681], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 66 / 176], [train main loss -1.951884], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 67 / 176], [train main loss -1.978555], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 68 / 176], [train main loss -2.004412], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 69 / 176], [train main loss -2.006217], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 70 / 176], [train main loss -2.008559], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 71 / 176], [train main loss -2.005128], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 72 / 176], [train main loss -2.003713], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 73 / 176], [train main loss -1.985870], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 74 / 176], [train main loss -1.972681], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 75 / 176], [train main loss -1.977631], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 76 / 176], [train main loss -1.963521], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 77 / 176], [train main loss -1.958233], [lr 0.003429] [batchtime 0.427]
[epoch 115], [iter 78 / 176], [train main loss -1.952660], [lr 0.003429] [batchtime 0.427]
[epoch 115], [iter 79 / 176], [train main loss -1.938057], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 80 / 176], [train main loss -1.945782], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 81 / 176], [train main loss -1.946007], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 82 / 176], [train main loss -1.938739], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 83 / 176], [train main loss -1.944078], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 84 / 176], [train main loss -1.917311], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 85 / 176], [train main loss -1.944875], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 86 / 176], [train main loss -1.953511], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 87 / 176], [train main loss -1.950842], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 88 / 176], [train main loss -1.942960], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 89 / 176], [train main loss -1.946799], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 90 / 176], [train main loss -1.946630], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 91 / 176], [train main loss -1.944942], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 92 / 176], [train main loss -1.932310], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 93 / 176], [train main loss -1.944606], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 94 / 176], [train main loss -1.948877], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 95 / 176], [train main loss -1.969461], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 96 / 176], [train main loss -1.969635], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 97 / 176], [train main loss -1.949474], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 98 / 176], [train main loss -1.953400], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 99 / 176], [train main loss -1.968953], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 100 / 176], [train main loss -1.978671], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 101 / 176], [train main loss -1.975411], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 102 / 176], [train main loss -1.984788], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 103 / 176], [train main loss -1.977504], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 104 / 176], [train main loss -1.962036], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 105 / 176], [train main loss -1.946911], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 106 / 176], [train main loss -1.952676], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 107 / 176], [train main loss -1.961110], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 108 / 176], [train main loss -1.970729], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 109 / 176], [train main loss -1.975651], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 110 / 176], [train main loss -2.004301], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 111 / 176], [train main loss -1.979026], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 112 / 176], [train main loss -1.987680], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 113 / 176], [train main loss -1.972254], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 114 / 176], [train main loss -2.000268], [lr 0.003429] [batchtime 0.416]
[epoch 115], [iter 115 / 176], [train main loss -2.021927], [lr 0.003429] [batchtime 0.416]
[epoch 115], [iter 116 / 176], [train main loss -2.049734], [lr 0.003429] [batchtime 0.416]
[epoch 115], [iter 117 / 176], [train main loss -2.056340], [lr 0.003429] [batchtime 0.416]
[epoch 115], [iter 118 / 176], [train main loss -2.060369], [lr 0.003429] [batchtime 0.416]
[epoch 115], [iter 119 / 176], [train main loss -2.051806], [lr 0.003429] [batchtime 0.416]
[epoch 115], [iter 120 / 176], [train main loss -2.045984], [lr 0.003429] [batchtime 0.415]
[epoch 115], [iter 121 / 176], [train main loss -2.041770], [lr 0.003429] [batchtime 0.415]
[epoch 115], [iter 122 / 176], [train main loss -2.039617], [lr 0.003429] [batchtime 0.415]
[epoch 115], [iter 123 / 176], [train main loss -2.039216], [lr 0.003429] [batchtime 0.415]
[epoch 115], [iter 124 / 176], [train main loss -2.045667], [lr 0.003429] [batchtime 0.415]
[epoch 115], [iter 125 / 176], [train main loss -2.020067], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 126 / 176], [train main loss -2.011323], [lr 0.003429] [batchtime 0.425]
[epoch 115], [iter 127 / 176], [train main loss -2.018926], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 128 / 176], [train main loss -2.016113], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 129 / 176], [train main loss -2.019072], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 130 / 176], [train main loss -2.034194], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 131 / 176], [train main loss -2.034145], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 132 / 176], [train main loss -2.043298], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 133 / 176], [train main loss -2.056590], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 134 / 176], [train main loss -2.045529], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 135 / 176], [train main loss -2.060974], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 136 / 176], [train main loss -2.070548], [lr 0.003429] [batchtime 0.423]
[epoch 115], [iter 137 / 176], [train main loss -2.053927], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 138 / 176], [train main loss -2.047311], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 139 / 176], [train main loss -2.076255], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 140 / 176], [train main loss -2.074685], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 141 / 176], [train main loss -2.057653], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 142 / 176], [train main loss -2.069380], [lr 0.003429] [batchtime 0.422]
[epoch 115], [iter 143 / 176], [train main loss -2.067692], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 144 / 176], [train main loss -2.063815], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 145 / 176], [train main loss -2.062250], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 146 / 176], [train main loss -2.079616], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 147 / 176], [train main loss -2.079525], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 148 / 176], [train main loss -2.079680], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 149 / 176], [train main loss -2.073277], [lr 0.003429] [batchtime 0.421]
[epoch 115], [iter 150 / 176], [train main loss -2.078687], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 151 / 176], [train main loss -2.089255], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 152 / 176], [train main loss -2.100403], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 153 / 176], [train main loss -2.107392], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 154 / 176], [train main loss -2.107891], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 155 / 176], [train main loss -2.139563], [lr 0.003429] [batchtime 0.42]
[epoch 115], [iter 156 / 176], [train main loss -2.137640], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 157 / 176], [train main loss -2.133554], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 158 / 176], [train main loss -2.125470], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 159 / 176], [train main loss -2.129828], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 160 / 176], [train main loss -2.134334], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 161 / 176], [train main loss -2.142707], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 162 / 176], [train main loss -2.139792], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 163 / 176], [train main loss -2.138458], [lr 0.003429] [batchtime 0.419]
[epoch 115], [iter 164 / 176], [train main loss -2.135310], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 165 / 176], [train main loss -2.128032], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 166 / 176], [train main loss -2.134275], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 167 / 176], [train main loss -2.126937], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 168 / 176], [train main loss -2.121292], [lr 0.003429] [batchtime 0.418]
[epoch 115], [iter 169 / 176], [train main loss -2.111787], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 170 / 176], [train main loss -2.112252], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 171 / 176], [train main loss -2.101875], [lr 0.003429] [batchtime 0.417]
[epoch 115], [iter 172 / 176], [train main loss -2.102716], [lr 0.003429] [batchtime 0.424]
[epoch 115], [iter 173 / 176], [train main loss -2.098758], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 174 / 176], [train main loss -2.105311], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 175 / 176], [train main loss -2.102721], [lr 0.003429] [batchtime 0.426]
[epoch 115], [iter 176 / 176], [train main loss -2.109670], [lr 0.003429] [batchtime 0.425]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.25  35.79   0.02  0.04         0.98      0.96
   1  sidewalk          66.36   4.98   0.32  0.18         0.76      0.85
   2  building          86.00  24.86   0.07  0.09         0.94      0.91
   3  wall              20.11   0.17   2.49  1.48         0.29      0.40
   4  fence             23.07   0.34   2.75  0.58         0.27      0.63
   5  pole              37.72   0.53   1.15  0.50         0.46      0.67
   6  traffic light     14.90   0.02   5.20  0.51         0.16      0.66
   7  traffic sign      20.80   0.12   3.59  0.21         0.22      0.82
   8  vegetation        83.05  11.64   0.06  0.14         0.94      0.88
   9  terrain           37.62   0.34   1.16  0.50         0.46      0.67
  10  sky               93.42   3.73   0.04  0.03         0.96      0.97
  11  person            52.36   1.06   0.45  0.46         0.69      0.68
  12  rider              9.80   0.01   7.98  1.22         0.11      0.45
  13  car               85.61   6.64   0.06  0.10         0.94      0.91
  14  truck              2.55   0.01  37.56  0.73         0.03      0.58
  15  bus               14.86   0.05   0.79  4.93         0.56      0.17
  16  train             25.96   0.07   1.51  1.34         0.40      0.43
  17  motorcycle         3.69   0.00  25.29  0.83         0.04      0.55
  18  bicycle           37.17   0.26   0.52  1.17         0.66      0.46
Mean: 42.60
-----------------------------------------------------------------------------------------------------------
this : [epoch 115], [val loss 0.31608], [acc 0.90624], [acc_cls 0.51902], [mean_iu 0.42595], [fwavacc 0.83729]
best : [epoch 112], [val loss 0.29958], [acc 0.90965], [acc_cls 0.53392], [mean_iu 0.43907], [fwavacc 0.84506]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 116], [iter 1 / 176], [train main loss 1.819921], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 2 / 176], [train main loss -0.838043], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 3 / 176], [train main loss -2.426845], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 4 / 176], [train main loss -1.896276], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 5 / 176], [train main loss -1.922325], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 6 / 176], [train main loss -2.037024], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 7 / 176], [train main loss -2.025243], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 8 / 176], [train main loss -1.925394], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 9 / 176], [train main loss -1.957779], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 10 / 176], [train main loss -1.954783], [lr 0.003371] [batchtime 0]
[epoch 116], [iter 11 / 176], [train main loss -1.988130], [lr 0.003371] [batchtime 0.37]
[epoch 116], [iter 12 / 176], [train main loss -1.747724], [lr 0.003371] [batchtime 0.382]
[epoch 116], [iter 13 / 176], [train main loss -1.501793], [lr 0.003371] [batchtime 0.391]
[epoch 116], [iter 14 / 176], [train main loss -1.476384], [lr 0.003371] [batchtime 0.393]
[epoch 116], [iter 15 / 176], [train main loss -1.528827], [lr 0.003371] [batchtime 0.396]
[epoch 116], [iter 16 / 176], [train main loss -1.578193], [lr 0.003371] [batchtime 0.405]
[epoch 116], [iter 17 / 176], [train main loss -1.545799], [lr 0.003371] [batchtime 0.404]
[epoch 116], [iter 18 / 176], [train main loss -1.511967], [lr 0.003371] [batchtime 0.403]
[epoch 116], [iter 19 / 176], [train main loss -1.672464], [lr 0.003371] [batchtime 0.403]
[epoch 116], [iter 20 / 176], [train main loss -1.632816], [lr 0.003371] [batchtime 0.401]
[epoch 116], [iter 21 / 176], [train main loss -1.733686], [lr 0.003371] [batchtime 0.4]
[epoch 116], [iter 22 / 176], [train main loss -1.829246], [lr 0.003371] [batchtime 0.4]
[epoch 116], [iter 23 / 176], [train main loss -1.992574], [lr 0.003371] [batchtime 0.399]
[epoch 116], [iter 24 / 176], [train main loss -1.958807], [lr 0.003371] [batchtime 0.399]
[epoch 116], [iter 25 / 176], [train main loss -1.857382], [lr 0.003371] [batchtime 0.399]
[epoch 116], [iter 26 / 176], [train main loss -1.859827], [lr 0.003371] [batchtime 0.428]
[epoch 116], [iter 27 / 176], [train main loss -1.839779], [lr 0.003371] [batchtime 0.436]
[epoch 116], [iter 28 / 176], [train main loss -1.922369], [lr 0.003371] [batchtime 0.433]
[epoch 116], [iter 29 / 176], [train main loss -1.964937], [lr 0.003371] [batchtime 0.431]
[epoch 116], [iter 30 / 176], [train main loss -1.910456], [lr 0.003371] [batchtime 0.429]
[epoch 116], [iter 31 / 176], [train main loss -1.820038], [lr 0.003371] [batchtime 0.427]
[epoch 116], [iter 32 / 176], [train main loss -1.785350], [lr 0.003371] [batchtime 0.426]
[epoch 116], [iter 33 / 176], [train main loss -1.812471], [lr 0.003371] [batchtime 0.425]
[epoch 116], [iter 34 / 176], [train main loss -1.872274], [lr 0.003371] [batchtime 0.423]
[epoch 116], [iter 35 / 176], [train main loss -1.915635], [lr 0.003371] [batchtime 0.423]
[epoch 116], [iter 36 / 176], [train main loss -1.943022], [lr 0.003371] [batchtime 0.422]
[epoch 116], [iter 37 / 176], [train main loss -1.946478], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 38 / 176], [train main loss -1.954165], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 39 / 176], [train main loss -1.966733], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 40 / 176], [train main loss -1.974248], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 41 / 176], [train main loss -1.973685], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 42 / 176], [train main loss -1.910693], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 43 / 176], [train main loss -1.934414], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 44 / 176], [train main loss -1.927037], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 45 / 176], [train main loss -1.949779], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 46 / 176], [train main loss -1.956008], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 47 / 176], [train main loss -1.954335], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 48 / 176], [train main loss -1.992627], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 49 / 176], [train main loss -1.988688], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 50 / 176], [train main loss -1.946581], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 51 / 176], [train main loss -1.996111], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 52 / 176], [train main loss -2.003271], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 53 / 176], [train main loss -2.005989], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 54 / 176], [train main loss -2.018060], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 55 / 176], [train main loss -1.984354], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 56 / 176], [train main loss -2.009508], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 57 / 176], [train main loss -1.987831], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 58 / 176], [train main loss -2.044057], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 59 / 176], [train main loss -2.062291], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 60 / 176], [train main loss -2.085700], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 61 / 176], [train main loss -2.110809], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 62 / 176], [train main loss -2.097734], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 63 / 176], [train main loss -2.073885], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 64 / 176], [train main loss -2.083082], [lr 0.003371] [batchtime 0.413]
[epoch 116], [iter 65 / 176], [train main loss -2.064268], [lr 0.003371] [batchtime 0.413]
[epoch 116], [iter 66 / 176], [train main loss -2.050713], [lr 0.003371] [batchtime 0.413]
[epoch 116], [iter 67 / 176], [train main loss -2.033738], [lr 0.003371] [batchtime 0.413]
[epoch 116], [iter 68 / 176], [train main loss -2.009268], [lr 0.003371] [batchtime 0.412]
[epoch 116], [iter 69 / 176], [train main loss -2.000969], [lr 0.003371] [batchtime 0.412]
[epoch 116], [iter 70 / 176], [train main loss -2.024334], [lr 0.003371] [batchtime 0.412]
[epoch 116], [iter 71 / 176], [train main loss -2.016465], [lr 0.003371] [batchtime 0.411]
[epoch 116], [iter 72 / 176], [train main loss -1.992092], [lr 0.003371] [batchtime 0.411]
[epoch 116], [iter 73 / 176], [train main loss -1.977384], [lr 0.003371] [batchtime 0.411]
[epoch 116], [iter 74 / 176], [train main loss -1.958724], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 75 / 176], [train main loss -1.942542], [lr 0.003371] [batchtime 0.421]
[epoch 116], [iter 76 / 176], [train main loss -1.918340], [lr 0.003371] [batchtime 0.421]
[epoch 116], [iter 77 / 176], [train main loss -1.910454], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 78 / 176], [train main loss -1.901133], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 79 / 176], [train main loss -1.880659], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 80 / 176], [train main loss -1.840658], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 81 / 176], [train main loss -1.817711], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 82 / 176], [train main loss -1.829634], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 83 / 176], [train main loss -1.837179], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 84 / 176], [train main loss -1.850618], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 85 / 176], [train main loss -1.857381], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 86 / 176], [train main loss -1.878799], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 87 / 176], [train main loss -1.882849], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 88 / 176], [train main loss -1.852775], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 89 / 176], [train main loss -1.832511], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 90 / 176], [train main loss -1.819292], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 91 / 176], [train main loss -1.841872], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 92 / 176], [train main loss -1.834485], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 93 / 176], [train main loss -1.849918], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 94 / 176], [train main loss -1.838157], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 95 / 176], [train main loss -1.819412], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 96 / 176], [train main loss -1.813979], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 97 / 176], [train main loss -1.803124], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 98 / 176], [train main loss -1.802744], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 99 / 176], [train main loss -1.823238], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 100 / 176], [train main loss -1.820241], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 101 / 176], [train main loss -1.808245], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 102 / 176], [train main loss -1.815425], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 103 / 176], [train main loss -1.833674], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 104 / 176], [train main loss -1.863787], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 105 / 176], [train main loss -1.842523], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 106 / 176], [train main loss -1.878971], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 107 / 176], [train main loss -1.857386], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 108 / 176], [train main loss -1.887435], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 109 / 176], [train main loss -1.877916], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 110 / 176], [train main loss -1.890284], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 111 / 176], [train main loss -1.910670], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 112 / 176], [train main loss -1.900460], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 113 / 176], [train main loss -1.891769], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 114 / 176], [train main loss -1.894851], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 115 / 176], [train main loss -1.899302], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 116 / 176], [train main loss -1.922675], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 117 / 176], [train main loss -1.907421], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 118 / 176], [train main loss -1.909581], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 119 / 176], [train main loss -1.906833], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 120 / 176], [train main loss -1.916191], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 121 / 176], [train main loss -1.929150], [lr 0.003371] [batchtime 0.414]
[epoch 116], [iter 122 / 176], [train main loss -1.947359], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 123 / 176], [train main loss -1.965946], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 124 / 176], [train main loss -1.967582], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 125 / 176], [train main loss -1.968851], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 126 / 176], [train main loss -1.973284], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 127 / 176], [train main loss -1.963139], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 128 / 176], [train main loss -1.957781], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 129 / 176], [train main loss -1.954097], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 130 / 176], [train main loss -1.974158], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 131 / 176], [train main loss -1.942504], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 132 / 176], [train main loss -1.936083], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 133 / 176], [train main loss -1.923133], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 134 / 176], [train main loss -1.922711], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 135 / 176], [train main loss -1.914478], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 136 / 176], [train main loss -1.903654], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 137 / 176], [train main loss -1.913882], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 138 / 176], [train main loss -1.915213], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 139 / 176], [train main loss -1.909966], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 140 / 176], [train main loss -1.911253], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 141 / 176], [train main loss -1.896861], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 142 / 176], [train main loss -1.899272], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 143 / 176], [train main loss -1.905799], [lr 0.003371] [batchtime 0.416]
[epoch 116], [iter 144 / 176], [train main loss -1.898292], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 145 / 176], [train main loss -1.900223], [lr 0.003371] [batchtime 0.415]
[epoch 116], [iter 146 / 176], [train main loss -1.897772], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 147 / 176], [train main loss -1.885957], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 148 / 176], [train main loss -1.892528], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 149 / 176], [train main loss -1.885265], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 150 / 176], [train main loss -1.880656], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 151 / 176], [train main loss -1.869237], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 152 / 176], [train main loss -1.855593], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 153 / 176], [train main loss -1.865197], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 154 / 176], [train main loss -1.883483], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 155 / 176], [train main loss -1.882971], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 156 / 176], [train main loss -1.883580], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 157 / 176], [train main loss -1.907926], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 158 / 176], [train main loss -1.910481], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 159 / 176], [train main loss -1.891471], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 160 / 176], [train main loss -1.892449], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 161 / 176], [train main loss -1.906628], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 162 / 176], [train main loss -1.909862], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 163 / 176], [train main loss -1.917680], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 164 / 176], [train main loss -1.915753], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 165 / 176], [train main loss -1.908538], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 166 / 176], [train main loss -1.905723], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 167 / 176], [train main loss -1.914923], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 168 / 176], [train main loss -1.917160], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 169 / 176], [train main loss -1.922438], [lr 0.003371] [batchtime 0.417]
[epoch 116], [iter 170 / 176], [train main loss -1.933214], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 171 / 176], [train main loss -1.922415], [lr 0.003371] [batchtime 0.42]
[epoch 116], [iter 172 / 176], [train main loss -1.920916], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 173 / 176], [train main loss -1.918910], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 174 / 176], [train main loss -1.908163], [lr 0.003371] [batchtime 0.419]
[epoch 116], [iter 175 / 176], [train main loss -1.908882], [lr 0.003371] [batchtime 0.418]
[epoch 116], [iter 176 / 176], [train main loss -1.906187], [lr 0.003371] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.39  35.75    0.02  0.04         0.98      0.96
   1  sidewalk          67.45   5.02    0.31  0.17         0.76      0.86
   2  building          86.08  24.56    0.08  0.08         0.92      0.93
   3  wall              17.98   0.15    2.91  1.65         0.26      0.38
   4  fence             22.77   0.33    2.81  0.59         0.26      0.63
   5  pole              38.96   0.58    0.95  0.62         0.51      0.62
   6  traffic light     18.25   0.03    3.72  0.76         0.21      0.57
   7  traffic sign      27.41   0.17    2.30  0.35         0.30      0.74
   8  vegetation        83.01  11.73    0.05  0.15         0.95      0.87
   9  terrain           40.60   0.41    0.81  0.65         0.55      0.61
  10  sky               93.56   3.76    0.03  0.04         0.97      0.96
  11  person            53.87   1.14    0.34  0.51         0.74      0.66
  12  rider              7.27   0.01   11.58  1.18         0.08      0.46
  13  car               86.05   6.71    0.05  0.11         0.95      0.90
  14  truck              0.68   0.00  144.75  0.40         0.01      0.71
  15  bus               13.74   0.04    1.24  5.04         0.45      0.17
  16  train             35.73   0.10    0.86  0.94         0.54      0.52
  17  motorcycle         3.35   0.00   28.28  0.58         0.03      0.63
  18  bicycle           38.88   0.25    0.54  1.04         0.65      0.49
Mean: 43.69
-----------------------------------------------------------------------------------------------------------
this : [epoch 116], [val loss 0.31539], [acc 0.90746], [acc_cls 0.53340], [mean_iu 0.43686], [fwavacc 0.84000]
best : [epoch 112], [val loss 0.29958], [acc 0.90965], [acc_cls 0.53392], [mean_iu 0.43907], [fwavacc 0.84506]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 117], [iter 1 / 176], [train main loss -3.330779], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 2 / 176], [train main loss -3.449400], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 3 / 176], [train main loss -3.435819], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 4 / 176], [train main loss -2.993161], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 5 / 176], [train main loss -2.942517], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 6 / 176], [train main loss -2.602219], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 7 / 176], [train main loss -2.355721], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 8 / 176], [train main loss -2.365085], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 9 / 176], [train main loss -2.354518], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 10 / 176], [train main loss -2.180328], [lr 0.003314] [batchtime 0]
[epoch 117], [iter 11 / 176], [train main loss -1.870191], [lr 0.003314] [batchtime 0.361]
[epoch 117], [iter 12 / 176], [train main loss -1.884248], [lr 0.003314] [batchtime 0.375]
[epoch 117], [iter 13 / 176], [train main loss -1.795240], [lr 0.003314] [batchtime 0.382]
[epoch 117], [iter 14 / 176], [train main loss -1.989152], [lr 0.003314] [batchtime 0.384]
[epoch 117], [iter 15 / 176], [train main loss -1.977618], [lr 0.003314] [batchtime 0.386]
[epoch 117], [iter 16 / 176], [train main loss -1.993844], [lr 0.003314] [batchtime 0.388]
[epoch 117], [iter 17 / 176], [train main loss -1.808885], [lr 0.003314] [batchtime 0.387]
[epoch 117], [iter 18 / 176], [train main loss -1.753117], [lr 0.003314] [batchtime 0.388]
[epoch 117], [iter 19 / 176], [train main loss -1.653619], [lr 0.003314] [batchtime 0.389]
[epoch 117], [iter 20 / 176], [train main loss -1.711620], [lr 0.003314] [batchtime 0.39]
[epoch 117], [iter 21 / 176], [train main loss -1.736348], [lr 0.003314] [batchtime 0.39]
[epoch 117], [iter 22 / 176], [train main loss -1.647403], [lr 0.003314] [batchtime 0.39]
[epoch 117], [iter 23 / 176], [train main loss -1.576507], [lr 0.003314] [batchtime 0.395]
[epoch 117], [iter 24 / 176], [train main loss -1.696766], [lr 0.003314] [batchtime 0.403]
[epoch 117], [iter 25 / 176], [train main loss -1.698247], [lr 0.003314] [batchtime 0.403]
[epoch 117], [iter 26 / 176], [train main loss -1.778070], [lr 0.003314] [batchtime 0.402]
[epoch 117], [iter 27 / 176], [train main loss -1.703635], [lr 0.003314] [batchtime 0.401]
[epoch 117], [iter 28 / 176], [train main loss -1.698275], [lr 0.003314] [batchtime 0.401]
[epoch 117], [iter 29 / 176], [train main loss -1.695395], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 30 / 176], [train main loss -1.705510], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 31 / 176], [train main loss -1.819105], [lr 0.003314] [batchtime 0.401]
[epoch 117], [iter 32 / 176], [train main loss -1.742110], [lr 0.003314] [batchtime 0.401]
[epoch 117], [iter 33 / 176], [train main loss -1.757518], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 34 / 176], [train main loss -1.757707], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 35 / 176], [train main loss -1.703401], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 36 / 176], [train main loss -1.727145], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 37 / 176], [train main loss -1.727441], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 38 / 176], [train main loss -1.682574], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 39 / 176], [train main loss -1.600794], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 40 / 176], [train main loss -1.555586], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 41 / 176], [train main loss -1.578603], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 42 / 176], [train main loss -1.562021], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 43 / 176], [train main loss -1.574911], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 44 / 176], [train main loss -1.590095], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 45 / 176], [train main loss -1.662258], [lr 0.003314] [batchtime 0.4]
[epoch 117], [iter 46 / 176], [train main loss -1.661033], [lr 0.003314] [batchtime 0.399]
[epoch 117], [iter 47 / 176], [train main loss -1.602858], [lr 0.003314] [batchtime 0.399]
[epoch 117], [iter 48 / 176], [train main loss -1.628801], [lr 0.003314] [batchtime 0.403]
[epoch 117], [iter 49 / 176], [train main loss -1.636219], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 50 / 176], [train main loss -1.670841], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 51 / 176], [train main loss -1.644225], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 52 / 176], [train main loss -1.588523], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 53 / 176], [train main loss -1.619282], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 54 / 176], [train main loss -1.621054], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 55 / 176], [train main loss -1.628980], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 56 / 176], [train main loss -1.639733], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 57 / 176], [train main loss -1.684302], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 58 / 176], [train main loss -1.751533], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 59 / 176], [train main loss -1.768424], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 60 / 176], [train main loss -1.821240], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 61 / 176], [train main loss -1.819557], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 62 / 176], [train main loss -1.866127], [lr 0.003314] [batchtime 0.417]
[epoch 117], [iter 63 / 176], [train main loss -1.867713], [lr 0.003314] [batchtime 0.417]
[epoch 117], [iter 64 / 176], [train main loss -1.839592], [lr 0.003314] [batchtime 0.417]
[epoch 117], [iter 65 / 176], [train main loss -1.853502], [lr 0.003314] [batchtime 0.416]
[epoch 117], [iter 66 / 176], [train main loss -1.840688], [lr 0.003314] [batchtime 0.416]
[epoch 117], [iter 67 / 176], [train main loss -1.849111], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 68 / 176], [train main loss -1.878725], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 69 / 176], [train main loss -1.845468], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 70 / 176], [train main loss -1.826765], [lr 0.003314] [batchtime 0.414]
[epoch 117], [iter 71 / 176], [train main loss -1.878470], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 72 / 176], [train main loss -1.868130], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 73 / 176], [train main loss -1.859756], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 74 / 176], [train main loss -1.869587], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 75 / 176], [train main loss -1.866995], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 76 / 176], [train main loss -1.853137], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 77 / 176], [train main loss -1.803344], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 78 / 176], [train main loss -1.785803], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 79 / 176], [train main loss -1.784944], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 80 / 176], [train main loss -1.823753], [lr 0.003314] [batchtime 0.417]
[epoch 117], [iter 81 / 176], [train main loss -1.856753], [lr 0.003314] [batchtime 0.417]
[epoch 117], [iter 82 / 176], [train main loss -1.862936], [lr 0.003314] [batchtime 0.417]
[epoch 117], [iter 83 / 176], [train main loss -1.872065], [lr 0.003314] [batchtime 0.416]
[epoch 117], [iter 84 / 176], [train main loss -1.867961], [lr 0.003314] [batchtime 0.416]
[epoch 117], [iter 85 / 176], [train main loss -1.847903], [lr 0.003314] [batchtime 0.416]
[epoch 117], [iter 86 / 176], [train main loss -1.845760], [lr 0.003314] [batchtime 0.416]
[epoch 117], [iter 87 / 176], [train main loss -1.822705], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 88 / 176], [train main loss -1.805202], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 89 / 176], [train main loss -1.810150], [lr 0.003314] [batchtime 0.415]
[epoch 117], [iter 90 / 176], [train main loss -1.807788], [lr 0.003314] [batchtime 0.414]
[epoch 117], [iter 91 / 176], [train main loss -1.807009], [lr 0.003314] [batchtime 0.414]
[epoch 117], [iter 92 / 176], [train main loss -1.801777], [lr 0.003314] [batchtime 0.414]
[epoch 117], [iter 93 / 176], [train main loss -1.801288], [lr 0.003314] [batchtime 0.414]
[epoch 117], [iter 94 / 176], [train main loss -1.803266], [lr 0.003314] [batchtime 0.413]
[epoch 117], [iter 95 / 176], [train main loss -1.796171], [lr 0.003314] [batchtime 0.413]
[epoch 117], [iter 96 / 176], [train main loss -1.792688], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 97 / 176], [train main loss -1.808874], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 98 / 176], [train main loss -1.804388], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 99 / 176], [train main loss -1.796017], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 100 / 176], [train main loss -1.807275], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 101 / 176], [train main loss -1.805154], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 102 / 176], [train main loss -1.803450], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 103 / 176], [train main loss -1.800649], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 104 / 176], [train main loss -1.807488], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 105 / 176], [train main loss -1.833155], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 106 / 176], [train main loss -1.840352], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 107 / 176], [train main loss -1.822498], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 108 / 176], [train main loss -1.832118], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 109 / 176], [train main loss -1.822432], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 110 / 176], [train main loss -1.822141], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 111 / 176], [train main loss -1.817599], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 112 / 176], [train main loss -1.815724], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 113 / 176], [train main loss -1.817680], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 114 / 176], [train main loss -1.811249], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 115 / 176], [train main loss -1.816387], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 116 / 176], [train main loss -1.818090], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 117 / 176], [train main loss -1.800563], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 118 / 176], [train main loss -1.803578], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 119 / 176], [train main loss -1.810174], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 120 / 176], [train main loss -1.800697], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 121 / 176], [train main loss -1.812293], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 122 / 176], [train main loss -1.779932], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 123 / 176], [train main loss -1.776279], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 124 / 176], [train main loss -1.754058], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 125 / 176], [train main loss -1.741269], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 126 / 176], [train main loss -1.754854], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 127 / 176], [train main loss -1.749539], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 128 / 176], [train main loss -1.767530], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 129 / 176], [train main loss -1.783180], [lr 0.003314] [batchtime 0.421]
[epoch 117], [iter 130 / 176], [train main loss -1.793994], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 131 / 176], [train main loss -1.780605], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 132 / 176], [train main loss -1.786188], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 133 / 176], [train main loss -1.768430], [lr 0.003314] [batchtime 0.42]
[epoch 117], [iter 134 / 176], [train main loss -1.759082], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 135 / 176], [train main loss -1.749757], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 136 / 176], [train main loss -1.755396], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 137 / 176], [train main loss -1.757912], [lr 0.003314] [batchtime 0.419]
[epoch 117], [iter 138 / 176], [train main loss -1.772699], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 139 / 176], [train main loss -1.764038], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 140 / 176], [train main loss -1.759226], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 141 / 176], [train main loss -1.760153], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 142 / 176], [train main loss -1.763250], [lr 0.003314] [batchtime 0.418]
[epoch 117], [iter 143 / 176], [train main loss -1.780560], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 144 / 176], [train main loss -1.791656], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 145 / 176], [train main loss -1.801196], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 146 / 176], [train main loss -1.809342], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 147 / 176], [train main loss -1.801207], [lr 0.003314] [batchtime 0.426]
[epoch 117], [iter 148 / 176], [train main loss -1.797669], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 149 / 176], [train main loss -1.814538], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 150 / 176], [train main loss -1.813606], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 151 / 176], [train main loss -1.831930], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 152 / 176], [train main loss -1.838798], [lr 0.003314] [batchtime 0.425]
[epoch 117], [iter 153 / 176], [train main loss -1.834705], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 154 / 176], [train main loss -1.829676], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 155 / 176], [train main loss -1.843482], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 156 / 176], [train main loss -1.841333], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 157 / 176], [train main loss -1.863919], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 158 / 176], [train main loss -1.856154], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 159 / 176], [train main loss -1.852614], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 160 / 176], [train main loss -1.847479], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 161 / 176], [train main loss -1.833494], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 162 / 176], [train main loss -1.822901], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 163 / 176], [train main loss -1.839606], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 164 / 176], [train main loss -1.836102], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 165 / 176], [train main loss -1.837586], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 166 / 176], [train main loss -1.834252], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 167 / 176], [train main loss -1.830471], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 168 / 176], [train main loss -1.831021], [lr 0.003314] [batchtime 0.424]
[epoch 117], [iter 169 / 176], [train main loss -1.838041], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 170 / 176], [train main loss -1.834475], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 171 / 176], [train main loss -1.839445], [lr 0.003314] [batchtime 0.423]
[epoch 117], [iter 172 / 176], [train main loss -1.843853], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 173 / 176], [train main loss -1.862401], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 174 / 176], [train main loss -1.864161], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 175 / 176], [train main loss -1.880102], [lr 0.003314] [batchtime 0.422]
[epoch 117], [iter 176 / 176], [train main loss -1.893088], [lr 0.003314] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.88  35.55   0.02  0.03         0.98      0.97
   1  sidewalk          69.91   5.39   0.22  0.21         0.82      0.83
   2  building          86.61  25.22   0.05  0.10         0.95      0.91
   3  wall              18.17   0.14   3.38  1.13         0.23      0.47
   4  fence             22.26   0.32   2.97  0.52         0.25      0.66
   5  pole              38.66   0.55   1.08  0.50         0.48      0.67
   6  traffic light     14.50   0.02   5.48  0.41         0.15      0.71
   7  traffic sign      22.12   0.13   3.30  0.23         0.23      0.82
   8  vegetation        83.94  11.67   0.06  0.13         0.94      0.88
   9  terrain           38.15   0.33   1.20  0.42         0.45      0.70
  10  sky               93.80   3.74   0.04  0.03         0.96      0.97
  11  person            54.24   1.09   0.40  0.44         0.71      0.69
  12  rider              6.28   0.01  14.12  0.81         0.07      0.55
  13  car               86.48   6.67   0.06  0.09         0.94      0.91
  14  truck              1.47   0.00  66.66  0.48         0.01      0.67
  15  bus               14.59   0.03   2.25  3.60         0.31      0.22
  16  train             46.12   0.11   0.68  0.49         0.60      0.67
  17  motorcycle         3.55   0.00  26.72  0.42         0.04      0.71
  18  bicycle           39.02   0.26   0.48  1.09         0.68      0.48
Mean: 43.93
-----------------------------------------------------------------------------------------------------------
this : [epoch 117], [val loss 0.30778], [acc 0.91235], [acc_cls 0.51634], [mean_iu 0.43934], [fwavacc 0.84602]
best : [epoch 117], [val loss 0.30778], [acc 0.91235], [acc_cls 0.51634], [mean_iu 0.43934], [fwavacc 0.84602]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 118], [iter 1 / 176], [train main loss -0.998019], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 2 / 176], [train main loss -0.767567], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 3 / 176], [train main loss -1.572721], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 4 / 176], [train main loss -2.219240], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 5 / 176], [train main loss -1.642276], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 6 / 176], [train main loss -1.600798], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 7 / 176], [train main loss -1.878996], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 8 / 176], [train main loss -1.911412], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 9 / 176], [train main loss -1.980213], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 10 / 176], [train main loss -2.024634], [lr 0.003257] [batchtime 0]
[epoch 118], [iter 11 / 176], [train main loss -2.090961], [lr 0.003257] [batchtime 0.39]
[epoch 118], [iter 12 / 176], [train main loss -2.098128], [lr 0.003257] [batchtime 0.395]
[epoch 118], [iter 13 / 176], [train main loss -1.700470], [lr 0.003257] [batchtime 0.394]
[epoch 118], [iter 14 / 176], [train main loss -1.861803], [lr 0.003257] [batchtime 0.397]
[epoch 118], [iter 15 / 176], [train main loss -1.759341], [lr 0.003257] [batchtime 0.438]
[epoch 118], [iter 16 / 176], [train main loss -1.831889], [lr 0.003257] [batchtime 0.459]
[epoch 118], [iter 17 / 176], [train main loss -1.869274], [lr 0.003257] [batchtime 0.449]
[epoch 118], [iter 18 / 176], [train main loss -1.845357], [lr 0.003257] [batchtime 0.442]
[epoch 118], [iter 19 / 176], [train main loss -1.965461], [lr 0.003257] [batchtime 0.437]
[epoch 118], [iter 20 / 176], [train main loss -1.945150], [lr 0.003257] [batchtime 0.433]
[epoch 118], [iter 21 / 176], [train main loss -2.088529], [lr 0.003257] [batchtime 0.431]
[epoch 118], [iter 22 / 176], [train main loss -2.058800], [lr 0.003257] [batchtime 0.428]
[epoch 118], [iter 23 / 176], [train main loss -2.013136], [lr 0.003257] [batchtime 0.425]
[epoch 118], [iter 24 / 176], [train main loss -2.110278], [lr 0.003257] [batchtime 0.423]
[epoch 118], [iter 25 / 176], [train main loss -2.018211], [lr 0.003257] [batchtime 0.422]
[epoch 118], [iter 26 / 176], [train main loss -1.949763], [lr 0.003257] [batchtime 0.42]
[epoch 118], [iter 27 / 176], [train main loss -1.957961], [lr 0.003257] [batchtime 0.418]
[epoch 118], [iter 28 / 176], [train main loss -1.904777], [lr 0.003257] [batchtime 0.418]
[epoch 118], [iter 29 / 176], [train main loss -1.915591], [lr 0.003257] [batchtime 0.417]
[epoch 118], [iter 30 / 176], [train main loss -1.981319], [lr 0.003257] [batchtime 0.416]
[epoch 118], [iter 31 / 176], [train main loss -2.018637], [lr 0.003257] [batchtime 0.415]
[epoch 118], [iter 32 / 176], [train main loss -1.983853], [lr 0.003257] [batchtime 0.414]
[epoch 118], [iter 33 / 176], [train main loss -2.009176], [lr 0.003257] [batchtime 0.414]
[epoch 118], [iter 34 / 176], [train main loss -1.918809], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 35 / 176], [train main loss -1.997801], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 36 / 176], [train main loss -2.028068], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 37 / 176], [train main loss -2.012314], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 38 / 176], [train main loss -2.001762], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 39 / 176], [train main loss -2.021925], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 40 / 176], [train main loss -2.032538], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 41 / 176], [train main loss -2.038686], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 42 / 176], [train main loss -2.032184], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 43 / 176], [train main loss -2.016385], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 44 / 176], [train main loss -2.040387], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 45 / 176], [train main loss -2.022511], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 46 / 176], [train main loss -2.048363], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 47 / 176], [train main loss -2.089049], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 48 / 176], [train main loss -2.084351], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 49 / 176], [train main loss -2.082536], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 50 / 176], [train main loss -2.078908], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 51 / 176], [train main loss -2.081202], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 52 / 176], [train main loss -2.041895], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 53 / 176], [train main loss -2.056232], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 54 / 176], [train main loss -2.048271], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 55 / 176], [train main loss -2.046216], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 56 / 176], [train main loss -2.022204], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 57 / 176], [train main loss -2.067750], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 58 / 176], [train main loss -2.071955], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 59 / 176], [train main loss -2.075909], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 60 / 176], [train main loss -2.072823], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 61 / 176], [train main loss -2.089475], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 62 / 176], [train main loss -2.092709], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 63 / 176], [train main loss -2.141723], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 64 / 176], [train main loss -2.139604], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 65 / 176], [train main loss -2.115878], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 66 / 176], [train main loss -2.085397], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 67 / 176], [train main loss -2.103049], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 68 / 176], [train main loss -2.128610], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 69 / 176], [train main loss -2.110566], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 70 / 176], [train main loss -2.132349], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 71 / 176], [train main loss -2.111367], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 72 / 176], [train main loss -2.079055], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 73 / 176], [train main loss -2.059601], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 74 / 176], [train main loss -2.094827], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 75 / 176], [train main loss -2.087912], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 76 / 176], [train main loss -2.088724], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 77 / 176], [train main loss -2.081071], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 78 / 176], [train main loss -2.094207], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 79 / 176], [train main loss -2.091567], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 80 / 176], [train main loss -2.092967], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 81 / 176], [train main loss -2.092072], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 82 / 176], [train main loss -2.067919], [lr 0.003257] [batchtime 0.406]
[epoch 118], [iter 83 / 176], [train main loss -2.102140], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 84 / 176], [train main loss -2.103047], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 85 / 176], [train main loss -2.120029], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 86 / 176], [train main loss -2.115546], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 87 / 176], [train main loss -2.148684], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 88 / 176], [train main loss -2.130044], [lr 0.003257] [batchtime 0.405]
[epoch 118], [iter 89 / 176], [train main loss -2.121298], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 90 / 176], [train main loss -2.080499], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 91 / 176], [train main loss -2.074470], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 92 / 176], [train main loss -2.060486], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 93 / 176], [train main loss -2.050416], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 94 / 176], [train main loss -2.043222], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 95 / 176], [train main loss -2.064493], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 96 / 176], [train main loss -2.054436], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 97 / 176], [train main loss -2.053074], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 98 / 176], [train main loss -2.033746], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 99 / 176], [train main loss -2.027558], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 100 / 176], [train main loss -2.030448], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 101 / 176], [train main loss -2.034264], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 102 / 176], [train main loss -2.020705], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 103 / 176], [train main loss -2.000591], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 104 / 176], [train main loss -1.998055], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 105 / 176], [train main loss -1.998065], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 106 / 176], [train main loss -1.986201], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 107 / 176], [train main loss -1.985384], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 108 / 176], [train main loss -1.976151], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 109 / 176], [train main loss -1.966862], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 110 / 176], [train main loss -1.969247], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 111 / 176], [train main loss -1.972812], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 112 / 176], [train main loss -1.967957], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 113 / 176], [train main loss -1.975945], [lr 0.003257] [batchtime 0.407]
[epoch 118], [iter 114 / 176], [train main loss -1.982079], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 115 / 176], [train main loss -1.993023], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 116 / 176], [train main loss -1.976364], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 117 / 176], [train main loss -1.980858], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 118 / 176], [train main loss -1.986646], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 119 / 176], [train main loss -1.991550], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 120 / 176], [train main loss -1.986462], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 121 / 176], [train main loss -1.980854], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 122 / 176], [train main loss -1.993613], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 123 / 176], [train main loss -2.006163], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 124 / 176], [train main loss -2.005281], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 125 / 176], [train main loss -1.969805], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 126 / 176], [train main loss -1.994063], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 127 / 176], [train main loss -1.973177], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 128 / 176], [train main loss -1.963538], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 129 / 176], [train main loss -1.972620], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 130 / 176], [train main loss -1.982679], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 131 / 176], [train main loss -1.962701], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 132 / 176], [train main loss -1.978544], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 133 / 176], [train main loss -1.967482], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 134 / 176], [train main loss -1.970761], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 135 / 176], [train main loss -1.970912], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 136 / 176], [train main loss -1.972748], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 137 / 176], [train main loss -1.976382], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 138 / 176], [train main loss -1.999408], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 139 / 176], [train main loss -2.016047], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 140 / 176], [train main loss -2.012256], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 141 / 176], [train main loss -2.016446], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 142 / 176], [train main loss -2.032739], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 143 / 176], [train main loss -2.039966], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 144 / 176], [train main loss -2.037732], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 145 / 176], [train main loss -2.042712], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 146 / 176], [train main loss -2.040095], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 147 / 176], [train main loss -2.015666], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 148 / 176], [train main loss -2.018628], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 149 / 176], [train main loss -2.004642], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 150 / 176], [train main loss -2.000804], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 151 / 176], [train main loss -2.022427], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 152 / 176], [train main loss -2.012614], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 153 / 176], [train main loss -2.004482], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 154 / 176], [train main loss -2.003964], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 155 / 176], [train main loss -2.027893], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 156 / 176], [train main loss -2.019734], [lr 0.003257] [batchtime 0.409]
[epoch 118], [iter 157 / 176], [train main loss -2.009461], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 158 / 176], [train main loss -2.020827], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 159 / 176], [train main loss -2.018158], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 160 / 176], [train main loss -2.013129], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 161 / 176], [train main loss -2.008960], [lr 0.003257] [batchtime 0.408]
[epoch 118], [iter 162 / 176], [train main loss -2.013524], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 163 / 176], [train main loss -2.021323], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 164 / 176], [train main loss -2.015243], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 165 / 176], [train main loss -2.013716], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 166 / 176], [train main loss -2.028856], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 167 / 176], [train main loss -2.024005], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 168 / 176], [train main loss -2.042634], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 169 / 176], [train main loss -2.039518], [lr 0.003257] [batchtime 0.412]
[epoch 118], [iter 170 / 176], [train main loss -2.035818], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 171 / 176], [train main loss -2.044478], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 172 / 176], [train main loss -2.046666], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 173 / 176], [train main loss -2.044673], [lr 0.003257] [batchtime 0.411]
[epoch 118], [iter 174 / 176], [train main loss -2.031257], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 175 / 176], [train main loss -2.036982], [lr 0.003257] [batchtime 0.41]
[epoch 118], [iter 176 / 176], [train main loss -2.036111], [lr 0.003257] [batchtime 0.41]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.58  35.52   0.02  0.03         0.98      0.97
   1  sidewalk          68.87   5.26   0.25  0.20         0.80      0.83
   2  building          86.09  24.75   0.07  0.09         0.93      0.92
   3  wall              19.43   0.17   2.45  1.70         0.29      0.37
   4  fence             26.65   0.46   1.77  0.98         0.36      0.50
   5  pole              38.90   0.58   0.97  0.61         0.51      0.62
   6  traffic light     15.24   0.02   5.08  0.48         0.16      0.67
   7  traffic sign      25.37   0.15   2.65  0.29         0.27      0.78
   8  vegetation        83.52  11.68   0.06  0.14         0.95      0.88
   9  terrain           41.24   0.39   0.90  0.53         0.53      0.66
  10  sky               93.72   3.74   0.04  0.03         0.97      0.97
  11  person            53.82   1.04   0.48  0.38         0.68      0.73
  12  rider              8.56   0.01   9.53  1.16         0.09      0.46
  13  car               85.97   6.65   0.06  0.10         0.94      0.91
  14  truck              1.53   0.01  63.50  0.66         0.02      0.60
  15  bus               15.20   0.04   0.95  4.63         0.51      0.18
  16  train             36.13   0.10   0.74  1.03         0.58      0.49
  17  motorcycle         4.07   0.00  22.87  0.68         0.04      0.59
  18  bicycle           39.34   0.25   0.54  1.00         0.65      0.50
Mean: 44.12
-----------------------------------------------------------------------------------------------------------
this : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 119], [iter 1 / 176], [train main loss -0.521279], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 2 / 176], [train main loss -1.285440], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 3 / 176], [train main loss -2.085201], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 4 / 176], [train main loss -2.302182], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 5 / 176], [train main loss -2.047731], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 6 / 176], [train main loss -2.270178], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 7 / 176], [train main loss -2.290138], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 8 / 176], [train main loss -2.332712], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 9 / 176], [train main loss -2.409946], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 10 / 176], [train main loss -2.172078], [lr 0.003200] [batchtime 0]
[epoch 119], [iter 11 / 176], [train main loss -2.312708], [lr 0.003200] [batchtime 0.364]
[epoch 119], [iter 12 / 176], [train main loss -2.511259], [lr 0.003200] [batchtime 0.385]
[epoch 119], [iter 13 / 176], [train main loss -2.528304], [lr 0.003200] [batchtime 0.396]
[epoch 119], [iter 14 / 176], [train main loss -2.376020], [lr 0.003200] [batchtime 0.398]
[epoch 119], [iter 15 / 176], [train main loss -2.328670], [lr 0.003200] [batchtime 0.422]
[epoch 119], [iter 16 / 176], [train main loss -2.272400], [lr 0.003200] [batchtime 0.447]
[epoch 119], [iter 17 / 176], [train main loss -2.085341], [lr 0.003200] [batchtime 0.438]
[epoch 119], [iter 18 / 176], [train main loss -2.147555], [lr 0.003200] [batchtime 0.433]
[epoch 119], [iter 19 / 176], [train main loss -2.159220], [lr 0.003200] [batchtime 0.428]
[epoch 119], [iter 20 / 176], [train main loss -2.152974], [lr 0.003200] [batchtime 0.425]
[epoch 119], [iter 21 / 176], [train main loss -2.083632], [lr 0.003200] [batchtime 0.422]
[epoch 119], [iter 22 / 176], [train main loss -2.052388], [lr 0.003200] [batchtime 0.421]
[epoch 119], [iter 23 / 176], [train main loss -2.012193], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 24 / 176], [train main loss -2.099414], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 25 / 176], [train main loss -2.149788], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 26 / 176], [train main loss -2.213735], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 27 / 176], [train main loss -2.231332], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 28 / 176], [train main loss -2.227229], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 29 / 176], [train main loss -2.239242], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 30 / 176], [train main loss -2.256263], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 31 / 176], [train main loss -2.316340], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 32 / 176], [train main loss -2.264688], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 33 / 176], [train main loss -2.303588], [lr 0.003200] [batchtime 0.408]
[epoch 119], [iter 34 / 176], [train main loss -2.289448], [lr 0.003200] [batchtime 0.408]
[epoch 119], [iter 35 / 176], [train main loss -2.362709], [lr 0.003200] [batchtime 0.407]
[epoch 119], [iter 36 / 176], [train main loss -2.335144], [lr 0.003200] [batchtime 0.407]
[epoch 119], [iter 37 / 176], [train main loss -2.340693], [lr 0.003200] [batchtime 0.406]
[epoch 119], [iter 38 / 176], [train main loss -2.252878], [lr 0.003200] [batchtime 0.406]
[epoch 119], [iter 39 / 176], [train main loss -2.221073], [lr 0.003200] [batchtime 0.405]
[epoch 119], [iter 40 / 176], [train main loss -2.291333], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 41 / 176], [train main loss -2.322734], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 42 / 176], [train main loss -2.402203], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 43 / 176], [train main loss -2.359664], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 44 / 176], [train main loss -2.354703], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 45 / 176], [train main loss -2.329216], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 46 / 176], [train main loss -2.342296], [lr 0.003200] [batchtime 0.414]
[epoch 119], [iter 47 / 176], [train main loss -2.392813], [lr 0.003200] [batchtime 0.414]
[epoch 119], [iter 48 / 176], [train main loss -2.428079], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 49 / 176], [train main loss -2.356943], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 50 / 176], [train main loss -2.385330], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 51 / 176], [train main loss -2.444964], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 52 / 176], [train main loss -2.451739], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 53 / 176], [train main loss -2.469708], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 54 / 176], [train main loss -2.440558], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 55 / 176], [train main loss -2.379984], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 56 / 176], [train main loss -2.359737], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 57 / 176], [train main loss -2.316444], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 58 / 176], [train main loss -2.269153], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 59 / 176], [train main loss -2.316344], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 60 / 176], [train main loss -2.326034], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 61 / 176], [train main loss -2.331344], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 62 / 176], [train main loss -2.294963], [lr 0.003200] [batchtime 0.408]
[epoch 119], [iter 63 / 176], [train main loss -2.315935], [lr 0.003200] [batchtime 0.408]
[epoch 119], [iter 64 / 176], [train main loss -2.396427], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 65 / 176], [train main loss -2.399303], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 66 / 176], [train main loss -2.433273], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 67 / 176], [train main loss -2.439562], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 68 / 176], [train main loss -2.442960], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 69 / 176], [train main loss -2.454916], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 70 / 176], [train main loss -2.427309], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 71 / 176], [train main loss -2.394262], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 72 / 176], [train main loss -2.392879], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 73 / 176], [train main loss -2.374020], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 74 / 176], [train main loss -2.351922], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 75 / 176], [train main loss -2.384688], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 76 / 176], [train main loss -2.400596], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 77 / 176], [train main loss -2.386861], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 78 / 176], [train main loss -2.344598], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 79 / 176], [train main loss -2.358886], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 80 / 176], [train main loss -2.359308], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 81 / 176], [train main loss -2.361628], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 82 / 176], [train main loss -2.386461], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 83 / 176], [train main loss -2.364967], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 84 / 176], [train main loss -2.384887], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 85 / 176], [train main loss -2.365617], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 86 / 176], [train main loss -2.371170], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 87 / 176], [train main loss -2.371268], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 88 / 176], [train main loss -2.379506], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 89 / 176], [train main loss -2.360225], [lr 0.003200] [batchtime 0.414]
[epoch 119], [iter 90 / 176], [train main loss -2.341478], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 91 / 176], [train main loss -2.350321], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 92 / 176], [train main loss -2.331817], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 93 / 176], [train main loss -2.340331], [lr 0.003200] [batchtime 0.413]
[epoch 119], [iter 94 / 176], [train main loss -2.341363], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 95 / 176], [train main loss -2.369758], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 96 / 176], [train main loss -2.346823], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 97 / 176], [train main loss -2.376592], [lr 0.003200] [batchtime 0.412]
[epoch 119], [iter 98 / 176], [train main loss -2.380693], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 99 / 176], [train main loss -2.385921], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 100 / 176], [train main loss -2.389444], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 101 / 176], [train main loss -2.390428], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 102 / 176], [train main loss -2.383650], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 103 / 176], [train main loss -2.392089], [lr 0.003200] [batchtime 0.411]
[epoch 119], [iter 104 / 176], [train main loss -2.367923], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 105 / 176], [train main loss -2.338697], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 106 / 176], [train main loss -2.352809], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 107 / 176], [train main loss -2.374550], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 108 / 176], [train main loss -2.375959], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 109 / 176], [train main loss -2.387835], [lr 0.003200] [batchtime 0.41]
[epoch 119], [iter 110 / 176], [train main loss -2.380064], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 111 / 176], [train main loss -2.399357], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 112 / 176], [train main loss -2.383001], [lr 0.003200] [batchtime 0.409]
[epoch 119], [iter 113 / 176], [train main loss -2.380158], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 114 / 176], [train main loss -2.355527], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 115 / 176], [train main loss -2.366062], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 116 / 176], [train main loss -2.375061], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 117 / 176], [train main loss -2.366771], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 118 / 176], [train main loss -2.369748], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 119 / 176], [train main loss -2.371941], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 120 / 176], [train main loss -2.361770], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 121 / 176], [train main loss -2.366028], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 122 / 176], [train main loss -2.346047], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 123 / 176], [train main loss -2.354132], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 124 / 176], [train main loss -2.361573], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 125 / 176], [train main loss -2.373833], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 126 / 176], [train main loss -2.372802], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 127 / 176], [train main loss -2.397482], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 128 / 176], [train main loss -2.406051], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 129 / 176], [train main loss -2.412389], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 130 / 176], [train main loss -2.408001], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 131 / 176], [train main loss -2.408776], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 132 / 176], [train main loss -2.395552], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 133 / 176], [train main loss -2.404379], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 134 / 176], [train main loss -2.413695], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 135 / 176], [train main loss -2.393190], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 136 / 176], [train main loss -2.393323], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 137 / 176], [train main loss -2.390345], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 138 / 176], [train main loss -2.404942], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 139 / 176], [train main loss -2.388302], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 140 / 176], [train main loss -2.382027], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 141 / 176], [train main loss -2.391513], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 142 / 176], [train main loss -2.391293], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 143 / 176], [train main loss -2.368843], [lr 0.003200] [batchtime 0.417]
[epoch 119], [iter 144 / 176], [train main loss -2.373099], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 145 / 176], [train main loss -2.378489], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 146 / 176], [train main loss -2.375732], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 147 / 176], [train main loss -2.389906], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 148 / 176], [train main loss -2.386356], [lr 0.003200] [batchtime 0.416]
[epoch 119], [iter 149 / 176], [train main loss -2.374023], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 150 / 176], [train main loss -2.363154], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 151 / 176], [train main loss -2.367808], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 152 / 176], [train main loss -2.371780], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 153 / 176], [train main loss -2.386787], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 154 / 176], [train main loss -2.390908], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 155 / 176], [train main loss -2.383612], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 156 / 176], [train main loss -2.394130], [lr 0.003200] [batchtime 0.415]
[epoch 119], [iter 157 / 176], [train main loss -2.403050], [lr 0.003200] [batchtime 0.414]
[epoch 119], [iter 158 / 176], [train main loss -2.412856], [lr 0.003200] [batchtime 0.414]
[epoch 119], [iter 159 / 176], [train main loss -2.420509], [lr 0.003200] [batchtime 0.414]
[epoch 119], [iter 160 / 176], [train main loss -2.426267], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 161 / 176], [train main loss -2.413766], [lr 0.003200] [batchtime 0.421]
[epoch 119], [iter 162 / 176], [train main loss -2.399319], [lr 0.003200] [batchtime 0.421]
[epoch 119], [iter 163 / 176], [train main loss -2.391232], [lr 0.003200] [batchtime 0.42]
[epoch 119], [iter 164 / 176], [train main loss -2.390221], [lr 0.003200] [batchtime 0.42]
[epoch 119], [iter 165 / 176], [train main loss -2.390087], [lr 0.003200] [batchtime 0.42]
[epoch 119], [iter 166 / 176], [train main loss -2.381491], [lr 0.003200] [batchtime 0.42]
[epoch 119], [iter 167 / 176], [train main loss -2.361984], [lr 0.003200] [batchtime 0.42]
[epoch 119], [iter 168 / 176], [train main loss -2.379451], [lr 0.003200] [batchtime 0.42]
[epoch 119], [iter 169 / 176], [train main loss -2.376814], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 170 / 176], [train main loss -2.364543], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 171 / 176], [train main loss -2.350382], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 172 / 176], [train main loss -2.357297], [lr 0.003200] [batchtime 0.419]
[epoch 119], [iter 173 / 176], [train main loss -2.372747], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 174 / 176], [train main loss -2.385295], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 175 / 176], [train main loss -2.381645], [lr 0.003200] [batchtime 0.418]
[epoch 119], [iter 176 / 176], [train main loss -2.369602], [lr 0.003200] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.58  35.60   0.02  0.04         0.98      0.97
   1  sidewalk          68.84   5.23   0.26  0.19         0.79      0.84
   2  building          86.53  24.89   0.07  0.09         0.94      0.92
   3  wall              17.94   0.14   3.17  1.40         0.24      0.42
   4  fence             24.19   0.36   2.49  0.65         0.29      0.61
   5  pole              39.39   0.58   0.96  0.57         0.51      0.64
   6  traffic light     14.31   0.02   5.59  0.40         0.15      0.71
   7  traffic sign      25.45   0.15   2.68  0.25         0.27      0.80
   8  vegetation        83.67  11.71   0.06  0.14         0.95      0.88
   9  terrain           42.38   0.41   0.81  0.55         0.55      0.65
  10  sky               93.59   3.73   0.04  0.03         0.96      0.97
  11  person            53.83   1.04   0.47  0.39         0.68      0.72
  12  rider             10.16   0.01   7.65  1.19         0.12      0.46
  13  car               86.00   6.72   0.05  0.11         0.95      0.90
  14  truck              2.34   0.01  41.22  0.49         0.02      0.67
  15  bus               14.05   0.03   1.49  4.62         0.40      0.18
  16  train             32.32   0.09   0.94  1.16         0.52      0.46
  17  motorcycle         2.99   0.00  32.00  0.48         0.03      0.68
  18  bicycle           36.89   0.27   0.45  1.27         0.69      0.44
Mean: 43.65
-----------------------------------------------------------------------------------------------------------
this : [epoch 119], [val loss 0.31266], [acc 0.90992], [acc_cls 0.52825], [mean_iu 0.43655], [fwavacc 0.84373]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 120], [iter 1 / 176], [train main loss -0.851977], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 2 / 176], [train main loss -0.575811], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 3 / 176], [train main loss -0.719788], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 4 / 176], [train main loss -1.173433], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 5 / 176], [train main loss -1.483975], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 6 / 176], [train main loss -1.338973], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 7 / 176], [train main loss -1.171883], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 8 / 176], [train main loss -1.431483], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 9 / 176], [train main loss -1.299420], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 10 / 176], [train main loss -1.524651], [lr 0.003143] [batchtime 0]
[epoch 120], [iter 11 / 176], [train main loss -1.481311], [lr 0.003143] [batchtime 0.366]
[epoch 120], [iter 12 / 176], [train main loss -1.705360], [lr 0.003143] [batchtime 0.38]
[epoch 120], [iter 13 / 176], [train main loss -1.816373], [lr 0.003143] [batchtime 0.384]
[epoch 120], [iter 14 / 176], [train main loss -1.872449], [lr 0.003143] [batchtime 0.387]
[epoch 120], [iter 15 / 176], [train main loss -1.954491], [lr 0.003143] [batchtime 0.388]
[epoch 120], [iter 16 / 176], [train main loss -1.899728], [lr 0.003143] [batchtime 0.39]
[epoch 120], [iter 17 / 176], [train main loss -1.762069], [lr 0.003143] [batchtime 0.393]
[epoch 120], [iter 18 / 176], [train main loss -1.639412], [lr 0.003143] [batchtime 0.395]
[epoch 120], [iter 19 / 176], [train main loss -1.625319], [lr 0.003143] [batchtime 0.394]
[epoch 120], [iter 20 / 176], [train main loss -1.671408], [lr 0.003143] [batchtime 0.393]
[epoch 120], [iter 21 / 176], [train main loss -1.747861], [lr 0.003143] [batchtime 0.4]
[epoch 120], [iter 22 / 176], [train main loss -1.691577], [lr 0.003143] [batchtime 0.399]
[epoch 120], [iter 23 / 176], [train main loss -1.669689], [lr 0.003143] [batchtime 0.398]
[epoch 120], [iter 24 / 176], [train main loss -1.692617], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 25 / 176], [train main loss -1.758731], [lr 0.003143] [batchtime 0.398]
[epoch 120], [iter 26 / 176], [train main loss -1.713442], [lr 0.003143] [batchtime 0.398]
[epoch 120], [iter 27 / 176], [train main loss -1.728543], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 28 / 176], [train main loss -1.714407], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 29 / 176], [train main loss -1.740930], [lr 0.003143] [batchtime 0.398]
[epoch 120], [iter 30 / 176], [train main loss -1.629884], [lr 0.003143] [batchtime 0.398]
[epoch 120], [iter 31 / 176], [train main loss -1.674915], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 32 / 176], [train main loss -1.661574], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 33 / 176], [train main loss -1.688734], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 34 / 176], [train main loss -1.762204], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 35 / 176], [train main loss -1.849231], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 36 / 176], [train main loss -1.805719], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 37 / 176], [train main loss -1.876765], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 38 / 176], [train main loss -1.855320], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 39 / 176], [train main loss -1.922412], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 40 / 176], [train main loss -1.962505], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 41 / 176], [train main loss -1.972268], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 42 / 176], [train main loss -1.989678], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 43 / 176], [train main loss -2.069451], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 44 / 176], [train main loss -2.067788], [lr 0.003143] [batchtime 0.397]
[epoch 120], [iter 45 / 176], [train main loss -2.105746], [lr 0.003143] [batchtime 0.402]
[epoch 120], [iter 46 / 176], [train main loss -2.197978], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 47 / 176], [train main loss -2.182076], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 48 / 176], [train main loss -2.233013], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 49 / 176], [train main loss -2.272617], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 50 / 176], [train main loss -2.280884], [lr 0.003143] [batchtime 0.431]
[epoch 120], [iter 51 / 176], [train main loss -2.216731], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 52 / 176], [train main loss -2.197540], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 53 / 176], [train main loss -2.187738], [lr 0.003143] [batchtime 0.429]
[epoch 120], [iter 54 / 176], [train main loss -2.173128], [lr 0.003143] [batchtime 0.428]
[epoch 120], [iter 55 / 176], [train main loss -2.150769], [lr 0.003143] [batchtime 0.427]
[epoch 120], [iter 56 / 176], [train main loss -2.137506], [lr 0.003143] [batchtime 0.427]
[epoch 120], [iter 57 / 176], [train main loss -2.103419], [lr 0.003143] [batchtime 0.426]
[epoch 120], [iter 58 / 176], [train main loss -2.126724], [lr 0.003143] [batchtime 0.426]
[epoch 120], [iter 59 / 176], [train main loss -2.130693], [lr 0.003143] [batchtime 0.425]
[epoch 120], [iter 60 / 176], [train main loss -2.202018], [lr 0.003143] [batchtime 0.425]
[epoch 120], [iter 61 / 176], [train main loss -2.166347], [lr 0.003143] [batchtime 0.424]
[epoch 120], [iter 62 / 176], [train main loss -2.146482], [lr 0.003143] [batchtime 0.424]
[epoch 120], [iter 63 / 176], [train main loss -2.134180], [lr 0.003143] [batchtime 0.423]
[epoch 120], [iter 64 / 176], [train main loss -2.149832], [lr 0.003143] [batchtime 0.423]
[epoch 120], [iter 65 / 176], [train main loss -2.167075], [lr 0.003143] [batchtime 0.422]
[epoch 120], [iter 66 / 176], [train main loss -2.150781], [lr 0.003143] [batchtime 0.422]
[epoch 120], [iter 67 / 176], [train main loss -2.189633], [lr 0.003143] [batchtime 0.422]
[epoch 120], [iter 68 / 176], [train main loss -2.164286], [lr 0.003143] [batchtime 0.423]
[epoch 120], [iter 69 / 176], [train main loss -2.165120], [lr 0.003143] [batchtime 0.423]
[epoch 120], [iter 70 / 176], [train main loss -2.149641], [lr 0.003143] [batchtime 0.422]
[epoch 120], [iter 71 / 176], [train main loss -2.134632], [lr 0.003143] [batchtime 0.422]
[epoch 120], [iter 72 / 176], [train main loss -2.119360], [lr 0.003143] [batchtime 0.421]
[epoch 120], [iter 73 / 176], [train main loss -2.170043], [lr 0.003143] [batchtime 0.421]
[epoch 120], [iter 74 / 176], [train main loss -2.144636], [lr 0.003143] [batchtime 0.421]
[epoch 120], [iter 75 / 176], [train main loss -2.124355], [lr 0.003143] [batchtime 0.421]
[epoch 120], [iter 76 / 176], [train main loss -2.126274], [lr 0.003143] [batchtime 0.42]
[epoch 120], [iter 77 / 176], [train main loss -2.134067], [lr 0.003143] [batchtime 0.42]
[epoch 120], [iter 78 / 176], [train main loss -2.164832], [lr 0.003143] [batchtime 0.42]
[epoch 120], [iter 79 / 176], [train main loss -2.208915], [lr 0.003143] [batchtime 0.419]
[epoch 120], [iter 80 / 176], [train main loss -2.178606], [lr 0.003143] [batchtime 0.419]
[epoch 120], [iter 81 / 176], [train main loss -2.168229], [lr 0.003143] [batchtime 0.419]
[epoch 120], [iter 82 / 176], [train main loss -2.178863], [lr 0.003143] [batchtime 0.418]
[epoch 120], [iter 83 / 176], [train main loss -2.184447], [lr 0.003143] [batchtime 0.418]
[epoch 120], [iter 84 / 176], [train main loss -2.205834], [lr 0.003143] [batchtime 0.419]
[epoch 120], [iter 85 / 176], [train main loss -2.193611], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 86 / 176], [train main loss -2.181958], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 87 / 176], [train main loss -2.146777], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 88 / 176], [train main loss -2.135566], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 89 / 176], [train main loss -2.162494], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 90 / 176], [train main loss -2.172154], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 91 / 176], [train main loss -2.198892], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 92 / 176], [train main loss -2.179623], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 93 / 176], [train main loss -2.156734], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 94 / 176], [train main loss -2.147899], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 95 / 176], [train main loss -2.188294], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 96 / 176], [train main loss -2.143915], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 97 / 176], [train main loss -2.158256], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 98 / 176], [train main loss -2.125183], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 99 / 176], [train main loss -2.123928], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 100 / 176], [train main loss -2.133768], [lr 0.003143] [batchtime 0.431]
[epoch 120], [iter 101 / 176], [train main loss -2.154464], [lr 0.003143] [batchtime 0.431]
[epoch 120], [iter 102 / 176], [train main loss -2.176580], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 103 / 176], [train main loss -2.192506], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 104 / 176], [train main loss -2.192583], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 105 / 176], [train main loss -2.185844], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 106 / 176], [train main loss -2.189698], [lr 0.003143] [batchtime 0.429]
[epoch 120], [iter 107 / 176], [train main loss -2.201662], [lr 0.003143] [batchtime 0.429]
[epoch 120], [iter 108 / 176], [train main loss -2.202166], [lr 0.003143] [batchtime 0.428]
[epoch 120], [iter 109 / 176], [train main loss -2.190875], [lr 0.003143] [batchtime 0.428]
[epoch 120], [iter 110 / 176], [train main loss -2.223117], [lr 0.003143] [batchtime 0.428]
[epoch 120], [iter 111 / 176], [train main loss -2.237107], [lr 0.003143] [batchtime 0.428]
[epoch 120], [iter 112 / 176], [train main loss -2.240925], [lr 0.003143] [batchtime 0.427]
[epoch 120], [iter 113 / 176], [train main loss -2.230007], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 114 / 176], [train main loss -2.229265], [lr 0.003143] [batchtime 0.444]
[epoch 120], [iter 115 / 176], [train main loss -2.214531], [lr 0.003143] [batchtime 0.443]
[epoch 120], [iter 116 / 176], [train main loss -2.200936], [lr 0.003143] [batchtime 0.443]
[epoch 120], [iter 117 / 176], [train main loss -2.196495], [lr 0.003143] [batchtime 0.442]
[epoch 120], [iter 118 / 176], [train main loss -2.230941], [lr 0.003143] [batchtime 0.442]
[epoch 120], [iter 119 / 176], [train main loss -2.226886], [lr 0.003143] [batchtime 0.442]
[epoch 120], [iter 120 / 176], [train main loss -2.216550], [lr 0.003143] [batchtime 0.441]
[epoch 120], [iter 121 / 176], [train main loss -2.201775], [lr 0.003143] [batchtime 0.441]
[epoch 120], [iter 122 / 176], [train main loss -2.191791], [lr 0.003143] [batchtime 0.44]
[epoch 120], [iter 123 / 176], [train main loss -2.171499], [lr 0.003143] [batchtime 0.44]
[epoch 120], [iter 124 / 176], [train main loss -2.167970], [lr 0.003143] [batchtime 0.44]
[epoch 120], [iter 125 / 176], [train main loss -2.167584], [lr 0.003143] [batchtime 0.439]
[epoch 120], [iter 126 / 176], [train main loss -2.177651], [lr 0.003143] [batchtime 0.439]
[epoch 120], [iter 127 / 176], [train main loss -2.176067], [lr 0.003143] [batchtime 0.438]
[epoch 120], [iter 128 / 176], [train main loss -2.156574], [lr 0.003143] [batchtime 0.438]
[epoch 120], [iter 129 / 176], [train main loss -2.162709], [lr 0.003143] [batchtime 0.438]
[epoch 120], [iter 130 / 176], [train main loss -2.160918], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 131 / 176], [train main loss -2.159514], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 132 / 176], [train main loss -2.165257], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 133 / 176], [train main loss -2.155273], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 134 / 176], [train main loss -2.138799], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 135 / 176], [train main loss -2.150461], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 136 / 176], [train main loss -2.152623], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 137 / 176], [train main loss -2.144549], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 138 / 176], [train main loss -2.148968], [lr 0.003143] [batchtime 0.439]
[epoch 120], [iter 139 / 176], [train main loss -2.140107], [lr 0.003143] [batchtime 0.438]
[epoch 120], [iter 140 / 176], [train main loss -2.142793], [lr 0.003143] [batchtime 0.438]
[epoch 120], [iter 141 / 176], [train main loss -2.142272], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 142 / 176], [train main loss -2.145285], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 143 / 176], [train main loss -2.137254], [lr 0.003143] [batchtime 0.437]
[epoch 120], [iter 144 / 176], [train main loss -2.131617], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 145 / 176], [train main loss -2.147455], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 146 / 176], [train main loss -2.137386], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 147 / 176], [train main loss -2.158044], [lr 0.003143] [batchtime 0.436]
[epoch 120], [iter 148 / 176], [train main loss -2.156607], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 149 / 176], [train main loss -2.146984], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 150 / 176], [train main loss -2.135864], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 151 / 176], [train main loss -2.135706], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 152 / 176], [train main loss -2.135591], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 153 / 176], [train main loss -2.134925], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 154 / 176], [train main loss -2.133909], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 155 / 176], [train main loss -2.158890], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 156 / 176], [train main loss -2.168675], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 157 / 176], [train main loss -2.143259], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 158 / 176], [train main loss -2.125214], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 159 / 176], [train main loss -2.133759], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 160 / 176], [train main loss -2.135102], [lr 0.003143] [batchtime 0.435]
[epoch 120], [iter 161 / 176], [train main loss -2.122061], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 162 / 176], [train main loss -2.110951], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 163 / 176], [train main loss -2.112428], [lr 0.003143] [batchtime 0.434]
[epoch 120], [iter 164 / 176], [train main loss -2.117331], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 165 / 176], [train main loss -2.116958], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 166 / 176], [train main loss -2.117634], [lr 0.003143] [batchtime 0.433]
[epoch 120], [iter 167 / 176], [train main loss -2.117148], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 168 / 176], [train main loss -2.120070], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 169 / 176], [train main loss -2.137218], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 170 / 176], [train main loss -2.146450], [lr 0.003143] [batchtime 0.432]
[epoch 120], [iter 171 / 176], [train main loss -2.135101], [lr 0.003143] [batchtime 0.431]
[epoch 120], [iter 172 / 176], [train main loss -2.116014], [lr 0.003143] [batchtime 0.431]
[epoch 120], [iter 173 / 176], [train main loss -2.113271], [lr 0.003143] [batchtime 0.431]
[epoch 120], [iter 174 / 176], [train main loss -2.113884], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 175 / 176], [train main loss -2.118518], [lr 0.003143] [batchtime 0.43]
[epoch 120], [iter 176 / 176], [train main loss -2.115727], [lr 0.003143] [batchtime 0.43]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.61  35.60   0.02  0.04         0.98      0.97
   1  sidewalk          69.15   5.24   0.26  0.19         0.80      0.84
   2  building          86.29  25.19   0.06  0.10         0.95      0.91
   3  wall              19.50   0.17   2.57  1.56         0.28      0.39
   4  fence             27.41   0.45   1.85  0.80         0.35      0.56
   5  pole              38.80   0.54   1.10  0.48         0.48      0.68
   6  traffic light     14.73   0.02   5.27  0.52         0.16      0.66
   7  traffic sign      23.20   0.14   3.07  0.24         0.25      0.81
   8  vegetation        84.46  11.50   0.07  0.11         0.93      0.90
   9  terrain           41.39   0.39   0.90  0.51         0.53      0.66
  10  sky               93.28   3.78   0.03  0.05         0.97      0.96
  11  person            51.37   0.92   0.66  0.28         0.60      0.78
  12  rider             10.25   0.01   7.76  1.00         0.11      0.50
  13  car               85.47   6.69   0.06  0.11         0.95      0.90
  14  truck              2.44   0.01  39.38  0.52         0.02      0.66
  15  bus               13.60   0.03   1.74  4.62         0.37      0.18
  16  train             38.26   0.11   0.66  0.95         0.60      0.51
  17  motorcycle         3.30   0.00  28.84  0.45         0.03      0.69
  18  bicycle           38.00   0.26   0.52  1.11         0.66      0.47
Mean: 43.97
-----------------------------------------------------------------------------------------------------------
this : [epoch 120], [val loss 0.31423], [acc 0.91029], [acc_cls 0.52669], [mean_iu 0.43974], [fwavacc 0.84389]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 121], [iter 1 / 176], [train main loss -3.639505], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 2 / 176], [train main loss -2.006884], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 3 / 176], [train main loss -1.510924], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 4 / 176], [train main loss -2.492928], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 5 / 176], [train main loss -2.158804], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 6 / 176], [train main loss -2.208896], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 7 / 176], [train main loss -2.111864], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 8 / 176], [train main loss -2.316933], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 9 / 176], [train main loss -2.282303], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 10 / 176], [train main loss -2.331469], [lr 0.003086] [batchtime 0]
[epoch 121], [iter 11 / 176], [train main loss -2.212806], [lr 0.003086] [batchtime 0.366]
[epoch 121], [iter 12 / 176], [train main loss -2.497131], [lr 0.003086] [batchtime 0.382]
[epoch 121], [iter 13 / 176], [train main loss -2.402955], [lr 0.003086] [batchtime 0.387]
[epoch 121], [iter 14 / 176], [train main loss -2.495538], [lr 0.003086] [batchtime 0.389]
[epoch 121], [iter 15 / 176], [train main loss -2.570121], [lr 0.003086] [batchtime 0.393]
[epoch 121], [iter 16 / 176], [train main loss -2.704349], [lr 0.003086] [batchtime 0.394]
[epoch 121], [iter 17 / 176], [train main loss -2.739709], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 18 / 176], [train main loss -2.866211], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 19 / 176], [train main loss -3.025321], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 20 / 176], [train main loss -2.912845], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 21 / 176], [train main loss -2.942013], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 22 / 176], [train main loss -2.883209], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 23 / 176], [train main loss -2.893889], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 24 / 176], [train main loss -2.895591], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 25 / 176], [train main loss -2.844350], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 26 / 176], [train main loss -2.955739], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 27 / 176], [train main loss -2.942951], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 28 / 176], [train main loss -2.888420], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 29 / 176], [train main loss -2.894079], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 30 / 176], [train main loss -2.860660], [lr 0.003086] [batchtime 0.396]
[epoch 121], [iter 31 / 176], [train main loss -2.856025], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 32 / 176], [train main loss -2.808109], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 33 / 176], [train main loss -2.775703], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 34 / 176], [train main loss -2.805178], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 35 / 176], [train main loss -2.764323], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 36 / 176], [train main loss -2.710326], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 37 / 176], [train main loss -2.644591], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 38 / 176], [train main loss -2.669833], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 39 / 176], [train main loss -2.628098], [lr 0.003086] [batchtime 0.398]
[epoch 121], [iter 40 / 176], [train main loss -2.588630], [lr 0.003086] [batchtime 0.397]
[epoch 121], [iter 41 / 176], [train main loss -2.546716], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 42 / 176], [train main loss -2.519614], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 43 / 176], [train main loss -2.525707], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 44 / 176], [train main loss -2.508343], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 45 / 176], [train main loss -2.515652], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 46 / 176], [train main loss -2.439902], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 47 / 176], [train main loss -2.374879], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 48 / 176], [train main loss -2.322554], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 49 / 176], [train main loss -2.353130], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 50 / 176], [train main loss -2.332204], [lr 0.003086] [batchtime 0.413]
[epoch 121], [iter 51 / 176], [train main loss -2.320902], [lr 0.003086] [batchtime 0.413]
[epoch 121], [iter 52 / 176], [train main loss -2.289185], [lr 0.003086] [batchtime 0.413]
[epoch 121], [iter 53 / 176], [train main loss -2.314447], [lr 0.003086] [batchtime 0.413]
[epoch 121], [iter 54 / 176], [train main loss -2.330284], [lr 0.003086] [batchtime 0.412]
[epoch 121], [iter 55 / 176], [train main loss -2.337959], [lr 0.003086] [batchtime 0.412]
[epoch 121], [iter 56 / 176], [train main loss -2.323620], [lr 0.003086] [batchtime 0.428]
[epoch 121], [iter 57 / 176], [train main loss -2.284292], [lr 0.003086] [batchtime 0.427]
[epoch 121], [iter 58 / 176], [train main loss -2.290544], [lr 0.003086] [batchtime 0.426]
[epoch 121], [iter 59 / 176], [train main loss -2.264702], [lr 0.003086] [batchtime 0.425]
[epoch 121], [iter 60 / 176], [train main loss -2.270761], [lr 0.003086] [batchtime 0.425]
[epoch 121], [iter 61 / 176], [train main loss -2.278189], [lr 0.003086] [batchtime 0.424]
[epoch 121], [iter 62 / 176], [train main loss -2.267215], [lr 0.003086] [batchtime 0.424]
[epoch 121], [iter 63 / 176], [train main loss -2.255138], [lr 0.003086] [batchtime 0.423]
[epoch 121], [iter 64 / 176], [train main loss -2.252768], [lr 0.003086] [batchtime 0.423]
[epoch 121], [iter 65 / 176], [train main loss -2.229232], [lr 0.003086] [batchtime 0.422]
[epoch 121], [iter 66 / 176], [train main loss -2.210555], [lr 0.003086] [batchtime 0.422]
[epoch 121], [iter 67 / 176], [train main loss -2.198512], [lr 0.003086] [batchtime 0.421]
[epoch 121], [iter 68 / 176], [train main loss -2.174092], [lr 0.003086] [batchtime 0.421]
[epoch 121], [iter 69 / 176], [train main loss -2.207995], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 70 / 176], [train main loss -2.212770], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 71 / 176], [train main loss -2.213068], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 72 / 176], [train main loss -2.181726], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 73 / 176], [train main loss -2.163159], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 74 / 176], [train main loss -2.202857], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 75 / 176], [train main loss -2.224981], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 76 / 176], [train main loss -2.151091], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 77 / 176], [train main loss -2.134901], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 78 / 176], [train main loss -2.144114], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 79 / 176], [train main loss -2.145513], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 80 / 176], [train main loss -2.171593], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 81 / 176], [train main loss -2.194335], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 82 / 176], [train main loss -2.214913], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 83 / 176], [train main loss -2.204226], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 84 / 176], [train main loss -2.193024], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 85 / 176], [train main loss -2.183006], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 86 / 176], [train main loss -2.186696], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 87 / 176], [train main loss -2.188828], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 88 / 176], [train main loss -2.200193], [lr 0.003086] [batchtime 0.424]
[epoch 121], [iter 89 / 176], [train main loss -2.180100], [lr 0.003086] [batchtime 0.426]
[epoch 121], [iter 90 / 176], [train main loss -2.162000], [lr 0.003086] [batchtime 0.425]
[epoch 121], [iter 91 / 176], [train main loss -2.147454], [lr 0.003086] [batchtime 0.425]
[epoch 121], [iter 92 / 176], [train main loss -2.120155], [lr 0.003086] [batchtime 0.424]
[epoch 121], [iter 93 / 176], [train main loss -2.122897], [lr 0.003086] [batchtime 0.424]
[epoch 121], [iter 94 / 176], [train main loss -2.110434], [lr 0.003086] [batchtime 0.424]
[epoch 121], [iter 95 / 176], [train main loss -2.115607], [lr 0.003086] [batchtime 0.423]
[epoch 121], [iter 96 / 176], [train main loss -2.097885], [lr 0.003086] [batchtime 0.423]
[epoch 121], [iter 97 / 176], [train main loss -2.122908], [lr 0.003086] [batchtime 0.423]
[epoch 121], [iter 98 / 176], [train main loss -2.112922], [lr 0.003086] [batchtime 0.422]
[epoch 121], [iter 99 / 176], [train main loss -2.130908], [lr 0.003086] [batchtime 0.422]
[epoch 121], [iter 100 / 176], [train main loss -2.136012], [lr 0.003086] [batchtime 0.422]
[epoch 121], [iter 101 / 176], [train main loss -2.146039], [lr 0.003086] [batchtime 0.422]
[epoch 121], [iter 102 / 176], [train main loss -2.139053], [lr 0.003086] [batchtime 0.421]
[epoch 121], [iter 103 / 176], [train main loss -2.168197], [lr 0.003086] [batchtime 0.421]
[epoch 121], [iter 104 / 176], [train main loss -2.161365], [lr 0.003086] [batchtime 0.421]
[epoch 121], [iter 105 / 176], [train main loss -2.158315], [lr 0.003086] [batchtime 0.421]
[epoch 121], [iter 106 / 176], [train main loss -2.155617], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 107 / 176], [train main loss -2.128499], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 108 / 176], [train main loss -2.148180], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 109 / 176], [train main loss -2.146285], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 110 / 176], [train main loss -2.141202], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 111 / 176], [train main loss -2.129927], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 112 / 176], [train main loss -2.142534], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 113 / 176], [train main loss -2.138785], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 114 / 176], [train main loss -2.144889], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 115 / 176], [train main loss -2.145343], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 116 / 176], [train main loss -2.129352], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 117 / 176], [train main loss -2.130760], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 118 / 176], [train main loss -2.135587], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 119 / 176], [train main loss -2.158936], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 120 / 176], [train main loss -2.159952], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 121 / 176], [train main loss -2.136693], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 122 / 176], [train main loss -2.117805], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 123 / 176], [train main loss -2.119245], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 124 / 176], [train main loss -2.141592], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 125 / 176], [train main loss -2.133900], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 126 / 176], [train main loss -2.129515], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 127 / 176], [train main loss -2.119994], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 128 / 176], [train main loss -2.119416], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 129 / 176], [train main loss -2.125919], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 130 / 176], [train main loss -2.115578], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 131 / 176], [train main loss -2.114307], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 132 / 176], [train main loss -2.128979], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 133 / 176], [train main loss -2.144630], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 134 / 176], [train main loss -2.120698], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 135 / 176], [train main loss -2.124388], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 136 / 176], [train main loss -2.120272], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 137 / 176], [train main loss -2.112738], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 138 / 176], [train main loss -2.119247], [lr 0.003086] [batchtime 0.42]
[epoch 121], [iter 139 / 176], [train main loss -2.121723], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 140 / 176], [train main loss -2.106103], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 141 / 176], [train main loss -2.104151], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 142 / 176], [train main loss -2.104342], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 143 / 176], [train main loss -2.119593], [lr 0.003086] [batchtime 0.419]
[epoch 121], [iter 144 / 176], [train main loss -2.118205], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 145 / 176], [train main loss -2.122743], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 146 / 176], [train main loss -2.120961], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 147 / 176], [train main loss -2.128291], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 148 / 176], [train main loss -2.128187], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 149 / 176], [train main loss -2.124539], [lr 0.003086] [batchtime 0.418]
[epoch 121], [iter 150 / 176], [train main loss -2.120323], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 151 / 176], [train main loss -2.111273], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 152 / 176], [train main loss -2.112574], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 153 / 176], [train main loss -2.116940], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 154 / 176], [train main loss -2.128060], [lr 0.003086] [batchtime 0.417]
[epoch 121], [iter 155 / 176], [train main loss -2.123945], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 156 / 176], [train main loss -2.126236], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 157 / 176], [train main loss -2.130265], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 158 / 176], [train main loss -2.129897], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 159 / 176], [train main loss -2.127111], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 160 / 176], [train main loss -2.120323], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 161 / 176], [train main loss -2.134557], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 162 / 176], [train main loss -2.140042], [lr 0.003086] [batchtime 0.416]
[epoch 121], [iter 163 / 176], [train main loss -2.154463], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 164 / 176], [train main loss -2.172354], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 165 / 176], [train main loss -2.183041], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 166 / 176], [train main loss -2.177923], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 167 / 176], [train main loss -2.167687], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 168 / 176], [train main loss -2.177188], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 169 / 176], [train main loss -2.180376], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 170 / 176], [train main loss -2.202740], [lr 0.003086] [batchtime 0.415]
[epoch 121], [iter 171 / 176], [train main loss -2.203034], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 172 / 176], [train main loss -2.222845], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 173 / 176], [train main loss -2.219566], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 174 / 176], [train main loss -2.205995], [lr 0.003086] [batchtime 0.414]
[epoch 121], [iter 175 / 176], [train main loss -2.216188], [lr 0.003086] [batchtime 0.413]
[epoch 121], [iter 176 / 176], [train main loss -2.217682], [lr 0.003086] [batchtime 0.413]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.81  35.60   0.02  0.03         0.98      0.97
   1  sidewalk          69.51   5.29   0.24  0.19         0.80      0.84
   2  building          86.34  24.85   0.07  0.09         0.93      0.92
   3  wall              18.26   0.14   3.14  1.34         0.24      0.43
   4  fence             25.68   0.39   2.25  0.64         0.31      0.61
   5  pole              39.50   0.57   1.00  0.54         0.50      0.65
   6  traffic light     18.57   0.03   3.73  0.65         0.21      0.60
   7  traffic sign      27.03   0.16   2.40  0.30         0.29      0.77
   8  vegetation        83.46  11.72   0.06  0.14         0.95      0.87
   9  terrain           41.13   0.38   0.92  0.51         0.52      0.66
  10  sky               93.63   3.76   0.03  0.04         0.97      0.96
  11  person            53.64   1.04   0.48  0.39         0.68      0.72
  12  rider             11.49   0.01   6.69  1.01         0.13      0.50
  13  car               86.35   6.68   0.06  0.10         0.94      0.91
  14  truck              1.32   0.00  74.40  0.42         0.01      0.71
  15  bus               15.01   0.04   1.14  4.52         0.47      0.18
  16  train             29.42   0.07   1.45  0.95         0.41      0.51
  17  motorcycle         3.11   0.00  30.53  0.67         0.03      0.60
  18  bicycle           36.32   0.28   0.38  1.37         0.72      0.42
Mean: 43.93
-----------------------------------------------------------------------------------------------------------
this : [epoch 121], [val loss 0.30482], [acc 0.91037], [acc_cls 0.53192], [mean_iu 0.43927], [fwavacc 0.84472]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 122], [iter 1 / 176], [train main loss -3.319557], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 2 / 176], [train main loss -2.803670], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 3 / 176], [train main loss -3.178511], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 4 / 176], [train main loss -3.182474], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 5 / 176], [train main loss -3.649244], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 6 / 176], [train main loss -3.366511], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 7 / 176], [train main loss -3.105057], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 8 / 176], [train main loss -2.707699], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 9 / 176], [train main loss -3.387181], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 10 / 176], [train main loss -3.250888], [lr 0.003029] [batchtime 0]
[epoch 122], [iter 11 / 176], [train main loss -3.211869], [lr 0.003029] [batchtime 0.368]
[epoch 122], [iter 12 / 176], [train main loss -2.869303], [lr 0.003029] [batchtime 0.384]
[epoch 122], [iter 13 / 176], [train main loss -2.904949], [lr 0.003029] [batchtime 0.393]
[epoch 122], [iter 14 / 176], [train main loss -2.820527], [lr 0.003029] [batchtime 0.396]
[epoch 122], [iter 15 / 176], [train main loss -2.643068], [lr 0.003029] [batchtime 0.398]
[epoch 122], [iter 16 / 176], [train main loss -2.704354], [lr 0.003029] [batchtime 0.399]
[epoch 122], [iter 17 / 176], [train main loss -2.718021], [lr 0.003029] [batchtime 0.4]
[epoch 122], [iter 18 / 176], [train main loss -2.472562], [lr 0.003029] [batchtime 0.451]
[epoch 122], [iter 19 / 176], [train main loss -2.481563], [lr 0.003029] [batchtime 0.444]
[epoch 122], [iter 20 / 176], [train main loss -2.340563], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 21 / 176], [train main loss -2.442252], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 22 / 176], [train main loss -2.446992], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 23 / 176], [train main loss -2.337034], [lr 0.003029] [batchtime 0.43]
[epoch 122], [iter 24 / 176], [train main loss -2.377744], [lr 0.003029] [batchtime 0.428]
[epoch 122], [iter 25 / 176], [train main loss -2.304239], [lr 0.003029] [batchtime 0.428]
[epoch 122], [iter 26 / 176], [train main loss -2.271186], [lr 0.003029] [batchtime 0.426]
[epoch 122], [iter 27 / 176], [train main loss -2.194630], [lr 0.003029] [batchtime 0.424]
[epoch 122], [iter 28 / 176], [train main loss -2.221334], [lr 0.003029] [batchtime 0.423]
[epoch 122], [iter 29 / 176], [train main loss -2.258135], [lr 0.003029] [batchtime 0.422]
[epoch 122], [iter 30 / 176], [train main loss -2.231412], [lr 0.003029] [batchtime 0.421]
[epoch 122], [iter 31 / 176], [train main loss -2.225518], [lr 0.003029] [batchtime 0.42]
[epoch 122], [iter 32 / 176], [train main loss -2.164317], [lr 0.003029] [batchtime 0.419]
[epoch 122], [iter 33 / 176], [train main loss -2.087862], [lr 0.003029] [batchtime 0.418]
[epoch 122], [iter 34 / 176], [train main loss -2.055572], [lr 0.003029] [batchtime 0.417]
[epoch 122], [iter 35 / 176], [train main loss -2.025346], [lr 0.003029] [batchtime 0.417]
[epoch 122], [iter 36 / 176], [train main loss -1.981534], [lr 0.003029] [batchtime 0.416]
[epoch 122], [iter 37 / 176], [train main loss -1.965335], [lr 0.003029] [batchtime 0.416]
[epoch 122], [iter 38 / 176], [train main loss -2.015109], [lr 0.003029] [batchtime 0.415]
[epoch 122], [iter 39 / 176], [train main loss -2.004530], [lr 0.003029] [batchtime 0.415]
[epoch 122], [iter 40 / 176], [train main loss -2.018036], [lr 0.003029] [batchtime 0.414]
[epoch 122], [iter 41 / 176], [train main loss -2.020035], [lr 0.003029] [batchtime 0.413]
[epoch 122], [iter 42 / 176], [train main loss -2.023118], [lr 0.003029] [batchtime 0.425]
[epoch 122], [iter 43 / 176], [train main loss -2.076954], [lr 0.003029] [batchtime 0.443]
[epoch 122], [iter 44 / 176], [train main loss -2.085062], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 45 / 176], [train main loss -2.023365], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 46 / 176], [train main loss -2.100515], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 47 / 176], [train main loss -2.080342], [lr 0.003029] [batchtime 0.438]
[epoch 122], [iter 48 / 176], [train main loss -2.173441], [lr 0.003029] [batchtime 0.436]
[epoch 122], [iter 49 / 176], [train main loss -2.153691], [lr 0.003029] [batchtime 0.436]
[epoch 122], [iter 50 / 176], [train main loss -2.165618], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 51 / 176], [train main loss -2.213125], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 52 / 176], [train main loss -2.232337], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 53 / 176], [train main loss -2.220051], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 54 / 176], [train main loss -2.246870], [lr 0.003029] [batchtime 0.431]
[epoch 122], [iter 55 / 176], [train main loss -2.241234], [lr 0.003029] [batchtime 0.43]
[epoch 122], [iter 56 / 176], [train main loss -2.236043], [lr 0.003029] [batchtime 0.43]
[epoch 122], [iter 57 / 176], [train main loss -2.204639], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 58 / 176], [train main loss -2.185210], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 59 / 176], [train main loss -2.173301], [lr 0.003029] [batchtime 0.428]
[epoch 122], [iter 60 / 176], [train main loss -2.187377], [lr 0.003029] [batchtime 0.427]
[epoch 122], [iter 61 / 176], [train main loss -2.188880], [lr 0.003029] [batchtime 0.427]
[epoch 122], [iter 62 / 176], [train main loss -2.206840], [lr 0.003029] [batchtime 0.426]
[epoch 122], [iter 63 / 176], [train main loss -2.198210], [lr 0.003029] [batchtime 0.426]
[epoch 122], [iter 64 / 176], [train main loss -2.161465], [lr 0.003029] [batchtime 0.426]
[epoch 122], [iter 65 / 176], [train main loss -2.193147], [lr 0.003029] [batchtime 0.425]
[epoch 122], [iter 66 / 176], [train main loss -2.208528], [lr 0.003029] [batchtime 0.425]
[epoch 122], [iter 67 / 176], [train main loss -2.219677], [lr 0.003029] [batchtime 0.424]
[epoch 122], [iter 68 / 176], [train main loss -2.173993], [lr 0.003029] [batchtime 0.424]
[epoch 122], [iter 69 / 176], [train main loss -2.211700], [lr 0.003029] [batchtime 0.424]
[epoch 122], [iter 70 / 176], [train main loss -2.254132], [lr 0.003029] [batchtime 0.424]
[epoch 122], [iter 71 / 176], [train main loss -2.270227], [lr 0.003029] [batchtime 0.423]
[epoch 122], [iter 72 / 176], [train main loss -2.303555], [lr 0.003029] [batchtime 0.423]
[epoch 122], [iter 73 / 176], [train main loss -2.278054], [lr 0.003029] [batchtime 0.422]
[epoch 122], [iter 74 / 176], [train main loss -2.274492], [lr 0.003029] [batchtime 0.422]
[epoch 122], [iter 75 / 176], [train main loss -2.258939], [lr 0.003029] [batchtime 0.422]
[epoch 122], [iter 76 / 176], [train main loss -2.235835], [lr 0.003029] [batchtime 0.421]
[epoch 122], [iter 77 / 176], [train main loss -2.235219], [lr 0.003029] [batchtime 0.421]
[epoch 122], [iter 78 / 176], [train main loss -2.250826], [lr 0.003029] [batchtime 0.42]
[epoch 122], [iter 79 / 176], [train main loss -2.256839], [lr 0.003029] [batchtime 0.42]
[epoch 122], [iter 80 / 176], [train main loss -2.246080], [lr 0.003029] [batchtime 0.42]
[epoch 122], [iter 81 / 176], [train main loss -2.235527], [lr 0.003029] [batchtime 0.419]
[epoch 122], [iter 82 / 176], [train main loss -2.258917], [lr 0.003029] [batchtime 0.419]
[epoch 122], [iter 83 / 176], [train main loss -2.269313], [lr 0.003029] [batchtime 0.419]
[epoch 122], [iter 84 / 176], [train main loss -2.272928], [lr 0.003029] [batchtime 0.42]
[epoch 122], [iter 85 / 176], [train main loss -2.285858], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 86 / 176], [train main loss -2.314034], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 87 / 176], [train main loss -2.315618], [lr 0.003029] [batchtime 0.431]
[epoch 122], [iter 88 / 176], [train main loss -2.342371], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 89 / 176], [train main loss -2.350710], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 90 / 176], [train main loss -2.333249], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 91 / 176], [train main loss -2.345148], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 92 / 176], [train main loss -2.337260], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 93 / 176], [train main loss -2.334619], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 94 / 176], [train main loss -2.331570], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 95 / 176], [train main loss -2.331136], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 96 / 176], [train main loss -2.329707], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 97 / 176], [train main loss -2.322699], [lr 0.003029] [batchtime 0.431]
[epoch 122], [iter 98 / 176], [train main loss -2.313346], [lr 0.003029] [batchtime 0.431]
[epoch 122], [iter 99 / 176], [train main loss -2.320025], [lr 0.003029] [batchtime 0.431]
[epoch 122], [iter 100 / 176], [train main loss -2.294657], [lr 0.003029] [batchtime 0.431]
[epoch 122], [iter 101 / 176], [train main loss -2.309297], [lr 0.003029] [batchtime 0.43]
[epoch 122], [iter 102 / 176], [train main loss -2.297594], [lr 0.003029] [batchtime 0.43]
[epoch 122], [iter 103 / 176], [train main loss -2.321191], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 104 / 176], [train main loss -2.318079], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 105 / 176], [train main loss -2.313510], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 106 / 176], [train main loss -2.306708], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 107 / 176], [train main loss -2.298537], [lr 0.003029] [batchtime 0.428]
[epoch 122], [iter 108 / 176], [train main loss -2.305436], [lr 0.003029] [batchtime 0.428]
[epoch 122], [iter 109 / 176], [train main loss -2.327201], [lr 0.003029] [batchtime 0.428]
[epoch 122], [iter 110 / 176], [train main loss -2.313822], [lr 0.003029] [batchtime 0.429]
[epoch 122], [iter 111 / 176], [train main loss -2.317453], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 112 / 176], [train main loss -2.302172], [lr 0.003029] [batchtime 0.446]
[epoch 122], [iter 113 / 176], [train main loss -2.356150], [lr 0.003029] [batchtime 0.446]
[epoch 122], [iter 114 / 176], [train main loss -2.351626], [lr 0.003029] [batchtime 0.445]
[epoch 122], [iter 115 / 176], [train main loss -2.376095], [lr 0.003029] [batchtime 0.445]
[epoch 122], [iter 116 / 176], [train main loss -2.380126], [lr 0.003029] [batchtime 0.445]
[epoch 122], [iter 117 / 176], [train main loss -2.368041], [lr 0.003029] [batchtime 0.444]
[epoch 122], [iter 118 / 176], [train main loss -2.370824], [lr 0.003029] [batchtime 0.444]
[epoch 122], [iter 119 / 176], [train main loss -2.373770], [lr 0.003029] [batchtime 0.443]
[epoch 122], [iter 120 / 176], [train main loss -2.387016], [lr 0.003029] [batchtime 0.443]
[epoch 122], [iter 121 / 176], [train main loss -2.363070], [lr 0.003029] [batchtime 0.442]
[epoch 122], [iter 122 / 176], [train main loss -2.364514], [lr 0.003029] [batchtime 0.442]
[epoch 122], [iter 123 / 176], [train main loss -2.349304], [lr 0.003029] [batchtime 0.442]
[epoch 122], [iter 124 / 176], [train main loss -2.350716], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 125 / 176], [train main loss -2.358994], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 126 / 176], [train main loss -2.364442], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 127 / 176], [train main loss -2.378670], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 128 / 176], [train main loss -2.375802], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 129 / 176], [train main loss -2.371329], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 130 / 176], [train main loss -2.372902], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 131 / 176], [train main loss -2.375663], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 132 / 176], [train main loss -2.363789], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 133 / 176], [train main loss -2.344060], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 134 / 176], [train main loss -2.338119], [lr 0.003029] [batchtime 0.438]
[epoch 122], [iter 135 / 176], [train main loss -2.338797], [lr 0.003029] [batchtime 0.438]
[epoch 122], [iter 136 / 176], [train main loss -2.339748], [lr 0.003029] [batchtime 0.437]
[epoch 122], [iter 137 / 176], [train main loss -2.334940], [lr 0.003029] [batchtime 0.437]
[epoch 122], [iter 138 / 176], [train main loss -2.324568], [lr 0.003029] [batchtime 0.437]
[epoch 122], [iter 139 / 176], [train main loss -2.333920], [lr 0.003029] [batchtime 0.437]
[epoch 122], [iter 140 / 176], [train main loss -2.322877], [lr 0.003029] [batchtime 0.436]
[epoch 122], [iter 141 / 176], [train main loss -2.304421], [lr 0.003029] [batchtime 0.436]
[epoch 122], [iter 142 / 176], [train main loss -2.299029], [lr 0.003029] [batchtime 0.436]
[epoch 122], [iter 143 / 176], [train main loss -2.302151], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 144 / 176], [train main loss -2.303870], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 145 / 176], [train main loss -2.293760], [lr 0.003029] [batchtime 0.435]
[epoch 122], [iter 146 / 176], [train main loss -2.307024], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 147 / 176], [train main loss -2.306239], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 148 / 176], [train main loss -2.282017], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 149 / 176], [train main loss -2.272977], [lr 0.003029] [batchtime 0.434]
[epoch 122], [iter 150 / 176], [train main loss -2.263580], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 151 / 176], [train main loss -2.262748], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 152 / 176], [train main loss -2.258576], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 153 / 176], [train main loss -2.261408], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 154 / 176], [train main loss -2.275825], [lr 0.003029] [batchtime 0.433]
[epoch 122], [iter 155 / 176], [train main loss -2.282277], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 156 / 176], [train main loss -2.270359], [lr 0.003029] [batchtime 0.432]
[epoch 122], [iter 157 / 176], [train main loss -2.274506], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 158 / 176], [train main loss -2.262686], [lr 0.003029] [batchtime 0.442]
[epoch 122], [iter 159 / 176], [train main loss -2.267002], [lr 0.003029] [batchtime 0.442]
[epoch 122], [iter 160 / 176], [train main loss -2.271723], [lr 0.003029] [batchtime 0.442]
[epoch 122], [iter 161 / 176], [train main loss -2.268724], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 162 / 176], [train main loss -2.270203], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 163 / 176], [train main loss -2.252764], [lr 0.003029] [batchtime 0.441]
[epoch 122], [iter 164 / 176], [train main loss -2.256690], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 165 / 176], [train main loss -2.256780], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 166 / 176], [train main loss -2.258735], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 167 / 176], [train main loss -2.264280], [lr 0.003029] [batchtime 0.44]
[epoch 122], [iter 168 / 176], [train main loss -2.264901], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 169 / 176], [train main loss -2.277612], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 170 / 176], [train main loss -2.282260], [lr 0.003029] [batchtime 0.439]
[epoch 122], [iter 171 / 176], [train main loss -2.285899], [lr 0.003029] [batchtime 0.438]
[epoch 122], [iter 172 / 176], [train main loss -2.286048], [lr 0.003029] [batchtime 0.438]
[epoch 122], [iter 173 / 176], [train main loss -2.283287], [lr 0.003029] [batchtime 0.438]
[epoch 122], [iter 174 / 176], [train main loss -2.288393], [lr 0.003029] [batchtime 0.437]
[epoch 122], [iter 175 / 176], [train main loss -2.291088], [lr 0.003029] [batchtime 0.437]
[epoch 122], [iter 176 / 176], [train main loss -2.295099], [lr 0.003029] [batchtime 0.437]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.67  35.27   0.03  0.03         0.97      0.98
   1  sidewalk          69.97   5.52   0.19  0.23         0.84      0.81
   2  building          86.53  25.12   0.06  0.10         0.95      0.91
   3  wall              18.53   0.15   3.02  1.38         0.25      0.42
   4  fence             25.18   0.38   2.35  0.62         0.30      0.62
   5  pole              39.39   0.56   1.01  0.52         0.50      0.66
   6  traffic light     16.28   0.03   4.65  0.49         0.18      0.67
   7  traffic sign      24.07   0.14   2.91  0.24         0.26      0.80
   8  vegetation        83.96  11.65   0.06  0.13         0.94      0.89
   9  terrain           39.12   0.36   1.04  0.52         0.49      0.66
  10  sky               93.55   3.77   0.03  0.04         0.97      0.96
  11  person            53.43   1.01   0.52  0.35         0.66      0.74
  12  rider              9.16   0.01   8.81  1.11         0.10      0.47
  13  car               86.07   6.73   0.05  0.11         0.95      0.90
  14  truck              1.80   0.01  53.79  0.62         0.02      0.62
  15  bus               15.60   0.04   1.32  4.09         0.43      0.20
  16  train             36.72   0.08   1.15  0.57         0.46      0.64
  17  motorcycle         3.57   0.00  26.40  0.61         0.04      0.62
  18  bicycle           37.80   0.26   0.48  1.17         0.68      0.46
Mean: 43.97
-----------------------------------------------------------------------------------------------------------
this : [epoch 122], [val loss 0.30669], [acc 0.91094], [acc_cls 0.52485], [mean_iu 0.43969], [fwavacc 0.84511]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 123], [iter 1 / 176], [train main loss -1.657825], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 2 / 176], [train main loss -2.094679], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 3 / 176], [train main loss -1.872203], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 4 / 176], [train main loss -1.454665], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 5 / 176], [train main loss -2.060354], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 6 / 176], [train main loss -2.087037], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 7 / 176], [train main loss -2.135512], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 8 / 176], [train main loss -2.307545], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 9 / 176], [train main loss -2.309329], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 10 / 176], [train main loss -2.105062], [lr 0.002971] [batchtime 0]
[epoch 123], [iter 11 / 176], [train main loss -2.094636], [lr 0.002971] [batchtime 0.369]
[epoch 123], [iter 12 / 176], [train main loss -2.177004], [lr 0.002971] [batchtime 0.384]
[epoch 123], [iter 13 / 176], [train main loss -2.134547], [lr 0.002971] [batchtime 0.388]
[epoch 123], [iter 14 / 176], [train main loss -2.036807], [lr 0.002971] [batchtime 0.391]
[epoch 123], [iter 15 / 176], [train main loss -2.051396], [lr 0.002971] [batchtime 0.392]
[epoch 123], [iter 16 / 176], [train main loss -1.892468], [lr 0.002971] [batchtime 0.394]
[epoch 123], [iter 17 / 176], [train main loss -1.957133], [lr 0.002971] [batchtime 0.395]
[epoch 123], [iter 18 / 176], [train main loss -1.836703], [lr 0.002971] [batchtime 0.397]
[epoch 123], [iter 19 / 176], [train main loss -1.742762], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 20 / 176], [train main loss -1.698924], [lr 0.002971] [batchtime 0.399]
[epoch 123], [iter 21 / 176], [train main loss -1.737632], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 22 / 176], [train main loss -1.730775], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 23 / 176], [train main loss -1.882966], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 24 / 176], [train main loss -1.884889], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 25 / 176], [train main loss -1.885905], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 26 / 176], [train main loss -1.944251], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 27 / 176], [train main loss -1.946177], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 28 / 176], [train main loss -2.005086], [lr 0.002971] [batchtime 0.399]
[epoch 123], [iter 29 / 176], [train main loss -2.006692], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 30 / 176], [train main loss -2.068147], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 31 / 176], [train main loss -2.083485], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 32 / 176], [train main loss -2.044294], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 33 / 176], [train main loss -2.015653], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 34 / 176], [train main loss -1.975740], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 35 / 176], [train main loss -1.886715], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 36 / 176], [train main loss -1.830072], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 37 / 176], [train main loss -1.838017], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 38 / 176], [train main loss -1.784490], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 39 / 176], [train main loss -1.807792], [lr 0.002971] [batchtime 0.398]
[epoch 123], [iter 40 / 176], [train main loss -1.849289], [lr 0.002971] [batchtime 0.432]
[epoch 123], [iter 41 / 176], [train main loss -1.862783], [lr 0.002971] [batchtime 0.439]
[epoch 123], [iter 42 / 176], [train main loss -1.921449], [lr 0.002971] [batchtime 0.437]
[epoch 123], [iter 43 / 176], [train main loss -1.924505], [lr 0.002971] [batchtime 0.436]
[epoch 123], [iter 44 / 176], [train main loss -1.858451], [lr 0.002971] [batchtime 0.435]
[epoch 123], [iter 45 / 176], [train main loss -1.891809], [lr 0.002971] [batchtime 0.434]
[epoch 123], [iter 46 / 176], [train main loss -1.897444], [lr 0.002971] [batchtime 0.432]
[epoch 123], [iter 47 / 176], [train main loss -1.911049], [lr 0.002971] [batchtime 0.431]
[epoch 123], [iter 48 / 176], [train main loss -1.919416], [lr 0.002971] [batchtime 0.43]
[epoch 123], [iter 49 / 176], [train main loss -1.925727], [lr 0.002971] [batchtime 0.43]
[epoch 123], [iter 50 / 176], [train main loss -1.930183], [lr 0.002971] [batchtime 0.429]
[epoch 123], [iter 51 / 176], [train main loss -1.937223], [lr 0.002971] [batchtime 0.428]
[epoch 123], [iter 52 / 176], [train main loss -1.931361], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 53 / 176], [train main loss -1.896997], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 54 / 176], [train main loss -1.912433], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 55 / 176], [train main loss -1.896914], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 56 / 176], [train main loss -1.896500], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 57 / 176], [train main loss -1.866125], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 58 / 176], [train main loss -1.925118], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 59 / 176], [train main loss -1.913348], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 60 / 176], [train main loss -1.902797], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 61 / 176], [train main loss -1.863777], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 62 / 176], [train main loss -1.855481], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 63 / 176], [train main loss -1.885458], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 64 / 176], [train main loss -1.886082], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 65 / 176], [train main loss -1.901555], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 66 / 176], [train main loss -1.909039], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 67 / 176], [train main loss -1.931405], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 68 / 176], [train main loss -1.931942], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 69 / 176], [train main loss -1.989765], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 70 / 176], [train main loss -1.975319], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 71 / 176], [train main loss -1.983688], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 72 / 176], [train main loss -2.026768], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 73 / 176], [train main loss -1.988026], [lr 0.002971] [batchtime 0.42]
[epoch 123], [iter 74 / 176], [train main loss -1.986248], [lr 0.002971] [batchtime 0.42]
[epoch 123], [iter 75 / 176], [train main loss -1.976985], [lr 0.002971] [batchtime 0.419]
[epoch 123], [iter 76 / 176], [train main loss -2.015823], [lr 0.002971] [batchtime 0.419]
[epoch 123], [iter 77 / 176], [train main loss -2.010264], [lr 0.002971] [batchtime 0.419]
[epoch 123], [iter 78 / 176], [train main loss -1.977694], [lr 0.002971] [batchtime 0.418]
[epoch 123], [iter 79 / 176], [train main loss -1.920489], [lr 0.002971] [batchtime 0.418]
[epoch 123], [iter 80 / 176], [train main loss -1.909343], [lr 0.002971] [batchtime 0.418]
[epoch 123], [iter 81 / 176], [train main loss -1.875420], [lr 0.002971] [batchtime 0.417]
[epoch 123], [iter 82 / 176], [train main loss -1.925852], [lr 0.002971] [batchtime 0.417]
[epoch 123], [iter 83 / 176], [train main loss -1.922760], [lr 0.002971] [batchtime 0.417]
[epoch 123], [iter 84 / 176], [train main loss -1.916990], [lr 0.002971] [batchtime 0.417]
[epoch 123], [iter 85 / 176], [train main loss -1.892894], [lr 0.002971] [batchtime 0.416]
[epoch 123], [iter 86 / 176], [train main loss -1.896502], [lr 0.002971] [batchtime 0.416]
[epoch 123], [iter 87 / 176], [train main loss -1.912451], [lr 0.002971] [batchtime 0.432]
[epoch 123], [iter 88 / 176], [train main loss -1.926730], [lr 0.002971] [batchtime 0.436]
[epoch 123], [iter 89 / 176], [train main loss -1.954073], [lr 0.002971] [batchtime 0.435]
[epoch 123], [iter 90 / 176], [train main loss -1.926661], [lr 0.002971] [batchtime 0.434]
[epoch 123], [iter 91 / 176], [train main loss -1.913887], [lr 0.002971] [batchtime 0.433]
[epoch 123], [iter 92 / 176], [train main loss -1.919769], [lr 0.002971] [batchtime 0.433]
[epoch 123], [iter 93 / 176], [train main loss -1.909191], [lr 0.002971] [batchtime 0.433]
[epoch 123], [iter 94 / 176], [train main loss -1.934373], [lr 0.002971] [batchtime 0.432]
[epoch 123], [iter 95 / 176], [train main loss -1.956928], [lr 0.002971] [batchtime 0.432]
[epoch 123], [iter 96 / 176], [train main loss -2.000110], [lr 0.002971] [batchtime 0.431]
[epoch 123], [iter 97 / 176], [train main loss -2.005551], [lr 0.002971] [batchtime 0.431]
[epoch 123], [iter 98 / 176], [train main loss -1.983283], [lr 0.002971] [batchtime 0.431]
[epoch 123], [iter 99 / 176], [train main loss -1.994310], [lr 0.002971] [batchtime 0.43]
[epoch 123], [iter 100 / 176], [train main loss -1.977211], [lr 0.002971] [batchtime 0.43]
[epoch 123], [iter 101 / 176], [train main loss -1.974737], [lr 0.002971] [batchtime 0.43]
[epoch 123], [iter 102 / 176], [train main loss -1.990805], [lr 0.002971] [batchtime 0.429]
[epoch 123], [iter 103 / 176], [train main loss -2.014181], [lr 0.002971] [batchtime 0.429]
[epoch 123], [iter 104 / 176], [train main loss -1.994702], [lr 0.002971] [batchtime 0.428]
[epoch 123], [iter 105 / 176], [train main loss -1.987790], [lr 0.002971] [batchtime 0.428]
[epoch 123], [iter 106 / 176], [train main loss -1.959847], [lr 0.002971] [batchtime 0.428]
[epoch 123], [iter 107 / 176], [train main loss -1.956000], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 108 / 176], [train main loss -1.968244], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 109 / 176], [train main loss -1.976381], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 110 / 176], [train main loss -1.980231], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 111 / 176], [train main loss -1.964990], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 112 / 176], [train main loss -1.959232], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 113 / 176], [train main loss -1.951796], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 114 / 176], [train main loss -1.965628], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 115 / 176], [train main loss -1.972169], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 116 / 176], [train main loss -1.979685], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 117 / 176], [train main loss -1.967018], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 118 / 176], [train main loss -1.988324], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 119 / 176], [train main loss -1.997628], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 120 / 176], [train main loss -2.010198], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 121 / 176], [train main loss -2.036696], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 122 / 176], [train main loss -2.043199], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 123 / 176], [train main loss -2.045307], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 124 / 176], [train main loss -2.070643], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 125 / 176], [train main loss -2.065171], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 126 / 176], [train main loss -2.058545], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 127 / 176], [train main loss -2.040358], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 128 / 176], [train main loss -2.041961], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 129 / 176], [train main loss -2.040257], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 130 / 176], [train main loss -2.058728], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 131 / 176], [train main loss -2.080666], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 132 / 176], [train main loss -2.064541], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 133 / 176], [train main loss -2.074534], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 134 / 176], [train main loss -2.071880], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 135 / 176], [train main loss -2.069414], [lr 0.002971] [batchtime 0.428]
[epoch 123], [iter 136 / 176], [train main loss -2.079271], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 137 / 176], [train main loss -2.077118], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 138 / 176], [train main loss -2.065649], [lr 0.002971] [batchtime 0.427]
[epoch 123], [iter 139 / 176], [train main loss -2.051121], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 140 / 176], [train main loss -2.047698], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 141 / 176], [train main loss -2.074104], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 142 / 176], [train main loss -2.074520], [lr 0.002971] [batchtime 0.426]
[epoch 123], [iter 143 / 176], [train main loss -2.064836], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 144 / 176], [train main loss -2.080851], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 145 / 176], [train main loss -2.089093], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 146 / 176], [train main loss -2.097652], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 147 / 176], [train main loss -2.106834], [lr 0.002971] [batchtime 0.425]
[epoch 123], [iter 148 / 176], [train main loss -2.100027], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 149 / 176], [train main loss -2.095130], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 150 / 176], [train main loss -2.087735], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 151 / 176], [train main loss -2.095580], [lr 0.002971] [batchtime 0.424]
[epoch 123], [iter 152 / 176], [train main loss -2.113719], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 153 / 176], [train main loss -2.119372], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 154 / 176], [train main loss -2.115678], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 155 / 176], [train main loss -2.108724], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 156 / 176], [train main loss -2.121433], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 157 / 176], [train main loss -2.134675], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 158 / 176], [train main loss -2.123630], [lr 0.002971] [batchtime 0.423]
[epoch 123], [iter 159 / 176], [train main loss -2.128641], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 160 / 176], [train main loss -2.125080], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 161 / 176], [train main loss -2.128132], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 162 / 176], [train main loss -2.136659], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 163 / 176], [train main loss -2.155061], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 164 / 176], [train main loss -2.156729], [lr 0.002971] [batchtime 0.422]
[epoch 123], [iter 165 / 176], [train main loss -2.154561], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 166 / 176], [train main loss -2.153157], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 167 / 176], [train main loss -2.140432], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 168 / 176], [train main loss -2.150248], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 169 / 176], [train main loss -2.147567], [lr 0.002971] [batchtime 0.421]
[epoch 123], [iter 170 / 176], [train main loss -2.155847], [lr 0.002971] [batchtime 0.42]
[epoch 123], [iter 171 / 176], [train main loss -2.150516], [lr 0.002971] [batchtime 0.42]
[epoch 123], [iter 172 / 176], [train main loss -2.158303], [lr 0.002971] [batchtime 0.42]
[epoch 123], [iter 173 / 176], [train main loss -2.149733], [lr 0.002971] [batchtime 0.42]
[epoch 123], [iter 174 / 176], [train main loss -2.141059], [lr 0.002971] [batchtime 0.419]
[epoch 123], [iter 175 / 176], [train main loss -2.122203], [lr 0.002971] [batchtime 0.419]
[epoch 123], [iter 176 / 176], [train main loss -2.135128], [lr 0.002971] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.69  35.67    0.02  0.04         0.98      0.96
   1  sidewalk          68.68   5.20    0.27  0.19         0.79      0.84
   2  building          86.74  25.17    0.06  0.10         0.95      0.91
   3  wall              16.74   0.12    3.81  1.16         0.21      0.46
   4  fence             26.53   0.41    2.10  0.67         0.32      0.60
   5  pole              38.86   0.55    1.07  0.50         0.48      0.67
   6  traffic light     16.56   0.03    4.57  0.47         0.18      0.68
   7  traffic sign      24.39   0.15    2.84  0.26         0.26      0.79
   8  vegetation        84.58  11.56    0.07  0.11         0.94      0.90
   9  terrain           43.13   0.42    0.73  0.59         0.58      0.63
  10  sky               93.52   3.73    0.04  0.03         0.96      0.97
  11  person            55.18   1.09    0.40  0.41         0.71      0.71
  12  rider              9.38   0.01    8.58  1.07         0.10      0.48
  13  car               86.58   6.69    0.06  0.10         0.95      0.91
  14  truck              0.59   0.00  167.06  0.52         0.01      0.66
  15  bus               15.17   0.05    0.83  4.76         0.55      0.17
  16  train             33.14   0.07    1.39  0.63         0.42      0.61
  17  motorcycle         4.19   0.00   22.39  0.46         0.04      0.68
  18  bicycle           38.87   0.26    0.50  1.07         0.66      0.48
Mean: 44.08
-----------------------------------------------------------------------------------------------------------
this : [epoch 123], [val loss 0.30755], [acc 0.91189], [acc_cls 0.53095], [mean_iu 0.44080], [fwavacc 0.84653]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 124], [iter 1 / 176], [train main loss -3.448892], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 2 / 176], [train main loss -3.440657], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 3 / 176], [train main loss -3.031470], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 4 / 176], [train main loss -2.418787], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 5 / 176], [train main loss -2.873552], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 6 / 176], [train main loss -2.833907], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 7 / 176], [train main loss -2.563671], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 8 / 176], [train main loss -2.479987], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 9 / 176], [train main loss -2.296851], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 10 / 176], [train main loss -2.467410], [lr 0.002914] [batchtime 0]
[epoch 124], [iter 11 / 176], [train main loss -2.338147], [lr 0.002914] [batchtime 0.371]
[epoch 124], [iter 12 / 176], [train main loss -2.427441], [lr 0.002914] [batchtime 0.387]
[epoch 124], [iter 13 / 176], [train main loss -2.200251], [lr 0.002914] [batchtime 0.394]
[epoch 124], [iter 14 / 176], [train main loss -2.246579], [lr 0.002914] [batchtime 0.396]
[epoch 124], [iter 15 / 176], [train main loss -2.281686], [lr 0.002914] [batchtime 0.398]
[epoch 124], [iter 16 / 176], [train main loss -2.405804], [lr 0.002914] [batchtime 0.398]
[epoch 124], [iter 17 / 176], [train main loss -2.329852], [lr 0.002914] [batchtime 0.4]
[epoch 124], [iter 18 / 176], [train main loss -2.207057], [lr 0.002914] [batchtime 0.4]
[epoch 124], [iter 19 / 176], [train main loss -2.084560], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 20 / 176], [train main loss -2.068299], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 21 / 176], [train main loss -2.124780], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 22 / 176], [train main loss -2.159153], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 23 / 176], [train main loss -2.092198], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 24 / 176], [train main loss -2.225407], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 25 / 176], [train main loss -2.052167], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 26 / 176], [train main loss -2.125897], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 27 / 176], [train main loss -2.083893], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 28 / 176], [train main loss -2.106583], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 29 / 176], [train main loss -2.033434], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 30 / 176], [train main loss -1.964412], [lr 0.002914] [batchtime 0.401]
[epoch 124], [iter 31 / 176], [train main loss -2.016519], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 32 / 176], [train main loss -2.038042], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 33 / 176], [train main loss -2.129433], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 34 / 176], [train main loss -2.208627], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 35 / 176], [train main loss -2.184824], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 36 / 176], [train main loss -2.175385], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 37 / 176], [train main loss -2.090601], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 38 / 176], [train main loss -2.095536], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 39 / 176], [train main loss -2.070697], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 40 / 176], [train main loss -2.078065], [lr 0.002914] [batchtime 0.402]
[epoch 124], [iter 41 / 176], [train main loss -2.036209], [lr 0.002914] [batchtime 0.403]
[epoch 124], [iter 42 / 176], [train main loss -2.104025], [lr 0.002914] [batchtime 0.444]
[epoch 124], [iter 43 / 176], [train main loss -2.081108], [lr 0.002914] [batchtime 0.452]
[epoch 124], [iter 44 / 176], [train main loss -2.115519], [lr 0.002914] [batchtime 0.451]
[epoch 124], [iter 45 / 176], [train main loss -2.111565], [lr 0.002914] [batchtime 0.449]
[epoch 124], [iter 46 / 176], [train main loss -2.074027], [lr 0.002914] [batchtime 0.448]
[epoch 124], [iter 47 / 176], [train main loss -2.051470], [lr 0.002914] [batchtime 0.446]
[epoch 124], [iter 48 / 176], [train main loss -2.007686], [lr 0.002914] [batchtime 0.445]
[epoch 124], [iter 49 / 176], [train main loss -2.017816], [lr 0.002914] [batchtime 0.444]
[epoch 124], [iter 50 / 176], [train main loss -1.994332], [lr 0.002914] [batchtime 0.443]
[epoch 124], [iter 51 / 176], [train main loss -2.013993], [lr 0.002914] [batchtime 0.442]
[epoch 124], [iter 52 / 176], [train main loss -2.001737], [lr 0.002914] [batchtime 0.441]
[epoch 124], [iter 53 / 176], [train main loss -2.007210], [lr 0.002914] [batchtime 0.44]
[epoch 124], [iter 54 / 176], [train main loss -1.979847], [lr 0.002914] [batchtime 0.439]
[epoch 124], [iter 55 / 176], [train main loss -2.100370], [lr 0.002914] [batchtime 0.438]
[epoch 124], [iter 56 / 176], [train main loss -2.109382], [lr 0.002914] [batchtime 0.437]
[epoch 124], [iter 57 / 176], [train main loss -2.064086], [lr 0.002914] [batchtime 0.437]
[epoch 124], [iter 58 / 176], [train main loss -2.046468], [lr 0.002914] [batchtime 0.436]
[epoch 124], [iter 59 / 176], [train main loss -2.040857], [lr 0.002914] [batchtime 0.435]
[epoch 124], [iter 60 / 176], [train main loss -2.025993], [lr 0.002914] [batchtime 0.435]
[epoch 124], [iter 61 / 176], [train main loss -2.038181], [lr 0.002914] [batchtime 0.434]
[epoch 124], [iter 62 / 176], [train main loss -2.029585], [lr 0.002914] [batchtime 0.433]
[epoch 124], [iter 63 / 176], [train main loss -1.994366], [lr 0.002914] [batchtime 0.433]
[epoch 124], [iter 64 / 176], [train main loss -1.998251], [lr 0.002914] [batchtime 0.432]
[epoch 124], [iter 65 / 176], [train main loss -2.060283], [lr 0.002914] [batchtime 0.431]
[epoch 124], [iter 66 / 176], [train main loss -2.042199], [lr 0.002914] [batchtime 0.431]
[epoch 124], [iter 67 / 176], [train main loss -2.079492], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 68 / 176], [train main loss -2.095062], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 69 / 176], [train main loss -2.101075], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 70 / 176], [train main loss -2.082121], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 71 / 176], [train main loss -2.109927], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 72 / 176], [train main loss -2.076542], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 73 / 176], [train main loss -2.025571], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 74 / 176], [train main loss -2.041584], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 75 / 176], [train main loss -2.045899], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 76 / 176], [train main loss -2.027999], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 77 / 176], [train main loss -2.042922], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 78 / 176], [train main loss -2.013023], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 79 / 176], [train main loss -2.003975], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 80 / 176], [train main loss -1.993260], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 81 / 176], [train main loss -1.976137], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 82 / 176], [train main loss -1.961276], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 83 / 176], [train main loss -2.012319], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 84 / 176], [train main loss -2.023615], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 85 / 176], [train main loss -2.016403], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 86 / 176], [train main loss -1.998521], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 87 / 176], [train main loss -1.996808], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 88 / 176], [train main loss -1.989529], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 89 / 176], [train main loss -1.983693], [lr 0.002914] [batchtime 0.433]
[epoch 124], [iter 90 / 176], [train main loss -2.007007], [lr 0.002914] [batchtime 0.432]
[epoch 124], [iter 91 / 176], [train main loss -1.999425], [lr 0.002914] [batchtime 0.432]
[epoch 124], [iter 92 / 176], [train main loss -1.998611], [lr 0.002914] [batchtime 0.431]
[epoch 124], [iter 93 / 176], [train main loss -1.993636], [lr 0.002914] [batchtime 0.431]
[epoch 124], [iter 94 / 176], [train main loss -2.035611], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 95 / 176], [train main loss -2.006927], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 96 / 176], [train main loss -2.000824], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 97 / 176], [train main loss -2.008546], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 98 / 176], [train main loss -1.970683], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 99 / 176], [train main loss -1.971723], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 100 / 176], [train main loss -1.966154], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 101 / 176], [train main loss -1.972242], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 102 / 176], [train main loss -1.977507], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 103 / 176], [train main loss -1.957787], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 104 / 176], [train main loss -1.986685], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 105 / 176], [train main loss -1.995963], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 106 / 176], [train main loss -1.976943], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 107 / 176], [train main loss -1.964573], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 108 / 176], [train main loss -1.947980], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 109 / 176], [train main loss -1.934997], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 110 / 176], [train main loss -1.959282], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 111 / 176], [train main loss -1.936657], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 112 / 176], [train main loss -1.946335], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 113 / 176], [train main loss -1.951277], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 114 / 176], [train main loss -1.959344], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 115 / 176], [train main loss -1.948750], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 116 / 176], [train main loss -1.958803], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 117 / 176], [train main loss -1.961966], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 118 / 176], [train main loss -1.975135], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 119 / 176], [train main loss -1.996147], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 120 / 176], [train main loss -2.004326], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 121 / 176], [train main loss -2.011609], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 122 / 176], [train main loss -2.012821], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 123 / 176], [train main loss -2.048325], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 124 / 176], [train main loss -2.071529], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 125 / 176], [train main loss -2.067723], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 126 / 176], [train main loss -2.074107], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 127 / 176], [train main loss -2.055471], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 128 / 176], [train main loss -2.064805], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 129 / 176], [train main loss -2.070550], [lr 0.002914] [batchtime 0.42]
[epoch 124], [iter 130 / 176], [train main loss -2.076885], [lr 0.002914] [batchtime 0.42]
[epoch 124], [iter 131 / 176], [train main loss -2.076035], [lr 0.002914] [batchtime 0.42]
[epoch 124], [iter 132 / 176], [train main loss -2.092256], [lr 0.002914] [batchtime 0.42]
[epoch 124], [iter 133 / 176], [train main loss -2.091221], [lr 0.002914] [batchtime 0.419]
[epoch 124], [iter 134 / 176], [train main loss -2.114756], [lr 0.002914] [batchtime 0.419]
[epoch 124], [iter 135 / 176], [train main loss -2.112064], [lr 0.002914] [batchtime 0.419]
[epoch 124], [iter 136 / 176], [train main loss -2.126668], [lr 0.002914] [batchtime 0.42]
[epoch 124], [iter 137 / 176], [train main loss -2.119865], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 138 / 176], [train main loss -2.100073], [lr 0.002914] [batchtime 0.43]
[epoch 124], [iter 139 / 176], [train main loss -2.101424], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 140 / 176], [train main loss -2.089698], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 141 / 176], [train main loss -2.086347], [lr 0.002914] [batchtime 0.429]
[epoch 124], [iter 142 / 176], [train main loss -2.092556], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 143 / 176], [train main loss -2.097105], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 144 / 176], [train main loss -2.077362], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 145 / 176], [train main loss -2.070349], [lr 0.002914] [batchtime 0.428]
[epoch 124], [iter 146 / 176], [train main loss -2.065056], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 147 / 176], [train main loss -2.076282], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 148 / 176], [train main loss -2.085012], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 149 / 176], [train main loss -2.071897], [lr 0.002914] [batchtime 0.427]
[epoch 124], [iter 150 / 176], [train main loss -2.067523], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 151 / 176], [train main loss -2.067263], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 152 / 176], [train main loss -2.066736], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 153 / 176], [train main loss -2.059875], [lr 0.002914] [batchtime 0.426]
[epoch 124], [iter 154 / 176], [train main loss -2.060336], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 155 / 176], [train main loss -2.060509], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 156 / 176], [train main loss -2.067379], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 157 / 176], [train main loss -2.074882], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 158 / 176], [train main loss -2.083437], [lr 0.002914] [batchtime 0.425]
[epoch 124], [iter 159 / 176], [train main loss -2.098155], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 160 / 176], [train main loss -2.089062], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 161 / 176], [train main loss -2.084040], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 162 / 176], [train main loss -2.109336], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 163 / 176], [train main loss -2.115810], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 164 / 176], [train main loss -2.118554], [lr 0.002914] [batchtime 0.424]
[epoch 124], [iter 165 / 176], [train main loss -2.113498], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 166 / 176], [train main loss -2.112733], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 167 / 176], [train main loss -2.121424], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 168 / 176], [train main loss -2.114358], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 169 / 176], [train main loss -2.108200], [lr 0.002914] [batchtime 0.423]
[epoch 124], [iter 170 / 176], [train main loss -2.100940], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 171 / 176], [train main loss -2.091526], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 172 / 176], [train main loss -2.074498], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 173 / 176], [train main loss -2.079322], [lr 0.002914] [batchtime 0.422]
[epoch 124], [iter 174 / 176], [train main loss -2.079559], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 175 / 176], [train main loss -2.081809], [lr 0.002914] [batchtime 0.421]
[epoch 124], [iter 176 / 176], [train main loss -2.077688], [lr 0.002914] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              94.57  35.47    0.02  0.03         0.98      0.97
   1  sidewalk          69.27   5.33    0.24  0.21         0.81      0.83
   2  building          86.49  24.77    0.07  0.08         0.93      0.92
   3  wall              16.13   0.13    3.40  1.80         0.23      0.36
   4  fence             25.53   0.39    2.28  0.64         0.31      0.61
   5  pole              39.80   0.60    0.89  0.62         0.53      0.62
   6  traffic light     17.64   0.03    4.08  0.59         0.20      0.63
   7  traffic sign      27.91   0.17    2.27  0.31         0.31      0.76
   8  vegetation        83.45  11.71    0.06  0.14         0.95      0.88
   9  terrain           40.80   0.40    0.86  0.59         0.54      0.63
  10  sky               93.85   3.77    0.03  0.04         0.97      0.96
  11  person            54.66   1.07    0.44  0.39         0.70      0.72
  12  rider             12.00   0.01    6.14  1.19         0.14      0.46
  13  car               86.26   6.70    0.06  0.10         0.95      0.91
  14  truck              0.49   0.00  204.10  0.59         0.00      0.63
  15  bus               14.08   0.05    0.73  5.37         0.58      0.16
  16  train             27.46   0.06    1.94  0.71         0.34      0.59
  17  motorcycle         4.42   0.01   21.09  0.53         0.05      0.65
  18  bicycle           38.21   0.27    0.44  1.17         0.69      0.46
Mean: 43.84
-----------------------------------------------------------------------------------------------------------
this : [epoch 124], [val loss 0.30613], [acc 0.90944], [acc_cls 0.53597], [mean_iu 0.43843], [fwavacc 0.84416]
best : [epoch 118], [val loss 0.30450], [acc 0.90845], [acc_cls 0.53937], [mean_iu 0.44118], [fwavacc 0.84286]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 125], [iter 1 / 176], [train main loss -1.300822], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 2 / 176], [train main loss -0.550454], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 3 / 176], [train main loss -1.308474], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 4 / 176], [train main loss -0.900310], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 5 / 176], [train main loss -1.570430], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 6 / 176], [train main loss -1.795047], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 7 / 176], [train main loss -2.493169], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 8 / 176], [train main loss -2.270864], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 9 / 176], [train main loss -2.467381], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 10 / 176], [train main loss -2.762774], [lr 0.002857] [batchtime 0]
[epoch 125], [iter 11 / 176], [train main loss -2.875000], [lr 0.002857] [batchtime 0.382]
[epoch 125], [iter 12 / 176], [train main loss -2.632680], [lr 0.002857] [batchtime 0.39]
[epoch 125], [iter 13 / 176], [train main loss -2.596353], [lr 0.002857] [batchtime 0.392]
[epoch 125], [iter 14 / 176], [train main loss -2.367282], [lr 0.002857] [batchtime 0.394]
[epoch 125], [iter 15 / 176], [train main loss -2.460623], [lr 0.002857] [batchtime 0.395]
[epoch 125], [iter 16 / 176], [train main loss -2.336699], [lr 0.002857] [batchtime 0.396]
[epoch 125], [iter 17 / 176], [train main loss -2.460720], [lr 0.002857] [batchtime 0.397]
[epoch 125], [iter 18 / 176], [train main loss -2.328094], [lr 0.002857] [batchtime 0.398]
[epoch 125], [iter 19 / 176], [train main loss -2.404598], [lr 0.002857] [batchtime 0.399]
[epoch 125], [iter 20 / 176], [train main loss -2.455156], [lr 0.002857] [batchtime 0.399]
[epoch 125], [iter 21 / 176], [train main loss -2.397801], [lr 0.002857] [batchtime 0.4]
[epoch 125], [iter 22 / 176], [train main loss -2.409009], [lr 0.002857] [batchtime 0.4]
[epoch 125], [iter 23 / 176], [train main loss -2.369722], [lr 0.002857] [batchtime 0.4]
[epoch 125], [iter 24 / 176], [train main loss -2.356035], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 25 / 176], [train main loss -2.319944], [lr 0.002857] [batchtime 0.402]
[epoch 125], [iter 26 / 176], [train main loss -2.215671], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 27 / 176], [train main loss -2.152937], [lr 0.002857] [batchtime 0.4]
[epoch 125], [iter 28 / 176], [train main loss -2.105462], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 29 / 176], [train main loss -2.067400], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 30 / 176], [train main loss -2.017016], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 31 / 176], [train main loss -2.084331], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 32 / 176], [train main loss -1.978036], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 33 / 176], [train main loss -1.935125], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 34 / 176], [train main loss -1.869054], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 35 / 176], [train main loss -1.889874], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 36 / 176], [train main loss -1.817405], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 37 / 176], [train main loss -1.796340], [lr 0.002857] [batchtime 0.401]
[epoch 125], [iter 38 / 176], [train main loss -1.739157], [lr 0.002857] [batchtime 0.4]
[epoch 125], [iter 39 / 176], [train main loss -1.744911], [lr 0.002857] [batchtime 0.406]
[epoch 125], [iter 40 / 176], [train main loss -1.787610], [lr 0.002857] [batchtime 0.448]
[epoch 125], [iter 41 / 176], [train main loss -1.815853], [lr 0.002857] [batchtime 0.446]
[epoch 125], [iter 42 / 176], [train main loss -1.747352], [lr 0.002857] [batchtime 0.444]
[epoch 125], [iter 43 / 176], [train main loss -1.743228], [lr 0.002857] [batchtime 0.442]
[epoch 125], [iter 44 / 176], [train main loss -1.815147], [lr 0.002857] [batchtime 0.441]
[epoch 125], [iter 45 / 176], [train main loss -1.797389], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 46 / 176], [train main loss -1.744747], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 47 / 176], [train main loss -1.781925], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 48 / 176], [train main loss -1.804829], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 49 / 176], [train main loss -1.758445], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 50 / 176], [train main loss -1.759990], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 51 / 176], [train main loss -1.741173], [lr 0.002857] [batchtime 0.433]
[epoch 125], [iter 52 / 176], [train main loss -1.732052], [lr 0.002857] [batchtime 0.432]
[epoch 125], [iter 53 / 176], [train main loss -1.738487], [lr 0.002857] [batchtime 0.432]
[epoch 125], [iter 54 / 176], [train main loss -1.778553], [lr 0.002857] [batchtime 0.431]
[epoch 125], [iter 55 / 176], [train main loss -1.814896], [lr 0.002857] [batchtime 0.43]
[epoch 125], [iter 56 / 176], [train main loss -1.827245], [lr 0.002857] [batchtime 0.429]
[epoch 125], [iter 57 / 176], [train main loss -1.830611], [lr 0.002857] [batchtime 0.429]
[epoch 125], [iter 58 / 176], [train main loss -1.828852], [lr 0.002857] [batchtime 0.428]
[epoch 125], [iter 59 / 176], [train main loss -1.826099], [lr 0.002857] [batchtime 0.427]
[epoch 125], [iter 60 / 176], [train main loss -1.849458], [lr 0.002857] [batchtime 0.427]
[epoch 125], [iter 61 / 176], [train main loss -1.850372], [lr 0.002857] [batchtime 0.426]
[epoch 125], [iter 62 / 176], [train main loss -1.850886], [lr 0.002857] [batchtime 0.426]
[epoch 125], [iter 63 / 176], [train main loss -1.836048], [lr 0.002857] [batchtime 0.425]
[epoch 125], [iter 64 / 176], [train main loss -1.838891], [lr 0.002857] [batchtime 0.425]
[epoch 125], [iter 65 / 176], [train main loss -1.814017], [lr 0.002857] [batchtime 0.424]
[epoch 125], [iter 66 / 176], [train main loss -1.834466], [lr 0.002857] [batchtime 0.424]
[epoch 125], [iter 67 / 176], [train main loss -1.825978], [lr 0.002857] [batchtime 0.423]
[epoch 125], [iter 68 / 176], [train main loss -1.846438], [lr 0.002857] [batchtime 0.423]
[epoch 125], [iter 69 / 176], [train main loss -1.871309], [lr 0.002857] [batchtime 0.423]
[epoch 125], [iter 70 / 176], [train main loss -1.867484], [lr 0.002857] [batchtime 0.422]
[epoch 125], [iter 71 / 176], [train main loss -1.875154], [lr 0.002857] [batchtime 0.422]
[epoch 125], [iter 72 / 176], [train main loss -1.906170], [lr 0.002857] [batchtime 0.421]
[epoch 125], [iter 73 / 176], [train main loss -1.934717], [lr 0.002857] [batchtime 0.421]
[epoch 125], [iter 74 / 176], [train main loss -1.905082], [lr 0.002857] [batchtime 0.421]
[epoch 125], [iter 75 / 176], [train main loss -1.945403], [lr 0.002857] [batchtime 0.42]
[epoch 125], [iter 76 / 176], [train main loss -1.936378], [lr 0.002857] [batchtime 0.42]
[epoch 125], [iter 77 / 176], [train main loss -1.970212], [lr 0.002857] [batchtime 0.419]
[epoch 125], [iter 78 / 176], [train main loss -1.960016], [lr 0.002857] [batchtime 0.419]
[epoch 125], [iter 79 / 176], [train main loss -1.959319], [lr 0.002857] [batchtime 0.419]
[epoch 125], [iter 80 / 176], [train main loss -1.964821], [lr 0.002857] [batchtime 0.418]
[epoch 125], [iter 81 / 176], [train main loss -1.958649], [lr 0.002857] [batchtime 0.418]
[epoch 125], [iter 82 / 176], [train main loss -1.947140], [lr 0.002857] [batchtime 0.418]
[epoch 125], [iter 83 / 176], [train main loss -1.937769], [lr 0.002857] [batchtime 0.417]
[epoch 125], [iter 84 / 176], [train main loss -1.952453], [lr 0.002857] [batchtime 0.417]
[epoch 125], [iter 85 / 176], [train main loss -1.955800], [lr 0.002857] [batchtime 0.417]
[epoch 125], [iter 86 / 176], [train main loss -1.984618], [lr 0.002857] [batchtime 0.419]
[epoch 125], [iter 87 / 176], [train main loss -2.000252], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 88 / 176], [train main loss -2.005785], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 89 / 176], [train main loss -2.023485], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 90 / 176], [train main loss -2.013522], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 91 / 176], [train main loss -2.017251], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 92 / 176], [train main loss -2.017642], [lr 0.002857] [batchtime 0.433]
[epoch 125], [iter 93 / 176], [train main loss -2.018218], [lr 0.002857] [batchtime 0.433]
[epoch 125], [iter 94 / 176], [train main loss -1.992094], [lr 0.002857] [batchtime 0.433]
[epoch 125], [iter 95 / 176], [train main loss -1.996158], [lr 0.002857] [batchtime 0.432]
[epoch 125], [iter 96 / 176], [train main loss -2.013323], [lr 0.002857] [batchtime 0.432]
[epoch 125], [iter 97 / 176], [train main loss -1.993212], [lr 0.002857] [batchtime 0.431]
[epoch 125], [iter 98 / 176], [train main loss -1.988178], [lr 0.002857] [batchtime 0.431]
[epoch 125], [iter 99 / 176], [train main loss -2.009777], [lr 0.002857] [batchtime 0.431]
[epoch 125], [iter 100 / 176], [train main loss -2.056416], [lr 0.002857] [batchtime 0.43]
[epoch 125], [iter 101 / 176], [train main loss -2.081202], [lr 0.002857] [batchtime 0.43]
[epoch 125], [iter 102 / 176], [train main loss -2.084186], [lr 0.002857] [batchtime 0.429]
[epoch 125], [iter 103 / 176], [train main loss -2.105200], [lr 0.002857] [batchtime 0.429]
[epoch 125], [iter 104 / 176], [train main loss -2.096845], [lr 0.002857] [batchtime 0.429]
[epoch 125], [iter 105 / 176], [train main loss -2.081730], [lr 0.002857] [batchtime 0.429]
[epoch 125], [iter 106 / 176], [train main loss -2.089835], [lr 0.002857] [batchtime 0.428]
[epoch 125], [iter 107 / 176], [train main loss -2.103318], [lr 0.002857] [batchtime 0.428]
[epoch 125], [iter 108 / 176], [train main loss -2.096586], [lr 0.002857] [batchtime 0.428]
[epoch 125], [iter 109 / 176], [train main loss -2.095044], [lr 0.002857] [batchtime 0.427]
[epoch 125], [iter 110 / 176], [train main loss -2.082188], [lr 0.002857] [batchtime 0.427]
[epoch 125], [iter 111 / 176], [train main loss -2.081611], [lr 0.002857] [batchtime 0.427]
[epoch 125], [iter 112 / 176], [train main loss -2.048247], [lr 0.002857] [batchtime 0.427]
[epoch 125], [iter 113 / 176], [train main loss -2.035452], [lr 0.002857] [batchtime 0.426]
[epoch 125], [iter 114 / 176], [train main loss -2.030957], [lr 0.002857] [batchtime 0.426]
[epoch 125], [iter 115 / 176], [train main loss -2.043179], [lr 0.002857] [batchtime 0.426]
[epoch 125], [iter 116 / 176], [train main loss -2.041213], [lr 0.002857] [batchtime 0.425]
[epoch 125], [iter 117 / 176], [train main loss -2.019147], [lr 0.002857] [batchtime 0.425]
[epoch 125], [iter 118 / 176], [train main loss -2.019436], [lr 0.002857] [batchtime 0.425]
[epoch 125], [iter 119 / 176], [train main loss -2.013840], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 120 / 176], [train main loss -2.010533], [lr 0.002857] [batchtime 0.44]
[epoch 125], [iter 121 / 176], [train main loss -2.005547], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 122 / 176], [train main loss -2.002303], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 123 / 176], [train main loss -2.012970], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 124 / 176], [train main loss -1.989904], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 125 / 176], [train main loss -1.999729], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 126 / 176], [train main loss -2.002420], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 127 / 176], [train main loss -2.018456], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 128 / 176], [train main loss -1.985144], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 129 / 176], [train main loss -2.009508], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 130 / 176], [train main loss -2.024889], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 131 / 176], [train main loss -2.037037], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 132 / 176], [train main loss -2.046731], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 133 / 176], [train main loss -2.047252], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 134 / 176], [train main loss -2.042329], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 135 / 176], [train main loss -2.042248], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 136 / 176], [train main loss -2.032386], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 137 / 176], [train main loss -2.018451], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 138 / 176], [train main loss -2.019114], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 139 / 176], [train main loss -2.013651], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 140 / 176], [train main loss -2.033220], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 141 / 176], [train main loss -2.070686], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 142 / 176], [train main loss -2.054865], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 143 / 176], [train main loss -2.062352], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 144 / 176], [train main loss -2.068644], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 145 / 176], [train main loss -2.063979], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 146 / 176], [train main loss -2.053049], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 147 / 176], [train main loss -2.043531], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 148 / 176], [train main loss -2.012816], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 149 / 176], [train main loss -2.002431], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 150 / 176], [train main loss -1.999421], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 151 / 176], [train main loss -1.997103], [lr 0.002857] [batchtime 0.433]
[epoch 125], [iter 152 / 176], [train main loss -2.000618], [lr 0.002857] [batchtime 0.433]
[epoch 125], [iter 153 / 176], [train main loss -1.990308], [lr 0.002857] [batchtime 0.44]
[epoch 125], [iter 154 / 176], [train main loss -1.987931], [lr 0.002857] [batchtime 0.44]
[epoch 125], [iter 155 / 176], [train main loss -1.974579], [lr 0.002857] [batchtime 0.44]
[epoch 125], [iter 156 / 176], [train main loss -1.980642], [lr 0.002857] [batchtime 0.44]
[epoch 125], [iter 157 / 176], [train main loss -1.983330], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 158 / 176], [train main loss -1.977178], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 159 / 176], [train main loss -1.960760], [lr 0.002857] [batchtime 0.439]
[epoch 125], [iter 160 / 176], [train main loss -1.963586], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 161 / 176], [train main loss -1.972804], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 162 / 176], [train main loss -1.955554], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 163 / 176], [train main loss -1.950771], [lr 0.002857] [batchtime 0.438]
[epoch 125], [iter 164 / 176], [train main loss -1.944399], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 165 / 176], [train main loss -1.947078], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 166 / 176], [train main loss -1.948082], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 167 / 176], [train main loss -1.942995], [lr 0.002857] [batchtime 0.437]
[epoch 125], [iter 168 / 176], [train main loss -1.948266], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 169 / 176], [train main loss -1.934036], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 170 / 176], [train main loss -1.929997], [lr 0.002857] [batchtime 0.436]
[epoch 125], [iter 171 / 176], [train main loss -1.936887], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 172 / 176], [train main loss -1.916918], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 173 / 176], [train main loss -1.913150], [lr 0.002857] [batchtime 0.435]
[epoch 125], [iter 174 / 176], [train main loss -1.910151], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 175 / 176], [train main loss -1.917523], [lr 0.002857] [batchtime 0.434]
[epoch 125], [iter 176 / 176], [train main loss -1.922929], [lr 0.002857] [batchtime 0.438]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.84  35.54   0.02  0.03         0.98      0.97
   1  sidewalk          70.56   5.33   0.24  0.18         0.81      0.85
   2  building          86.09  25.02   0.06  0.10         0.94      0.91
   3  wall              19.60   0.17   2.42  1.68         0.29      0.37
   4  fence             25.59   0.39   2.28  0.63         0.31      0.61
   5  pole              39.17   0.56   1.03  0.53         0.49      0.66
   6  traffic light     16.25   0.03   4.65  0.51         0.18      0.66
   7  traffic sign      26.75   0.16   2.45  0.29         0.29      0.78
   8  vegetation        83.52  11.60   0.07  0.13         0.94      0.88
   9  terrain           43.03   0.42   0.76  0.57         0.57      0.64
  10  sky               93.71   3.77   0.03  0.04         0.97      0.96
  11  person            53.61   1.02   0.50  0.37         0.67      0.73
  12  rider             11.84   0.01   6.12  1.32         0.14      0.43
  13  car               85.69   6.66   0.06  0.10         0.94      0.91
  14  truck              2.41   0.01  39.78  0.71         0.02      0.58
  15  bus               15.81   0.04   1.26  4.06         0.44      0.20
  16  train             39.45   0.09   0.98  0.56         0.51      0.64
  17  motorcycle         5.00   0.01  18.22  0.77         0.05      0.57
  18  bicycle           39.70   0.26   0.51  1.01         0.66      0.50
Mean: 44.88
-----------------------------------------------------------------------------------------------------------
this : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 126], [iter 1 / 176], [train main loss -4.346979], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 2 / 176], [train main loss -3.798379], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 3 / 176], [train main loss -2.891986], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 4 / 176], [train main loss -2.655768], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 5 / 176], [train main loss -2.323632], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 6 / 176], [train main loss -2.123052], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 7 / 176], [train main loss -1.923632], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 8 / 176], [train main loss -1.732806], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 9 / 176], [train main loss -1.758529], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 10 / 176], [train main loss -1.922054], [lr 0.002800] [batchtime 0]
[epoch 126], [iter 11 / 176], [train main loss -2.253448], [lr 0.002800] [batchtime 0.363]
[epoch 126], [iter 12 / 176], [train main loss -2.043973], [lr 0.002800] [batchtime 0.378]
[epoch 126], [iter 13 / 176], [train main loss -1.910744], [lr 0.002800] [batchtime 0.388]
[epoch 126], [iter 14 / 176], [train main loss -1.925638], [lr 0.002800] [batchtime 0.391]
[epoch 126], [iter 15 / 176], [train main loss -1.937581], [lr 0.002800] [batchtime 0.394]
[epoch 126], [iter 16 / 176], [train main loss -2.037824], [lr 0.002800] [batchtime 0.398]
[epoch 126], [iter 17 / 176], [train main loss -2.052930], [lr 0.002800] [batchtime 0.397]
[epoch 126], [iter 18 / 176], [train main loss -2.125656], [lr 0.002800] [batchtime 0.399]
[epoch 126], [iter 19 / 176], [train main loss -2.103524], [lr 0.002800] [batchtime 0.398]
[epoch 126], [iter 20 / 176], [train main loss -2.114926], [lr 0.002800] [batchtime 0.409]
[epoch 126], [iter 21 / 176], [train main loss -2.100383], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 22 / 176], [train main loss -2.062476], [lr 0.002800] [batchtime 0.407]
[epoch 126], [iter 23 / 176], [train main loss -2.021261], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 24 / 176], [train main loss -2.020287], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 25 / 176], [train main loss -2.100868], [lr 0.002800] [batchtime 0.412]
[epoch 126], [iter 26 / 176], [train main loss -2.193039], [lr 0.002800] [batchtime 0.411]
[epoch 126], [iter 27 / 176], [train main loss -2.217223], [lr 0.002800] [batchtime 0.411]
[epoch 126], [iter 28 / 176], [train main loss -2.187017], [lr 0.002800] [batchtime 0.41]
[epoch 126], [iter 29 / 176], [train main loss -2.214772], [lr 0.002800] [batchtime 0.409]
[epoch 126], [iter 30 / 176], [train main loss -2.213896], [lr 0.002800] [batchtime 0.409]
[epoch 126], [iter 31 / 176], [train main loss -2.191077], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 32 / 176], [train main loss -2.238623], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 33 / 176], [train main loss -2.190162], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 34 / 176], [train main loss -2.179640], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 35 / 176], [train main loss -2.214514], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 36 / 176], [train main loss -2.218659], [lr 0.002800] [batchtime 0.408]
[epoch 126], [iter 37 / 176], [train main loss -2.167951], [lr 0.002800] [batchtime 0.407]
[epoch 126], [iter 38 / 176], [train main loss -2.146755], [lr 0.002800] [batchtime 0.407]
[epoch 126], [iter 39 / 176], [train main loss -2.087371], [lr 0.002800] [batchtime 0.407]
[epoch 126], [iter 40 / 176], [train main loss -2.030652], [lr 0.002800] [batchtime 0.407]
[epoch 126], [iter 41 / 176], [train main loss -2.069326], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 42 / 176], [train main loss -2.132687], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 43 / 176], [train main loss -2.170550], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 44 / 176], [train main loss -2.232227], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 45 / 176], [train main loss -2.262468], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 46 / 176], [train main loss -2.292571], [lr 0.002800] [batchtime 0.406]
[epoch 126], [iter 47 / 176], [train main loss -2.256605], [lr 0.002800] [batchtime 0.405]
[epoch 126], [iter 48 / 176], [train main loss -2.246286], [lr 0.002800] [batchtime 0.405]
[epoch 126], [iter 49 / 176], [train main loss -2.261369], [lr 0.002800] [batchtime 0.409]
[epoch 126], [iter 50 / 176], [train main loss -2.249142], [lr 0.002800] [batchtime 0.44]
[epoch 126], [iter 51 / 176], [train main loss -2.269086], [lr 0.002800] [batchtime 0.439]
[epoch 126], [iter 52 / 176], [train main loss -2.291335], [lr 0.002800] [batchtime 0.438]
[epoch 126], [iter 53 / 176], [train main loss -2.249170], [lr 0.002800] [batchtime 0.437]
[epoch 126], [iter 54 / 176], [train main loss -2.249668], [lr 0.002800] [batchtime 0.436]
[epoch 126], [iter 55 / 176], [train main loss -2.240678], [lr 0.002800] [batchtime 0.435]
[epoch 126], [iter 56 / 176], [train main loss -2.252210], [lr 0.002800] [batchtime 0.435]
[epoch 126], [iter 57 / 176], [train main loss -2.277531], [lr 0.002800] [batchtime 0.434]
[epoch 126], [iter 58 / 176], [train main loss -2.274747], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 59 / 176], [train main loss -2.270557], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 60 / 176], [train main loss -2.303163], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 61 / 176], [train main loss -2.309587], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 62 / 176], [train main loss -2.299435], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 63 / 176], [train main loss -2.289927], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 64 / 176], [train main loss -2.261321], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 65 / 176], [train main loss -2.289680], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 66 / 176], [train main loss -2.276551], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 67 / 176], [train main loss -2.279405], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 68 / 176], [train main loss -2.277574], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 69 / 176], [train main loss -2.279761], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 70 / 176], [train main loss -2.301727], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 71 / 176], [train main loss -2.302022], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 72 / 176], [train main loss -2.329217], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 73 / 176], [train main loss -2.307918], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 74 / 176], [train main loss -2.304740], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 75 / 176], [train main loss -2.331768], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 76 / 176], [train main loss -2.303273], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 77 / 176], [train main loss -2.346120], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 78 / 176], [train main loss -2.382579], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 79 / 176], [train main loss -2.374796], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 80 / 176], [train main loss -2.390964], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 81 / 176], [train main loss -2.374214], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 82 / 176], [train main loss -2.390234], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 83 / 176], [train main loss -2.400729], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 84 / 176], [train main loss -2.389745], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 85 / 176], [train main loss -2.400098], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 86 / 176], [train main loss -2.383367], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 87 / 176], [train main loss -2.375123], [lr 0.002800] [batchtime 0.422]
[epoch 126], [iter 88 / 176], [train main loss -2.360640], [lr 0.002800] [batchtime 0.422]
[epoch 126], [iter 89 / 176], [train main loss -2.360918], [lr 0.002800] [batchtime 0.422]
[epoch 126], [iter 90 / 176], [train main loss -2.385851], [lr 0.002800] [batchtime 0.422]
[epoch 126], [iter 91 / 176], [train main loss -2.377553], [lr 0.002800] [batchtime 0.421]
[epoch 126], [iter 92 / 176], [train main loss -2.419141], [lr 0.002800] [batchtime 0.421]
[epoch 126], [iter 93 / 176], [train main loss -2.387269], [lr 0.002800] [batchtime 0.421]
[epoch 126], [iter 94 / 176], [train main loss -2.360770], [lr 0.002800] [batchtime 0.42]
[epoch 126], [iter 95 / 176], [train main loss -2.365395], [lr 0.002800] [batchtime 0.42]
[epoch 126], [iter 96 / 176], [train main loss -2.365625], [lr 0.002800] [batchtime 0.434]
[epoch 126], [iter 97 / 176], [train main loss -2.343141], [lr 0.002800] [batchtime 0.434]
[epoch 126], [iter 98 / 176], [train main loss -2.340224], [lr 0.002800] [batchtime 0.434]
[epoch 126], [iter 99 / 176], [train main loss -2.340818], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 100 / 176], [train main loss -2.316513], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 101 / 176], [train main loss -2.328629], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 102 / 176], [train main loss -2.346573], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 103 / 176], [train main loss -2.363816], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 104 / 176], [train main loss -2.350644], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 105 / 176], [train main loss -2.341972], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 106 / 176], [train main loss -2.341349], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 107 / 176], [train main loss -2.332448], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 108 / 176], [train main loss -2.321354], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 109 / 176], [train main loss -2.337088], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 110 / 176], [train main loss -2.338194], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 111 / 176], [train main loss -2.341700], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 112 / 176], [train main loss -2.315284], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 113 / 176], [train main loss -2.282720], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 114 / 176], [train main loss -2.271833], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 115 / 176], [train main loss -2.259529], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 116 / 176], [train main loss -2.271929], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 117 / 176], [train main loss -2.261830], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 118 / 176], [train main loss -2.286470], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 119 / 176], [train main loss -2.275779], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 120 / 176], [train main loss -2.256963], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 121 / 176], [train main loss -2.256461], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 122 / 176], [train main loss -2.253682], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 123 / 176], [train main loss -2.255061], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 124 / 176], [train main loss -2.267926], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 125 / 176], [train main loss -2.271094], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 126 / 176], [train main loss -2.267747], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 127 / 176], [train main loss -2.252456], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 128 / 176], [train main loss -2.248562], [lr 0.002800] [batchtime 0.426]
[epoch 126], [iter 129 / 176], [train main loss -2.251040], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 130 / 176], [train main loss -2.259982], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 131 / 176], [train main loss -2.263115], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 132 / 176], [train main loss -2.257070], [lr 0.002800] [batchtime 0.425]
[epoch 126], [iter 133 / 176], [train main loss -2.275875], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 134 / 176], [train main loss -2.296240], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 135 / 176], [train main loss -2.295060], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 136 / 176], [train main loss -2.282794], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 137 / 176], [train main loss -2.271117], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 138 / 176], [train main loss -2.274188], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 139 / 176], [train main loss -2.264510], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 140 / 176], [train main loss -2.306435], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 141 / 176], [train main loss -2.309069], [lr 0.002800] [batchtime 0.423]
[epoch 126], [iter 142 / 176], [train main loss -2.317682], [lr 0.002800] [batchtime 0.424]
[epoch 126], [iter 143 / 176], [train main loss -2.319165], [lr 0.002800] [batchtime 0.434]
[epoch 126], [iter 144 / 176], [train main loss -2.300139], [lr 0.002800] [batchtime 0.434]
[epoch 126], [iter 145 / 176], [train main loss -2.294682], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 146 / 176], [train main loss -2.298385], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 147 / 176], [train main loss -2.285941], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 148 / 176], [train main loss -2.286933], [lr 0.002800] [batchtime 0.433]
[epoch 126], [iter 149 / 176], [train main loss -2.275038], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 150 / 176], [train main loss -2.273375], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 151 / 176], [train main loss -2.262942], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 152 / 176], [train main loss -2.262260], [lr 0.002800] [batchtime 0.432]
[epoch 126], [iter 153 / 176], [train main loss -2.273329], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 154 / 176], [train main loss -2.277523], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 155 / 176], [train main loss -2.296215], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 156 / 176], [train main loss -2.304025], [lr 0.002800] [batchtime 0.431]
[epoch 126], [iter 157 / 176], [train main loss -2.308296], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 158 / 176], [train main loss -2.314360], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 159 / 176], [train main loss -2.305761], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 160 / 176], [train main loss -2.305226], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 161 / 176], [train main loss -2.307230], [lr 0.002800] [batchtime 0.43]
[epoch 126], [iter 162 / 176], [train main loss -2.288082], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 163 / 176], [train main loss -2.295716], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 164 / 176], [train main loss -2.294376], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 165 / 176], [train main loss -2.292004], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 166 / 176], [train main loss -2.288698], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 167 / 176], [train main loss -2.296288], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 168 / 176], [train main loss -2.312839], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 169 / 176], [train main loss -2.308098], [lr 0.002800] [batchtime 0.429]
[epoch 126], [iter 170 / 176], [train main loss -2.303652], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 171 / 176], [train main loss -2.303242], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 172 / 176], [train main loss -2.289182], [lr 0.002800] [batchtime 0.428]
[epoch 126], [iter 173 / 176], [train main loss -2.273275], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 174 / 176], [train main loss -2.272964], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 175 / 176], [train main loss -2.261002], [lr 0.002800] [batchtime 0.427]
[epoch 126], [iter 176 / 176], [train main loss -2.263992], [lr 0.002800] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.44  35.46   0.03  0.03         0.98      0.97
   1  sidewalk          68.80   5.39   0.22  0.23         0.82      0.81
   2  building          86.39  24.90   0.07  0.09         0.94      0.92
   3  wall              18.28   0.15   2.92  1.55         0.26      0.39
   4  fence             24.77   0.37   2.46  0.58         0.29      0.63
   5  pole              39.44   0.58   0.97  0.56         0.51      0.64
   6  traffic light     15.35   0.02   5.16  0.36         0.16      0.74
   7  traffic sign      26.90   0.16   2.44  0.28         0.29      0.78
   8  vegetation        83.40  11.72   0.06  0.14         0.95      0.87
   9  terrain           40.61   0.40   0.86  0.60         0.54      0.62
  10  sky               93.39   3.76   0.03  0.04         0.97      0.96
  11  person            54.33   1.04   0.48  0.36         0.68      0.74
  12  rider             10.67   0.01   7.35  1.02         0.12      0.49
  13  car               86.71   6.67   0.06  0.09         0.94      0.92
  14  truck              1.77   0.01  55.31  0.26         0.02      0.79
  15  bus               14.53   0.03   1.75  4.14         0.36      0.19
  16  train             40.92   0.10   0.76  0.68         0.57      0.60
  17  motorcycle         4.57   0.01  20.34  0.53         0.05      0.65
  18  bicycle           40.50   0.24   0.60  0.87         0.62      0.54
Mean: 44.51
-----------------------------------------------------------------------------------------------------------
this : [epoch 126], [val loss 0.31060], [acc 0.91007], [acc_cls 0.52882], [mean_iu 0.44513], [fwavacc 0.84336]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 127], [iter 1 / 176], [train main loss -2.719360], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 2 / 176], [train main loss -3.340560], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 3 / 176], [train main loss -3.085490], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 4 / 176], [train main loss -3.070373], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 5 / 176], [train main loss -3.245376], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 6 / 176], [train main loss -3.066171], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 7 / 176], [train main loss -2.703899], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 8 / 176], [train main loss -2.433556], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 9 / 176], [train main loss -2.281431], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 10 / 176], [train main loss -2.256079], [lr 0.002743] [batchtime 0]
[epoch 127], [iter 11 / 176], [train main loss -2.229858], [lr 0.002743] [batchtime 0.379]
[epoch 127], [iter 12 / 176], [train main loss -2.188750], [lr 0.002743] [batchtime 0.389]
[epoch 127], [iter 13 / 176], [train main loss -1.836661], [lr 0.002743] [batchtime 0.394]
[epoch 127], [iter 14 / 176], [train main loss -2.130830], [lr 0.002743] [batchtime 0.394]
[epoch 127], [iter 15 / 176], [train main loss -2.158891], [lr 0.002743] [batchtime 0.396]
[epoch 127], [iter 16 / 176], [train main loss -2.208798], [lr 0.002743] [batchtime 0.396]
[epoch 127], [iter 17 / 176], [train main loss -2.304267], [lr 0.002743] [batchtime 0.396]
[epoch 127], [iter 18 / 176], [train main loss -2.566337], [lr 0.002743] [batchtime 0.396]
[epoch 127], [iter 19 / 176], [train main loss -2.628100], [lr 0.002743] [batchtime 0.398]
[epoch 127], [iter 20 / 176], [train main loss -2.569693], [lr 0.002743] [batchtime 0.398]
[epoch 127], [iter 21 / 176], [train main loss -2.512735], [lr 0.002743] [batchtime 0.398]
[epoch 127], [iter 22 / 176], [train main loss -2.491393], [lr 0.002743] [batchtime 0.398]
[epoch 127], [iter 23 / 176], [train main loss -2.430502], [lr 0.002743] [batchtime 0.405]
[epoch 127], [iter 24 / 176], [train main loss -2.337644], [lr 0.002743] [batchtime 0.417]
[epoch 127], [iter 25 / 176], [train main loss -2.338569], [lr 0.002743] [batchtime 0.416]
[epoch 127], [iter 26 / 176], [train main loss -2.328688], [lr 0.002743] [batchtime 0.415]
[epoch 127], [iter 27 / 176], [train main loss -2.340187], [lr 0.002743] [batchtime 0.414]
[epoch 127], [iter 28 / 176], [train main loss -2.271461], [lr 0.002743] [batchtime 0.412]
[epoch 127], [iter 29 / 176], [train main loss -2.291057], [lr 0.002743] [batchtime 0.412]
[epoch 127], [iter 30 / 176], [train main loss -2.472510], [lr 0.002743] [batchtime 0.412]
[epoch 127], [iter 31 / 176], [train main loss -2.531464], [lr 0.002743] [batchtime 0.411]
[epoch 127], [iter 32 / 176], [train main loss -2.489945], [lr 0.002743] [batchtime 0.411]
[epoch 127], [iter 33 / 176], [train main loss -2.487844], [lr 0.002743] [batchtime 0.411]
[epoch 127], [iter 34 / 176], [train main loss -2.371035], [lr 0.002743] [batchtime 0.41]
[epoch 127], [iter 35 / 176], [train main loss -2.316375], [lr 0.002743] [batchtime 0.41]
[epoch 127], [iter 36 / 176], [train main loss -2.263373], [lr 0.002743] [batchtime 0.409]
[epoch 127], [iter 37 / 176], [train main loss -2.336317], [lr 0.002743] [batchtime 0.408]
[epoch 127], [iter 38 / 176], [train main loss -2.278318], [lr 0.002743] [batchtime 0.408]
[epoch 127], [iter 39 / 176], [train main loss -2.251227], [lr 0.002743] [batchtime 0.407]
[epoch 127], [iter 40 / 176], [train main loss -2.209617], [lr 0.002743] [batchtime 0.407]
[epoch 127], [iter 41 / 176], [train main loss -2.141814], [lr 0.002743] [batchtime 0.407]
[epoch 127], [iter 42 / 176], [train main loss -2.163335], [lr 0.002743] [batchtime 0.406]
[epoch 127], [iter 43 / 176], [train main loss -2.148973], [lr 0.002743] [batchtime 0.406]
[epoch 127], [iter 44 / 176], [train main loss -2.152471], [lr 0.002743] [batchtime 0.406]
[epoch 127], [iter 45 / 176], [train main loss -2.148076], [lr 0.002743] [batchtime 0.406]
[epoch 127], [iter 46 / 176], [train main loss -2.181991], [lr 0.002743] [batchtime 0.406]
[epoch 127], [iter 47 / 176], [train main loss -2.128446], [lr 0.002743] [batchtime 0.409]
[epoch 127], [iter 48 / 176], [train main loss -2.143340], [lr 0.002743] [batchtime 0.442]
[epoch 127], [iter 49 / 176], [train main loss -2.154500], [lr 0.002743] [batchtime 0.441]
[epoch 127], [iter 50 / 176], [train main loss -2.140061], [lr 0.002743] [batchtime 0.44]
[epoch 127], [iter 51 / 176], [train main loss -2.119013], [lr 0.002743] [batchtime 0.438]
[epoch 127], [iter 52 / 176], [train main loss -2.096800], [lr 0.002743] [batchtime 0.437]
[epoch 127], [iter 53 / 176], [train main loss -2.076732], [lr 0.002743] [batchtime 0.436]
[epoch 127], [iter 54 / 176], [train main loss -2.035774], [lr 0.002743] [batchtime 0.435]
[epoch 127], [iter 55 / 176], [train main loss -2.032532], [lr 0.002743] [batchtime 0.434]
[epoch 127], [iter 56 / 176], [train main loss -2.015343], [lr 0.002743] [batchtime 0.434]
[epoch 127], [iter 57 / 176], [train main loss -1.960334], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 58 / 176], [train main loss -1.937986], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 59 / 176], [train main loss -1.882477], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 60 / 176], [train main loss -1.872830], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 61 / 176], [train main loss -1.912274], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 62 / 176], [train main loss -1.915739], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 63 / 176], [train main loss -1.926329], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 64 / 176], [train main loss -1.920095], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 65 / 176], [train main loss -1.870178], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 66 / 176], [train main loss -1.870728], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 67 / 176], [train main loss -1.871582], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 68 / 176], [train main loss -1.884033], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 69 / 176], [train main loss -1.895068], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 70 / 176], [train main loss -1.927150], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 71 / 176], [train main loss -1.902022], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 72 / 176], [train main loss -1.890924], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 73 / 176], [train main loss -1.835223], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 74 / 176], [train main loss -1.857747], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 75 / 176], [train main loss -1.830123], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 76 / 176], [train main loss -1.844659], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 77 / 176], [train main loss -1.866327], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 78 / 176], [train main loss -1.871617], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 79 / 176], [train main loss -1.869597], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 80 / 176], [train main loss -1.844200], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 81 / 176], [train main loss -1.850625], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 82 / 176], [train main loss -1.823159], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 83 / 176], [train main loss -1.783567], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 84 / 176], [train main loss -1.766629], [lr 0.002743] [batchtime 0.424]
[epoch 127], [iter 85 / 176], [train main loss -1.762773], [lr 0.002743] [batchtime 0.424]
[epoch 127], [iter 86 / 176], [train main loss -1.746976], [lr 0.002743] [batchtime 0.423]
[epoch 127], [iter 87 / 176], [train main loss -1.746140], [lr 0.002743] [batchtime 0.423]
[epoch 127], [iter 88 / 176], [train main loss -1.740358], [lr 0.002743] [batchtime 0.423]
[epoch 127], [iter 89 / 176], [train main loss -1.739801], [lr 0.002743] [batchtime 0.423]
[epoch 127], [iter 90 / 176], [train main loss -1.767264], [lr 0.002743] [batchtime 0.422]
[epoch 127], [iter 91 / 176], [train main loss -1.755890], [lr 0.002743] [batchtime 0.422]
[epoch 127], [iter 92 / 176], [train main loss -1.748614], [lr 0.002743] [batchtime 0.422]
[epoch 127], [iter 93 / 176], [train main loss -1.754088], [lr 0.002743] [batchtime 0.423]
[epoch 127], [iter 94 / 176], [train main loss -1.749435], [lr 0.002743] [batchtime 0.437]
[epoch 127], [iter 95 / 176], [train main loss -1.756904], [lr 0.002743] [batchtime 0.437]
[epoch 127], [iter 96 / 176], [train main loss -1.795521], [lr 0.002743] [batchtime 0.436]
[epoch 127], [iter 97 / 176], [train main loss -1.813108], [lr 0.002743] [batchtime 0.436]
[epoch 127], [iter 98 / 176], [train main loss -1.820528], [lr 0.002743] [batchtime 0.435]
[epoch 127], [iter 99 / 176], [train main loss -1.850225], [lr 0.002743] [batchtime 0.435]
[epoch 127], [iter 100 / 176], [train main loss -1.860348], [lr 0.002743] [batchtime 0.434]
[epoch 127], [iter 101 / 176], [train main loss -1.856342], [lr 0.002743] [batchtime 0.434]
[epoch 127], [iter 102 / 176], [train main loss -1.884544], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 103 / 176], [train main loss -1.890415], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 104 / 176], [train main loss -1.897261], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 105 / 176], [train main loss -1.905643], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 106 / 176], [train main loss -1.893260], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 107 / 176], [train main loss -1.875095], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 108 / 176], [train main loss -1.859384], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 109 / 176], [train main loss -1.850113], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 110 / 176], [train main loss -1.840296], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 111 / 176], [train main loss -1.847447], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 112 / 176], [train main loss -1.844093], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 113 / 176], [train main loss -1.856900], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 114 / 176], [train main loss -1.886958], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 115 / 176], [train main loss -1.905422], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 116 / 176], [train main loss -1.893308], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 117 / 176], [train main loss -1.885197], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 118 / 176], [train main loss -1.866958], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 119 / 176], [train main loss -1.854895], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 120 / 176], [train main loss -1.871685], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 121 / 176], [train main loss -1.857473], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 122 / 176], [train main loss -1.841786], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 123 / 176], [train main loss -1.838134], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 124 / 176], [train main loss -1.860282], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 125 / 176], [train main loss -1.855384], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 126 / 176], [train main loss -1.849000], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 127 / 176], [train main loss -1.846695], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 128 / 176], [train main loss -1.853380], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 129 / 176], [train main loss -1.853965], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 130 / 176], [train main loss -1.861542], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 131 / 176], [train main loss -1.855000], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 132 / 176], [train main loss -1.850944], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 133 / 176], [train main loss -1.846450], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 134 / 176], [train main loss -1.871813], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 135 / 176], [train main loss -1.869077], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 136 / 176], [train main loss -1.873046], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 137 / 176], [train main loss -1.857831], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 138 / 176], [train main loss -1.874726], [lr 0.002743] [batchtime 0.424]
[epoch 127], [iter 139 / 176], [train main loss -1.874487], [lr 0.002743] [batchtime 0.424]
[epoch 127], [iter 140 / 176], [train main loss -1.877273], [lr 0.002743] [batchtime 0.425]
[epoch 127], [iter 141 / 176], [train main loss -1.903769], [lr 0.002743] [batchtime 0.434]
[epoch 127], [iter 142 / 176], [train main loss -1.899639], [lr 0.002743] [batchtime 0.434]
[epoch 127], [iter 143 / 176], [train main loss -1.906822], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 144 / 176], [train main loss -1.912440], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 145 / 176], [train main loss -1.917573], [lr 0.002743] [batchtime 0.433]
[epoch 127], [iter 146 / 176], [train main loss -1.931230], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 147 / 176], [train main loss -1.945648], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 148 / 176], [train main loss -1.937928], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 149 / 176], [train main loss -1.932533], [lr 0.002743] [batchtime 0.432]
[epoch 127], [iter 150 / 176], [train main loss -1.947537], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 151 / 176], [train main loss -1.942774], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 152 / 176], [train main loss -1.952352], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 153 / 176], [train main loss -1.965979], [lr 0.002743] [batchtime 0.431]
[epoch 127], [iter 154 / 176], [train main loss -1.958043], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 155 / 176], [train main loss -1.962805], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 156 / 176], [train main loss -1.953402], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 157 / 176], [train main loss -1.951743], [lr 0.002743] [batchtime 0.43]
[epoch 127], [iter 158 / 176], [train main loss -1.958469], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 159 / 176], [train main loss -1.947650], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 160 / 176], [train main loss -1.945649], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 161 / 176], [train main loss -1.946447], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 162 / 176], [train main loss -1.940893], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 163 / 176], [train main loss -1.951492], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 164 / 176], [train main loss -1.936957], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 165 / 176], [train main loss -1.935134], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 166 / 176], [train main loss -1.924757], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 167 / 176], [train main loss -1.929810], [lr 0.002743] [batchtime 0.429]
[epoch 127], [iter 168 / 176], [train main loss -1.919611], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 169 / 176], [train main loss -1.901339], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 170 / 176], [train main loss -1.896235], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 171 / 176], [train main loss -1.897224], [lr 0.002743] [batchtime 0.428]
[epoch 127], [iter 172 / 176], [train main loss -1.893499], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 173 / 176], [train main loss -1.898108], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 174 / 176], [train main loss -1.900815], [lr 0.002743] [batchtime 0.427]
[epoch 127], [iter 175 / 176], [train main loss -1.922079], [lr 0.002743] [batchtime 0.426]
[epoch 127], [iter 176 / 176], [train main loss -1.926606], [lr 0.002743] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.82  35.48   0.02  0.03         0.98      0.97
   1  sidewalk          69.97   5.47   0.20  0.23         0.83      0.82
   2  building          86.68  25.16   0.06  0.10         0.95      0.91
   3  wall              19.71   0.18   2.36  1.71         0.30      0.37
   4  fence             26.52   0.42   2.06  0.71         0.33      0.58
   5  pole              39.41   0.56   1.01  0.52         0.50      0.66
   6  traffic light     17.74   0.03   4.16  0.47         0.19      0.68
   7  traffic sign      27.18   0.16   2.42  0.26         0.29      0.79
   8  vegetation        84.47  11.45   0.08  0.10         0.93      0.91
   9  terrain           39.97   0.37   1.01  0.49         0.50      0.67
  10  sky               93.71   3.74   0.03  0.03         0.97      0.97
  11  person            53.91   1.04   0.47  0.38         0.68      0.72
  12  rider              8.78   0.01   9.59  0.80         0.09      0.56
  13  car               86.25   6.73   0.05  0.11         0.95      0.90
  14  truck              3.08   0.01  31.04  0.48         0.03      0.67
  15  bus               15.90   0.03   1.54  3.74         0.39      0.21
  16  train             38.23   0.09   0.97  0.64         0.51      0.61
  17  motorcycle         3.79   0.00  24.85  0.54         0.04      0.65
  18  bicycle           38.21   0.27   0.46  1.16         0.69      0.46
Mean: 44.65
-----------------------------------------------------------------------------------------------------------
this : [epoch 127], [val loss 0.30045], [acc 0.91197], [acc_cls 0.53312], [mean_iu 0.44650], [fwavacc 0.84757]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 128], [iter 1 / 176], [train main loss -2.585393], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 2 / 176], [train main loss -0.830879], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 3 / 176], [train main loss -0.270508], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 4 / 176], [train main loss -0.851258], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 5 / 176], [train main loss -1.139051], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 6 / 176], [train main loss -1.735286], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 7 / 176], [train main loss -1.762371], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 8 / 176], [train main loss -1.797215], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 9 / 176], [train main loss -1.810362], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 10 / 176], [train main loss -1.728593], [lr 0.002686] [batchtime 0]
[epoch 128], [iter 11 / 176], [train main loss -2.010654], [lr 0.002686] [batchtime 0.38]
[epoch 128], [iter 12 / 176], [train main loss -2.171283], [lr 0.002686] [batchtime 0.391]
[epoch 128], [iter 13 / 176], [train main loss -2.199596], [lr 0.002686] [batchtime 0.392]
[epoch 128], [iter 14 / 176], [train main loss -2.115632], [lr 0.002686] [batchtime 0.391]
[epoch 128], [iter 15 / 176], [train main loss -2.301428], [lr 0.002686] [batchtime 0.393]
[epoch 128], [iter 16 / 176], [train main loss -2.434442], [lr 0.002686] [batchtime 0.394]
[epoch 128], [iter 17 / 176], [train main loss -2.255855], [lr 0.002686] [batchtime 0.394]
[epoch 128], [iter 18 / 176], [train main loss -2.205113], [lr 0.002686] [batchtime 0.394]
[epoch 128], [iter 19 / 176], [train main loss -2.273018], [lr 0.002686] [batchtime 0.395]
[epoch 128], [iter 20 / 176], [train main loss -2.230762], [lr 0.002686] [batchtime 0.397]
[epoch 128], [iter 21 / 176], [train main loss -2.265483], [lr 0.002686] [batchtime 0.398]
[epoch 128], [iter 22 / 176], [train main loss -2.240652], [lr 0.002686] [batchtime 0.404]
[epoch 128], [iter 23 / 176], [train main loss -2.301301], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 24 / 176], [train main loss -2.389799], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 25 / 176], [train main loss -2.380479], [lr 0.002686] [batchtime 0.415]
[epoch 128], [iter 26 / 176], [train main loss -2.417769], [lr 0.002686] [batchtime 0.413]
[epoch 128], [iter 27 / 176], [train main loss -2.424855], [lr 0.002686] [batchtime 0.412]
[epoch 128], [iter 28 / 176], [train main loss -2.444055], [lr 0.002686] [batchtime 0.412]
[epoch 128], [iter 29 / 176], [train main loss -2.522188], [lr 0.002686] [batchtime 0.411]
[epoch 128], [iter 30 / 176], [train main loss -2.496139], [lr 0.002686] [batchtime 0.41]
[epoch 128], [iter 31 / 176], [train main loss -2.487343], [lr 0.002686] [batchtime 0.41]
[epoch 128], [iter 32 / 176], [train main loss -2.455646], [lr 0.002686] [batchtime 0.409]
[epoch 128], [iter 33 / 176], [train main loss -2.373623], [lr 0.002686] [batchtime 0.408]
[epoch 128], [iter 34 / 176], [train main loss -2.355236], [lr 0.002686] [batchtime 0.408]
[epoch 128], [iter 35 / 176], [train main loss -2.472347], [lr 0.002686] [batchtime 0.407]
[epoch 128], [iter 36 / 176], [train main loss -2.469663], [lr 0.002686] [batchtime 0.407]
[epoch 128], [iter 37 / 176], [train main loss -2.440363], [lr 0.002686] [batchtime 0.406]
[epoch 128], [iter 38 / 176], [train main loss -2.466219], [lr 0.002686] [batchtime 0.406]
[epoch 128], [iter 39 / 176], [train main loss -2.456862], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 40 / 176], [train main loss -2.513118], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 41 / 176], [train main loss -2.474532], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 42 / 176], [train main loss -2.485894], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 43 / 176], [train main loss -2.483459], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 44 / 176], [train main loss -2.526798], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 45 / 176], [train main loss -2.458670], [lr 0.002686] [batchtime 0.405]
[epoch 128], [iter 46 / 176], [train main loss -2.455950], [lr 0.002686] [batchtime 0.409]
[epoch 128], [iter 47 / 176], [train main loss -2.441673], [lr 0.002686] [batchtime 0.442]
[epoch 128], [iter 48 / 176], [train main loss -2.497620], [lr 0.002686] [batchtime 0.44]
[epoch 128], [iter 49 / 176], [train main loss -2.467888], [lr 0.002686] [batchtime 0.439]
[epoch 128], [iter 50 / 176], [train main loss -2.458694], [lr 0.002686] [batchtime 0.438]
[epoch 128], [iter 51 / 176], [train main loss -2.443754], [lr 0.002686] [batchtime 0.437]
[epoch 128], [iter 52 / 176], [train main loss -2.465118], [lr 0.002686] [batchtime 0.436]
[epoch 128], [iter 53 / 176], [train main loss -2.454608], [lr 0.002686] [batchtime 0.435]
[epoch 128], [iter 54 / 176], [train main loss -2.458763], [lr 0.002686] [batchtime 0.434]
[epoch 128], [iter 55 / 176], [train main loss -2.466985], [lr 0.002686] [batchtime 0.433]
[epoch 128], [iter 56 / 176], [train main loss -2.493139], [lr 0.002686] [batchtime 0.433]
[epoch 128], [iter 57 / 176], [train main loss -2.475019], [lr 0.002686] [batchtime 0.432]
[epoch 128], [iter 58 / 176], [train main loss -2.454545], [lr 0.002686] [batchtime 0.431]
[epoch 128], [iter 59 / 176], [train main loss -2.421448], [lr 0.002686] [batchtime 0.431]
[epoch 128], [iter 60 / 176], [train main loss -2.433049], [lr 0.002686] [batchtime 0.43]
[epoch 128], [iter 61 / 176], [train main loss -2.440522], [lr 0.002686] [batchtime 0.43]
[epoch 128], [iter 62 / 176], [train main loss -2.468550], [lr 0.002686] [batchtime 0.429]
[epoch 128], [iter 63 / 176], [train main loss -2.472022], [lr 0.002686] [batchtime 0.428]
[epoch 128], [iter 64 / 176], [train main loss -2.430879], [lr 0.002686] [batchtime 0.428]
[epoch 128], [iter 65 / 176], [train main loss -2.400511], [lr 0.002686] [batchtime 0.427]
[epoch 128], [iter 66 / 176], [train main loss -2.416449], [lr 0.002686] [batchtime 0.427]
[epoch 128], [iter 67 / 176], [train main loss -2.436646], [lr 0.002686] [batchtime 0.426]
[epoch 128], [iter 68 / 176], [train main loss -2.448849], [lr 0.002686] [batchtime 0.427]
[epoch 128], [iter 69 / 176], [train main loss -2.436540], [lr 0.002686] [batchtime 0.43]
[epoch 128], [iter 70 / 176], [train main loss -2.440629], [lr 0.002686] [batchtime 0.429]
[epoch 128], [iter 71 / 176], [train main loss -2.410605], [lr 0.002686] [batchtime 0.428]
[epoch 128], [iter 72 / 176], [train main loss -2.434565], [lr 0.002686] [batchtime 0.428]
[epoch 128], [iter 73 / 176], [train main loss -2.487236], [lr 0.002686] [batchtime 0.427]
[epoch 128], [iter 74 / 176], [train main loss -2.497535], [lr 0.002686] [batchtime 0.427]
[epoch 128], [iter 75 / 176], [train main loss -2.523145], [lr 0.002686] [batchtime 0.426]
[epoch 128], [iter 76 / 176], [train main loss -2.538493], [lr 0.002686] [batchtime 0.426]
[epoch 128], [iter 77 / 176], [train main loss -2.537533], [lr 0.002686] [batchtime 0.425]
[epoch 128], [iter 78 / 176], [train main loss -2.547034], [lr 0.002686] [batchtime 0.425]
[epoch 128], [iter 79 / 176], [train main loss -2.517291], [lr 0.002686] [batchtime 0.424]
[epoch 128], [iter 80 / 176], [train main loss -2.503641], [lr 0.002686] [batchtime 0.424]
[epoch 128], [iter 81 / 176], [train main loss -2.491208], [lr 0.002686] [batchtime 0.424]
[epoch 128], [iter 82 / 176], [train main loss -2.484299], [lr 0.002686] [batchtime 0.423]
[epoch 128], [iter 83 / 176], [train main loss -2.484324], [lr 0.002686] [batchtime 0.423]
[epoch 128], [iter 84 / 176], [train main loss -2.483919], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 85 / 176], [train main loss -2.456361], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 86 / 176], [train main loss -2.445074], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 87 / 176], [train main loss -2.463965], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 88 / 176], [train main loss -2.447347], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 89 / 176], [train main loss -2.426397], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 90 / 176], [train main loss -2.431562], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 91 / 176], [train main loss -2.419704], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 92 / 176], [train main loss -2.422735], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 93 / 176], [train main loss -2.441342], [lr 0.002686] [batchtime 0.426]
[epoch 128], [iter 94 / 176], [train main loss -2.459397], [lr 0.002686] [batchtime 0.425]
[epoch 128], [iter 95 / 176], [train main loss -2.473975], [lr 0.002686] [batchtime 0.425]
[epoch 128], [iter 96 / 176], [train main loss -2.466144], [lr 0.002686] [batchtime 0.425]
[epoch 128], [iter 97 / 176], [train main loss -2.481909], [lr 0.002686] [batchtime 0.424]
[epoch 128], [iter 98 / 176], [train main loss -2.465579], [lr 0.002686] [batchtime 0.424]
[epoch 128], [iter 99 / 176], [train main loss -2.478346], [lr 0.002686] [batchtime 0.424]
[epoch 128], [iter 100 / 176], [train main loss -2.459567], [lr 0.002686] [batchtime 0.423]
[epoch 128], [iter 101 / 176], [train main loss -2.457105], [lr 0.002686] [batchtime 0.423]
[epoch 128], [iter 102 / 176], [train main loss -2.454228], [lr 0.002686] [batchtime 0.423]
[epoch 128], [iter 103 / 176], [train main loss -2.446478], [lr 0.002686] [batchtime 0.423]
[epoch 128], [iter 104 / 176], [train main loss -2.415741], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 105 / 176], [train main loss -2.380228], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 106 / 176], [train main loss -2.359281], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 107 / 176], [train main loss -2.341925], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 108 / 176], [train main loss -2.338601], [lr 0.002686] [batchtime 0.422]
[epoch 128], [iter 109 / 176], [train main loss -2.360629], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 110 / 176], [train main loss -2.376552], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 111 / 176], [train main loss -2.369174], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 112 / 176], [train main loss -2.355702], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 113 / 176], [train main loss -2.351110], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 114 / 176], [train main loss -2.351089], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 115 / 176], [train main loss -2.354434], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 116 / 176], [train main loss -2.349491], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 117 / 176], [train main loss -2.363341], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 118 / 176], [train main loss -2.334835], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 119 / 176], [train main loss -2.318747], [lr 0.002686] [batchtime 0.421]
[epoch 128], [iter 120 / 176], [train main loss -2.306069], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 121 / 176], [train main loss -2.292654], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 122 / 176], [train main loss -2.296691], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 123 / 176], [train main loss -2.286405], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 124 / 176], [train main loss -2.261122], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 125 / 176], [train main loss -2.251674], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 126 / 176], [train main loss -2.239989], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 127 / 176], [train main loss -2.239626], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 128 / 176], [train main loss -2.241225], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 129 / 176], [train main loss -2.227198], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 130 / 176], [train main loss -2.228788], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 131 / 176], [train main loss -2.243703], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 132 / 176], [train main loss -2.253490], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 133 / 176], [train main loss -2.270476], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 134 / 176], [train main loss -2.287703], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 135 / 176], [train main loss -2.300703], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 136 / 176], [train main loss -2.294902], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 137 / 176], [train main loss -2.287052], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 138 / 176], [train main loss -2.284175], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 139 / 176], [train main loss -2.274666], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 140 / 176], [train main loss -2.281713], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 141 / 176], [train main loss -2.285667], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 142 / 176], [train main loss -2.290905], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 143 / 176], [train main loss -2.278144], [lr 0.002686] [batchtime 0.42]
[epoch 128], [iter 144 / 176], [train main loss -2.283997], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 145 / 176], [train main loss -2.277747], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 146 / 176], [train main loss -2.285557], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 147 / 176], [train main loss -2.276190], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 148 / 176], [train main loss -2.266594], [lr 0.002686] [batchtime 0.419]
[epoch 128], [iter 149 / 176], [train main loss -2.256631], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 150 / 176], [train main loss -2.252331], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 151 / 176], [train main loss -2.252328], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 152 / 176], [train main loss -2.274105], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 153 / 176], [train main loss -2.275053], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 154 / 176], [train main loss -2.278797], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 155 / 176], [train main loss -2.277324], [lr 0.002686] [batchtime 0.418]
[epoch 128], [iter 156 / 176], [train main loss -2.273719], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 157 / 176], [train main loss -2.291401], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 158 / 176], [train main loss -2.291378], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 159 / 176], [train main loss -2.289376], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 160 / 176], [train main loss -2.273746], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 161 / 176], [train main loss -2.270934], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 162 / 176], [train main loss -2.278408], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 163 / 176], [train main loss -2.284411], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 164 / 176], [train main loss -2.277867], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 165 / 176], [train main loss -2.272679], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 166 / 176], [train main loss -2.263841], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 167 / 176], [train main loss -2.253497], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 168 / 176], [train main loss -2.260039], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 169 / 176], [train main loss -2.260521], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 170 / 176], [train main loss -2.256998], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 171 / 176], [train main loss -2.274703], [lr 0.002686] [batchtime 0.417]
[epoch 128], [iter 172 / 176], [train main loss -2.277870], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 173 / 176], [train main loss -2.282876], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 174 / 176], [train main loss -2.292393], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 175 / 176], [train main loss -2.276411], [lr 0.002686] [batchtime 0.416]
[epoch 128], [iter 176 / 176], [train main loss -2.263097], [lr 0.002686] [batchtime 0.415]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.63  35.29   0.03  0.03         0.97      0.97
   1  sidewalk          69.83   5.55   0.19  0.24         0.84      0.80
   2  building          86.49  25.20   0.05  0.10         0.95      0.91
   3  wall              19.03   0.16   2.76  1.49         0.27      0.40
   4  fence             26.48   0.41   2.09  0.69         0.32      0.59
   5  pole              38.25   0.54   1.10  0.51         0.48      0.66
   6  traffic light     14.71   0.02   5.49  0.30         0.15      0.77
   7  traffic sign      21.89   0.13   3.40  0.17         0.23      0.86
   8  vegetation        83.97  11.63   0.06  0.13         0.94      0.89
   9  terrain           38.69   0.35   1.13  0.46         0.47      0.69
  10  sky               93.82   3.75   0.03  0.03         0.97      0.97
  11  person            51.85   0.95   0.62  0.31         0.62      0.76
  12  rider             11.13   0.01   7.03  0.95         0.12      0.51
  13  car               86.47   6.68   0.06  0.10         0.94      0.91
  14  truck              2.10   0.01  46.10  0.41         0.02      0.71
  15  bus               17.33   0.04   1.39  3.38         0.42      0.23
  16  train             38.71   0.09   1.08  0.50         0.48      0.66
  17  motorcycle         4.11   0.00  22.63  0.68         0.04      0.60
  18  bicycle           36.54   0.28   0.39  1.34         0.72      0.43
Mean: 44.00
-----------------------------------------------------------------------------------------------------------
this : [epoch 128], [val loss 0.31096], [acc 0.91068], [acc_cls 0.52367], [mean_iu 0.44002], [fwavacc 0.84483]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 129], [iter 1 / 176], [train main loss -3.849963], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 2 / 176], [train main loss -2.417749], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 3 / 176], [train main loss -1.748725], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 4 / 176], [train main loss -1.819959], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 5 / 176], [train main loss -2.706931], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 6 / 176], [train main loss -2.425494], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 7 / 176], [train main loss -2.045135], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 8 / 176], [train main loss -2.023923], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 9 / 176], [train main loss -1.920269], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 10 / 176], [train main loss -1.809082], [lr 0.002629] [batchtime 0]
[epoch 129], [iter 11 / 176], [train main loss -1.959313], [lr 0.002629] [batchtime 0.372]
[epoch 129], [iter 12 / 176], [train main loss -2.070159], [lr 0.002629] [batchtime 0.387]
[epoch 129], [iter 13 / 176], [train main loss -2.092248], [lr 0.002629] [batchtime 0.389]
[epoch 129], [iter 14 / 176], [train main loss -2.088939], [lr 0.002629] [batchtime 0.391]
[epoch 129], [iter 15 / 176], [train main loss -1.951733], [lr 0.002629] [batchtime 0.392]
[epoch 129], [iter 16 / 176], [train main loss -1.970776], [lr 0.002629] [batchtime 0.393]
[epoch 129], [iter 17 / 176], [train main loss -2.093163], [lr 0.002629] [batchtime 0.394]
[epoch 129], [iter 18 / 176], [train main loss -2.179289], [lr 0.002629] [batchtime 0.395]
[epoch 129], [iter 19 / 176], [train main loss -2.089226], [lr 0.002629] [batchtime 0.394]
[epoch 129], [iter 20 / 176], [train main loss -2.250625], [lr 0.002629] [batchtime 0.396]
[epoch 129], [iter 21 / 176], [train main loss -2.160749], [lr 0.002629] [batchtime 0.398]
[epoch 129], [iter 22 / 176], [train main loss -2.170342], [lr 0.002629] [batchtime 0.439]
[epoch 129], [iter 23 / 176], [train main loss -2.219201], [lr 0.002629] [batchtime 0.436]
[epoch 129], [iter 24 / 176], [train main loss -2.249356], [lr 0.002629] [batchtime 0.433]
[epoch 129], [iter 25 / 176], [train main loss -2.332862], [lr 0.002629] [batchtime 0.43]
[epoch 129], [iter 26 / 176], [train main loss -2.407250], [lr 0.002629] [batchtime 0.428]
[epoch 129], [iter 27 / 176], [train main loss -2.468397], [lr 0.002629] [batchtime 0.427]
[epoch 129], [iter 28 / 176], [train main loss -2.406470], [lr 0.002629] [batchtime 0.425]
[epoch 129], [iter 29 / 176], [train main loss -2.478489], [lr 0.002629] [batchtime 0.424]
[epoch 129], [iter 30 / 176], [train main loss -2.458988], [lr 0.002629] [batchtime 0.423]
[epoch 129], [iter 31 / 176], [train main loss -2.347018], [lr 0.002629] [batchtime 0.422]
[epoch 129], [iter 32 / 176], [train main loss -2.308213], [lr 0.002629] [batchtime 0.421]
[epoch 129], [iter 33 / 176], [train main loss -2.256383], [lr 0.002629] [batchtime 0.42]
[epoch 129], [iter 34 / 176], [train main loss -2.199929], [lr 0.002629] [batchtime 0.419]
[epoch 129], [iter 35 / 176], [train main loss -2.208203], [lr 0.002629] [batchtime 0.418]
[epoch 129], [iter 36 / 176], [train main loss -2.219416], [lr 0.002629] [batchtime 0.418]
[epoch 129], [iter 37 / 176], [train main loss -2.235750], [lr 0.002629] [batchtime 0.417]
[epoch 129], [iter 38 / 176], [train main loss -2.183513], [lr 0.002629] [batchtime 0.416]
[epoch 129], [iter 39 / 176], [train main loss -2.182824], [lr 0.002629] [batchtime 0.416]
[epoch 129], [iter 40 / 176], [train main loss -2.127307], [lr 0.002629] [batchtime 0.415]
[epoch 129], [iter 41 / 176], [train main loss -2.162241], [lr 0.002629] [batchtime 0.418]
[epoch 129], [iter 42 / 176], [train main loss -2.233489], [lr 0.002629] [batchtime 0.418]
[epoch 129], [iter 43 / 176], [train main loss -2.193057], [lr 0.002629] [batchtime 0.417]
[epoch 129], [iter 44 / 176], [train main loss -2.207716], [lr 0.002629] [batchtime 0.416]
[epoch 129], [iter 45 / 176], [train main loss -2.208939], [lr 0.002629] [batchtime 0.416]
[epoch 129], [iter 46 / 176], [train main loss -2.245243], [lr 0.002629] [batchtime 0.423]
[epoch 129], [iter 47 / 176], [train main loss -2.215635], [lr 0.002629] [batchtime 0.427]
[epoch 129], [iter 48 / 176], [train main loss -2.166460], [lr 0.002629] [batchtime 0.426]
[epoch 129], [iter 49 / 176], [train main loss -2.144089], [lr 0.002629] [batchtime 0.448]
[epoch 129], [iter 50 / 176], [train main loss -2.161276], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 51 / 176], [train main loss -2.188630], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 52 / 176], [train main loss -2.183069], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 53 / 176], [train main loss -2.155480], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 54 / 176], [train main loss -2.124311], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 55 / 176], [train main loss -2.148860], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 56 / 176], [train main loss -2.146347], [lr 0.002629] [batchtime 0.44]
[epoch 129], [iter 57 / 176], [train main loss -2.085656], [lr 0.002629] [batchtime 0.439]
[epoch 129], [iter 58 / 176], [train main loss -2.130020], [lr 0.002629] [batchtime 0.438]
[epoch 129], [iter 59 / 176], [train main loss -2.172730], [lr 0.002629] [batchtime 0.438]
[epoch 129], [iter 60 / 176], [train main loss -2.173828], [lr 0.002629] [batchtime 0.437]
[epoch 129], [iter 61 / 176], [train main loss -2.174922], [lr 0.002629] [batchtime 0.436]
[epoch 129], [iter 62 / 176], [train main loss -2.224867], [lr 0.002629] [batchtime 0.436]
[epoch 129], [iter 63 / 176], [train main loss -2.247879], [lr 0.002629] [batchtime 0.435]
[epoch 129], [iter 64 / 176], [train main loss -2.245120], [lr 0.002629] [batchtime 0.434]
[epoch 129], [iter 65 / 176], [train main loss -2.278218], [lr 0.002629] [batchtime 0.434]
[epoch 129], [iter 66 / 176], [train main loss -2.298058], [lr 0.002629] [batchtime 0.433]
[epoch 129], [iter 67 / 176], [train main loss -2.278445], [lr 0.002629] [batchtime 0.432]
[epoch 129], [iter 68 / 176], [train main loss -2.254620], [lr 0.002629] [batchtime 0.434]
[epoch 129], [iter 69 / 176], [train main loss -2.249456], [lr 0.002629] [batchtime 0.434]
[epoch 129], [iter 70 / 176], [train main loss -2.222353], [lr 0.002629] [batchtime 0.433]
[epoch 129], [iter 71 / 176], [train main loss -2.228543], [lr 0.002629] [batchtime 0.432]
[epoch 129], [iter 72 / 176], [train main loss -2.217957], [lr 0.002629] [batchtime 0.432]
[epoch 129], [iter 73 / 176], [train main loss -2.205020], [lr 0.002629] [batchtime 0.453]
[epoch 129], [iter 74 / 176], [train main loss -2.151083], [lr 0.002629] [batchtime 0.452]
[epoch 129], [iter 75 / 176], [train main loss -2.144772], [lr 0.002629] [batchtime 0.451]
[epoch 129], [iter 76 / 176], [train main loss -2.130577], [lr 0.002629] [batchtime 0.45]
[epoch 129], [iter 77 / 176], [train main loss -2.115928], [lr 0.002629] [batchtime 0.449]
[epoch 129], [iter 78 / 176], [train main loss -2.106794], [lr 0.002629] [batchtime 0.449]
[epoch 129], [iter 79 / 176], [train main loss -2.098293], [lr 0.002629] [batchtime 0.448]
[epoch 129], [iter 80 / 176], [train main loss -2.130503], [lr 0.002629] [batchtime 0.447]
[epoch 129], [iter 81 / 176], [train main loss -2.135000], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 82 / 176], [train main loss -2.145037], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 83 / 176], [train main loss -2.123940], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 84 / 176], [train main loss -2.146401], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 85 / 176], [train main loss -2.184807], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 86 / 176], [train main loss -2.150583], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 87 / 176], [train main loss -2.132268], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 88 / 176], [train main loss -2.117798], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 89 / 176], [train main loss -2.102911], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 90 / 176], [train main loss -2.085643], [lr 0.002629] [batchtime 0.461]
[epoch 129], [iter 91 / 176], [train main loss -2.098118], [lr 0.002629] [batchtime 0.46]
[epoch 129], [iter 92 / 176], [train main loss -2.109270], [lr 0.002629] [batchtime 0.459]
[epoch 129], [iter 93 / 176], [train main loss -2.101046], [lr 0.002629] [batchtime 0.459]
[epoch 129], [iter 94 / 176], [train main loss -2.080310], [lr 0.002629] [batchtime 0.458]
[epoch 129], [iter 95 / 176], [train main loss -2.060147], [lr 0.002629] [batchtime 0.457]
[epoch 129], [iter 96 / 176], [train main loss -2.075911], [lr 0.002629] [batchtime 0.457]
[epoch 129], [iter 97 / 176], [train main loss -2.089596], [lr 0.002629] [batchtime 0.456]
[epoch 129], [iter 98 / 176], [train main loss -2.075833], [lr 0.002629] [batchtime 0.455]
[epoch 129], [iter 99 / 176], [train main loss -2.081824], [lr 0.002629] [batchtime 0.455]
[epoch 129], [iter 100 / 176], [train main loss -2.090488], [lr 0.002629] [batchtime 0.454]
[epoch 129], [iter 101 / 176], [train main loss -2.096252], [lr 0.002629] [batchtime 0.453]
[epoch 129], [iter 102 / 176], [train main loss -2.080857], [lr 0.002629] [batchtime 0.453]
[epoch 129], [iter 103 / 176], [train main loss -2.098438], [lr 0.002629] [batchtime 0.452]
[epoch 129], [iter 104 / 176], [train main loss -2.087246], [lr 0.002629] [batchtime 0.452]
[epoch 129], [iter 105 / 176], [train main loss -2.101113], [lr 0.002629] [batchtime 0.451]
[epoch 129], [iter 106 / 176], [train main loss -2.106385], [lr 0.002629] [batchtime 0.451]
[epoch 129], [iter 107 / 176], [train main loss -2.108693], [lr 0.002629] [batchtime 0.45]
[epoch 129], [iter 108 / 176], [train main loss -2.103927], [lr 0.002629] [batchtime 0.45]
[epoch 129], [iter 109 / 176], [train main loss -2.115509], [lr 0.002629] [batchtime 0.449]
[epoch 129], [iter 110 / 176], [train main loss -2.108627], [lr 0.002629] [batchtime 0.449]
[epoch 129], [iter 111 / 176], [train main loss -2.121009], [lr 0.002629] [batchtime 0.449]
[epoch 129], [iter 112 / 176], [train main loss -2.121107], [lr 0.002629] [batchtime 0.448]
[epoch 129], [iter 113 / 176], [train main loss -2.133274], [lr 0.002629] [batchtime 0.448]
[epoch 129], [iter 114 / 176], [train main loss -2.146187], [lr 0.002629] [batchtime 0.447]
[epoch 129], [iter 115 / 176], [train main loss -2.171997], [lr 0.002629] [batchtime 0.447]
[epoch 129], [iter 116 / 176], [train main loss -2.157513], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 117 / 176], [train main loss -2.159428], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 118 / 176], [train main loss -2.144575], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 119 / 176], [train main loss -2.125775], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 120 / 176], [train main loss -2.148901], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 121 / 176], [train main loss -2.143903], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 122 / 176], [train main loss -2.141768], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 123 / 176], [train main loss -2.141916], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 124 / 176], [train main loss -2.157297], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 125 / 176], [train main loss -2.149481], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 126 / 176], [train main loss -2.124891], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 127 / 176], [train main loss -2.139383], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 128 / 176], [train main loss -2.130220], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 129 / 176], [train main loss -2.128875], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 130 / 176], [train main loss -2.137387], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 131 / 176], [train main loss -2.133491], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 132 / 176], [train main loss -2.132013], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 133 / 176], [train main loss -2.126644], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 134 / 176], [train main loss -2.114171], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 135 / 176], [train main loss -2.124803], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 136 / 176], [train main loss -2.126935], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 137 / 176], [train main loss -2.123946], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 138 / 176], [train main loss -2.113212], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 139 / 176], [train main loss -2.094185], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 140 / 176], [train main loss -2.112691], [lr 0.002629] [batchtime 0.446]
[epoch 129], [iter 141 / 176], [train main loss -2.115298], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 142 / 176], [train main loss -2.099309], [lr 0.002629] [batchtime 0.445]
[epoch 129], [iter 143 / 176], [train main loss -2.106855], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 144 / 176], [train main loss -2.124294], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 145 / 176], [train main loss -2.111628], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 146 / 176], [train main loss -2.104050], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 147 / 176], [train main loss -2.083526], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 148 / 176], [train main loss -2.079466], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 149 / 176], [train main loss -2.083175], [lr 0.002629] [batchtime 0.444]
[epoch 129], [iter 150 / 176], [train main loss -2.072345], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 151 / 176], [train main loss -2.058420], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 152 / 176], [train main loss -2.076490], [lr 0.002629] [batchtime 0.443]
[epoch 129], [iter 153 / 176], [train main loss -2.066906], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 154 / 176], [train main loss -2.085998], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 155 / 176], [train main loss -2.093557], [lr 0.002629] [batchtime 0.442]
[epoch 129], [iter 156 / 176], [train main loss -2.083427], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 157 / 176], [train main loss -2.102465], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 158 / 176], [train main loss -2.111766], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 159 / 176], [train main loss -2.103214], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 160 / 176], [train main loss -2.103772], [lr 0.002629] [batchtime 0.441]
[epoch 129], [iter 161 / 176], [train main loss -2.107516], [lr 0.002629] [batchtime 0.44]
[epoch 129], [iter 162 / 176], [train main loss -2.122184], [lr 0.002629] [batchtime 0.44]
[epoch 129], [iter 163 / 176], [train main loss -2.135978], [lr 0.002629] [batchtime 0.44]
[epoch 129], [iter 164 / 176], [train main loss -2.143035], [lr 0.002629] [batchtime 0.439]
[epoch 129], [iter 165 / 176], [train main loss -2.147956], [lr 0.002629] [batchtime 0.439]
[epoch 129], [iter 166 / 176], [train main loss -2.153420], [lr 0.002629] [batchtime 0.439]
[epoch 129], [iter 167 / 176], [train main loss -2.145653], [lr 0.002629] [batchtime 0.439]
[epoch 129], [iter 168 / 176], [train main loss -2.135045], [lr 0.002629] [batchtime 0.438]
[epoch 129], [iter 169 / 176], [train main loss -2.152455], [lr 0.002629] [batchtime 0.438]
[epoch 129], [iter 170 / 176], [train main loss -2.162582], [lr 0.002629] [batchtime 0.438]
[epoch 129], [iter 171 / 176], [train main loss -2.150252], [lr 0.002629] [batchtime 0.437]
[epoch 129], [iter 172 / 176], [train main loss -2.160961], [lr 0.002629] [batchtime 0.437]
[epoch 129], [iter 173 / 176], [train main loss -2.162988], [lr 0.002629] [batchtime 0.437]
[epoch 129], [iter 174 / 176], [train main loss -2.178106], [lr 0.002629] [batchtime 0.436]
[epoch 129], [iter 175 / 176], [train main loss -2.178997], [lr 0.002629] [batchtime 0.436]
[epoch 129], [iter 176 / 176], [train main loss -2.177955], [lr 0.002629] [batchtime 0.436]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.41  35.72   0.02  0.04         0.98      0.96
   1  sidewalk          67.52   5.02   0.31  0.17         0.76      0.86
   2  building          86.35  25.14   0.06  0.10         0.95      0.91
   3  wall              17.86   0.13   3.47  1.13         0.22      0.47
   4  fence             25.42   0.37   2.40  0.53         0.29      0.65
   5  pole              39.41   0.57   0.99  0.55         0.50      0.64
   6  traffic light     17.51   0.03   4.23  0.48         0.19      0.68
   7  traffic sign      28.01   0.17   2.30  0.27         0.30      0.79
   8  vegetation        83.81  11.62   0.06  0.13         0.94      0.89
   9  terrain           41.95   0.40   0.82  0.56         0.55      0.64
  10  sky               93.77   3.75   0.03  0.03         0.97      0.97
  11  person            53.29   0.99   0.55  0.33         0.65      0.75
  12  rider             12.73   0.01   5.93  0.93         0.14      0.52
  13  car               86.10   6.70   0.06  0.11         0.95      0.90
  14  truck              3.42   0.01  27.75  0.48         0.03      0.67
  15  bus               16.36   0.04   1.47  3.64         0.40      0.22
  16  train             39.77   0.09   0.97  0.55         0.51      0.65
  17  motorcycle         4.39   0.01  21.01  0.79         0.05      0.56
  18  bicycle           38.06   0.27   0.46  1.17         0.69      0.46
Mean: 44.74
-----------------------------------------------------------------------------------------------------------
this : [epoch 129], [val loss 0.30717], [acc 0.91035], [acc_cls 0.53040], [mean_iu 0.44744], [fwavacc 0.84259]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 130], [iter 1 / 176], [train main loss -1.482847], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 2 / 176], [train main loss -3.504019], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 3 / 176], [train main loss -3.559727], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 4 / 176], [train main loss -3.629185], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 5 / 176], [train main loss -3.803960], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 6 / 176], [train main loss -3.640690], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 7 / 176], [train main loss -3.292830], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 8 / 176], [train main loss -3.208436], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 9 / 176], [train main loss -3.230845], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 10 / 176], [train main loss -2.828573], [lr 0.002571] [batchtime 0]
[epoch 130], [iter 11 / 176], [train main loss -2.919819], [lr 0.002571] [batchtime 0.37]
[epoch 130], [iter 12 / 176], [train main loss -2.899008], [lr 0.002571] [batchtime 0.387]
[epoch 130], [iter 13 / 176], [train main loss -2.596167], [lr 0.002571] [batchtime 0.394]
[epoch 130], [iter 14 / 176], [train main loss -2.580301], [lr 0.002571] [batchtime 0.394]
[epoch 130], [iter 15 / 176], [train main loss -2.547136], [lr 0.002571] [batchtime 0.394]
[epoch 130], [iter 16 / 176], [train main loss -2.594235], [lr 0.002571] [batchtime 0.396]
[epoch 130], [iter 17 / 176], [train main loss -2.672509], [lr 0.002571] [batchtime 0.397]
[epoch 130], [iter 18 / 176], [train main loss -2.502618], [lr 0.002571] [batchtime 0.455]
[epoch 130], [iter 19 / 176], [train main loss -2.364375], [lr 0.002571] [batchtime 0.447]
[epoch 130], [iter 20 / 176], [train main loss -2.284488], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 21 / 176], [train main loss -2.147824], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 22 / 176], [train main loss -2.034065], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 23 / 176], [train main loss -1.986758], [lr 0.002571] [batchtime 0.431]
[epoch 130], [iter 24 / 176], [train main loss -1.914041], [lr 0.002571] [batchtime 0.43]
[epoch 130], [iter 25 / 176], [train main loss -1.939320], [lr 0.002571] [batchtime 0.429]
[epoch 130], [iter 26 / 176], [train main loss -1.952742], [lr 0.002571] [batchtime 0.426]
[epoch 130], [iter 27 / 176], [train main loss -1.997950], [lr 0.002571] [batchtime 0.425]
[epoch 130], [iter 28 / 176], [train main loss -1.943191], [lr 0.002571] [batchtime 0.424]
[epoch 130], [iter 29 / 176], [train main loss -1.988548], [lr 0.002571] [batchtime 0.423]
[epoch 130], [iter 30 / 176], [train main loss -2.062182], [lr 0.002571] [batchtime 0.422]
[epoch 130], [iter 31 / 176], [train main loss -2.081095], [lr 0.002571] [batchtime 0.42]
[epoch 130], [iter 32 / 176], [train main loss -2.070124], [lr 0.002571] [batchtime 0.419]
[epoch 130], [iter 33 / 176], [train main loss -2.070582], [lr 0.002571] [batchtime 0.418]
[epoch 130], [iter 34 / 176], [train main loss -1.993202], [lr 0.002571] [batchtime 0.418]
[epoch 130], [iter 35 / 176], [train main loss -2.049161], [lr 0.002571] [batchtime 0.417]
[epoch 130], [iter 36 / 176], [train main loss -2.076294], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 37 / 176], [train main loss -2.105691], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 38 / 176], [train main loss -2.157743], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 39 / 176], [train main loss -2.141288], [lr 0.002571] [batchtime 0.415]
[epoch 130], [iter 40 / 176], [train main loss -2.114535], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 41 / 176], [train main loss -2.162813], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 42 / 176], [train main loss -2.174134], [lr 0.002571] [batchtime 0.421]
[epoch 130], [iter 43 / 176], [train main loss -2.198831], [lr 0.002571] [batchtime 0.425]
[epoch 130], [iter 44 / 176], [train main loss -2.280141], [lr 0.002571] [batchtime 0.424]
[epoch 130], [iter 45 / 176], [train main loss -2.234411], [lr 0.002571] [batchtime 0.424]
[epoch 130], [iter 46 / 176], [train main loss -2.263595], [lr 0.002571] [batchtime 0.423]
[epoch 130], [iter 47 / 176], [train main loss -2.310470], [lr 0.002571] [batchtime 0.422]
[epoch 130], [iter 48 / 176], [train main loss -2.321951], [lr 0.002571] [batchtime 0.422]
[epoch 130], [iter 49 / 176], [train main loss -2.285357], [lr 0.002571] [batchtime 0.421]
[epoch 130], [iter 50 / 176], [train main loss -2.304546], [lr 0.002571] [batchtime 0.421]
[epoch 130], [iter 51 / 176], [train main loss -2.319817], [lr 0.002571] [batchtime 0.42]
[epoch 130], [iter 52 / 176], [train main loss -2.382092], [lr 0.002571] [batchtime 0.42]
[epoch 130], [iter 53 / 176], [train main loss -2.353323], [lr 0.002571] [batchtime 0.419]
[epoch 130], [iter 54 / 176], [train main loss -2.332073], [lr 0.002571] [batchtime 0.419]
[epoch 130], [iter 55 / 176], [train main loss -2.323170], [lr 0.002571] [batchtime 0.418]
[epoch 130], [iter 56 / 176], [train main loss -2.306387], [lr 0.002571] [batchtime 0.418]
[epoch 130], [iter 57 / 176], [train main loss -2.287169], [lr 0.002571] [batchtime 0.418]
[epoch 130], [iter 58 / 176], [train main loss -2.301457], [lr 0.002571] [batchtime 0.417]
[epoch 130], [iter 59 / 176], [train main loss -2.270551], [lr 0.002571] [batchtime 0.417]
[epoch 130], [iter 60 / 176], [train main loss -2.215708], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 61 / 176], [train main loss -2.229923], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 62 / 176], [train main loss -2.252398], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 63 / 176], [train main loss -2.223679], [lr 0.002571] [batchtime 0.416]
[epoch 130], [iter 64 / 176], [train main loss -2.202653], [lr 0.002571] [batchtime 0.415]
[epoch 130], [iter 65 / 176], [train main loss -2.185252], [lr 0.002571] [batchtime 0.415]
[epoch 130], [iter 66 / 176], [train main loss -2.182857], [lr 0.002571] [batchtime 0.415]
[epoch 130], [iter 67 / 176], [train main loss -2.087090], [lr 0.002571] [batchtime 0.415]
[epoch 130], [iter 68 / 176], [train main loss -2.075800], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 69 / 176], [train main loss -2.089542], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 70 / 176], [train main loss -2.081157], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 71 / 176], [train main loss -2.079023], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 72 / 176], [train main loss -2.085408], [lr 0.002571] [batchtime 0.414]
[epoch 130], [iter 73 / 176], [train main loss -2.089995], [lr 0.002571] [batchtime 0.413]
[epoch 130], [iter 74 / 176], [train main loss -2.108875], [lr 0.002571] [batchtime 0.413]
[epoch 130], [iter 75 / 176], [train main loss -2.139662], [lr 0.002571] [batchtime 0.413]
[epoch 130], [iter 76 / 176], [train main loss -2.156068], [lr 0.002571] [batchtime 0.413]
[epoch 130], [iter 77 / 176], [train main loss -2.126437], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 78 / 176], [train main loss -2.125579], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 79 / 176], [train main loss -2.101133], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 80 / 176], [train main loss -2.098019], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 81 / 176], [train main loss -2.074095], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 82 / 176], [train main loss -2.085468], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 83 / 176], [train main loss -2.101925], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 84 / 176], [train main loss -2.104905], [lr 0.002571] [batchtime 0.412]
[epoch 130], [iter 85 / 176], [train main loss -2.085813], [lr 0.002571] [batchtime 0.411]
[epoch 130], [iter 86 / 176], [train main loss -2.064694], [lr 0.002571] [batchtime 0.411]
[epoch 130], [iter 87 / 176], [train main loss -2.067556], [lr 0.002571] [batchtime 0.411]
[epoch 130], [iter 88 / 176], [train main loss -2.079017], [lr 0.002571] [batchtime 0.411]
[epoch 130], [iter 89 / 176], [train main loss -2.065544], [lr 0.002571] [batchtime 0.411]
[epoch 130], [iter 90 / 176], [train main loss -2.029204], [lr 0.002571] [batchtime 0.411]
[epoch 130], [iter 91 / 176], [train main loss -2.017590], [lr 0.002571] [batchtime 0.426]
[epoch 130], [iter 92 / 176], [train main loss -2.001912], [lr 0.002571] [batchtime 0.427]
[epoch 130], [iter 93 / 176], [train main loss -2.042733], [lr 0.002571] [batchtime 0.427]
[epoch 130], [iter 94 / 176], [train main loss -2.036394], [lr 0.002571] [batchtime 0.451]
[epoch 130], [iter 95 / 176], [train main loss -2.058594], [lr 0.002571] [batchtime 0.45]
[epoch 130], [iter 96 / 176], [train main loss -2.073002], [lr 0.002571] [batchtime 0.449]
[epoch 130], [iter 97 / 176], [train main loss -2.069087], [lr 0.002571] [batchtime 0.448]
[epoch 130], [iter 98 / 176], [train main loss -2.089953], [lr 0.002571] [batchtime 0.448]
[epoch 130], [iter 99 / 176], [train main loss -2.087864], [lr 0.002571] [batchtime 0.447]
[epoch 130], [iter 100 / 176], [train main loss -2.093157], [lr 0.002571] [batchtime 0.447]
[epoch 130], [iter 101 / 176], [train main loss -2.109504], [lr 0.002571] [batchtime 0.446]
[epoch 130], [iter 102 / 176], [train main loss -2.112224], [lr 0.002571] [batchtime 0.446]
[epoch 130], [iter 103 / 176], [train main loss -2.119407], [lr 0.002571] [batchtime 0.445]
[epoch 130], [iter 104 / 176], [train main loss -2.110113], [lr 0.002571] [batchtime 0.445]
[epoch 130], [iter 105 / 176], [train main loss -2.101313], [lr 0.002571] [batchtime 0.444]
[epoch 130], [iter 106 / 176], [train main loss -2.083589], [lr 0.002571] [batchtime 0.444]
[epoch 130], [iter 107 / 176], [train main loss -2.065674], [lr 0.002571] [batchtime 0.443]
[epoch 130], [iter 108 / 176], [train main loss -2.079432], [lr 0.002571] [batchtime 0.443]
[epoch 130], [iter 109 / 176], [train main loss -2.063402], [lr 0.002571] [batchtime 0.443]
[epoch 130], [iter 110 / 176], [train main loss -2.053144], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 111 / 176], [train main loss -2.044261], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 112 / 176], [train main loss -2.058378], [lr 0.002571] [batchtime 0.441]
[epoch 130], [iter 113 / 176], [train main loss -2.042115], [lr 0.002571] [batchtime 0.441]
[epoch 130], [iter 114 / 176], [train main loss -2.039344], [lr 0.002571] [batchtime 0.44]
[epoch 130], [iter 115 / 176], [train main loss -2.040224], [lr 0.002571] [batchtime 0.44]
[epoch 130], [iter 116 / 176], [train main loss -2.066008], [lr 0.002571] [batchtime 0.44]
[epoch 130], [iter 117 / 176], [train main loss -2.058120], [lr 0.002571] [batchtime 0.439]
[epoch 130], [iter 118 / 176], [train main loss -2.046862], [lr 0.002571] [batchtime 0.439]
[epoch 130], [iter 119 / 176], [train main loss -2.043665], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 120 / 176], [train main loss -2.030311], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 121 / 176], [train main loss -2.044223], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 122 / 176], [train main loss -2.041302], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 123 / 176], [train main loss -2.030694], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 124 / 176], [train main loss -2.030845], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 125 / 176], [train main loss -2.023249], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 126 / 176], [train main loss -2.005535], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 127 / 176], [train main loss -2.014689], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 128 / 176], [train main loss -2.014242], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 129 / 176], [train main loss -2.004022], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 130 / 176], [train main loss -2.000994], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 131 / 176], [train main loss -1.990506], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 132 / 176], [train main loss -2.009733], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 133 / 176], [train main loss -2.015633], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 134 / 176], [train main loss -1.999672], [lr 0.002571] [batchtime 0.443]
[epoch 130], [iter 135 / 176], [train main loss -1.987939], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 136 / 176], [train main loss -1.980593], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 137 / 176], [train main loss -1.966899], [lr 0.002571] [batchtime 0.442]
[epoch 130], [iter 138 / 176], [train main loss -1.953824], [lr 0.002571] [batchtime 0.441]
[epoch 130], [iter 139 / 176], [train main loss -1.970442], [lr 0.002571] [batchtime 0.441]
[epoch 130], [iter 140 / 176], [train main loss -1.967318], [lr 0.002571] [batchtime 0.441]
[epoch 130], [iter 141 / 176], [train main loss -1.972229], [lr 0.002571] [batchtime 0.44]
[epoch 130], [iter 142 / 176], [train main loss -1.981426], [lr 0.002571] [batchtime 0.44]
[epoch 130], [iter 143 / 176], [train main loss -1.984335], [lr 0.002571] [batchtime 0.44]
[epoch 130], [iter 144 / 176], [train main loss -1.986654], [lr 0.002571] [batchtime 0.439]
[epoch 130], [iter 145 / 176], [train main loss -1.993076], [lr 0.002571] [batchtime 0.439]
[epoch 130], [iter 146 / 176], [train main loss -1.996286], [lr 0.002571] [batchtime 0.439]
[epoch 130], [iter 147 / 176], [train main loss -2.001115], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 148 / 176], [train main loss -2.022069], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 149 / 176], [train main loss -2.032378], [lr 0.002571] [batchtime 0.438]
[epoch 130], [iter 150 / 176], [train main loss -2.023459], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 151 / 176], [train main loss -2.029050], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 152 / 176], [train main loss -2.020976], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 153 / 176], [train main loss -2.017379], [lr 0.002571] [batchtime 0.437]
[epoch 130], [iter 154 / 176], [train main loss -2.009546], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 155 / 176], [train main loss -1.998988], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 156 / 176], [train main loss -2.018265], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 157 / 176], [train main loss -2.018937], [lr 0.002571] [batchtime 0.436]
[epoch 130], [iter 158 / 176], [train main loss -2.006406], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 159 / 176], [train main loss -1.998354], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 160 / 176], [train main loss -1.993274], [lr 0.002571] [batchtime 0.435]
[epoch 130], [iter 161 / 176], [train main loss -2.005063], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 162 / 176], [train main loss -2.021959], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 163 / 176], [train main loss -2.030032], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 164 / 176], [train main loss -2.034681], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 165 / 176], [train main loss -2.037158], [lr 0.002571] [batchtime 0.434]
[epoch 130], [iter 166 / 176], [train main loss -2.047062], [lr 0.002571] [batchtime 0.433]
[epoch 130], [iter 167 / 176], [train main loss -2.038574], [lr 0.002571] [batchtime 0.433]
[epoch 130], [iter 168 / 176], [train main loss -2.019344], [lr 0.002571] [batchtime 0.433]
[epoch 130], [iter 169 / 176], [train main loss -2.022609], [lr 0.002571] [batchtime 0.433]
[epoch 130], [iter 170 / 176], [train main loss -2.016885], [lr 0.002571] [batchtime 0.433]
[epoch 130], [iter 171 / 176], [train main loss -2.020278], [lr 0.002571] [batchtime 0.432]
[epoch 130], [iter 172 / 176], [train main loss -2.022685], [lr 0.002571] [batchtime 0.432]
[epoch 130], [iter 173 / 176], [train main loss -2.018414], [lr 0.002571] [batchtime 0.432]
[epoch 130], [iter 174 / 176], [train main loss -2.015982], [lr 0.002571] [batchtime 0.431]
[epoch 130], [iter 175 / 176], [train main loss -2.007430], [lr 0.002571] [batchtime 0.431]
[epoch 130], [iter 176 / 176], [train main loss -2.014982], [lr 0.002571] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.72  35.66   0.02  0.04         0.98      0.97
   1  sidewalk          69.42   5.22   0.26  0.18         0.79      0.85
   2  building          86.51  24.88   0.07  0.09         0.94      0.92
   3  wall              17.31   0.13   3.48  1.29         0.22      0.44
   4  fence             26.18   0.40   2.15  0.67         0.32      0.60
   5  pole              39.56   0.57   1.01  0.52         0.50      0.66
   6  traffic light     17.81   0.03   4.17  0.44         0.19      0.69
   7  traffic sign      25.54   0.15   2.69  0.22         0.27      0.82
   8  vegetation        83.08  11.78   0.05  0.15         0.95      0.87
   9  terrain           40.05   0.35   1.07  0.42         0.48      0.70
  10  sky               93.67   3.74   0.04  0.03         0.97      0.97
  11  person            53.99   1.03   0.49  0.36         0.67      0.74
  12  rider             13.45   0.01   5.26  1.17         0.16      0.46
  13  car               86.32   6.70   0.06  0.10         0.95      0.91
  14  truck              3.50   0.01  26.87  0.70         0.04      0.59
  15  bus               15.06   0.03   1.83  3.81         0.35      0.21
  16  train             38.02   0.11   0.68  0.95         0.59      0.51
  17  motorcycle         5.87   0.01  15.20  0.83         0.06      0.55
  18  bicycle           37.55   0.27   0.42  1.24         0.70      0.45
Mean: 44.61
-----------------------------------------------------------------------------------------------------------
this : [epoch 130], [val loss 0.31171], [acc 0.91088], [acc_cls 0.53354], [mean_iu 0.44612], [fwavacc 0.84447]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 131], [iter 1 / 176], [train main loss -2.865387], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 2 / 176], [train main loss -2.676733], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 3 / 176], [train main loss -3.166657], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 4 / 176], [train main loss -3.409184], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 5 / 176], [train main loss -2.862857], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 6 / 176], [train main loss -2.855794], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 7 / 176], [train main loss -2.777299], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 8 / 176], [train main loss -2.974516], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 9 / 176], [train main loss -2.904743], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 10 / 176], [train main loss -2.691266], [lr 0.002514] [batchtime 0]
[epoch 131], [iter 11 / 176], [train main loss -2.740543], [lr 0.002514] [batchtime 0.381]
[epoch 131], [iter 12 / 176], [train main loss -2.776781], [lr 0.002514] [batchtime 0.387]
[epoch 131], [iter 13 / 176], [train main loss -2.705730], [lr 0.002514] [batchtime 0.39]
[epoch 131], [iter 14 / 176], [train main loss -2.693860], [lr 0.002514] [batchtime 0.392]
[epoch 131], [iter 15 / 176], [train main loss -2.423114], [lr 0.002514] [batchtime 0.395]
[epoch 131], [iter 16 / 176], [train main loss -2.313069], [lr 0.002514] [batchtime 0.397]
[epoch 131], [iter 17 / 176], [train main loss -2.350112], [lr 0.002514] [batchtime 0.398]
[epoch 131], [iter 18 / 176], [train main loss -2.409885], [lr 0.002514] [batchtime 0.4]
[epoch 131], [iter 19 / 176], [train main loss -2.553329], [lr 0.002514] [batchtime 0.399]
[epoch 131], [iter 20 / 176], [train main loss -2.438393], [lr 0.002514] [batchtime 0.399]
[epoch 131], [iter 21 / 176], [train main loss -2.322563], [lr 0.002514] [batchtime 0.399]
[epoch 131], [iter 22 / 176], [train main loss -2.374285], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 23 / 176], [train main loss -2.366765], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 24 / 176], [train main loss -2.408855], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 25 / 176], [train main loss -2.392197], [lr 0.002514] [batchtime 0.427]
[epoch 131], [iter 26 / 176], [train main loss -2.310766], [lr 0.002514] [batchtime 0.424]
[epoch 131], [iter 27 / 176], [train main loss -2.196480], [lr 0.002514] [batchtime 0.423]
[epoch 131], [iter 28 / 176], [train main loss -2.148159], [lr 0.002514] [batchtime 0.421]
[epoch 131], [iter 29 / 176], [train main loss -2.223596], [lr 0.002514] [batchtime 0.42]
[epoch 131], [iter 30 / 176], [train main loss -2.144284], [lr 0.002514] [batchtime 0.419]
[epoch 131], [iter 31 / 176], [train main loss -2.130032], [lr 0.002514] [batchtime 0.418]
[epoch 131], [iter 32 / 176], [train main loss -2.119007], [lr 0.002514] [batchtime 0.418]
[epoch 131], [iter 33 / 176], [train main loss -2.076864], [lr 0.002514] [batchtime 0.417]
[epoch 131], [iter 34 / 176], [train main loss -2.064739], [lr 0.002514] [batchtime 0.417]
[epoch 131], [iter 35 / 176], [train main loss -2.084269], [lr 0.002514] [batchtime 0.416]
[epoch 131], [iter 36 / 176], [train main loss -2.032627], [lr 0.002514] [batchtime 0.416]
[epoch 131], [iter 37 / 176], [train main loss -1.990744], [lr 0.002514] [batchtime 0.415]
[epoch 131], [iter 38 / 176], [train main loss -1.988094], [lr 0.002514] [batchtime 0.414]
[epoch 131], [iter 39 / 176], [train main loss -1.956200], [lr 0.002514] [batchtime 0.459]
[epoch 131], [iter 40 / 176], [train main loss -1.952791], [lr 0.002514] [batchtime 0.463]
[epoch 131], [iter 41 / 176], [train main loss -1.977868], [lr 0.002514] [batchtime 0.461]
[epoch 131], [iter 42 / 176], [train main loss -2.009069], [lr 0.002514] [batchtime 0.459]
[epoch 131], [iter 43 / 176], [train main loss -1.983322], [lr 0.002514] [batchtime 0.457]
[epoch 131], [iter 44 / 176], [train main loss -1.981897], [lr 0.002514] [batchtime 0.455]
[epoch 131], [iter 45 / 176], [train main loss -1.961326], [lr 0.002514] [batchtime 0.454]
[epoch 131], [iter 46 / 176], [train main loss -2.063697], [lr 0.002514] [batchtime 0.452]
[epoch 131], [iter 47 / 176], [train main loss -2.013319], [lr 0.002514] [batchtime 0.451]
[epoch 131], [iter 48 / 176], [train main loss -1.987785], [lr 0.002514] [batchtime 0.45]
[epoch 131], [iter 49 / 176], [train main loss -1.981364], [lr 0.002514] [batchtime 0.448]
[epoch 131], [iter 50 / 176], [train main loss -1.987819], [lr 0.002514] [batchtime 0.447]
[epoch 131], [iter 51 / 176], [train main loss -1.988418], [lr 0.002514] [batchtime 0.446]
[epoch 131], [iter 52 / 176], [train main loss -1.957853], [lr 0.002514] [batchtime 0.445]
[epoch 131], [iter 53 / 176], [train main loss -1.950273], [lr 0.002514] [batchtime 0.444]
[epoch 131], [iter 54 / 176], [train main loss -1.951960], [lr 0.002514] [batchtime 0.443]
[epoch 131], [iter 55 / 176], [train main loss -1.950901], [lr 0.002514] [batchtime 0.442]
[epoch 131], [iter 56 / 176], [train main loss -1.932305], [lr 0.002514] [batchtime 0.441]
[epoch 131], [iter 57 / 176], [train main loss -1.943098], [lr 0.002514] [batchtime 0.44]
[epoch 131], [iter 58 / 176], [train main loss -1.979045], [lr 0.002514] [batchtime 0.439]
[epoch 131], [iter 59 / 176], [train main loss -1.993010], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 60 / 176], [train main loss -1.941775], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 61 / 176], [train main loss -1.951020], [lr 0.002514] [batchtime 0.44]
[epoch 131], [iter 62 / 176], [train main loss -1.959312], [lr 0.002514] [batchtime 0.439]
[epoch 131], [iter 63 / 176], [train main loss -1.969017], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 64 / 176], [train main loss -1.952060], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 65 / 176], [train main loss -1.960174], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 66 / 176], [train main loss -1.986967], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 67 / 176], [train main loss -1.971747], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 68 / 176], [train main loss -1.959777], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 69 / 176], [train main loss -1.984427], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 70 / 176], [train main loss -1.939863], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 71 / 176], [train main loss -1.942214], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 72 / 176], [train main loss -1.935712], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 73 / 176], [train main loss -1.928724], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 74 / 176], [train main loss -1.934035], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 75 / 176], [train main loss -1.915635], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 76 / 176], [train main loss -1.958037], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 77 / 176], [train main loss -1.982305], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 78 / 176], [train main loss -2.031861], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 79 / 176], [train main loss -2.029438], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 80 / 176], [train main loss -2.050744], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 81 / 176], [train main loss -2.068494], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 82 / 176], [train main loss -2.025114], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 83 / 176], [train main loss -2.011159], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 84 / 176], [train main loss -2.022376], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 85 / 176], [train main loss -2.010957], [lr 0.002514] [batchtime 0.449]
[epoch 131], [iter 86 / 176], [train main loss -2.003126], [lr 0.002514] [batchtime 0.448]
[epoch 131], [iter 87 / 176], [train main loss -1.992120], [lr 0.002514] [batchtime 0.447]
[epoch 131], [iter 88 / 176], [train main loss -1.987360], [lr 0.002514] [batchtime 0.446]
[epoch 131], [iter 89 / 176], [train main loss -2.003284], [lr 0.002514] [batchtime 0.445]
[epoch 131], [iter 90 / 176], [train main loss -2.015657], [lr 0.002514] [batchtime 0.445]
[epoch 131], [iter 91 / 176], [train main loss -2.006875], [lr 0.002514] [batchtime 0.444]
[epoch 131], [iter 92 / 176], [train main loss -1.993508], [lr 0.002514] [batchtime 0.443]
[epoch 131], [iter 93 / 176], [train main loss -2.000919], [lr 0.002514] [batchtime 0.443]
[epoch 131], [iter 94 / 176], [train main loss -2.013921], [lr 0.002514] [batchtime 0.442]
[epoch 131], [iter 95 / 176], [train main loss -2.005837], [lr 0.002514] [batchtime 0.442]
[epoch 131], [iter 96 / 176], [train main loss -2.023103], [lr 0.002514] [batchtime 0.441]
[epoch 131], [iter 97 / 176], [train main loss -2.019180], [lr 0.002514] [batchtime 0.441]
[epoch 131], [iter 98 / 176], [train main loss -1.985205], [lr 0.002514] [batchtime 0.44]
[epoch 131], [iter 99 / 176], [train main loss -1.966907], [lr 0.002514] [batchtime 0.44]
[epoch 131], [iter 100 / 176], [train main loss -1.952408], [lr 0.002514] [batchtime 0.439]
[epoch 131], [iter 101 / 176], [train main loss -1.940192], [lr 0.002514] [batchtime 0.439]
[epoch 131], [iter 102 / 176], [train main loss -1.921409], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 103 / 176], [train main loss -1.950117], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 104 / 176], [train main loss -1.941787], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 105 / 176], [train main loss -1.930786], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 106 / 176], [train main loss -1.939684], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 107 / 176], [train main loss -1.954315], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 108 / 176], [train main loss -1.930698], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 109 / 176], [train main loss -1.919832], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 110 / 176], [train main loss -1.919729], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 111 / 176], [train main loss -1.922319], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 112 / 176], [train main loss -1.928110], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 113 / 176], [train main loss -1.938712], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 114 / 176], [train main loss -1.938812], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 115 / 176], [train main loss -1.935608], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 116 / 176], [train main loss -1.924776], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 117 / 176], [train main loss -1.904396], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 118 / 176], [train main loss -1.902916], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 119 / 176], [train main loss -1.924023], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 120 / 176], [train main loss -1.914061], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 121 / 176], [train main loss -1.914383], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 122 / 176], [train main loss -1.925117], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 123 / 176], [train main loss -1.955659], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 124 / 176], [train main loss -1.976976], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 125 / 176], [train main loss -1.970244], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 126 / 176], [train main loss -1.963887], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 127 / 176], [train main loss -1.967634], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 128 / 176], [train main loss -1.953776], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 129 / 176], [train main loss -1.966852], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 130 / 176], [train main loss -1.974374], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 131 / 176], [train main loss -1.963999], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 132 / 176], [train main loss -1.946426], [lr 0.002514] [batchtime 0.441]
[epoch 131], [iter 133 / 176], [train main loss -1.944491], [lr 0.002514] [batchtime 0.44]
[epoch 131], [iter 134 / 176], [train main loss -1.939427], [lr 0.002514] [batchtime 0.44]
[epoch 131], [iter 135 / 176], [train main loss -1.950921], [lr 0.002514] [batchtime 0.439]
[epoch 131], [iter 136 / 176], [train main loss -1.982067], [lr 0.002514] [batchtime 0.439]
[epoch 131], [iter 137 / 176], [train main loss -1.956956], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 138 / 176], [train main loss -1.948756], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 139 / 176], [train main loss -1.946169], [lr 0.002514] [batchtime 0.438]
[epoch 131], [iter 140 / 176], [train main loss -1.956027], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 141 / 176], [train main loss -1.962409], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 142 / 176], [train main loss -1.975941], [lr 0.002514] [batchtime 0.437]
[epoch 131], [iter 143 / 176], [train main loss -1.981648], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 144 / 176], [train main loss -1.968903], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 145 / 176], [train main loss -1.965237], [lr 0.002514] [batchtime 0.436]
[epoch 131], [iter 146 / 176], [train main loss -1.981585], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 147 / 176], [train main loss -1.979869], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 148 / 176], [train main loss -1.992030], [lr 0.002514] [batchtime 0.435]
[epoch 131], [iter 149 / 176], [train main loss -2.009459], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 150 / 176], [train main loss -2.002927], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 151 / 176], [train main loss -2.016204], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 152 / 176], [train main loss -2.006631], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 153 / 176], [train main loss -2.005953], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 154 / 176], [train main loss -2.009613], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 155 / 176], [train main loss -2.017670], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 156 / 176], [train main loss -2.027708], [lr 0.002514] [batchtime 0.434]
[epoch 131], [iter 157 / 176], [train main loss -2.016582], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 158 / 176], [train main loss -2.020406], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 159 / 176], [train main loss -2.020337], [lr 0.002514] [batchtime 0.433]
[epoch 131], [iter 160 / 176], [train main loss -2.019626], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 161 / 176], [train main loss -2.018554], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 162 / 176], [train main loss -2.021565], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 163 / 176], [train main loss -2.008919], [lr 0.002514] [batchtime 0.432]
[epoch 131], [iter 164 / 176], [train main loss -2.010328], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 165 / 176], [train main loss -2.005389], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 166 / 176], [train main loss -2.000225], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 167 / 176], [train main loss -1.982754], [lr 0.002514] [batchtime 0.431]
[epoch 131], [iter 168 / 176], [train main loss -1.978306], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 169 / 176], [train main loss -1.988512], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 170 / 176], [train main loss -1.998353], [lr 0.002514] [batchtime 0.43]
[epoch 131], [iter 171 / 176], [train main loss -2.010097], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 172 / 176], [train main loss -2.010497], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 173 / 176], [train main loss -2.017435], [lr 0.002514] [batchtime 0.429]
[epoch 131], [iter 174 / 176], [train main loss -2.015866], [lr 0.002514] [batchtime 0.428]
[epoch 131], [iter 175 / 176], [train main loss -2.007058], [lr 0.002514] [batchtime 0.428]
[epoch 131], [iter 176 / 176], [train main loss -2.012710], [lr 0.002514] [batchtime 0.428]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.87  35.56   0.02  0.03         0.98      0.97
   1  sidewalk          70.39   5.37   0.23  0.19         0.82      0.84
   2  building          86.24  24.67   0.08  0.08         0.93      0.92
   3  wall              16.51   0.14   3.11  1.94         0.24      0.34
   4  fence             27.86   0.48   1.63  0.96         0.38      0.51
   5  pole              39.32   0.55   1.06  0.48         0.49      0.67
   6  traffic light     16.90   0.03   4.44  0.47         0.18      0.68
   7  traffic sign      25.94   0.15   2.61  0.24         0.28      0.81
   8  vegetation        83.78  11.70   0.06  0.14         0.95      0.88
   9  terrain           38.24   0.34   1.16  0.46         0.46      0.69
  10  sky               93.75   3.77   0.03  0.04         0.97      0.96
  11  person            54.88   1.10   0.39  0.43         0.72      0.70
  12  rider             10.79   0.01   7.12  1.15         0.12      0.47
  13  car               86.33   6.68   0.06  0.10         0.94      0.91
  14  truck              1.82   0.01  53.03  0.84         0.02      0.54
  15  bus               11.20   0.04   1.02  6.90         0.49      0.13
  16  train             14.09   0.06   2.23  3.87         0.31      0.21
  17  motorcycle         4.55   0.01  20.33  0.67         0.05      0.60
  18  bicycle           40.58   0.25   0.53  0.93         0.65      0.52
Mean: 43.05
-----------------------------------------------------------------------------------------------------------
this : [epoch 131], [val loss 0.30231], [acc 0.90932], [acc_cls 0.52540], [mean_iu 0.43055], [fwavacc 0.84558]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 132], [iter 1 / 176], [train main loss -4.049889], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 2 / 176], [train main loss -3.623628], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 3 / 176], [train main loss -2.527629], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 4 / 176], [train main loss -1.915699], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 5 / 176], [train main loss -2.848086], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 6 / 176], [train main loss -2.401870], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 7 / 176], [train main loss -2.494472], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 8 / 176], [train main loss -2.624229], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 9 / 176], [train main loss -2.380907], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 10 / 176], [train main loss -2.410518], [lr 0.002457] [batchtime 0]
[epoch 132], [iter 11 / 176], [train main loss -2.532239], [lr 0.002457] [batchtime 0.392]
[epoch 132], [iter 12 / 176], [train main loss -2.808645], [lr 0.002457] [batchtime 0.393]
[epoch 132], [iter 13 / 176], [train main loss -2.757909], [lr 0.002457] [batchtime 0.391]
[epoch 132], [iter 14 / 176], [train main loss -2.664480], [lr 0.002457] [batchtime 0.391]
[epoch 132], [iter 15 / 176], [train main loss -2.703673], [lr 0.002457] [batchtime 0.394]
[epoch 132], [iter 16 / 176], [train main loss -2.734271], [lr 0.002457] [batchtime 0.394]
[epoch 132], [iter 17 / 176], [train main loss -2.701661], [lr 0.002457] [batchtime 0.395]
[epoch 132], [iter 18 / 176], [train main loss -2.519082], [lr 0.002457] [batchtime 0.395]
[epoch 132], [iter 19 / 176], [train main loss -2.541137], [lr 0.002457] [batchtime 0.394]
[epoch 132], [iter 20 / 176], [train main loss -2.487667], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 21 / 176], [train main loss -2.591852], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 22 / 176], [train main loss -2.688679], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 23 / 176], [train main loss -2.770533], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 24 / 176], [train main loss -2.692036], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 25 / 176], [train main loss -2.762941], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 26 / 176], [train main loss -2.640361], [lr 0.002457] [batchtime 0.395]
[epoch 132], [iter 27 / 176], [train main loss -2.578096], [lr 0.002457] [batchtime 0.396]
[epoch 132], [iter 28 / 176], [train main loss -2.612204], [lr 0.002457] [batchtime 0.404]
[epoch 132], [iter 29 / 176], [train main loss -2.595277], [lr 0.002457] [batchtime 0.404]
[epoch 132], [iter 30 / 176], [train main loss -2.558882], [lr 0.002457] [batchtime 0.403]
[epoch 132], [iter 31 / 176], [train main loss -2.607823], [lr 0.002457] [batchtime 0.403]
[epoch 132], [iter 32 / 176], [train main loss -2.539611], [lr 0.002457] [batchtime 0.402]
[epoch 132], [iter 33 / 176], [train main loss -2.517959], [lr 0.002457] [batchtime 0.402]
[epoch 132], [iter 34 / 176], [train main loss -2.706005], [lr 0.002457] [batchtime 0.402]
[epoch 132], [iter 35 / 176], [train main loss -2.627296], [lr 0.002457] [batchtime 0.433]
[epoch 132], [iter 36 / 176], [train main loss -2.627770], [lr 0.002457] [batchtime 0.439]
[epoch 132], [iter 37 / 176], [train main loss -2.657645], [lr 0.002457] [batchtime 0.437]
[epoch 132], [iter 38 / 176], [train main loss -2.623258], [lr 0.002457] [batchtime 0.435]
[epoch 132], [iter 39 / 176], [train main loss -2.679748], [lr 0.002457] [batchtime 0.434]
[epoch 132], [iter 40 / 176], [train main loss -2.637604], [lr 0.002457] [batchtime 0.432]
[epoch 132], [iter 41 / 176], [train main loss -2.641784], [lr 0.002457] [batchtime 0.431]
[epoch 132], [iter 42 / 176], [train main loss -2.611130], [lr 0.002457] [batchtime 0.43]
[epoch 132], [iter 43 / 176], [train main loss -2.580899], [lr 0.002457] [batchtime 0.429]
[epoch 132], [iter 44 / 176], [train main loss -2.501524], [lr 0.002457] [batchtime 0.428]
[epoch 132], [iter 45 / 176], [train main loss -2.434374], [lr 0.002457] [batchtime 0.427]
[epoch 132], [iter 46 / 176], [train main loss -2.402452], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 47 / 176], [train main loss -2.347671], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 48 / 176], [train main loss -2.352028], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 49 / 176], [train main loss -2.395907], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 50 / 176], [train main loss -2.404078], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 51 / 176], [train main loss -2.408237], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 52 / 176], [train main loss -2.379660], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 53 / 176], [train main loss -2.382706], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 54 / 176], [train main loss -2.372364], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 55 / 176], [train main loss -2.317366], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 56 / 176], [train main loss -2.339616], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 57 / 176], [train main loss -2.356645], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 58 / 176], [train main loss -2.288789], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 59 / 176], [train main loss -2.295923], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 60 / 176], [train main loss -2.299688], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 61 / 176], [train main loss -2.311194], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 62 / 176], [train main loss -2.278378], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 63 / 176], [train main loss -2.334743], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 64 / 176], [train main loss -2.336806], [lr 0.002457] [batchtime 0.415]
[epoch 132], [iter 65 / 176], [train main loss -2.334448], [lr 0.002457] [batchtime 0.415]
[epoch 132], [iter 66 / 176], [train main loss -2.325520], [lr 0.002457] [batchtime 0.415]
[epoch 132], [iter 67 / 176], [train main loss -2.276808], [lr 0.002457] [batchtime 0.414]
[epoch 132], [iter 68 / 176], [train main loss -2.295285], [lr 0.002457] [batchtime 0.414]
[epoch 132], [iter 69 / 176], [train main loss -2.300214], [lr 0.002457] [batchtime 0.414]
[epoch 132], [iter 70 / 176], [train main loss -2.327112], [lr 0.002457] [batchtime 0.413]
[epoch 132], [iter 71 / 176], [train main loss -2.327466], [lr 0.002457] [batchtime 0.413]
[epoch 132], [iter 72 / 176], [train main loss -2.330488], [lr 0.002457] [batchtime 0.413]
[epoch 132], [iter 73 / 176], [train main loss -2.296699], [lr 0.002457] [batchtime 0.413]
[epoch 132], [iter 74 / 176], [train main loss -2.300642], [lr 0.002457] [batchtime 0.412]
[epoch 132], [iter 75 / 176], [train main loss -2.283843], [lr 0.002457] [batchtime 0.412]
[epoch 132], [iter 76 / 176], [train main loss -2.265826], [lr 0.002457] [batchtime 0.412]
[epoch 132], [iter 77 / 176], [train main loss -2.277764], [lr 0.002457] [batchtime 0.411]
[epoch 132], [iter 78 / 176], [train main loss -2.293796], [lr 0.002457] [batchtime 0.411]
[epoch 132], [iter 79 / 176], [train main loss -2.303680], [lr 0.002457] [batchtime 0.411]
[epoch 132], [iter 80 / 176], [train main loss -2.317997], [lr 0.002457] [batchtime 0.411]
[epoch 132], [iter 81 / 176], [train main loss -2.309213], [lr 0.002457] [batchtime 0.41]
[epoch 132], [iter 82 / 176], [train main loss -2.278164], [lr 0.002457] [batchtime 0.41]
[epoch 132], [iter 83 / 176], [train main loss -2.251463], [lr 0.002457] [batchtime 0.412]
[epoch 132], [iter 84 / 176], [train main loss -2.260040], [lr 0.002457] [batchtime 0.429]
[epoch 132], [iter 85 / 176], [train main loss -2.262564], [lr 0.002457] [batchtime 0.428]
[epoch 132], [iter 86 / 176], [train main loss -2.261695], [lr 0.002457] [batchtime 0.428]
[epoch 132], [iter 87 / 176], [train main loss -2.253302], [lr 0.002457] [batchtime 0.427]
[epoch 132], [iter 88 / 176], [train main loss -2.276301], [lr 0.002457] [batchtime 0.427]
[epoch 132], [iter 89 / 176], [train main loss -2.262634], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 90 / 176], [train main loss -2.241585], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 91 / 176], [train main loss -2.253832], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 92 / 176], [train main loss -2.234007], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 93 / 176], [train main loss -2.224197], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 94 / 176], [train main loss -2.216397], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 95 / 176], [train main loss -2.209149], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 96 / 176], [train main loss -2.192597], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 97 / 176], [train main loss -2.203159], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 98 / 176], [train main loss -2.206534], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 99 / 176], [train main loss -2.192963], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 100 / 176], [train main loss -2.208358], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 101 / 176], [train main loss -2.201023], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 102 / 176], [train main loss -2.189656], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 103 / 176], [train main loss -2.198978], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 104 / 176], [train main loss -2.177734], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 105 / 176], [train main loss -2.169996], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 106 / 176], [train main loss -2.178961], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 107 / 176], [train main loss -2.197840], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 108 / 176], [train main loss -2.187626], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 109 / 176], [train main loss -2.199585], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 110 / 176], [train main loss -2.211355], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 111 / 176], [train main loss -2.240536], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 112 / 176], [train main loss -2.244245], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 113 / 176], [train main loss -2.261205], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 114 / 176], [train main loss -2.280565], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 115 / 176], [train main loss -2.275472], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 116 / 176], [train main loss -2.266383], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 117 / 176], [train main loss -2.265835], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 118 / 176], [train main loss -2.245176], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 119 / 176], [train main loss -2.228029], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 120 / 176], [train main loss -2.229631], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 121 / 176], [train main loss -2.221771], [lr 0.002457] [batchtime 0.418]
[epoch 132], [iter 122 / 176], [train main loss -2.222850], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 123 / 176], [train main loss -2.219768], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 124 / 176], [train main loss -2.214506], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 125 / 176], [train main loss -2.223053], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 126 / 176], [train main loss -2.239570], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 127 / 176], [train main loss -2.250321], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 128 / 176], [train main loss -2.222744], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 129 / 176], [train main loss -2.201828], [lr 0.002457] [batchtime 0.416]
[epoch 132], [iter 130 / 176], [train main loss -2.190862], [lr 0.002457] [batchtime 0.417]
[epoch 132], [iter 131 / 176], [train main loss -2.197553], [lr 0.002457] [batchtime 0.428]
[epoch 132], [iter 132 / 176], [train main loss -2.210800], [lr 0.002457] [batchtime 0.428]
[epoch 132], [iter 133 / 176], [train main loss -2.219094], [lr 0.002457] [batchtime 0.427]
[epoch 132], [iter 134 / 176], [train main loss -2.230596], [lr 0.002457] [batchtime 0.427]
[epoch 132], [iter 135 / 176], [train main loss -2.230308], [lr 0.002457] [batchtime 0.427]
[epoch 132], [iter 136 / 176], [train main loss -2.213876], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 137 / 176], [train main loss -2.213384], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 138 / 176], [train main loss -2.211649], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 139 / 176], [train main loss -2.207077], [lr 0.002457] [batchtime 0.426]
[epoch 132], [iter 140 / 176], [train main loss -2.200834], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 141 / 176], [train main loss -2.205343], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 142 / 176], [train main loss -2.204416], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 143 / 176], [train main loss -2.188411], [lr 0.002457] [batchtime 0.425]
[epoch 132], [iter 144 / 176], [train main loss -2.185674], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 145 / 176], [train main loss -2.178725], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 146 / 176], [train main loss -2.175833], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 147 / 176], [train main loss -2.164734], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 148 / 176], [train main loss -2.158946], [lr 0.002457] [batchtime 0.424]
[epoch 132], [iter 149 / 176], [train main loss -2.169487], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 150 / 176], [train main loss -2.183205], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 151 / 176], [train main loss -2.191979], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 152 / 176], [train main loss -2.211038], [lr 0.002457] [batchtime 0.423]
[epoch 132], [iter 153 / 176], [train main loss -2.215589], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 154 / 176], [train main loss -2.222838], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 155 / 176], [train main loss -2.223938], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 156 / 176], [train main loss -2.224525], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 157 / 176], [train main loss -2.226969], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 158 / 176], [train main loss -2.225321], [lr 0.002457] [batchtime 0.422]
[epoch 132], [iter 159 / 176], [train main loss -2.212132], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 160 / 176], [train main loss -2.213637], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 161 / 176], [train main loss -2.217654], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 162 / 176], [train main loss -2.206901], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 163 / 176], [train main loss -2.210422], [lr 0.002457] [batchtime 0.421]
[epoch 132], [iter 164 / 176], [train main loss -2.217202], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 165 / 176], [train main loss -2.225237], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 166 / 176], [train main loss -2.236603], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 167 / 176], [train main loss -2.218609], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 168 / 176], [train main loss -2.243396], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 169 / 176], [train main loss -2.244451], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 170 / 176], [train main loss -2.241360], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 171 / 176], [train main loss -2.233149], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 172 / 176], [train main loss -2.247895], [lr 0.002457] [batchtime 0.42]
[epoch 132], [iter 173 / 176], [train main loss -2.259967], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 174 / 176], [train main loss -2.270800], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 175 / 176], [train main loss -2.271570], [lr 0.002457] [batchtime 0.419]
[epoch 132], [iter 176 / 176], [train main loss -2.292275], [lr 0.002457] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.61  35.29   0.03  0.03         0.97      0.97
   1  sidewalk          69.86   5.51   0.20  0.24         0.84      0.81
   2  building          86.79  25.09   0.06  0.09         0.94      0.91
   3  wall              18.83   0.16   2.60  1.71         0.28      0.37
   4  fence             23.69   0.35   2.66  0.56         0.27      0.64
   5  pole              39.23   0.55   1.06  0.49         0.49      0.67
   6  traffic light     15.71   0.03   5.04  0.33         0.17      0.75
   7  traffic sign      25.98   0.15   2.62  0.23         0.28      0.81
   8  vegetation        84.04  11.70   0.06  0.13         0.95      0.88
   9  terrain           38.37   0.37   1.00  0.60         0.50      0.62
  10  sky               93.81   3.74   0.04  0.03         0.97      0.97
  11  person            53.66   1.00   0.54  0.32         0.65      0.76
  12  rider             12.56   0.01   5.96  1.00         0.14      0.50
  13  car               85.54   6.73   0.05  0.12         0.95      0.89
  14  truck              1.60   0.01  61.06  0.43         0.02      0.70
  15  bus               15.42   0.04   1.02  4.46         0.49      0.18
  16  train             28.00   0.06   1.84  0.73         0.35      0.58
  17  motorcycle         4.07   0.00  22.99  0.60         0.04      0.63
  18  bicycle           38.33   0.27   0.47  1.14         0.68      0.47
Mean: 43.69
-----------------------------------------------------------------------------------------------------------
this : [epoch 132], [val loss 0.30106], [acc 0.91066], [acc_cls 0.52486], [mean_iu 0.43689], [fwavacc 0.84510]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 133], [iter 1 / 176], [train main loss 2.426718], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 2 / 176], [train main loss 0.576020], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 3 / 176], [train main loss 0.235765], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 4 / 176], [train main loss -0.979410], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 5 / 176], [train main loss -1.037608], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 6 / 176], [train main loss -1.170243], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 7 / 176], [train main loss -1.531572], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 8 / 176], [train main loss -1.576469], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 9 / 176], [train main loss -1.419917], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 10 / 176], [train main loss -1.544155], [lr 0.002400] [batchtime 0]
[epoch 133], [iter 11 / 176], [train main loss -1.559179], [lr 0.002400] [batchtime 0.384]
[epoch 133], [iter 12 / 176], [train main loss -1.675722], [lr 0.002400] [batchtime 0.405]
[epoch 133], [iter 13 / 176], [train main loss -1.856756], [lr 0.002400] [batchtime 0.4]
[epoch 133], [iter 14 / 176], [train main loss -1.852447], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 15 / 176], [train main loss -1.770602], [lr 0.002400] [batchtime 0.4]
[epoch 133], [iter 16 / 176], [train main loss -1.845886], [lr 0.002400] [batchtime 0.4]
[epoch 133], [iter 17 / 176], [train main loss -1.943378], [lr 0.002400] [batchtime 0.4]
[epoch 133], [iter 18 / 176], [train main loss -2.000130], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 19 / 176], [train main loss -1.960112], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 20 / 176], [train main loss -1.978943], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 21 / 176], [train main loss -1.972952], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 22 / 176], [train main loss -1.960644], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 23 / 176], [train main loss -1.978939], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 24 / 176], [train main loss -2.081976], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 25 / 176], [train main loss -2.142934], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 26 / 176], [train main loss -1.988698], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 27 / 176], [train main loss -2.106981], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 28 / 176], [train main loss -2.147577], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 29 / 176], [train main loss -2.135523], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 30 / 176], [train main loss -2.177398], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 31 / 176], [train main loss -2.171463], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 32 / 176], [train main loss -2.201199], [lr 0.002400] [batchtime 0.399]
[epoch 133], [iter 33 / 176], [train main loss -2.243596], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 34 / 176], [train main loss -2.282554], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 35 / 176], [train main loss -2.331795], [lr 0.002400] [batchtime 0.398]
[epoch 133], [iter 36 / 176], [train main loss -2.310308], [lr 0.002400] [batchtime 0.452]
[epoch 133], [iter 37 / 176], [train main loss -2.358575], [lr 0.002400] [batchtime 0.459]
[epoch 133], [iter 38 / 176], [train main loss -2.269632], [lr 0.002400] [batchtime 0.456]
[epoch 133], [iter 39 / 176], [train main loss -2.190879], [lr 0.002400] [batchtime 0.454]
[epoch 133], [iter 40 / 176], [train main loss -2.154375], [lr 0.002400] [batchtime 0.452]
[epoch 133], [iter 41 / 176], [train main loss -2.157539], [lr 0.002400] [batchtime 0.45]
[epoch 133], [iter 42 / 176], [train main loss -2.149147], [lr 0.002400] [batchtime 0.448]
[epoch 133], [iter 43 / 176], [train main loss -2.101611], [lr 0.002400] [batchtime 0.446]
[epoch 133], [iter 44 / 176], [train main loss -2.054512], [lr 0.002400] [batchtime 0.445]
[epoch 133], [iter 45 / 176], [train main loss -2.057517], [lr 0.002400] [batchtime 0.443]
[epoch 133], [iter 46 / 176], [train main loss -2.111112], [lr 0.002400] [batchtime 0.442]
[epoch 133], [iter 47 / 176], [train main loss -2.159067], [lr 0.002400] [batchtime 0.441]
[epoch 133], [iter 48 / 176], [train main loss -2.200731], [lr 0.002400] [batchtime 0.44]
[epoch 133], [iter 49 / 176], [train main loss -2.162035], [lr 0.002400] [batchtime 0.439]
[epoch 133], [iter 50 / 176], [train main loss -2.186015], [lr 0.002400] [batchtime 0.438]
[epoch 133], [iter 51 / 176], [train main loss -2.225117], [lr 0.002400] [batchtime 0.437]
[epoch 133], [iter 52 / 176], [train main loss -2.170907], [lr 0.002400] [batchtime 0.436]
[epoch 133], [iter 53 / 176], [train main loss -2.181780], [lr 0.002400] [batchtime 0.435]
[epoch 133], [iter 54 / 176], [train main loss -2.199488], [lr 0.002400] [batchtime 0.434]
[epoch 133], [iter 55 / 176], [train main loss -2.173494], [lr 0.002400] [batchtime 0.433]
[epoch 133], [iter 56 / 176], [train main loss -2.168483], [lr 0.002400] [batchtime 0.432]
[epoch 133], [iter 57 / 176], [train main loss -2.179574], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 58 / 176], [train main loss -2.151824], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 59 / 176], [train main loss -2.179398], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 60 / 176], [train main loss -2.194250], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 61 / 176], [train main loss -2.186417], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 62 / 176], [train main loss -2.147348], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 63 / 176], [train main loss -2.159514], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 64 / 176], [train main loss -2.195315], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 65 / 176], [train main loss -2.147103], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 66 / 176], [train main loss -2.189486], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 67 / 176], [train main loss -2.156328], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 68 / 176], [train main loss -2.122763], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 69 / 176], [train main loss -2.153454], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 70 / 176], [train main loss -2.185716], [lr 0.002400] [batchtime 0.423]
[epoch 133], [iter 71 / 176], [train main loss -2.164518], [lr 0.002400] [batchtime 0.423]
[epoch 133], [iter 72 / 176], [train main loss -2.151647], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 73 / 176], [train main loss -2.140587], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 74 / 176], [train main loss -2.184757], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 75 / 176], [train main loss -2.220662], [lr 0.002400] [batchtime 0.421]
[epoch 133], [iter 76 / 176], [train main loss -2.198169], [lr 0.002400] [batchtime 0.42]
[epoch 133], [iter 77 / 176], [train main loss -2.196251], [lr 0.002400] [batchtime 0.42]
[epoch 133], [iter 78 / 176], [train main loss -2.193926], [lr 0.002400] [batchtime 0.42]
[epoch 133], [iter 79 / 176], [train main loss -2.216968], [lr 0.002400] [batchtime 0.419]
[epoch 133], [iter 80 / 176], [train main loss -2.203562], [lr 0.002400] [batchtime 0.419]
[epoch 133], [iter 81 / 176], [train main loss -2.196028], [lr 0.002400] [batchtime 0.419]
[epoch 133], [iter 82 / 176], [train main loss -2.161803], [lr 0.002400] [batchtime 0.42]
[epoch 133], [iter 83 / 176], [train main loss -2.176239], [lr 0.002400] [batchtime 0.438]
[epoch 133], [iter 84 / 176], [train main loss -2.252081], [lr 0.002400] [batchtime 0.438]
[epoch 133], [iter 85 / 176], [train main loss -2.264544], [lr 0.002400] [batchtime 0.437]
[epoch 133], [iter 86 / 176], [train main loss -2.240522], [lr 0.002400] [batchtime 0.437]
[epoch 133], [iter 87 / 176], [train main loss -2.249882], [lr 0.002400] [batchtime 0.436]
[epoch 133], [iter 88 / 176], [train main loss -2.239546], [lr 0.002400] [batchtime 0.436]
[epoch 133], [iter 89 / 176], [train main loss -2.237850], [lr 0.002400] [batchtime 0.435]
[epoch 133], [iter 90 / 176], [train main loss -2.249148], [lr 0.002400] [batchtime 0.434]
[epoch 133], [iter 91 / 176], [train main loss -2.231656], [lr 0.002400] [batchtime 0.434]
[epoch 133], [iter 92 / 176], [train main loss -2.246991], [lr 0.002400] [batchtime 0.433]
[epoch 133], [iter 93 / 176], [train main loss -2.253469], [lr 0.002400] [batchtime 0.433]
[epoch 133], [iter 94 / 176], [train main loss -2.293114], [lr 0.002400] [batchtime 0.432]
[epoch 133], [iter 95 / 176], [train main loss -2.270589], [lr 0.002400] [batchtime 0.432]
[epoch 133], [iter 96 / 176], [train main loss -2.274351], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 97 / 176], [train main loss -2.264589], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 98 / 176], [train main loss -2.233778], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 99 / 176], [train main loss -2.237837], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 100 / 176], [train main loss -2.243297], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 101 / 176], [train main loss -2.219604], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 102 / 176], [train main loss -2.201738], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 103 / 176], [train main loss -2.185533], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 104 / 176], [train main loss -2.160450], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 105 / 176], [train main loss -2.167236], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 106 / 176], [train main loss -2.168299], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 107 / 176], [train main loss -2.160862], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 108 / 176], [train main loss -2.154908], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 109 / 176], [train main loss -2.160917], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 110 / 176], [train main loss -2.171577], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 111 / 176], [train main loss -2.165851], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 112 / 176], [train main loss -2.166311], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 113 / 176], [train main loss -2.180722], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 114 / 176], [train main loss -2.180444], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 115 / 176], [train main loss -2.187518], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 116 / 176], [train main loss -2.201820], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 117 / 176], [train main loss -2.210999], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 118 / 176], [train main loss -2.196401], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 119 / 176], [train main loss -2.185811], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 120 / 176], [train main loss -2.196981], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 121 / 176], [train main loss -2.187530], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 122 / 176], [train main loss -2.207621], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 123 / 176], [train main loss -2.203403], [lr 0.002400] [batchtime 0.423]
[epoch 133], [iter 124 / 176], [train main loss -2.187731], [lr 0.002400] [batchtime 0.423]
[epoch 133], [iter 125 / 176], [train main loss -2.199962], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 126 / 176], [train main loss -2.184250], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 127 / 176], [train main loss -2.185965], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 128 / 176], [train main loss -2.184959], [lr 0.002400] [batchtime 0.422]
[epoch 133], [iter 129 / 176], [train main loss -2.186044], [lr 0.002400] [batchtime 0.423]
[epoch 133], [iter 130 / 176], [train main loss -2.183296], [lr 0.002400] [batchtime 0.435]
[epoch 133], [iter 131 / 176], [train main loss -2.169386], [lr 0.002400] [batchtime 0.434]
[epoch 133], [iter 132 / 176], [train main loss -2.163623], [lr 0.002400] [batchtime 0.434]
[epoch 133], [iter 133 / 176], [train main loss -2.161131], [lr 0.002400] [batchtime 0.434]
[epoch 133], [iter 134 / 176], [train main loss -2.142589], [lr 0.002400] [batchtime 0.433]
[epoch 133], [iter 135 / 176], [train main loss -2.142629], [lr 0.002400] [batchtime 0.433]
[epoch 133], [iter 136 / 176], [train main loss -2.126551], [lr 0.002400] [batchtime 0.433]
[epoch 133], [iter 137 / 176], [train main loss -2.111955], [lr 0.002400] [batchtime 0.432]
[epoch 133], [iter 138 / 176], [train main loss -2.110187], [lr 0.002400] [batchtime 0.432]
[epoch 133], [iter 139 / 176], [train main loss -2.101920], [lr 0.002400] [batchtime 0.432]
[epoch 133], [iter 140 / 176], [train main loss -2.101200], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 141 / 176], [train main loss -2.090364], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 142 / 176], [train main loss -2.078114], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 143 / 176], [train main loss -2.084719], [lr 0.002400] [batchtime 0.431]
[epoch 133], [iter 144 / 176], [train main loss -2.080369], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 145 / 176], [train main loss -2.089541], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 146 / 176], [train main loss -2.085246], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 147 / 176], [train main loss -2.103894], [lr 0.002400] [batchtime 0.43]
[epoch 133], [iter 148 / 176], [train main loss -2.123227], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 149 / 176], [train main loss -2.149134], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 150 / 176], [train main loss -2.150686], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 151 / 176], [train main loss -2.145599], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 152 / 176], [train main loss -2.153181], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 153 / 176], [train main loss -2.162966], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 154 / 176], [train main loss -2.155011], [lr 0.002400] [batchtime 0.429]
[epoch 133], [iter 155 / 176], [train main loss -2.142574], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 156 / 176], [train main loss -2.139251], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 157 / 176], [train main loss -2.149084], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 158 / 176], [train main loss -2.133004], [lr 0.002400] [batchtime 0.428]
[epoch 133], [iter 159 / 176], [train main loss -2.122847], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 160 / 176], [train main loss -2.134359], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 161 / 176], [train main loss -2.128303], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 162 / 176], [train main loss -2.122202], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 163 / 176], [train main loss -2.117591], [lr 0.002400] [batchtime 0.427]
[epoch 133], [iter 164 / 176], [train main loss -2.132904], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 165 / 176], [train main loss -2.138949], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 166 / 176], [train main loss -2.159143], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 167 / 176], [train main loss -2.142009], [lr 0.002400] [batchtime 0.426]
[epoch 133], [iter 168 / 176], [train main loss -2.144898], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 169 / 176], [train main loss -2.155056], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 170 / 176], [train main loss -2.166072], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 171 / 176], [train main loss -2.175129], [lr 0.002400] [batchtime 0.425]
[epoch 133], [iter 172 / 176], [train main loss -2.182285], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 173 / 176], [train main loss -2.177983], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 174 / 176], [train main loss -2.170566], [lr 0.002400] [batchtime 0.424]
[epoch 133], [iter 175 / 176], [train main loss -2.176824], [lr 0.002400] [batchtime 0.423]
[epoch 133], [iter 176 / 176], [train main loss -2.169301], [lr 0.002400] [batchtime 0.425]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.65  35.32   0.03  0.03         0.97      0.97
   1  sidewalk          69.93   5.49   0.20  0.23         0.83      0.81
   2  building          86.78  25.19   0.06  0.10         0.95      0.91
   3  wall              18.35   0.14   3.24  1.21         0.24      0.45
   4  fence             27.01   0.43   1.98  0.72         0.34      0.58
   5  pole              39.69   0.56   1.03  0.49         0.49      0.67
   6  traffic light     18.74   0.03   3.90  0.44         0.20      0.70
   7  traffic sign      25.92   0.16   2.61  0.25         0.28      0.80
   8  vegetation        84.92  11.54   0.07  0.11         0.93      0.90
   9  terrain           40.29   0.36   1.02  0.46         0.50      0.68
  10  sky               93.68   3.77   0.03  0.04         0.97      0.96
  11  person            55.88   1.10   0.40  0.39         0.72      0.72
  12  rider             11.65   0.01   6.50  1.08         0.13      0.48
  13  car               85.62   6.74   0.05  0.12         0.95      0.89
  14  truck              2.32   0.01  41.56  0.52         0.02      0.66
  15  bus               14.57   0.04   1.09  4.77         0.48      0.17
  16  train             31.09   0.08   1.34  0.88         0.43      0.53
  17  motorcycle         5.21   0.01  17.54  0.66         0.05      0.60
  18  bicycle           40.12   0.26   0.49  1.00         0.67      0.50
Mean: 44.55
-----------------------------------------------------------------------------------------------------------
this : [epoch 133], [val loss 0.29185], [acc 0.91219], [acc_cls 0.53460], [mean_iu 0.44549], [fwavacc 0.84752]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 134], [iter 1 / 176], [train main loss -0.549554], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 2 / 176], [train main loss -1.285931], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 3 / 176], [train main loss -1.009249], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 4 / 176], [train main loss -0.650439], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 5 / 176], [train main loss -1.046167], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 6 / 176], [train main loss -1.011627], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 7 / 176], [train main loss -1.053287], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 8 / 176], [train main loss -1.585550], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 9 / 176], [train main loss -1.583987], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 10 / 176], [train main loss -1.545019], [lr 0.002343] [batchtime 0]
[epoch 134], [iter 11 / 176], [train main loss -1.414551], [lr 0.002343] [batchtime 0.376]
[epoch 134], [iter 12 / 176], [train main loss -1.552340], [lr 0.002343] [batchtime 0.387]
[epoch 134], [iter 13 / 176], [train main loss -1.457042], [lr 0.002343] [batchtime 0.391]
[epoch 134], [iter 14 / 176], [train main loss -1.298441], [lr 0.002343] [batchtime 0.392]
[epoch 134], [iter 15 / 176], [train main loss -1.512563], [lr 0.002343] [batchtime 0.396]
[epoch 134], [iter 16 / 176], [train main loss -1.572904], [lr 0.002343] [batchtime 0.397]
[epoch 134], [iter 17 / 176], [train main loss -1.656308], [lr 0.002343] [batchtime 0.398]
[epoch 134], [iter 18 / 176], [train main loss -1.784738], [lr 0.002343] [batchtime 0.398]
[epoch 134], [iter 19 / 176], [train main loss -1.781268], [lr 0.002343] [batchtime 0.399]
[epoch 134], [iter 20 / 176], [train main loss -1.707355], [lr 0.002343] [batchtime 0.416]
[epoch 134], [iter 21 / 176], [train main loss -1.660950], [lr 0.002343] [batchtime 0.414]
[epoch 134], [iter 22 / 176], [train main loss -1.752507], [lr 0.002343] [batchtime 0.412]
[epoch 134], [iter 23 / 176], [train main loss -1.711616], [lr 0.002343] [batchtime 0.411]
[epoch 134], [iter 24 / 176], [train main loss -1.729194], [lr 0.002343] [batchtime 0.41]
[epoch 134], [iter 25 / 176], [train main loss -1.678393], [lr 0.002343] [batchtime 0.409]
[epoch 134], [iter 26 / 176], [train main loss -1.748822], [lr 0.002343] [batchtime 0.408]
[epoch 134], [iter 27 / 176], [train main loss -1.799796], [lr 0.002343] [batchtime 0.408]
[epoch 134], [iter 28 / 176], [train main loss -1.796414], [lr 0.002343] [batchtime 0.407]
[epoch 134], [iter 29 / 176], [train main loss -1.742174], [lr 0.002343] [batchtime 0.407]
[epoch 134], [iter 30 / 176], [train main loss -1.792662], [lr 0.002343] [batchtime 0.415]
[epoch 134], [iter 31 / 176], [train main loss -1.788496], [lr 0.002343] [batchtime 0.482]
[epoch 134], [iter 32 / 176], [train main loss -1.811751], [lr 0.002343] [batchtime 0.477]
[epoch 134], [iter 33 / 176], [train main loss -1.836563], [lr 0.002343] [batchtime 0.473]
[epoch 134], [iter 34 / 176], [train main loss -1.898547], [lr 0.002343] [batchtime 0.47]
[epoch 134], [iter 35 / 176], [train main loss -1.998585], [lr 0.002343] [batchtime 0.466]
[epoch 134], [iter 36 / 176], [train main loss -1.967394], [lr 0.002343] [batchtime 0.464]
[epoch 134], [iter 37 / 176], [train main loss -1.916012], [lr 0.002343] [batchtime 0.461]
[epoch 134], [iter 38 / 176], [train main loss -1.903832], [lr 0.002343] [batchtime 0.459]
[epoch 134], [iter 39 / 176], [train main loss -1.844694], [lr 0.002343] [batchtime 0.456]
[epoch 134], [iter 40 / 176], [train main loss -1.792986], [lr 0.002343] [batchtime 0.454]
[epoch 134], [iter 41 / 176], [train main loss -1.733863], [lr 0.002343] [batchtime 0.453]
[epoch 134], [iter 42 / 176], [train main loss -1.753489], [lr 0.002343] [batchtime 0.451]
[epoch 134], [iter 43 / 176], [train main loss -1.766663], [lr 0.002343] [batchtime 0.45]
[epoch 134], [iter 44 / 176], [train main loss -1.744217], [lr 0.002343] [batchtime 0.448]
[epoch 134], [iter 45 / 176], [train main loss -1.775011], [lr 0.002343] [batchtime 0.446]
[epoch 134], [iter 46 / 176], [train main loss -1.812512], [lr 0.002343] [batchtime 0.445]
[epoch 134], [iter 47 / 176], [train main loss -1.879501], [lr 0.002343] [batchtime 0.444]
[epoch 134], [iter 48 / 176], [train main loss -1.904241], [lr 0.002343] [batchtime 0.443]
[epoch 134], [iter 49 / 176], [train main loss -1.881763], [lr 0.002343] [batchtime 0.442]
[epoch 134], [iter 50 / 176], [train main loss -1.861823], [lr 0.002343] [batchtime 0.44]
[epoch 134], [iter 51 / 176], [train main loss -1.865502], [lr 0.002343] [batchtime 0.439]
[epoch 134], [iter 52 / 176], [train main loss -1.860265], [lr 0.002343] [batchtime 0.438]
[epoch 134], [iter 53 / 176], [train main loss -1.812487], [lr 0.002343] [batchtime 0.437]
[epoch 134], [iter 54 / 176], [train main loss -1.841301], [lr 0.002343] [batchtime 0.436]
[epoch 134], [iter 55 / 176], [train main loss -1.851010], [lr 0.002343] [batchtime 0.435]
[epoch 134], [iter 56 / 176], [train main loss -1.851481], [lr 0.002343] [batchtime 0.435]
[epoch 134], [iter 57 / 176], [train main loss -1.858273], [lr 0.002343] [batchtime 0.434]
[epoch 134], [iter 58 / 176], [train main loss -1.835040], [lr 0.002343] [batchtime 0.433]
[epoch 134], [iter 59 / 176], [train main loss -1.882943], [lr 0.002343] [batchtime 0.432]
[epoch 134], [iter 60 / 176], [train main loss -1.878298], [lr 0.002343] [batchtime 0.431]
[epoch 134], [iter 61 / 176], [train main loss -1.895496], [lr 0.002343] [batchtime 0.431]
[epoch 134], [iter 62 / 176], [train main loss -1.890232], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 63 / 176], [train main loss -1.859625], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 64 / 176], [train main loss -1.840792], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 65 / 176], [train main loss -1.846974], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 66 / 176], [train main loss -1.828641], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 67 / 176], [train main loss -1.788426], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 68 / 176], [train main loss -1.773372], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 69 / 176], [train main loss -1.757349], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 70 / 176], [train main loss -1.780631], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 71 / 176], [train main loss -1.793431], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 72 / 176], [train main loss -1.817312], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 73 / 176], [train main loss -1.791435], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 74 / 176], [train main loss -1.797377], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 75 / 176], [train main loss -1.762131], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 76 / 176], [train main loss -1.740138], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 77 / 176], [train main loss -1.734934], [lr 0.002343] [batchtime 0.441]
[epoch 134], [iter 78 / 176], [train main loss -1.768416], [lr 0.002343] [batchtime 0.445]
[epoch 134], [iter 79 / 176], [train main loss -1.784776], [lr 0.002343] [batchtime 0.444]
[epoch 134], [iter 80 / 176], [train main loss -1.798066], [lr 0.002343] [batchtime 0.443]
[epoch 134], [iter 81 / 176], [train main loss -1.831864], [lr 0.002343] [batchtime 0.442]
[epoch 134], [iter 82 / 176], [train main loss -1.806780], [lr 0.002343] [batchtime 0.441]
[epoch 134], [iter 83 / 176], [train main loss -1.820099], [lr 0.002343] [batchtime 0.441]
[epoch 134], [iter 84 / 176], [train main loss -1.853728], [lr 0.002343] [batchtime 0.44]
[epoch 134], [iter 85 / 176], [train main loss -1.834937], [lr 0.002343] [batchtime 0.439]
[epoch 134], [iter 86 / 176], [train main loss -1.845404], [lr 0.002343] [batchtime 0.439]
[epoch 134], [iter 87 / 176], [train main loss -1.854178], [lr 0.002343] [batchtime 0.438]
[epoch 134], [iter 88 / 176], [train main loss -1.862957], [lr 0.002343] [batchtime 0.438]
[epoch 134], [iter 89 / 176], [train main loss -1.850594], [lr 0.002343] [batchtime 0.437]
[epoch 134], [iter 90 / 176], [train main loss -1.849024], [lr 0.002343] [batchtime 0.437]
[epoch 134], [iter 91 / 176], [train main loss -1.851220], [lr 0.002343] [batchtime 0.436]
[epoch 134], [iter 92 / 176], [train main loss -1.905123], [lr 0.002343] [batchtime 0.436]
[epoch 134], [iter 93 / 176], [train main loss -1.897311], [lr 0.002343] [batchtime 0.435]
[epoch 134], [iter 94 / 176], [train main loss -1.896047], [lr 0.002343] [batchtime 0.435]
[epoch 134], [iter 95 / 176], [train main loss -1.905151], [lr 0.002343] [batchtime 0.434]
[epoch 134], [iter 96 / 176], [train main loss -1.913914], [lr 0.002343] [batchtime 0.434]
[epoch 134], [iter 97 / 176], [train main loss -1.905796], [lr 0.002343] [batchtime 0.433]
[epoch 134], [iter 98 / 176], [train main loss -1.930304], [lr 0.002343] [batchtime 0.433]
[epoch 134], [iter 99 / 176], [train main loss -1.906392], [lr 0.002343] [batchtime 0.432]
[epoch 134], [iter 100 / 176], [train main loss -1.940326], [lr 0.002343] [batchtime 0.432]
[epoch 134], [iter 101 / 176], [train main loss -1.937397], [lr 0.002343] [batchtime 0.432]
[epoch 134], [iter 102 / 176], [train main loss -1.932178], [lr 0.002343] [batchtime 0.431]
[epoch 134], [iter 103 / 176], [train main loss -1.946333], [lr 0.002343] [batchtime 0.431]
[epoch 134], [iter 104 / 176], [train main loss -1.942127], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 105 / 176], [train main loss -1.952485], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 106 / 176], [train main loss -1.952630], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 107 / 176], [train main loss -1.946096], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 108 / 176], [train main loss -1.927137], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 109 / 176], [train main loss -1.936829], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 110 / 176], [train main loss -1.951720], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 111 / 176], [train main loss -1.965189], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 112 / 176], [train main loss -1.969631], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 113 / 176], [train main loss -1.960693], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 114 / 176], [train main loss -1.952954], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 115 / 176], [train main loss -1.973523], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 116 / 176], [train main loss -1.974750], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 117 / 176], [train main loss -1.954955], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 118 / 176], [train main loss -1.950488], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 119 / 176], [train main loss -1.920014], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 120 / 176], [train main loss -1.940823], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 121 / 176], [train main loss -1.955712], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 122 / 176], [train main loss -1.954442], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 123 / 176], [train main loss -1.964617], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 124 / 176], [train main loss -1.955183], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 125 / 176], [train main loss -1.964420], [lr 0.002343] [batchtime 0.431]
[epoch 134], [iter 126 / 176], [train main loss -1.976296], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 127 / 176], [train main loss -1.973791], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 128 / 176], [train main loss -1.982321], [lr 0.002343] [batchtime 0.43]
[epoch 134], [iter 129 / 176], [train main loss -1.992105], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 130 / 176], [train main loss -1.998696], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 131 / 176], [train main loss -1.991559], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 132 / 176], [train main loss -1.987729], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 133 / 176], [train main loss -1.983657], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 134 / 176], [train main loss -1.995029], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 135 / 176], [train main loss -1.999335], [lr 0.002343] [batchtime 0.428]
[epoch 134], [iter 136 / 176], [train main loss -1.997218], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 137 / 176], [train main loss -2.014065], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 138 / 176], [train main loss -2.013996], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 139 / 176], [train main loss -1.998416], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 140 / 176], [train main loss -2.003307], [lr 0.002343] [batchtime 0.427]
[epoch 134], [iter 141 / 176], [train main loss -2.014182], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 142 / 176], [train main loss -2.010311], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 143 / 176], [train main loss -2.010679], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 144 / 176], [train main loss -2.011970], [lr 0.002343] [batchtime 0.426]
[epoch 134], [iter 145 / 176], [train main loss -2.013480], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 146 / 176], [train main loss -2.008274], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 147 / 176], [train main loss -1.993567], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 148 / 176], [train main loss -1.997589], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 149 / 176], [train main loss -1.990561], [lr 0.002343] [batchtime 0.425]
[epoch 134], [iter 150 / 176], [train main loss -1.986756], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 151 / 176], [train main loss -1.988348], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 152 / 176], [train main loss -1.979745], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 153 / 176], [train main loss -1.974425], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 154 / 176], [train main loss -1.965345], [lr 0.002343] [batchtime 0.424]
[epoch 134], [iter 155 / 176], [train main loss -1.972064], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 156 / 176], [train main loss -1.971782], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 157 / 176], [train main loss -1.964475], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 158 / 176], [train main loss -1.954194], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 159 / 176], [train main loss -1.956305], [lr 0.002343] [batchtime 0.423]
[epoch 134], [iter 160 / 176], [train main loss -1.942837], [lr 0.002343] [batchtime 0.422]
[epoch 134], [iter 161 / 176], [train main loss -1.943404], [lr 0.002343] [batchtime 0.422]
[epoch 134], [iter 162 / 176], [train main loss -1.935092], [lr 0.002343] [batchtime 0.422]
[epoch 134], [iter 163 / 176], [train main loss -1.941671], [lr 0.002343] [batchtime 0.422]
[epoch 134], [iter 164 / 176], [train main loss -1.944447], [lr 0.002343] [batchtime 0.422]
[epoch 134], [iter 165 / 176], [train main loss -1.943317], [lr 0.002343] [batchtime 0.422]
[epoch 134], [iter 166 / 176], [train main loss -1.937740], [lr 0.002343] [batchtime 0.421]
[epoch 134], [iter 167 / 176], [train main loss -1.955447], [lr 0.002343] [batchtime 0.421]
[epoch 134], [iter 168 / 176], [train main loss -1.953582], [lr 0.002343] [batchtime 0.421]
[epoch 134], [iter 169 / 176], [train main loss -1.937444], [lr 0.002343] [batchtime 0.421]
[epoch 134], [iter 170 / 176], [train main loss -1.927752], [lr 0.002343] [batchtime 0.42]
[epoch 134], [iter 171 / 176], [train main loss -1.923354], [lr 0.002343] [batchtime 0.42]
[epoch 134], [iter 172 / 176], [train main loss -1.931017], [lr 0.002343] [batchtime 0.42]
[epoch 134], [iter 173 / 176], [train main loss -1.954597], [lr 0.002343] [batchtime 0.429]
[epoch 134], [iter 174 / 176], [train main loss -1.962864], [lr 0.002343] [batchtime 0.432]
[epoch 134], [iter 175 / 176], [train main loss -1.971716], [lr 0.002343] [batchtime 0.431]
[epoch 134], [iter 176 / 176], [train main loss -1.959339], [lr 0.002343] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.92  35.58   0.02  0.03         0.98      0.97
   1  sidewalk          70.31   5.45   0.21  0.21         0.83      0.82
   2  building          86.50  25.14   0.06  0.10         0.95      0.91
   3  wall              19.50   0.16   2.73  1.40         0.27      0.42
   4  fence             23.95   0.35   2.63  0.55         0.28      0.65
   5  pole              38.85   0.54   1.09  0.48         0.48      0.68
   6  traffic light     15.99   0.03   4.86  0.39         0.17      0.72
   7  traffic sign      23.42   0.14   3.09  0.18         0.24      0.85
   8  vegetation        84.11  11.65   0.06  0.13         0.94      0.89
   9  terrain           38.93   0.34   1.14  0.43         0.47      0.70
  10  sky               93.55   3.77   0.03  0.04         0.97      0.96
  11  person            54.55   1.03   0.49  0.35         0.67      0.74
  12  rider             11.82   0.01   6.46  1.00         0.13      0.50
  13  car               86.31   6.68   0.06  0.10         0.94      0.91
  14  truck              1.66   0.01  58.72  0.49         0.02      0.67
  15  bus               15.98   0.03   1.89  3.37         0.35      0.23
  16  train             39.83   0.08   1.12  0.39         0.47      0.72
  17  motorcycle         4.76   0.01  19.50  0.53         0.05      0.66
  18  bicycle           39.41   0.27   0.45  1.08         0.69      0.48
Mean: 44.44
-----------------------------------------------------------------------------------------------------------
this : [epoch 134], [val loss 0.30910], [acc 0.91265], [acc_cls 0.52070], [mean_iu 0.44440], [fwavacc 0.84664]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 135], [iter 1 / 176], [train main loss -3.585551], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 2 / 176], [train main loss -2.872567], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 3 / 176], [train main loss -1.967341], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 4 / 176], [train main loss -2.497161], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 5 / 176], [train main loss -2.232941], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 6 / 176], [train main loss -2.313082], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 7 / 176], [train main loss -2.465431], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 8 / 176], [train main loss -1.911971], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 9 / 176], [train main loss -2.104084], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 10 / 176], [train main loss -2.107733], [lr 0.002286] [batchtime 0]
[epoch 135], [iter 11 / 176], [train main loss -2.167487], [lr 0.002286] [batchtime 0.383]
[epoch 135], [iter 12 / 176], [train main loss -2.097426], [lr 0.002286] [batchtime 0.394]
[epoch 135], [iter 13 / 176], [train main loss -2.041852], [lr 0.002286] [batchtime 0.402]
[epoch 135], [iter 14 / 176], [train main loss -2.002754], [lr 0.002286] [batchtime 0.403]
[epoch 135], [iter 15 / 176], [train main loss -2.093481], [lr 0.002286] [batchtime 0.401]
[epoch 135], [iter 16 / 176], [train main loss -2.062209], [lr 0.002286] [batchtime 0.4]
[epoch 135], [iter 17 / 176], [train main loss -2.003107], [lr 0.002286] [batchtime 0.4]
[epoch 135], [iter 18 / 176], [train main loss -1.982480], [lr 0.002286] [batchtime 0.4]
[epoch 135], [iter 19 / 176], [train main loss -2.086972], [lr 0.002286] [batchtime 0.4]
[epoch 135], [iter 20 / 176], [train main loss -2.084751], [lr 0.002286] [batchtime 0.426]
[epoch 135], [iter 21 / 176], [train main loss -2.182020], [lr 0.002286] [batchtime 0.424]
[epoch 135], [iter 22 / 176], [train main loss -2.251086], [lr 0.002286] [batchtime 0.421]
[epoch 135], [iter 23 / 176], [train main loss -2.355130], [lr 0.002286] [batchtime 0.419]
[epoch 135], [iter 24 / 176], [train main loss -2.325932], [lr 0.002286] [batchtime 0.418]
[epoch 135], [iter 25 / 176], [train main loss -2.298804], [lr 0.002286] [batchtime 0.416]
[epoch 135], [iter 26 / 176], [train main loss -2.371229], [lr 0.002286] [batchtime 0.414]
[epoch 135], [iter 27 / 176], [train main loss -2.305833], [lr 0.002286] [batchtime 0.413]
[epoch 135], [iter 28 / 176], [train main loss -2.299828], [lr 0.002286] [batchtime 0.412]
[epoch 135], [iter 29 / 176], [train main loss -2.353231], [lr 0.002286] [batchtime 0.491]
[epoch 135], [iter 30 / 176], [train main loss -2.399977], [lr 0.002286] [batchtime 0.493]
[epoch 135], [iter 31 / 176], [train main loss -2.387502], [lr 0.002286] [batchtime 0.488]
[epoch 135], [iter 32 / 176], [train main loss -2.403713], [lr 0.002286] [batchtime 0.483]
[epoch 135], [iter 33 / 176], [train main loss -2.516785], [lr 0.002286] [batchtime 0.479]
[epoch 135], [iter 34 / 176], [train main loss -2.438556], [lr 0.002286] [batchtime 0.476]
[epoch 135], [iter 35 / 176], [train main loss -2.443028], [lr 0.002286] [batchtime 0.473]
[epoch 135], [iter 36 / 176], [train main loss -2.437773], [lr 0.002286] [batchtime 0.47]
[epoch 135], [iter 37 / 176], [train main loss -2.433001], [lr 0.002286] [batchtime 0.467]
[epoch 135], [iter 38 / 176], [train main loss -2.416117], [lr 0.002286] [batchtime 0.465]
[epoch 135], [iter 39 / 176], [train main loss -2.406497], [lr 0.002286] [batchtime 0.462]
[epoch 135], [iter 40 / 176], [train main loss -2.479681], [lr 0.002286] [batchtime 0.46]
[epoch 135], [iter 41 / 176], [train main loss -2.424682], [lr 0.002286] [batchtime 0.458]
[epoch 135], [iter 42 / 176], [train main loss -2.416771], [lr 0.002286] [batchtime 0.456]
[epoch 135], [iter 43 / 176], [train main loss -2.420166], [lr 0.002286] [batchtime 0.454]
[epoch 135], [iter 44 / 176], [train main loss -2.452872], [lr 0.002286] [batchtime 0.453]
[epoch 135], [iter 45 / 176], [train main loss -2.444089], [lr 0.002286] [batchtime 0.451]
[epoch 135], [iter 46 / 176], [train main loss -2.401171], [lr 0.002286] [batchtime 0.449]
[epoch 135], [iter 47 / 176], [train main loss -2.367280], [lr 0.002286] [batchtime 0.448]
[epoch 135], [iter 48 / 176], [train main loss -2.342536], [lr 0.002286] [batchtime 0.447]
[epoch 135], [iter 49 / 176], [train main loss -2.352178], [lr 0.002286] [batchtime 0.445]
[epoch 135], [iter 50 / 176], [train main loss -2.301454], [lr 0.002286] [batchtime 0.444]
[epoch 135], [iter 51 / 176], [train main loss -2.270562], [lr 0.002286] [batchtime 0.443]
[epoch 135], [iter 52 / 176], [train main loss -2.292656], [lr 0.002286] [batchtime 0.442]
[epoch 135], [iter 53 / 176], [train main loss -2.288794], [lr 0.002286] [batchtime 0.441]
[epoch 135], [iter 54 / 176], [train main loss -2.312241], [lr 0.002286] [batchtime 0.44]
[epoch 135], [iter 55 / 176], [train main loss -2.360565], [lr 0.002286] [batchtime 0.44]
[epoch 135], [iter 56 / 176], [train main loss -2.373479], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 57 / 176], [train main loss -2.385339], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 58 / 176], [train main loss -2.359274], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 59 / 176], [train main loss -2.346350], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 60 / 176], [train main loss -2.361183], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 61 / 176], [train main loss -2.334712], [lr 0.002286] [batchtime 0.435]
[epoch 135], [iter 62 / 176], [train main loss -2.300218], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 63 / 176], [train main loss -2.273523], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 64 / 176], [train main loss -2.284360], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 65 / 176], [train main loss -2.273481], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 66 / 176], [train main loss -2.277451], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 67 / 176], [train main loss -2.295199], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 68 / 176], [train main loss -2.275976], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 69 / 176], [train main loss -2.285899], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 70 / 176], [train main loss -2.285244], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 71 / 176], [train main loss -2.304230], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 72 / 176], [train main loss -2.278160], [lr 0.002286] [batchtime 0.428]
[epoch 135], [iter 73 / 176], [train main loss -2.289716], [lr 0.002286] [batchtime 0.428]
[epoch 135], [iter 74 / 176], [train main loss -2.260565], [lr 0.002286] [batchtime 0.427]
[epoch 135], [iter 75 / 176], [train main loss -2.254988], [lr 0.002286] [batchtime 0.448]
[epoch 135], [iter 76 / 176], [train main loss -2.271717], [lr 0.002286] [batchtime 0.451]
[epoch 135], [iter 77 / 176], [train main loss -2.295278], [lr 0.002286] [batchtime 0.45]
[epoch 135], [iter 78 / 176], [train main loss -2.273758], [lr 0.002286] [batchtime 0.449]
[epoch 135], [iter 79 / 176], [train main loss -2.262660], [lr 0.002286] [batchtime 0.448]
[epoch 135], [iter 80 / 176], [train main loss -2.266725], [lr 0.002286] [batchtime 0.447]
[epoch 135], [iter 81 / 176], [train main loss -2.232697], [lr 0.002286] [batchtime 0.446]
[epoch 135], [iter 82 / 176], [train main loss -2.212860], [lr 0.002286] [batchtime 0.446]
[epoch 135], [iter 83 / 176], [train main loss -2.233650], [lr 0.002286] [batchtime 0.445]
[epoch 135], [iter 84 / 176], [train main loss -2.228199], [lr 0.002286] [batchtime 0.444]
[epoch 135], [iter 85 / 176], [train main loss -2.236945], [lr 0.002286] [batchtime 0.444]
[epoch 135], [iter 86 / 176], [train main loss -2.237950], [lr 0.002286] [batchtime 0.443]
[epoch 135], [iter 87 / 176], [train main loss -2.204798], [lr 0.002286] [batchtime 0.443]
[epoch 135], [iter 88 / 176], [train main loss -2.217360], [lr 0.002286] [batchtime 0.442]
[epoch 135], [iter 89 / 176], [train main loss -2.203723], [lr 0.002286] [batchtime 0.441]
[epoch 135], [iter 90 / 176], [train main loss -2.194561], [lr 0.002286] [batchtime 0.441]
[epoch 135], [iter 91 / 176], [train main loss -2.205682], [lr 0.002286] [batchtime 0.44]
[epoch 135], [iter 92 / 176], [train main loss -2.205723], [lr 0.002286] [batchtime 0.44]
[epoch 135], [iter 93 / 176], [train main loss -2.186605], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 94 / 176], [train main loss -2.206651], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 95 / 176], [train main loss -2.208886], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 96 / 176], [train main loss -2.237022], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 97 / 176], [train main loss -2.221054], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 98 / 176], [train main loss -2.184483], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 99 / 176], [train main loss -2.180939], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 100 / 176], [train main loss -2.190261], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 101 / 176], [train main loss -2.199128], [lr 0.002286] [batchtime 0.435]
[epoch 135], [iter 102 / 176], [train main loss -2.169050], [lr 0.002286] [batchtime 0.435]
[epoch 135], [iter 103 / 176], [train main loss -2.181867], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 104 / 176], [train main loss -2.198470], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 105 / 176], [train main loss -2.225567], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 106 / 176], [train main loss -2.219742], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 107 / 176], [train main loss -2.201084], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 108 / 176], [train main loss -2.204648], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 109 / 176], [train main loss -2.218742], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 110 / 176], [train main loss -2.220189], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 111 / 176], [train main loss -2.243023], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 112 / 176], [train main loss -2.248799], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 113 / 176], [train main loss -2.265829], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 114 / 176], [train main loss -2.237112], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 115 / 176], [train main loss -2.250127], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 116 / 176], [train main loss -2.245522], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 117 / 176], [train main loss -2.252402], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 118 / 176], [train main loss -2.249816], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 119 / 176], [train main loss -2.250171], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 120 / 176], [train main loss -2.269004], [lr 0.002286] [batchtime 0.428]
[epoch 135], [iter 121 / 176], [train main loss -2.283375], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 122 / 176], [train main loss -2.278305], [lr 0.002286] [batchtime 0.442]
[epoch 135], [iter 123 / 176], [train main loss -2.300114], [lr 0.002286] [batchtime 0.441]
[epoch 135], [iter 124 / 176], [train main loss -2.299523], [lr 0.002286] [batchtime 0.441]
[epoch 135], [iter 125 / 176], [train main loss -2.292916], [lr 0.002286] [batchtime 0.441]
[epoch 135], [iter 126 / 176], [train main loss -2.281185], [lr 0.002286] [batchtime 0.44]
[epoch 135], [iter 127 / 176], [train main loss -2.306007], [lr 0.002286] [batchtime 0.44]
[epoch 135], [iter 128 / 176], [train main loss -2.296854], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 129 / 176], [train main loss -2.303133], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 130 / 176], [train main loss -2.311797], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 131 / 176], [train main loss -2.340820], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 132 / 176], [train main loss -2.335245], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 133 / 176], [train main loss -2.334273], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 134 / 176], [train main loss -2.358241], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 135 / 176], [train main loss -2.374102], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 136 / 176], [train main loss -2.361876], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 137 / 176], [train main loss -2.367431], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 138 / 176], [train main loss -2.349862], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 139 / 176], [train main loss -2.356715], [lr 0.002286] [batchtime 0.435]
[epoch 135], [iter 140 / 176], [train main loss -2.357367], [lr 0.002286] [batchtime 0.435]
[epoch 135], [iter 141 / 176], [train main loss -2.358848], [lr 0.002286] [batchtime 0.435]
[epoch 135], [iter 142 / 176], [train main loss -2.378270], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 143 / 176], [train main loss -2.366407], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 144 / 176], [train main loss -2.370406], [lr 0.002286] [batchtime 0.434]
[epoch 135], [iter 145 / 176], [train main loss -2.362190], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 146 / 176], [train main loss -2.344665], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 147 / 176], [train main loss -2.336886], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 148 / 176], [train main loss -2.344276], [lr 0.002286] [batchtime 0.433]
[epoch 135], [iter 149 / 176], [train main loss -2.353194], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 150 / 176], [train main loss -2.365036], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 151 / 176], [train main loss -2.375112], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 152 / 176], [train main loss -2.378991], [lr 0.002286] [batchtime 0.432]
[epoch 135], [iter 153 / 176], [train main loss -2.372876], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 154 / 176], [train main loss -2.382539], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 155 / 176], [train main loss -2.375574], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 156 / 176], [train main loss -2.362292], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 157 / 176], [train main loss -2.375833], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 158 / 176], [train main loss -2.379790], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 159 / 176], [train main loss -2.379189], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 160 / 176], [train main loss -2.370345], [lr 0.002286] [batchtime 0.431]
[epoch 135], [iter 161 / 176], [train main loss -2.376037], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 162 / 176], [train main loss -2.382268], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 163 / 176], [train main loss -2.393097], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 164 / 176], [train main loss -2.420425], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 165 / 176], [train main loss -2.420006], [lr 0.002286] [batchtime 0.43]
[epoch 135], [iter 166 / 176], [train main loss -2.413785], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 167 / 176], [train main loss -2.394762], [lr 0.002286] [batchtime 0.429]
[epoch 135], [iter 168 / 176], [train main loss -2.385021], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 169 / 176], [train main loss -2.403560], [lr 0.002286] [batchtime 0.439]
[epoch 135], [iter 170 / 176], [train main loss -2.395318], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 171 / 176], [train main loss -2.406951], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 172 / 176], [train main loss -2.420346], [lr 0.002286] [batchtime 0.438]
[epoch 135], [iter 173 / 176], [train main loss -2.424923], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 174 / 176], [train main loss -2.407945], [lr 0.002286] [batchtime 0.437]
[epoch 135], [iter 175 / 176], [train main loss -2.409037], [lr 0.002286] [batchtime 0.436]
[epoch 135], [iter 176 / 176], [train main loss -2.406268], [lr 0.002286] [batchtime 0.436]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.64  35.59   0.02  0.03         0.98      0.97
   1  sidewalk          69.17   5.29   0.25  0.20         0.80      0.83
   2  building          86.65  24.91   0.07  0.09         0.94      0.92
   3  wall              18.67   0.16   2.75  1.61         0.27      0.38
   4  fence             26.06   0.40   2.14  0.70         0.32      0.59
   5  pole              38.66   0.54   1.11  0.48         0.47      0.68
   6  traffic light     17.53   0.03   4.17  0.53         0.19      0.65
   7  traffic sign      23.63   0.14   3.03  0.20         0.25      0.83
   8  vegetation        83.84  11.70   0.06  0.14         0.95      0.88
   9  terrain           40.98   0.40   0.85  0.59         0.54      0.63
  10  sky               93.90   3.76   0.03  0.03         0.97      0.97
  11  person            54.30   1.03   0.49  0.36         0.67      0.74
  12  rider             12.69   0.01   5.87  1.01         0.15      0.50
  13  car               85.80   6.73   0.05  0.11         0.95      0.90
  14  truck              1.44   0.00  68.11  0.54         0.01      0.65
  15  bus               12.75   0.04   1.35  5.49         0.43      0.15
  16  train             20.78   0.05   2.95  0.86         0.25      0.54
  17  motorcycle         4.69   0.01  19.61  0.73         0.05      0.58
  18  bicycle           38.33   0.26   0.48  1.13         0.67      0.47
Mean: 43.39
-----------------------------------------------------------------------------------------------------------
this : [epoch 135], [val loss 0.31000], [acc 0.91041], [acc_cls 0.51911], [mean_iu 0.43395], [fwavacc 0.84461]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 136], [iter 1 / 176], [train main loss -0.847629], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 2 / 176], [train main loss -1.128586], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 3 / 176], [train main loss -1.848020], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 4 / 176], [train main loss -2.089167], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 5 / 176], [train main loss -1.871801], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 6 / 176], [train main loss -1.430942], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 7 / 176], [train main loss -1.523466], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 8 / 176], [train main loss -1.595630], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 9 / 176], [train main loss -1.845568], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 10 / 176], [train main loss -1.729405], [lr 0.002229] [batchtime 0]
[epoch 136], [iter 11 / 176], [train main loss -1.737775], [lr 0.002229] [batchtime 0.373]
[epoch 136], [iter 12 / 176], [train main loss -1.647024], [lr 0.002229] [batchtime 0.385]
[epoch 136], [iter 13 / 176], [train main loss -1.649330], [lr 0.002229] [batchtime 0.394]
[epoch 136], [iter 14 / 176], [train main loss -1.845582], [lr 0.002229] [batchtime 0.392]
[epoch 136], [iter 15 / 176], [train main loss -1.838412], [lr 0.002229] [batchtime 0.393]
[epoch 136], [iter 16 / 176], [train main loss -1.660784], [lr 0.002229] [batchtime 0.393]
[epoch 136], [iter 17 / 176], [train main loss -1.596750], [lr 0.002229] [batchtime 0.396]
[epoch 136], [iter 18 / 176], [train main loss -1.773192], [lr 0.002229] [batchtime 0.395]
[epoch 136], [iter 19 / 176], [train main loss -1.771235], [lr 0.002229] [batchtime 0.398]
[epoch 136], [iter 20 / 176], [train main loss -1.837341], [lr 0.002229] [batchtime 0.397]
[epoch 136], [iter 21 / 176], [train main loss -1.909645], [lr 0.002229] [batchtime 0.397]
[epoch 136], [iter 22 / 176], [train main loss -1.886654], [lr 0.002229] [batchtime 0.397]
[epoch 136], [iter 23 / 176], [train main loss -1.822909], [lr 0.002229] [batchtime 0.397]
[epoch 136], [iter 24 / 176], [train main loss -1.857797], [lr 0.002229] [batchtime 0.408]
[epoch 136], [iter 25 / 176], [train main loss -1.807667], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 26 / 176], [train main loss -1.798806], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 27 / 176], [train main loss -1.644363], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 28 / 176], [train main loss -1.731367], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 29 / 176], [train main loss -1.825688], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 30 / 176], [train main loss -1.853454], [lr 0.002229] [batchtime 0.413]
[epoch 136], [iter 31 / 176], [train main loss -1.930995], [lr 0.002229] [batchtime 0.412]
[epoch 136], [iter 32 / 176], [train main loss -1.902748], [lr 0.002229] [batchtime 0.411]
[epoch 136], [iter 33 / 176], [train main loss -1.903986], [lr 0.002229] [batchtime 0.412]
[epoch 136], [iter 34 / 176], [train main loss -1.909940], [lr 0.002229] [batchtime 0.411]
[epoch 136], [iter 35 / 176], [train main loss -1.871270], [lr 0.002229] [batchtime 0.41]
[epoch 136], [iter 36 / 176], [train main loss -1.863166], [lr 0.002229] [batchtime 0.409]
[epoch 136], [iter 37 / 176], [train main loss -1.881077], [lr 0.002229] [batchtime 0.409]
[epoch 136], [iter 38 / 176], [train main loss -1.961742], [lr 0.002229] [batchtime 0.409]
[epoch 136], [iter 39 / 176], [train main loss -1.997521], [lr 0.002229] [batchtime 0.408]
[epoch 136], [iter 40 / 176], [train main loss -2.133572], [lr 0.002229] [batchtime 0.408]
[epoch 136], [iter 41 / 176], [train main loss -2.164120], [lr 0.002229] [batchtime 0.407]
[epoch 136], [iter 42 / 176], [train main loss -2.140062], [lr 0.002229] [batchtime 0.407]
[epoch 136], [iter 43 / 176], [train main loss -2.139638], [lr 0.002229] [batchtime 0.407]
[epoch 136], [iter 44 / 176], [train main loss -2.124934], [lr 0.002229] [batchtime 0.406]
[epoch 136], [iter 45 / 176], [train main loss -2.117237], [lr 0.002229] [batchtime 0.406]
[epoch 136], [iter 46 / 176], [train main loss -2.173711], [lr 0.002229] [batchtime 0.406]
[epoch 136], [iter 47 / 176], [train main loss -2.165062], [lr 0.002229] [batchtime 0.406]
[epoch 136], [iter 48 / 176], [train main loss -2.162971], [lr 0.002229] [batchtime 0.409]
[epoch 136], [iter 49 / 176], [train main loss -2.135795], [lr 0.002229] [batchtime 0.442]
[epoch 136], [iter 50 / 176], [train main loss -2.092527], [lr 0.002229] [batchtime 0.44]
[epoch 136], [iter 51 / 176], [train main loss -2.046584], [lr 0.002229] [batchtime 0.439]
[epoch 136], [iter 52 / 176], [train main loss -2.081053], [lr 0.002229] [batchtime 0.438]
[epoch 136], [iter 53 / 176], [train main loss -2.080432], [lr 0.002229] [batchtime 0.437]
[epoch 136], [iter 54 / 176], [train main loss -2.116113], [lr 0.002229] [batchtime 0.436]
[epoch 136], [iter 55 / 176], [train main loss -2.120273], [lr 0.002229] [batchtime 0.435]
[epoch 136], [iter 56 / 176], [train main loss -2.161729], [lr 0.002229] [batchtime 0.434]
[epoch 136], [iter 57 / 176], [train main loss -2.155352], [lr 0.002229] [batchtime 0.433]
[epoch 136], [iter 58 / 176], [train main loss -2.176284], [lr 0.002229] [batchtime 0.432]
[epoch 136], [iter 59 / 176], [train main loss -2.163699], [lr 0.002229] [batchtime 0.431]
[epoch 136], [iter 60 / 176], [train main loss -2.165144], [lr 0.002229] [batchtime 0.43]
[epoch 136], [iter 61 / 176], [train main loss -2.201246], [lr 0.002229] [batchtime 0.43]
[epoch 136], [iter 62 / 176], [train main loss -2.201303], [lr 0.002229] [batchtime 0.429]
[epoch 136], [iter 63 / 176], [train main loss -2.189265], [lr 0.002229] [batchtime 0.428]
[epoch 136], [iter 64 / 176], [train main loss -2.152087], [lr 0.002229] [batchtime 0.428]
[epoch 136], [iter 65 / 176], [train main loss -2.190597], [lr 0.002229] [batchtime 0.427]
[epoch 136], [iter 66 / 176], [train main loss -2.190945], [lr 0.002229] [batchtime 0.426]
[epoch 136], [iter 67 / 176], [train main loss -2.217672], [lr 0.002229] [batchtime 0.426]
[epoch 136], [iter 68 / 176], [train main loss -2.213213], [lr 0.002229] [batchtime 0.426]
[epoch 136], [iter 69 / 176], [train main loss -2.197761], [lr 0.002229] [batchtime 0.425]
[epoch 136], [iter 70 / 176], [train main loss -2.173068], [lr 0.002229] [batchtime 0.425]
[epoch 136], [iter 71 / 176], [train main loss -2.207503], [lr 0.002229] [batchtime 0.428]
[epoch 136], [iter 72 / 176], [train main loss -2.209644], [lr 0.002229] [batchtime 0.427]
[epoch 136], [iter 73 / 176], [train main loss -2.202892], [lr 0.002229] [batchtime 0.426]
[epoch 136], [iter 74 / 176], [train main loss -2.212918], [lr 0.002229] [batchtime 0.426]
[epoch 136], [iter 75 / 176], [train main loss -2.193820], [lr 0.002229] [batchtime 0.425]
[epoch 136], [iter 76 / 176], [train main loss -2.178744], [lr 0.002229] [batchtime 0.425]
[epoch 136], [iter 77 / 176], [train main loss -2.204703], [lr 0.002229] [batchtime 0.424]
[epoch 136], [iter 78 / 176], [train main loss -2.195536], [lr 0.002229] [batchtime 0.424]
[epoch 136], [iter 79 / 176], [train main loss -2.207061], [lr 0.002229] [batchtime 0.424]
[epoch 136], [iter 80 / 176], [train main loss -2.209232], [lr 0.002229] [batchtime 0.423]
[epoch 136], [iter 81 / 176], [train main loss -2.206729], [lr 0.002229] [batchtime 0.423]
[epoch 136], [iter 82 / 176], [train main loss -2.220628], [lr 0.002229] [batchtime 0.423]
[epoch 136], [iter 83 / 176], [train main loss -2.186746], [lr 0.002229] [batchtime 0.422]
[epoch 136], [iter 84 / 176], [train main loss -2.188721], [lr 0.002229] [batchtime 0.422]
[epoch 136], [iter 85 / 176], [train main loss -2.190541], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 86 / 176], [train main loss -2.200080], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 87 / 176], [train main loss -2.185354], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 88 / 176], [train main loss -2.208332], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 89 / 176], [train main loss -2.218544], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 90 / 176], [train main loss -2.227151], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 91 / 176], [train main loss -2.193449], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 92 / 176], [train main loss -2.153094], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 93 / 176], [train main loss -2.137945], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 94 / 176], [train main loss -2.141699], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 95 / 176], [train main loss -2.142387], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 96 / 176], [train main loss -2.116271], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 97 / 176], [train main loss -2.086328], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 98 / 176], [train main loss -2.054042], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 99 / 176], [train main loss -2.053883], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 100 / 176], [train main loss -2.031229], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 101 / 176], [train main loss -2.038746], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 102 / 176], [train main loss -2.063603], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 103 / 176], [train main loss -2.064464], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 104 / 176], [train main loss -2.089455], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 105 / 176], [train main loss -2.086493], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 106 / 176], [train main loss -2.071987], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 107 / 176], [train main loss -2.084994], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 108 / 176], [train main loss -2.072538], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 109 / 176], [train main loss -2.063819], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 110 / 176], [train main loss -2.064811], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 111 / 176], [train main loss -2.048802], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 112 / 176], [train main loss -2.063775], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 113 / 176], [train main loss -2.056621], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 114 / 176], [train main loss -2.069704], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 115 / 176], [train main loss -2.066623], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 116 / 176], [train main loss -2.092486], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 117 / 176], [train main loss -2.087996], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 118 / 176], [train main loss -2.093840], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 119 / 176], [train main loss -2.102224], [lr 0.002229] [batchtime 0.413]
[epoch 136], [iter 120 / 176], [train main loss -2.100988], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 121 / 176], [train main loss -2.091104], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 122 / 176], [train main loss -2.103796], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 123 / 176], [train main loss -2.113326], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 124 / 176], [train main loss -2.117451], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 125 / 176], [train main loss -2.116475], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 126 / 176], [train main loss -2.126411], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 127 / 176], [train main loss -2.122405], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 128 / 176], [train main loss -2.126251], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 129 / 176], [train main loss -2.131604], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 130 / 176], [train main loss -2.133206], [lr 0.002229] [batchtime 0.417]
[epoch 136], [iter 131 / 176], [train main loss -2.136129], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 132 / 176], [train main loss -2.132203], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 133 / 176], [train main loss -2.114039], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 134 / 176], [train main loss -2.112506], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 135 / 176], [train main loss -2.124504], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 136 / 176], [train main loss -2.127487], [lr 0.002229] [batchtime 0.416]
[epoch 136], [iter 137 / 176], [train main loss -2.152525], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 138 / 176], [train main loss -2.145984], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 139 / 176], [train main loss -2.174820], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 140 / 176], [train main loss -2.176164], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 141 / 176], [train main loss -2.186296], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 142 / 176], [train main loss -2.190933], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 143 / 176], [train main loss -2.219231], [lr 0.002229] [batchtime 0.414]
[epoch 136], [iter 144 / 176], [train main loss -2.203075], [lr 0.002229] [batchtime 0.415]
[epoch 136], [iter 145 / 176], [train main loss -2.185554], [lr 0.002229] [batchtime 0.422]
[epoch 136], [iter 146 / 176], [train main loss -2.189202], [lr 0.002229] [batchtime 0.422]
[epoch 136], [iter 147 / 176], [train main loss -2.205244], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 148 / 176], [train main loss -2.215298], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 149 / 176], [train main loss -2.210643], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 150 / 176], [train main loss -2.196397], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 151 / 176], [train main loss -2.171975], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 152 / 176], [train main loss -2.171492], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 153 / 176], [train main loss -2.181496], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 154 / 176], [train main loss -2.181519], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 155 / 176], [train main loss -2.169141], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 156 / 176], [train main loss -2.177765], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 157 / 176], [train main loss -2.171947], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 158 / 176], [train main loss -2.167089], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 159 / 176], [train main loss -2.158521], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 160 / 176], [train main loss -2.148055], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 161 / 176], [train main loss -2.138478], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 162 / 176], [train main loss -2.140865], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 163 / 176], [train main loss -2.155277], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 164 / 176], [train main loss -2.154786], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 165 / 176], [train main loss -2.154794], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 166 / 176], [train main loss -2.148428], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 167 / 176], [train main loss -2.138184], [lr 0.002229] [batchtime 0.418]
[epoch 136], [iter 168 / 176], [train main loss -2.129186], [lr 0.002229] [batchtime 0.421]
[epoch 136], [iter 169 / 176], [train main loss -2.144153], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 170 / 176], [train main loss -2.137312], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 171 / 176], [train main loss -2.120411], [lr 0.002229] [batchtime 0.42]
[epoch 136], [iter 172 / 176], [train main loss -2.125341], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 173 / 176], [train main loss -2.117170], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 174 / 176], [train main loss -2.111471], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 175 / 176], [train main loss -2.096930], [lr 0.002229] [batchtime 0.419]
[epoch 136], [iter 176 / 176], [train main loss -2.078433], [lr 0.002229] [batchtime 0.418]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.00  35.53   0.02  0.03         0.98      0.97
   1  sidewalk          71.12   5.43   0.21  0.19         0.82      0.84
   2  building          86.71  25.07   0.06  0.09         0.94      0.92
   3  wall              17.34   0.13   3.40  1.37         0.23      0.42
   4  fence             25.42   0.38   2.33  0.60         0.30      0.62
   5  pole              39.95   0.57   1.00  0.50         0.50      0.67
   6  traffic light     16.63   0.03   4.65  0.36         0.18      0.73
   7  traffic sign      27.09   0.16   2.44  0.26         0.29      0.80
   8  vegetation        83.71  11.71   0.06  0.14         0.95      0.88
   9  terrain           41.33   0.40   0.86  0.56         0.54      0.64
  10  sky               93.72   3.76   0.03  0.04         0.97      0.97
  11  person            53.58   1.00   0.54  0.33         0.65      0.75
  12  rider             13.06   0.01   5.59  1.07         0.15      0.48
  13  car               86.58   6.71   0.05  0.10         0.95      0.91
  14  truck              1.07   0.00  91.83  0.64         0.01      0.61
  15  bus               13.98   0.04   0.97  5.19         0.51      0.16
  16  train             23.85   0.06   2.10  1.09         0.32      0.48
  17  motorcycle         3.81   0.00  24.62  0.60         0.04      0.62
  18  bicycle           39.22   0.27   0.44  1.11         0.69      0.47
Mean: 43.85
-----------------------------------------------------------------------------------------------------------
this : [epoch 136], [val loss 0.29368], [acc 0.91252], [acc_cls 0.52727], [mean_iu 0.43851], [fwavacc 0.84790]
best : [epoch 125], [val loss 0.31180], [acc 0.91078], [acc_cls 0.53686], [mean_iu 0.44875], [fwavacc 0.84496]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 137], [iter 1 / 176], [train main loss -1.171654], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 2 / 176], [train main loss -0.672182], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 3 / 176], [train main loss -1.797520], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 4 / 176], [train main loss -1.968262], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 5 / 176], [train main loss -2.173950], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 6 / 176], [train main loss -2.333555], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 7 / 176], [train main loss -2.430976], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 8 / 176], [train main loss -2.386747], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 9 / 176], [train main loss -2.273885], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 10 / 176], [train main loss -2.251920], [lr 0.002171] [batchtime 0]
[epoch 137], [iter 11 / 176], [train main loss -2.435907], [lr 0.002171] [batchtime 0.375]
[epoch 137], [iter 12 / 176], [train main loss -2.234470], [lr 0.002171] [batchtime 0.383]
[epoch 137], [iter 13 / 176], [train main loss -2.193144], [lr 0.002171] [batchtime 0.388]
[epoch 137], [iter 14 / 176], [train main loss -2.130845], [lr 0.002171] [batchtime 0.388]
[epoch 137], [iter 15 / 176], [train main loss -2.318059], [lr 0.002171] [batchtime 0.388]
[epoch 137], [iter 16 / 176], [train main loss -2.404023], [lr 0.002171] [batchtime 0.391]
[epoch 137], [iter 17 / 176], [train main loss -2.313298], [lr 0.002171] [batchtime 0.393]
[epoch 137], [iter 18 / 176], [train main loss -2.178572], [lr 0.002171] [batchtime 0.392]
[epoch 137], [iter 19 / 176], [train main loss -2.145555], [lr 0.002171] [batchtime 0.392]
[epoch 137], [iter 20 / 176], [train main loss -2.230641], [lr 0.002171] [batchtime 0.393]
[epoch 137], [iter 21 / 176], [train main loss -2.242355], [lr 0.002171] [batchtime 0.395]
[epoch 137], [iter 22 / 176], [train main loss -2.092297], [lr 0.002171] [batchtime 0.394]
[epoch 137], [iter 23 / 176], [train main loss -2.139835], [lr 0.002171] [batchtime 0.395]
[epoch 137], [iter 24 / 176], [train main loss -2.188207], [lr 0.002171] [batchtime 0.409]
[epoch 137], [iter 25 / 176], [train main loss -2.194818], [lr 0.002171] [batchtime 0.419]
[epoch 137], [iter 26 / 176], [train main loss -2.170217], [lr 0.002171] [batchtime 0.417]
[epoch 137], [iter 27 / 176], [train main loss -2.184961], [lr 0.002171] [batchtime 0.415]
[epoch 137], [iter 28 / 176], [train main loss -2.205965], [lr 0.002171] [batchtime 0.414]
[epoch 137], [iter 29 / 176], [train main loss -2.164631], [lr 0.002171] [batchtime 0.413]
[epoch 137], [iter 30 / 176], [train main loss -2.232845], [lr 0.002171] [batchtime 0.412]
[epoch 137], [iter 31 / 176], [train main loss -2.260942], [lr 0.002171] [batchtime 0.411]
[epoch 137], [iter 32 / 176], [train main loss -2.222014], [lr 0.002171] [batchtime 0.411]
[epoch 137], [iter 33 / 176], [train main loss -2.272350], [lr 0.002171] [batchtime 0.41]
[epoch 137], [iter 34 / 176], [train main loss -2.317749], [lr 0.002171] [batchtime 0.409]
[epoch 137], [iter 35 / 176], [train main loss -2.369806], [lr 0.002171] [batchtime 0.409]
[epoch 137], [iter 36 / 176], [train main loss -2.304188], [lr 0.002171] [batchtime 0.409]
[epoch 137], [iter 37 / 176], [train main loss -2.230247], [lr 0.002171] [batchtime 0.408]
[epoch 137], [iter 38 / 176], [train main loss -2.205057], [lr 0.002171] [batchtime 0.407]
[epoch 137], [iter 39 / 176], [train main loss -2.239379], [lr 0.002171] [batchtime 0.407]
[epoch 137], [iter 40 / 176], [train main loss -2.287025], [lr 0.002171] [batchtime 0.407]
[epoch 137], [iter 41 / 176], [train main loss -2.277023], [lr 0.002171] [batchtime 0.407]
[epoch 137], [iter 42 / 176], [train main loss -2.268670], [lr 0.002171] [batchtime 0.406]
[epoch 137], [iter 43 / 176], [train main loss -2.249695], [lr 0.002171] [batchtime 0.406]
[epoch 137], [iter 44 / 176], [train main loss -2.271131], [lr 0.002171] [batchtime 0.406]
[epoch 137], [iter 45 / 176], [train main loss -2.271481], [lr 0.002171] [batchtime 0.405]
[epoch 137], [iter 46 / 176], [train main loss -2.243943], [lr 0.002171] [batchtime 0.405]
[epoch 137], [iter 47 / 176], [train main loss -2.218395], [lr 0.002171] [batchtime 0.405]
[epoch 137], [iter 48 / 176], [train main loss -2.232810], [lr 0.002171] [batchtime 0.408]
[epoch 137], [iter 49 / 176], [train main loss -2.250516], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 50 / 176], [train main loss -2.239726], [lr 0.002171] [batchtime 0.439]
[epoch 137], [iter 51 / 176], [train main loss -2.208616], [lr 0.002171] [batchtime 0.438]
[epoch 137], [iter 52 / 176], [train main loss -2.203672], [lr 0.002171] [batchtime 0.437]
[epoch 137], [iter 53 / 176], [train main loss -2.183098], [lr 0.002171] [batchtime 0.436]
[epoch 137], [iter 54 / 176], [train main loss -2.180310], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 55 / 176], [train main loss -2.149076], [lr 0.002171] [batchtime 0.459]
[epoch 137], [iter 56 / 176], [train main loss -2.144554], [lr 0.002171] [batchtime 0.457]
[epoch 137], [iter 57 / 176], [train main loss -2.102549], [lr 0.002171] [batchtime 0.461]
[epoch 137], [iter 58 / 176], [train main loss -2.110682], [lr 0.002171] [batchtime 0.46]
[epoch 137], [iter 59 / 176], [train main loss -2.106142], [lr 0.002171] [batchtime 0.458]
[epoch 137], [iter 60 / 176], [train main loss -2.084473], [lr 0.002171] [batchtime 0.457]
[epoch 137], [iter 61 / 176], [train main loss -2.049981], [lr 0.002171] [batchtime 0.456]
[epoch 137], [iter 62 / 176], [train main loss -2.058628], [lr 0.002171] [batchtime 0.454]
[epoch 137], [iter 63 / 176], [train main loss -2.105358], [lr 0.002171] [batchtime 0.453]
[epoch 137], [iter 64 / 176], [train main loss -2.143870], [lr 0.002171] [batchtime 0.452]
[epoch 137], [iter 65 / 176], [train main loss -2.157908], [lr 0.002171] [batchtime 0.451]
[epoch 137], [iter 66 / 176], [train main loss -2.173179], [lr 0.002171] [batchtime 0.45]
[epoch 137], [iter 67 / 176], [train main loss -2.165834], [lr 0.002171] [batchtime 0.45]
[epoch 137], [iter 68 / 176], [train main loss -2.139370], [lr 0.002171] [batchtime 0.449]
[epoch 137], [iter 69 / 176], [train main loss -2.170489], [lr 0.002171] [batchtime 0.448]
[epoch 137], [iter 70 / 176], [train main loss -2.212438], [lr 0.002171] [batchtime 0.447]
[epoch 137], [iter 71 / 176], [train main loss -2.247438], [lr 0.002171] [batchtime 0.446]
[epoch 137], [iter 72 / 176], [train main loss -2.269907], [lr 0.002171] [batchtime 0.445]
[epoch 137], [iter 73 / 176], [train main loss -2.287092], [lr 0.002171] [batchtime 0.445]
[epoch 137], [iter 74 / 176], [train main loss -2.314607], [lr 0.002171] [batchtime 0.444]
[epoch 137], [iter 75 / 176], [train main loss -2.267327], [lr 0.002171] [batchtime 0.443]
[epoch 137], [iter 76 / 176], [train main loss -2.288765], [lr 0.002171] [batchtime 0.442]
[epoch 137], [iter 77 / 176], [train main loss -2.297758], [lr 0.002171] [batchtime 0.442]
[epoch 137], [iter 78 / 176], [train main loss -2.269223], [lr 0.002171] [batchtime 0.441]
[epoch 137], [iter 79 / 176], [train main loss -2.268831], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 80 / 176], [train main loss -2.255617], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 81 / 176], [train main loss -2.247061], [lr 0.002171] [batchtime 0.439]
[epoch 137], [iter 82 / 176], [train main loss -2.245202], [lr 0.002171] [batchtime 0.438]
[epoch 137], [iter 83 / 176], [train main loss -2.192655], [lr 0.002171] [batchtime 0.438]
[epoch 137], [iter 84 / 176], [train main loss -2.199368], [lr 0.002171] [batchtime 0.437]
[epoch 137], [iter 85 / 176], [train main loss -2.196208], [lr 0.002171] [batchtime 0.437]
[epoch 137], [iter 86 / 176], [train main loss -2.173989], [lr 0.002171] [batchtime 0.436]
[epoch 137], [iter 87 / 176], [train main loss -2.185749], [lr 0.002171] [batchtime 0.436]
[epoch 137], [iter 88 / 176], [train main loss -2.174261], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 89 / 176], [train main loss -2.190273], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 90 / 176], [train main loss -2.205900], [lr 0.002171] [batchtime 0.434]
[epoch 137], [iter 91 / 176], [train main loss -2.191699], [lr 0.002171] [batchtime 0.434]
[epoch 137], [iter 92 / 176], [train main loss -2.164111], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 93 / 176], [train main loss -2.157870], [lr 0.002171] [batchtime 0.442]
[epoch 137], [iter 94 / 176], [train main loss -2.157268], [lr 0.002171] [batchtime 0.441]
[epoch 137], [iter 95 / 176], [train main loss -2.115142], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 96 / 176], [train main loss -2.134727], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 97 / 176], [train main loss -2.132662], [lr 0.002171] [batchtime 0.439]
[epoch 137], [iter 98 / 176], [train main loss -2.146348], [lr 0.002171] [batchtime 0.439]
[epoch 137], [iter 99 / 176], [train main loss -2.153787], [lr 0.002171] [batchtime 0.442]
[epoch 137], [iter 100 / 176], [train main loss -2.151678], [lr 0.002171] [batchtime 0.441]
[epoch 137], [iter 101 / 176], [train main loss -2.168990], [lr 0.002171] [batchtime 0.441]
[epoch 137], [iter 102 / 176], [train main loss -2.161836], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 103 / 176], [train main loss -2.138915], [lr 0.002171] [batchtime 0.44]
[epoch 137], [iter 104 / 176], [train main loss -2.116114], [lr 0.002171] [batchtime 0.439]
[epoch 137], [iter 105 / 176], [train main loss -2.130621], [lr 0.002171] [batchtime 0.439]
[epoch 137], [iter 106 / 176], [train main loss -2.115620], [lr 0.002171] [batchtime 0.438]
[epoch 137], [iter 107 / 176], [train main loss -2.123525], [lr 0.002171] [batchtime 0.438]
[epoch 137], [iter 108 / 176], [train main loss -2.143309], [lr 0.002171] [batchtime 0.437]
[epoch 137], [iter 109 / 176], [train main loss -2.154973], [lr 0.002171] [batchtime 0.437]
[epoch 137], [iter 110 / 176], [train main loss -2.163669], [lr 0.002171] [batchtime 0.436]
[epoch 137], [iter 111 / 176], [train main loss -2.155080], [lr 0.002171] [batchtime 0.436]
[epoch 137], [iter 112 / 176], [train main loss -2.144356], [lr 0.002171] [batchtime 0.436]
[epoch 137], [iter 113 / 176], [train main loss -2.138138], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 114 / 176], [train main loss -2.129154], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 115 / 176], [train main loss -2.133325], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 116 / 176], [train main loss -2.127539], [lr 0.002171] [batchtime 0.435]
[epoch 137], [iter 117 / 176], [train main loss -2.131364], [lr 0.002171] [batchtime 0.434]
[epoch 137], [iter 118 / 176], [train main loss -2.146168], [lr 0.002171] [batchtime 0.434]
[epoch 137], [iter 119 / 176], [train main loss -2.154529], [lr 0.002171] [batchtime 0.434]
[epoch 137], [iter 120 / 176], [train main loss -2.151547], [lr 0.002171] [batchtime 0.433]
[epoch 137], [iter 121 / 176], [train main loss -2.128983], [lr 0.002171] [batchtime 0.433]
[epoch 137], [iter 122 / 176], [train main loss -2.123295], [lr 0.002171] [batchtime 0.433]
[epoch 137], [iter 123 / 176], [train main loss -2.119625], [lr 0.002171] [batchtime 0.432]
[epoch 137], [iter 124 / 176], [train main loss -2.143122], [lr 0.002171] [batchtime 0.432]
[epoch 137], [iter 125 / 176], [train main loss -2.131507], [lr 0.002171] [batchtime 0.432]
[epoch 137], [iter 126 / 176], [train main loss -2.119977], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 127 / 176], [train main loss -2.118855], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 128 / 176], [train main loss -2.146584], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 129 / 176], [train main loss -2.146426], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 130 / 176], [train main loss -2.148683], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 131 / 176], [train main loss -2.167344], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 132 / 176], [train main loss -2.166795], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 133 / 176], [train main loss -2.157913], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 134 / 176], [train main loss -2.169157], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 135 / 176], [train main loss -2.168643], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 136 / 176], [train main loss -2.146062], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 137 / 176], [train main loss -2.145181], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 138 / 176], [train main loss -2.149117], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 139 / 176], [train main loss -2.166139], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 140 / 176], [train main loss -2.168498], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 141 / 176], [train main loss -2.154884], [lr 0.002171] [batchtime 0.432]
[epoch 137], [iter 142 / 176], [train main loss -2.174068], [lr 0.002171] [batchtime 0.432]
[epoch 137], [iter 143 / 176], [train main loss -2.190219], [lr 0.002171] [batchtime 0.432]
[epoch 137], [iter 144 / 176], [train main loss -2.190917], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 145 / 176], [train main loss -2.183408], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 146 / 176], [train main loss -2.186052], [lr 0.002171] [batchtime 0.431]
[epoch 137], [iter 147 / 176], [train main loss -2.177734], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 148 / 176], [train main loss -2.168399], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 149 / 176], [train main loss -2.159151], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 150 / 176], [train main loss -2.155613], [lr 0.002171] [batchtime 0.43]
[epoch 137], [iter 151 / 176], [train main loss -2.155720], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 152 / 176], [train main loss -2.161631], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 153 / 176], [train main loss -2.164548], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 154 / 176], [train main loss -2.162845], [lr 0.002171] [batchtime 0.429]
[epoch 137], [iter 155 / 176], [train main loss -2.153119], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 156 / 176], [train main loss -2.162746], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 157 / 176], [train main loss -2.137800], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 158 / 176], [train main loss -2.137433], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 159 / 176], [train main loss -2.133611], [lr 0.002171] [batchtime 0.428]
[epoch 137], [iter 160 / 176], [train main loss -2.147822], [lr 0.002171] [batchtime 0.427]
[epoch 137], [iter 161 / 176], [train main loss -2.136365], [lr 0.002171] [batchtime 0.427]
[epoch 137], [iter 162 / 176], [train main loss -2.126025], [lr 0.002171] [batchtime 0.427]
[epoch 137], [iter 163 / 176], [train main loss -2.135916], [lr 0.002171] [batchtime 0.427]
[epoch 137], [iter 164 / 176], [train main loss -2.134489], [lr 0.002171] [batchtime 0.427]
[epoch 137], [iter 165 / 176], [train main loss -2.144213], [lr 0.002171] [batchtime 0.427]
[epoch 137], [iter 166 / 176], [train main loss -2.133695], [lr 0.002171] [batchtime 0.426]
[epoch 137], [iter 167 / 176], [train main loss -2.144067], [lr 0.002171] [batchtime 0.426]
[epoch 137], [iter 168 / 176], [train main loss -2.138550], [lr 0.002171] [batchtime 0.426]
[epoch 137], [iter 169 / 176], [train main loss -2.132819], [lr 0.002171] [batchtime 0.426]
[epoch 137], [iter 170 / 176], [train main loss -2.126825], [lr 0.002171] [batchtime 0.426]
[epoch 137], [iter 171 / 176], [train main loss -2.133487], [lr 0.002171] [batchtime 0.425]
[epoch 137], [iter 172 / 176], [train main loss -2.139051], [lr 0.002171] [batchtime 0.425]
[epoch 137], [iter 173 / 176], [train main loss -2.148989], [lr 0.002171] [batchtime 0.425]
[epoch 137], [iter 174 / 176], [train main loss -2.151626], [lr 0.002171] [batchtime 0.424]
[epoch 137], [iter 175 / 176], [train main loss -2.148226], [lr 0.002171] [batchtime 0.424]
[epoch 137], [iter 176 / 176], [train main loss -2.171169], [lr 0.002171] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.76  35.26   0.03  0.02         0.97      0.98
   1  sidewalk          70.87   5.57   0.18  0.23         0.85      0.81
   2  building          86.69  25.06   0.06  0.09         0.94      0.91
   3  wall              19.10   0.16   2.70  1.54         0.27      0.39
   4  fence             26.28   0.40   2.16  0.65         0.32      0.61
   5  pole              39.48   0.57   1.00  0.53         0.50      0.65
   6  traffic light     18.62   0.03   3.86  0.51         0.21      0.66
   7  traffic sign      26.55   0.16   2.52  0.25         0.28      0.80
   8  vegetation        83.80  11.70   0.06  0.14         0.95      0.88
   9  terrain           41.16   0.39   0.88  0.55         0.53      0.64
  10  sky               93.66   3.77   0.03  0.04         0.97      0.96
  11  person            53.10   0.97   0.59  0.30         0.63      0.77
  12  rider             15.47   0.02   4.46  1.00         0.18      0.50
  13  car               86.29   6.72   0.05  0.11         0.95      0.90
  14  truck              1.43   0.00  68.61  0.28         0.01      0.78
  15  bus               15.87   0.04   1.21  4.10         0.45      0.20
  16  train             36.11   0.08   1.27  0.50         0.44      0.67
  17  motorcycle         4.98   0.01  18.46  0.63         0.05      0.62
  18  bicycle           39.08   0.27   0.44  1.12         0.69      0.47
Mean: 44.91
-----------------------------------------------------------------------------------------------------------
this : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
best : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 138], [iter 1 / 176], [train main loss 0.232422], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 2 / 176], [train main loss -1.083814], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 3 / 176], [train main loss -0.810955], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 4 / 176], [train main loss -1.641183], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 5 / 176], [train main loss -1.053170], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 6 / 176], [train main loss -1.052736], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 7 / 176], [train main loss -1.239809], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 8 / 176], [train main loss -0.902670], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 9 / 176], [train main loss -1.004224], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 10 / 176], [train main loss -1.262643], [lr 0.002114] [batchtime 0]
[epoch 138], [iter 11 / 176], [train main loss -1.368535], [lr 0.002114] [batchtime 0.358]
[epoch 138], [iter 12 / 176], [train main loss -1.306869], [lr 0.002114] [batchtime 0.372]
[epoch 138], [iter 13 / 176], [train main loss -1.464689], [lr 0.002114] [batchtime 0.38]
[epoch 138], [iter 14 / 176], [train main loss -1.410596], [lr 0.002114] [batchtime 0.386]
[epoch 138], [iter 15 / 176], [train main loss -1.617717], [lr 0.002114] [batchtime 0.412]
[epoch 138], [iter 16 / 176], [train main loss -1.521537], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 17 / 176], [train main loss -1.631822], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 18 / 176], [train main loss -1.794563], [lr 0.002114] [batchtime 0.411]
[epoch 138], [iter 19 / 176], [train main loss -2.000243], [lr 0.002114] [batchtime 0.409]
[epoch 138], [iter 20 / 176], [train main loss -2.174617], [lr 0.002114] [batchtime 0.407]
[epoch 138], [iter 21 / 176], [train main loss -2.253359], [lr 0.002114] [batchtime 0.406]
[epoch 138], [iter 22 / 176], [train main loss -2.182565], [lr 0.002114] [batchtime 0.405]
[epoch 138], [iter 23 / 176], [train main loss -2.153792], [lr 0.002114] [batchtime 0.404]
[epoch 138], [iter 24 / 176], [train main loss -2.151075], [lr 0.002114] [batchtime 0.404]
[epoch 138], [iter 25 / 176], [train main loss -2.185768], [lr 0.002114] [batchtime 0.403]
[epoch 138], [iter 26 / 176], [train main loss -2.102249], [lr 0.002114] [batchtime 0.403]
[epoch 138], [iter 27 / 176], [train main loss -2.197551], [lr 0.002114] [batchtime 0.403]
[epoch 138], [iter 28 / 176], [train main loss -2.200035], [lr 0.002114] [batchtime 0.402]
[epoch 138], [iter 29 / 176], [train main loss -2.101235], [lr 0.002114] [batchtime 0.402]
[epoch 138], [iter 30 / 176], [train main loss -2.100209], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 31 / 176], [train main loss -2.069976], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 32 / 176], [train main loss -2.120692], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 33 / 176], [train main loss -2.158311], [lr 0.002114] [batchtime 0.402]
[epoch 138], [iter 34 / 176], [train main loss -2.152346], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 35 / 176], [train main loss -2.117914], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 36 / 176], [train main loss -2.088751], [lr 0.002114] [batchtime 0.402]
[epoch 138], [iter 37 / 176], [train main loss -2.070482], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 38 / 176], [train main loss -2.041992], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 39 / 176], [train main loss -2.035841], [lr 0.002114] [batchtime 0.401]
[epoch 138], [iter 40 / 176], [train main loss -2.012696], [lr 0.002114] [batchtime 0.415]
[epoch 138], [iter 41 / 176], [train main loss -1.894570], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 42 / 176], [train main loss -1.981366], [lr 0.002114] [batchtime 0.417]
[epoch 138], [iter 43 / 176], [train main loss -2.069370], [lr 0.002114] [batchtime 0.417]
[epoch 138], [iter 44 / 176], [train main loss -2.087763], [lr 0.002114] [batchtime 0.416]
[epoch 138], [iter 45 / 176], [train main loss -2.083824], [lr 0.002114] [batchtime 0.416]
[epoch 138], [iter 46 / 176], [train main loss -2.051648], [lr 0.002114] [batchtime 0.416]
[epoch 138], [iter 47 / 176], [train main loss -2.077808], [lr 0.002114] [batchtime 0.415]
[epoch 138], [iter 48 / 176], [train main loss -2.035044], [lr 0.002114] [batchtime 0.415]
[epoch 138], [iter 49 / 176], [train main loss -2.047791], [lr 0.002114] [batchtime 0.415]
[epoch 138], [iter 50 / 176], [train main loss -2.024649], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 51 / 176], [train main loss -2.008114], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 52 / 176], [train main loss -1.978465], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 53 / 176], [train main loss -1.986619], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 54 / 176], [train main loss -1.966947], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 55 / 176], [train main loss -1.940035], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 56 / 176], [train main loss -1.912939], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 57 / 176], [train main loss -1.885224], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 58 / 176], [train main loss -1.869367], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 59 / 176], [train main loss -1.891031], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 60 / 176], [train main loss -1.858576], [lr 0.002114] [batchtime 0.412]
[epoch 138], [iter 61 / 176], [train main loss -1.872564], [lr 0.002114] [batchtime 0.412]
[epoch 138], [iter 62 / 176], [train main loss -1.877724], [lr 0.002114] [batchtime 0.412]
[epoch 138], [iter 63 / 176], [train main loss -1.894804], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 64 / 176], [train main loss -1.939501], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 65 / 176], [train main loss -1.960637], [lr 0.002114] [batchtime 0.413]
[epoch 138], [iter 66 / 176], [train main loss -1.967880], [lr 0.002114] [batchtime 0.412]
[epoch 138], [iter 67 / 176], [train main loss -1.965190], [lr 0.002114] [batchtime 0.412]
[epoch 138], [iter 68 / 176], [train main loss -1.944802], [lr 0.002114] [batchtime 0.414]
[epoch 138], [iter 69 / 176], [train main loss -1.955867], [lr 0.002114] [batchtime 0.43]
[epoch 138], [iter 70 / 176], [train main loss -1.966185], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 71 / 176], [train main loss -1.961120], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 72 / 176], [train main loss -1.975596], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 73 / 176], [train main loss -1.966806], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 74 / 176], [train main loss -1.957090], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 75 / 176], [train main loss -1.959390], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 76 / 176], [train main loss -2.001617], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 77 / 176], [train main loss -2.011065], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 78 / 176], [train main loss -1.980455], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 79 / 176], [train main loss -1.964810], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 80 / 176], [train main loss -1.968696], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 81 / 176], [train main loss -1.966275], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 82 / 176], [train main loss -1.959331], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 83 / 176], [train main loss -1.980234], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 84 / 176], [train main loss -1.976481], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 85 / 176], [train main loss -1.960716], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 86 / 176], [train main loss -1.969408], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 87 / 176], [train main loss -1.965373], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 88 / 176], [train main loss -1.971139], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 89 / 176], [train main loss -1.979713], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 90 / 176], [train main loss -1.972757], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 91 / 176], [train main loss -1.987663], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 92 / 176], [train main loss -1.963643], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 93 / 176], [train main loss -1.990986], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 94 / 176], [train main loss -2.008823], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 95 / 176], [train main loss -1.986254], [lr 0.002114] [batchtime 0.42]
[epoch 138], [iter 96 / 176], [train main loss -1.999370], [lr 0.002114] [batchtime 0.42]
[epoch 138], [iter 97 / 176], [train main loss -1.987846], [lr 0.002114] [batchtime 0.42]
[epoch 138], [iter 98 / 176], [train main loss -1.978901], [lr 0.002114] [batchtime 0.419]
[epoch 138], [iter 99 / 176], [train main loss -1.978128], [lr 0.002114] [batchtime 0.419]
[epoch 138], [iter 100 / 176], [train main loss -1.978671], [lr 0.002114] [batchtime 0.419]
[epoch 138], [iter 101 / 176], [train main loss -1.993717], [lr 0.002114] [batchtime 0.419]
[epoch 138], [iter 102 / 176], [train main loss -2.004273], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 103 / 176], [train main loss -1.999959], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 104 / 176], [train main loss -2.027315], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 105 / 176], [train main loss -2.032557], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 106 / 176], [train main loss -2.049570], [lr 0.002114] [batchtime 0.418]
[epoch 138], [iter 107 / 176], [train main loss -2.064184], [lr 0.002114] [batchtime 0.417]
[epoch 138], [iter 108 / 176], [train main loss -2.048930], [lr 0.002114] [batchtime 0.417]
[epoch 138], [iter 109 / 176], [train main loss -2.055022], [lr 0.002114] [batchtime 0.417]
[epoch 138], [iter 110 / 176], [train main loss -2.058285], [lr 0.002114] [batchtime 0.417]
[epoch 138], [iter 111 / 176], [train main loss -2.073704], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 112 / 176], [train main loss -2.065908], [lr 0.002114] [batchtime 0.43]
[epoch 138], [iter 113 / 176], [train main loss -2.078709], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 114 / 176], [train main loss -2.076594], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 115 / 176], [train main loss -2.086621], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 116 / 176], [train main loss -2.095975], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 117 / 176], [train main loss -2.119291], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 118 / 176], [train main loss -2.104722], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 119 / 176], [train main loss -2.103442], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 120 / 176], [train main loss -2.087925], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 121 / 176], [train main loss -2.095135], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 122 / 176], [train main loss -2.107240], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 123 / 176], [train main loss -2.116089], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 124 / 176], [train main loss -2.105435], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 125 / 176], [train main loss -2.090318], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 126 / 176], [train main loss -2.077484], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 127 / 176], [train main loss -2.073953], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 128 / 176], [train main loss -2.082434], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 129 / 176], [train main loss -2.060755], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 130 / 176], [train main loss -2.065638], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 131 / 176], [train main loss -2.069624], [lr 0.002114] [batchtime 0.425]
[epoch 138], [iter 132 / 176], [train main loss -2.075938], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 133 / 176], [train main loss -2.070768], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 134 / 176], [train main loss -2.067934], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 135 / 176], [train main loss -2.081280], [lr 0.002114] [batchtime 0.424]
[epoch 138], [iter 136 / 176], [train main loss -2.076266], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 137 / 176], [train main loss -2.087989], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 138 / 176], [train main loss -2.070710], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 139 / 176], [train main loss -2.060327], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 140 / 176], [train main loss -2.077118], [lr 0.002114] [batchtime 0.423]
[epoch 138], [iter 141 / 176], [train main loss -2.076171], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 142 / 176], [train main loss -2.075295], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 143 / 176], [train main loss -2.094249], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 144 / 176], [train main loss -2.090792], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 145 / 176], [train main loss -2.086006], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 146 / 176], [train main loss -2.071783], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 147 / 176], [train main loss -2.073690], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 148 / 176], [train main loss -2.066655], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 149 / 176], [train main loss -2.066243], [lr 0.002114] [batchtime 0.422]
[epoch 138], [iter 150 / 176], [train main loss -2.045257], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 151 / 176], [train main loss -2.038361], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 152 / 176], [train main loss -2.031081], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 153 / 176], [train main loss -2.033205], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 154 / 176], [train main loss -2.017907], [lr 0.002114] [batchtime 0.421]
[epoch 138], [iter 155 / 176], [train main loss -2.007788], [lr 0.002114] [batchtime 0.42]
[epoch 138], [iter 156 / 176], [train main loss -2.017485], [lr 0.002114] [batchtime 0.42]
[epoch 138], [iter 157 / 176], [train main loss -2.021442], [lr 0.002114] [batchtime 0.42]
[epoch 138], [iter 158 / 176], [train main loss -2.009976], [lr 0.002114] [batchtime 0.43]
[epoch 138], [iter 159 / 176], [train main loss -2.022166], [lr 0.002114] [batchtime 0.43]
[epoch 138], [iter 160 / 176], [train main loss -2.013464], [lr 0.002114] [batchtime 0.43]
[epoch 138], [iter 161 / 176], [train main loss -2.014044], [lr 0.002114] [batchtime 0.43]
[epoch 138], [iter 162 / 176], [train main loss -2.033987], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 163 / 176], [train main loss -2.019426], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 164 / 176], [train main loss -2.029949], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 165 / 176], [train main loss -2.027331], [lr 0.002114] [batchtime 0.429]
[epoch 138], [iter 166 / 176], [train main loss -2.021393], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 167 / 176], [train main loss -2.027643], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 168 / 176], [train main loss -2.014332], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 169 / 176], [train main loss -2.027422], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 170 / 176], [train main loss -2.020222], [lr 0.002114] [batchtime 0.428]
[epoch 138], [iter 171 / 176], [train main loss -2.007541], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 172 / 176], [train main loss -2.002910], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 173 / 176], [train main loss -2.001148], [lr 0.002114] [batchtime 0.427]
[epoch 138], [iter 174 / 176], [train main loss -1.994456], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 175 / 176], [train main loss -1.996681], [lr 0.002114] [batchtime 0.426]
[epoch 138], [iter 176 / 176], [train main loss -1.995900], [lr 0.002114] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.50  35.39   0.03  0.03         0.97      0.97
   1  sidewalk          69.33   5.38   0.22  0.22         0.82      0.82
   2  building          86.82  25.14   0.06  0.09         0.95      0.91
   3  wall              17.81   0.14   3.16  1.46         0.24      0.41
   4  fence             24.51   0.36   2.51  0.57         0.28      0.64
   5  pole              39.18   0.56   1.04  0.51         0.49      0.66
   6  traffic light     17.53   0.03   4.28  0.42         0.19      0.70
   7  traffic sign      26.49   0.16   2.55  0.23         0.28      0.81
   8  vegetation        84.05  11.62   0.06  0.13         0.94      0.89
   9  terrain           39.70   0.37   0.98  0.54         0.51      0.65
  10  sky               93.92   3.75   0.03  0.03         0.97      0.97
  11  person            55.11   1.09   0.40  0.41         0.71      0.71
  12  rider             12.11   0.01   6.28  0.98         0.14      0.51
  13  car               86.19   6.72   0.05  0.11         0.95      0.90
  14  truck              2.64   0.01  36.28  0.60         0.03      0.63
  15  bus               14.49   0.05   0.82  5.08         0.55      0.16
  16  train             23.09   0.05   2.49  0.84         0.29      0.54
  17  motorcycle         5.30   0.01  17.23  0.64         0.05      0.61
  18  bicycle           40.00   0.26   0.50  1.00         0.67      0.50
Mean: 43.83
-----------------------------------------------------------------------------------------------------------
this : [epoch 138], [val loss 0.30099], [acc 0.91097], [acc_cls 0.52743], [mean_iu 0.43830], [fwavacc 0.84541]
best : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 139], [iter 1 / 176], [train main loss -2.728599], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 2 / 176], [train main loss -2.902969], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 3 / 176], [train main loss -3.642597], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 4 / 176], [train main loss -3.154185], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 5 / 176], [train main loss -2.955213], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 6 / 176], [train main loss -2.662346], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 7 / 176], [train main loss -2.734832], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 8 / 176], [train main loss -2.605631], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 9 / 176], [train main loss -2.488227], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 10 / 176], [train main loss -2.516374], [lr 0.002057] [batchtime 0]
[epoch 139], [iter 11 / 176], [train main loss -2.499498], [lr 0.002057] [batchtime 0.991]
[epoch 139], [iter 12 / 176], [train main loss -2.360630], [lr 0.002057] [batchtime 0.689]
[epoch 139], [iter 13 / 176], [train main loss -2.254707], [lr 0.002057] [batchtime 0.59]
[epoch 139], [iter 14 / 176], [train main loss -2.285459], [lr 0.002057] [batchtime 0.54]
[epoch 139], [iter 15 / 176], [train main loss -2.171813], [lr 0.002057] [batchtime 0.512]
[epoch 139], [iter 16 / 176], [train main loss -1.952941], [lr 0.002057] [batchtime 0.492]
[epoch 139], [iter 17 / 176], [train main loss -1.935381], [lr 0.002057] [batchtime 0.479]
[epoch 139], [iter 18 / 176], [train main loss -1.837992], [lr 0.002057] [batchtime 0.469]
[epoch 139], [iter 19 / 176], [train main loss -1.721369], [lr 0.002057] [batchtime 0.461]
[epoch 139], [iter 20 / 176], [train main loss -1.730968], [lr 0.002057] [batchtime 0.455]
[epoch 139], [iter 21 / 176], [train main loss -1.907866], [lr 0.002057] [batchtime 0.449]
[epoch 139], [iter 22 / 176], [train main loss -1.933192], [lr 0.002057] [batchtime 0.445]
[epoch 139], [iter 23 / 176], [train main loss -1.942958], [lr 0.002057] [batchtime 0.441]
[epoch 139], [iter 24 / 176], [train main loss -1.912189], [lr 0.002057] [batchtime 0.438]
[epoch 139], [iter 25 / 176], [train main loss -2.009303], [lr 0.002057] [batchtime 0.436]
[epoch 139], [iter 26 / 176], [train main loss -2.036701], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 27 / 176], [train main loss -2.038901], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 28 / 176], [train main loss -2.108359], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 29 / 176], [train main loss -2.136411], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 30 / 176], [train main loss -1.988328], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 31 / 176], [train main loss -1.954785], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 32 / 176], [train main loss -1.943328], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 33 / 176], [train main loss -1.951284], [lr 0.002057] [batchtime 0.423]
[epoch 139], [iter 34 / 176], [train main loss -1.924299], [lr 0.002057] [batchtime 0.422]
[epoch 139], [iter 35 / 176], [train main loss -1.885934], [lr 0.002057] [batchtime 0.421]
[epoch 139], [iter 36 / 176], [train main loss -1.951157], [lr 0.002057] [batchtime 0.42]
[epoch 139], [iter 37 / 176], [train main loss -1.902665], [lr 0.002057] [batchtime 0.419]
[epoch 139], [iter 38 / 176], [train main loss -1.984199], [lr 0.002057] [batchtime 0.418]
[epoch 139], [iter 39 / 176], [train main loss -2.038439], [lr 0.002057] [batchtime 0.422]
[epoch 139], [iter 40 / 176], [train main loss -2.079176], [lr 0.002057] [batchtime 0.464]
[epoch 139], [iter 41 / 176], [train main loss -2.034433], [lr 0.002057] [batchtime 0.461]
[epoch 139], [iter 42 / 176], [train main loss -2.083914], [lr 0.002057] [batchtime 0.459]
[epoch 139], [iter 43 / 176], [train main loss -2.142809], [lr 0.002057] [batchtime 0.457]
[epoch 139], [iter 44 / 176], [train main loss -2.139352], [lr 0.002057] [batchtime 0.455]
[epoch 139], [iter 45 / 176], [train main loss -2.154899], [lr 0.002057] [batchtime 0.453]
[epoch 139], [iter 46 / 176], [train main loss -2.171398], [lr 0.002057] [batchtime 0.452]
[epoch 139], [iter 47 / 176], [train main loss -2.199121], [lr 0.002057] [batchtime 0.45]
[epoch 139], [iter 48 / 176], [train main loss -2.233395], [lr 0.002057] [batchtime 0.449]
[epoch 139], [iter 49 / 176], [train main loss -2.242012], [lr 0.002057] [batchtime 0.448]
[epoch 139], [iter 50 / 176], [train main loss -2.222660], [lr 0.002057] [batchtime 0.446]
[epoch 139], [iter 51 / 176], [train main loss -2.176827], [lr 0.002057] [batchtime 0.445]
[epoch 139], [iter 52 / 176], [train main loss -2.200172], [lr 0.002057] [batchtime 0.444]
[epoch 139], [iter 53 / 176], [train main loss -2.163280], [lr 0.002057] [batchtime 0.443]
[epoch 139], [iter 54 / 176], [train main loss -2.183086], [lr 0.002057] [batchtime 0.442]
[epoch 139], [iter 55 / 176], [train main loss -2.157628], [lr 0.002057] [batchtime 0.441]
[epoch 139], [iter 56 / 176], [train main loss -2.180849], [lr 0.002057] [batchtime 0.44]
[epoch 139], [iter 57 / 176], [train main loss -2.197070], [lr 0.002057] [batchtime 0.439]
[epoch 139], [iter 58 / 176], [train main loss -2.193101], [lr 0.002057] [batchtime 0.438]
[epoch 139], [iter 59 / 176], [train main loss -2.172381], [lr 0.002057] [batchtime 0.437]
[epoch 139], [iter 60 / 176], [train main loss -2.179769], [lr 0.002057] [batchtime 0.436]
[epoch 139], [iter 61 / 176], [train main loss -2.183833], [lr 0.002057] [batchtime 0.435]
[epoch 139], [iter 62 / 176], [train main loss -2.243863], [lr 0.002057] [batchtime 0.435]
[epoch 139], [iter 63 / 176], [train main loss -2.243833], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 64 / 176], [train main loss -2.263529], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 65 / 176], [train main loss -2.226926], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 66 / 176], [train main loss -2.220600], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 67 / 176], [train main loss -2.212379], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 68 / 176], [train main loss -2.216264], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 69 / 176], [train main loss -2.178727], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 70 / 176], [train main loss -2.165996], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 71 / 176], [train main loss -2.193841], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 72 / 176], [train main loss -2.184689], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 73 / 176], [train main loss -2.186800], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 74 / 176], [train main loss -2.232382], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 75 / 176], [train main loss -2.252456], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 76 / 176], [train main loss -2.260677], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 77 / 176], [train main loss -2.238269], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 78 / 176], [train main loss -2.256834], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 79 / 176], [train main loss -2.209407], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 80 / 176], [train main loss -2.206953], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 81 / 176], [train main loss -2.165398], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 82 / 176], [train main loss -2.166010], [lr 0.002057] [batchtime 0.423]
[epoch 139], [iter 83 / 176], [train main loss -2.191647], [lr 0.002057] [batchtime 0.423]
[epoch 139], [iter 84 / 176], [train main loss -2.180442], [lr 0.002057] [batchtime 0.422]
[epoch 139], [iter 85 / 176], [train main loss -2.169128], [lr 0.002057] [batchtime 0.422]
[epoch 139], [iter 86 / 176], [train main loss -2.138017], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 87 / 176], [train main loss -2.142430], [lr 0.002057] [batchtime 0.441]
[epoch 139], [iter 88 / 176], [train main loss -2.166460], [lr 0.002057] [batchtime 0.44]
[epoch 139], [iter 89 / 176], [train main loss -2.170112], [lr 0.002057] [batchtime 0.44]
[epoch 139], [iter 90 / 176], [train main loss -2.176837], [lr 0.002057] [batchtime 0.439]
[epoch 139], [iter 91 / 176], [train main loss -2.181297], [lr 0.002057] [batchtime 0.439]
[epoch 139], [iter 92 / 176], [train main loss -2.209815], [lr 0.002057] [batchtime 0.438]
[epoch 139], [iter 93 / 176], [train main loss -2.201371], [lr 0.002057] [batchtime 0.437]
[epoch 139], [iter 94 / 176], [train main loss -2.179808], [lr 0.002057] [batchtime 0.437]
[epoch 139], [iter 95 / 176], [train main loss -2.172634], [lr 0.002057] [batchtime 0.436]
[epoch 139], [iter 96 / 176], [train main loss -2.205108], [lr 0.002057] [batchtime 0.436]
[epoch 139], [iter 97 / 176], [train main loss -2.238290], [lr 0.002057] [batchtime 0.436]
[epoch 139], [iter 98 / 176], [train main loss -2.221596], [lr 0.002057] [batchtime 0.435]
[epoch 139], [iter 99 / 176], [train main loss -2.205326], [lr 0.002057] [batchtime 0.435]
[epoch 139], [iter 100 / 176], [train main loss -2.204762], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 101 / 176], [train main loss -2.213752], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 102 / 176], [train main loss -2.225096], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 103 / 176], [train main loss -2.241343], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 104 / 176], [train main loss -2.229943], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 105 / 176], [train main loss -2.186257], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 106 / 176], [train main loss -2.207479], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 107 / 176], [train main loss -2.202946], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 108 / 176], [train main loss -2.195555], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 109 / 176], [train main loss -2.187221], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 110 / 176], [train main loss -2.181130], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 111 / 176], [train main loss -2.173589], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 112 / 176], [train main loss -2.166036], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 113 / 176], [train main loss -2.158419], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 114 / 176], [train main loss -2.183263], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 115 / 176], [train main loss -2.175994], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 116 / 176], [train main loss -2.160775], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 117 / 176], [train main loss -2.154233], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 118 / 176], [train main loss -2.152109], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 119 / 176], [train main loss -2.122129], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 120 / 176], [train main loss -2.110260], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 121 / 176], [train main loss -2.093731], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 122 / 176], [train main loss -2.092766], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 123 / 176], [train main loss -2.104946], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 124 / 176], [train main loss -2.091291], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 125 / 176], [train main loss -2.093879], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 126 / 176], [train main loss -2.091507], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 127 / 176], [train main loss -2.094468], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 128 / 176], [train main loss -2.107390], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 129 / 176], [train main loss -2.108549], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 130 / 176], [train main loss -2.098436], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 131 / 176], [train main loss -2.117896], [lr 0.002057] [batchtime 0.423]
[epoch 139], [iter 132 / 176], [train main loss -2.107698], [lr 0.002057] [batchtime 0.423]
[epoch 139], [iter 133 / 176], [train main loss -2.128637], [lr 0.002057] [batchtime 0.423]
[epoch 139], [iter 134 / 176], [train main loss -2.130135], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 135 / 176], [train main loss -2.133519], [lr 0.002057] [batchtime 0.435]
[epoch 139], [iter 136 / 176], [train main loss -2.127120], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 137 / 176], [train main loss -2.108006], [lr 0.002057] [batchtime 0.434]
[epoch 139], [iter 138 / 176], [train main loss -2.091715], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 139 / 176], [train main loss -2.081814], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 140 / 176], [train main loss -2.085049], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 141 / 176], [train main loss -2.081895], [lr 0.002057] [batchtime 0.433]
[epoch 139], [iter 142 / 176], [train main loss -2.076199], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 143 / 176], [train main loss -2.064257], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 144 / 176], [train main loss -2.065205], [lr 0.002057] [batchtime 0.432]
[epoch 139], [iter 145 / 176], [train main loss -2.067223], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 146 / 176], [train main loss -2.060874], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 147 / 176], [train main loss -2.063213], [lr 0.002057] [batchtime 0.431]
[epoch 139], [iter 148 / 176], [train main loss -2.071592], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 149 / 176], [train main loss -2.067762], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 150 / 176], [train main loss -2.074065], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 151 / 176], [train main loss -2.083266], [lr 0.002057] [batchtime 0.43]
[epoch 139], [iter 152 / 176], [train main loss -2.083997], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 153 / 176], [train main loss -2.071407], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 154 / 176], [train main loss -2.069935], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 155 / 176], [train main loss -2.045189], [lr 0.002057] [batchtime 0.429]
[epoch 139], [iter 156 / 176], [train main loss -2.054255], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 157 / 176], [train main loss -2.053988], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 158 / 176], [train main loss -2.042695], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 159 / 176], [train main loss -2.067445], [lr 0.002057] [batchtime 0.428]
[epoch 139], [iter 160 / 176], [train main loss -2.079711], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 161 / 176], [train main loss -2.064576], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 162 / 176], [train main loss -2.069655], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 163 / 176], [train main loss -2.078596], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 164 / 176], [train main loss -2.089493], [lr 0.002057] [batchtime 0.427]
[epoch 139], [iter 165 / 176], [train main loss -2.090467], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 166 / 176], [train main loss -2.079693], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 167 / 176], [train main loss -2.089388], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 168 / 176], [train main loss -2.086485], [lr 0.002057] [batchtime 0.426]
[epoch 139], [iter 169 / 176], [train main loss -2.082556], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 170 / 176], [train main loss -2.091130], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 171 / 176], [train main loss -2.087284], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 172 / 176], [train main loss -2.091085], [lr 0.002057] [batchtime 0.425]
[epoch 139], [iter 173 / 176], [train main loss -2.095316], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 174 / 176], [train main loss -2.091993], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 175 / 176], [train main loss -2.088938], [lr 0.002057] [batchtime 0.424]
[epoch 139], [iter 176 / 176], [train main loss -2.096099], [lr 0.002057] [batchtime 0.423]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.77  35.60   0.02  0.03         0.98      0.97
   1  sidewalk          69.85   5.30   0.24  0.19         0.80      0.84
   2  building          86.81  24.95   0.07  0.09         0.94      0.92
   3  wall              16.84   0.13   3.69  1.24         0.21      0.45
   4  fence             26.59   0.41   2.10  0.66         0.32      0.60
   5  pole              40.07   0.57   0.99  0.50         0.50      0.66
   6  traffic light     18.79   0.03   3.88  0.44         0.20      0.70
   7  traffic sign      27.04   0.16   2.45  0.25         0.29      0.80
   8  vegetation        83.78  11.72   0.05  0.14         0.95      0.88
   9  terrain           38.90   0.35   1.10  0.47         0.48      0.68
  10  sky               93.94   3.75   0.03  0.03         0.97      0.97
  11  person            54.88   1.05   0.45  0.37         0.69      0.73
  12  rider             12.94   0.01   5.60  1.12         0.15      0.47
  13  car               85.75   6.76   0.05  0.12         0.96      0.89
  14  truck              1.29   0.00  75.86  0.66         0.01      0.60
  15  bus               16.24   0.04   0.99  4.17         0.50      0.19
  16  train             25.49   0.06   2.06  0.86         0.33      0.54
  17  motorcycle         5.63   0.01  16.02  0.73         0.06      0.58
  18  bicycle           38.23   0.27   0.42  1.20         0.70      0.46
Mean: 44.10
-----------------------------------------------------------------------------------------------------------
this : [epoch 139], [val loss 0.30237], [acc 0.91182], [acc_cls 0.52859], [mean_iu 0.44096], [fwavacc 0.84628]
best : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 140], [iter 1 / 176], [train main loss -0.572245], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 2 / 176], [train main loss -2.020656], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 3 / 176], [train main loss -1.581495], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 4 / 176], [train main loss -1.942977], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 5 / 176], [train main loss -1.573887], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 6 / 176], [train main loss -1.322444], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 7 / 176], [train main loss -1.448144], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 8 / 176], [train main loss -1.608866], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 9 / 176], [train main loss -1.621210], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 10 / 176], [train main loss -1.990334], [lr 0.002000] [batchtime 0]
[epoch 140], [iter 11 / 176], [train main loss -1.903330], [lr 0.002000] [batchtime 0.387]
[epoch 140], [iter 12 / 176], [train main loss -1.825707], [lr 0.002000] [batchtime 0.391]
[epoch 140], [iter 13 / 176], [train main loss -1.678201], [lr 0.002000] [batchtime 0.396]
[epoch 140], [iter 14 / 176], [train main loss -1.816622], [lr 0.002000] [batchtime 0.397]
[epoch 140], [iter 15 / 176], [train main loss -1.743249], [lr 0.002000] [batchtime 0.4]
[epoch 140], [iter 16 / 176], [train main loss -1.709055], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 17 / 176], [train main loss -1.620497], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 18 / 176], [train main loss -1.727300], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 19 / 176], [train main loss -1.831285], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 20 / 176], [train main loss -1.699591], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 21 / 176], [train main loss -1.727291], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 22 / 176], [train main loss -1.745309], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 23 / 176], [train main loss -1.749110], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 24 / 176], [train main loss -1.678607], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 25 / 176], [train main loss -1.648541], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 26 / 176], [train main loss -1.589580], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 27 / 176], [train main loss -1.568027], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 28 / 176], [train main loss -1.552009], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 29 / 176], [train main loss -1.525933], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 30 / 176], [train main loss -1.646824], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 31 / 176], [train main loss -1.700627], [lr 0.002000] [batchtime 0.4]
[epoch 140], [iter 32 / 176], [train main loss -1.660511], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 33 / 176], [train main loss -1.740320], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 34 / 176], [train main loss -1.724703], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 35 / 176], [train main loss -1.667036], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 36 / 176], [train main loss -1.679312], [lr 0.002000] [batchtime 0.399]
[epoch 140], [iter 37 / 176], [train main loss -1.644610], [lr 0.002000] [batchtime 0.401]
[epoch 140], [iter 38 / 176], [train main loss -1.652674], [lr 0.002000] [batchtime 0.45]
[epoch 140], [iter 39 / 176], [train main loss -1.623045], [lr 0.002000] [batchtime 0.447]
[epoch 140], [iter 40 / 176], [train main loss -1.661573], [lr 0.002000] [batchtime 0.445]
[epoch 140], [iter 41 / 176], [train main loss -1.659732], [lr 0.002000] [batchtime 0.443]
[epoch 140], [iter 42 / 176], [train main loss -1.747728], [lr 0.002000] [batchtime 0.442]
[epoch 140], [iter 43 / 176], [train main loss -1.754762], [lr 0.002000] [batchtime 0.44]
[epoch 140], [iter 44 / 176], [train main loss -1.776669], [lr 0.002000] [batchtime 0.439]
[epoch 140], [iter 45 / 176], [train main loss -1.785702], [lr 0.002000] [batchtime 0.438]
[epoch 140], [iter 46 / 176], [train main loss -1.786432], [lr 0.002000] [batchtime 0.436]
[epoch 140], [iter 47 / 176], [train main loss -1.796492], [lr 0.002000] [batchtime 0.44]
[epoch 140], [iter 48 / 176], [train main loss -1.840747], [lr 0.002000] [batchtime 0.439]
[epoch 140], [iter 49 / 176], [train main loss -1.851619], [lr 0.002000] [batchtime 0.437]
[epoch 140], [iter 50 / 176], [train main loss -1.842783], [lr 0.002000] [batchtime 0.436]
[epoch 140], [iter 51 / 176], [train main loss -1.795747], [lr 0.002000] [batchtime 0.435]
[epoch 140], [iter 52 / 176], [train main loss -1.769942], [lr 0.002000] [batchtime 0.434]
[epoch 140], [iter 53 / 176], [train main loss -1.738956], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 54 / 176], [train main loss -1.723200], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 55 / 176], [train main loss -1.787819], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 56 / 176], [train main loss -1.848970], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 57 / 176], [train main loss -1.798542], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 58 / 176], [train main loss -1.787579], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 59 / 176], [train main loss -1.819377], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 60 / 176], [train main loss -1.829573], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 61 / 176], [train main loss -1.863476], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 62 / 176], [train main loss -1.842444], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 63 / 176], [train main loss -1.849342], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 64 / 176], [train main loss -1.834192], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 65 / 176], [train main loss -1.826562], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 66 / 176], [train main loss -1.843772], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 67 / 176], [train main loss -1.844058], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 68 / 176], [train main loss -1.844387], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 69 / 176], [train main loss -1.894068], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 70 / 176], [train main loss -1.937092], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 71 / 176], [train main loss -1.918360], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 72 / 176], [train main loss -1.925443], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 73 / 176], [train main loss -1.947573], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 74 / 176], [train main loss -1.937714], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 75 / 176], [train main loss -1.909242], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 76 / 176], [train main loss -1.913209], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 77 / 176], [train main loss -1.890485], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 78 / 176], [train main loss -1.897371], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 79 / 176], [train main loss -1.881865], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 80 / 176], [train main loss -1.910276], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 81 / 176], [train main loss -1.909653], [lr 0.002000] [batchtime 0.421]
[epoch 140], [iter 82 / 176], [train main loss -1.903271], [lr 0.002000] [batchtime 0.421]
[epoch 140], [iter 83 / 176], [train main loss -1.924253], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 84 / 176], [train main loss -1.960018], [lr 0.002000] [batchtime 0.44]
[epoch 140], [iter 85 / 176], [train main loss -1.968951], [lr 0.002000] [batchtime 0.439]
[epoch 140], [iter 86 / 176], [train main loss -1.970371], [lr 0.002000] [batchtime 0.438]
[epoch 140], [iter 87 / 176], [train main loss -1.966976], [lr 0.002000] [batchtime 0.437]
[epoch 140], [iter 88 / 176], [train main loss -1.987510], [lr 0.002000] [batchtime 0.437]
[epoch 140], [iter 89 / 176], [train main loss -2.007155], [lr 0.002000] [batchtime 0.436]
[epoch 140], [iter 90 / 176], [train main loss -2.016576], [lr 0.002000] [batchtime 0.436]
[epoch 140], [iter 91 / 176], [train main loss -2.022219], [lr 0.002000] [batchtime 0.435]
[epoch 140], [iter 92 / 176], [train main loss -2.008832], [lr 0.002000] [batchtime 0.435]
[epoch 140], [iter 93 / 176], [train main loss -2.015905], [lr 0.002000] [batchtime 0.434]
[epoch 140], [iter 94 / 176], [train main loss -2.020856], [lr 0.002000] [batchtime 0.434]
[epoch 140], [iter 95 / 176], [train main loss -2.015270], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 96 / 176], [train main loss -1.996720], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 97 / 176], [train main loss -1.970951], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 98 / 176], [train main loss -1.958559], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 99 / 176], [train main loss -1.959576], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 100 / 176], [train main loss -1.954084], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 101 / 176], [train main loss -1.960242], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 102 / 176], [train main loss -1.966350], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 103 / 176], [train main loss -1.972474], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 104 / 176], [train main loss -1.982595], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 105 / 176], [train main loss -1.992471], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 106 / 176], [train main loss -1.979019], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 107 / 176], [train main loss -1.946541], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 108 / 176], [train main loss -1.964144], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 109 / 176], [train main loss -1.963659], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 110 / 176], [train main loss -1.982057], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 111 / 176], [train main loss -1.964082], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 112 / 176], [train main loss -1.964089], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 113 / 176], [train main loss -1.946660], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 114 / 176], [train main loss -1.941053], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 115 / 176], [train main loss -1.942836], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 116 / 176], [train main loss -1.945002], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 117 / 176], [train main loss -1.944898], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 118 / 176], [train main loss -1.946171], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 119 / 176], [train main loss -1.932915], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 120 / 176], [train main loss -1.938638], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 121 / 176], [train main loss -1.945869], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 122 / 176], [train main loss -1.939827], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 123 / 176], [train main loss -1.928053], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 124 / 176], [train main loss -1.924548], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 125 / 176], [train main loss -1.935495], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 126 / 176], [train main loss -1.921370], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 127 / 176], [train main loss -1.928678], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 128 / 176], [train main loss -1.938929], [lr 0.002000] [batchtime 0.421]
[epoch 140], [iter 129 / 176], [train main loss -1.936573], [lr 0.002000] [batchtime 0.421]
[epoch 140], [iter 130 / 176], [train main loss -1.931075], [lr 0.002000] [batchtime 0.421]
[epoch 140], [iter 131 / 176], [train main loss -1.927942], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 132 / 176], [train main loss -1.920367], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 133 / 176], [train main loss -1.944713], [lr 0.002000] [batchtime 0.433]
[epoch 140], [iter 134 / 176], [train main loss -1.957044], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 135 / 176], [train main loss -1.963543], [lr 0.002000] [batchtime 0.432]
[epoch 140], [iter 136 / 176], [train main loss -1.990786], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 137 / 176], [train main loss -1.982991], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 138 / 176], [train main loss -1.986789], [lr 0.002000] [batchtime 0.431]
[epoch 140], [iter 139 / 176], [train main loss -1.994948], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 140 / 176], [train main loss -1.997289], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 141 / 176], [train main loss -2.010880], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 142 / 176], [train main loss -2.003732], [lr 0.002000] [batchtime 0.43]
[epoch 140], [iter 143 / 176], [train main loss -2.009351], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 144 / 176], [train main loss -2.011385], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 145 / 176], [train main loss -2.011463], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 146 / 176], [train main loss -2.005202], [lr 0.002000] [batchtime 0.429]
[epoch 140], [iter 147 / 176], [train main loss -2.004443], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 148 / 176], [train main loss -2.001076], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 149 / 176], [train main loss -2.005216], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 150 / 176], [train main loss -2.017042], [lr 0.002000] [batchtime 0.428]
[epoch 140], [iter 151 / 176], [train main loss -1.998323], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 152 / 176], [train main loss -2.015177], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 153 / 176], [train main loss -1.999654], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 154 / 176], [train main loss -2.001657], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 155 / 176], [train main loss -1.988881], [lr 0.002000] [batchtime 0.427]
[epoch 140], [iter 156 / 176], [train main loss -1.997280], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 157 / 176], [train main loss -2.002993], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 158 / 176], [train main loss -2.003080], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 159 / 176], [train main loss -2.001079], [lr 0.002000] [batchtime 0.426]
[epoch 140], [iter 160 / 176], [train main loss -2.010096], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 161 / 176], [train main loss -2.021739], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 162 / 176], [train main loss -2.029917], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 163 / 176], [train main loss -2.041976], [lr 0.002000] [batchtime 0.425]
[epoch 140], [iter 164 / 176], [train main loss -2.031834], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 165 / 176], [train main loss -2.042182], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 166 / 176], [train main loss -2.035217], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 167 / 176], [train main loss -2.024532], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 168 / 176], [train main loss -2.041688], [lr 0.002000] [batchtime 0.424]
[epoch 140], [iter 169 / 176], [train main loss -2.037492], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 170 / 176], [train main loss -2.042990], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 171 / 176], [train main loss -2.061007], [lr 0.002000] [batchtime 0.423]
[epoch 140], [iter 172 / 176], [train main loss -2.059849], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 173 / 176], [train main loss -2.045507], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 174 / 176], [train main loss -2.060525], [lr 0.002000] [batchtime 0.422]
[epoch 140], [iter 175 / 176], [train main loss -2.058870], [lr 0.002000] [batchtime 0.421]
[epoch 140], [iter 176 / 176], [train main loss -2.062410], [lr 0.002000] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.79  35.59   0.02  0.03         0.98      0.97
   1  sidewalk          70.08   5.32   0.24  0.19         0.81      0.84
   2  building          87.00  25.22   0.05  0.10         0.95      0.91
   3  wall              17.79   0.14   3.37  1.25         0.23      0.44
   4  fence             26.77   0.41   2.09  0.64         0.32      0.61
   5  pole              39.72   0.56   1.04  0.47         0.49      0.68
   6  traffic light     16.90   0.03   4.56  0.36         0.18      0.74
   7  traffic sign      27.66   0.17   2.35  0.27         0.30      0.79
   8  vegetation        84.92  11.61   0.06  0.11         0.94      0.90
   9  terrain           40.18   0.36   1.05  0.44         0.49      0.69
  10  sky               93.79   3.75   0.03  0.03         0.97      0.97
  11  person            54.57   1.03   0.49  0.34         0.67      0.75
  12  rider             16.27   0.02   3.97  1.17         0.20      0.46
  13  car               86.08   6.75   0.05  0.11         0.95      0.90
  14  truck              3.74   0.01  25.21  0.54         0.04      0.65
  15  bus               15.60   0.04   1.02  4.39         0.50      0.19
  16  train             28.85   0.07   1.72  0.74         0.37      0.57
  17  motorcycle         7.03   0.01  12.56  0.67         0.07      0.60
  18  bicycle           38.46   0.28   0.41  1.19         0.71      0.46
Mean: 44.75
-----------------------------------------------------------------------------------------------------------
this : [epoch 140], [val loss 0.29730], [acc 0.91344], [acc_cls 0.53471], [mean_iu 0.44747], [fwavacc 0.84886]
best : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 141], [iter 1 / 176], [train main loss -4.183681], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 2 / 176], [train main loss -2.956496], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 3 / 176], [train main loss -2.485105], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 4 / 176], [train main loss -2.249923], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 5 / 176], [train main loss -2.756047], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 6 / 176], [train main loss -2.331047], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 7 / 176], [train main loss -1.980077], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 8 / 176], [train main loss -2.358542], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 9 / 176], [train main loss -2.114839], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 10 / 176], [train main loss -2.086547], [lr 0.001943] [batchtime 0]
[epoch 141], [iter 11 / 176], [train main loss -2.000051], [lr 0.001943] [batchtime 0.366]
[epoch 141], [iter 12 / 176], [train main loss -2.165565], [lr 0.001943] [batchtime 0.38]
[epoch 141], [iter 13 / 176], [train main loss -2.149530], [lr 0.001943] [batchtime 0.383]
[epoch 141], [iter 14 / 176], [train main loss -2.340985], [lr 0.001943] [batchtime 0.389]
[epoch 141], [iter 15 / 176], [train main loss -2.332200], [lr 0.001943] [batchtime 0.393]
[epoch 141], [iter 16 / 176], [train main loss -2.401577], [lr 0.001943] [batchtime 0.394]
[epoch 141], [iter 17 / 176], [train main loss -2.351532], [lr 0.001943] [batchtime 0.395]
[epoch 141], [iter 18 / 176], [train main loss -2.360258], [lr 0.001943] [batchtime 0.396]
[epoch 141], [iter 19 / 176], [train main loss -2.243287], [lr 0.001943] [batchtime 0.395]
[epoch 141], [iter 20 / 176], [train main loss -2.209954], [lr 0.001943] [batchtime 0.395]
[epoch 141], [iter 21 / 176], [train main loss -2.193873], [lr 0.001943] [batchtime 0.396]
[epoch 141], [iter 22 / 176], [train main loss -2.136190], [lr 0.001943] [batchtime 0.396]
[epoch 141], [iter 23 / 176], [train main loss -2.181680], [lr 0.001943] [batchtime 0.397]
[epoch 141], [iter 24 / 176], [train main loss -2.234532], [lr 0.001943] [batchtime 0.397]
[epoch 141], [iter 25 / 176], [train main loss -2.223986], [lr 0.001943] [batchtime 0.397]
[epoch 141], [iter 26 / 176], [train main loss -2.219522], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 27 / 176], [train main loss -2.263828], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 28 / 176], [train main loss -2.312652], [lr 0.001943] [batchtime 0.397]
[epoch 141], [iter 29 / 176], [train main loss -2.389957], [lr 0.001943] [batchtime 0.397]
[epoch 141], [iter 30 / 176], [train main loss -2.362558], [lr 0.001943] [batchtime 0.397]
[epoch 141], [iter 31 / 176], [train main loss -2.356791], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 32 / 176], [train main loss -2.326660], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 33 / 176], [train main loss -2.321333], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 34 / 176], [train main loss -2.296323], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 35 / 176], [train main loss -2.236066], [lr 0.001943] [batchtime 0.398]
[epoch 141], [iter 36 / 176], [train main loss -2.191936], [lr 0.001943] [batchtime 0.404]
[epoch 141], [iter 37 / 176], [train main loss -2.247065], [lr 0.001943] [batchtime 0.455]
[epoch 141], [iter 38 / 176], [train main loss -2.307895], [lr 0.001943] [batchtime 0.452]
[epoch 141], [iter 39 / 176], [train main loss -2.376642], [lr 0.001943] [batchtime 0.45]
[epoch 141], [iter 40 / 176], [train main loss -2.333165], [lr 0.001943] [batchtime 0.448]
[epoch 141], [iter 41 / 176], [train main loss -2.347859], [lr 0.001943] [batchtime 0.446]
[epoch 141], [iter 42 / 176], [train main loss -2.388916], [lr 0.001943] [batchtime 0.445]
[epoch 141], [iter 43 / 176], [train main loss -2.313139], [lr 0.001943] [batchtime 0.443]
[epoch 141], [iter 44 / 176], [train main loss -2.264948], [lr 0.001943] [batchtime 0.442]
[epoch 141], [iter 45 / 176], [train main loss -2.243252], [lr 0.001943] [batchtime 0.44]
[epoch 141], [iter 46 / 176], [train main loss -2.152485], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 47 / 176], [train main loss -2.174114], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 48 / 176], [train main loss -2.217410], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 49 / 176], [train main loss -2.243385], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 50 / 176], [train main loss -2.223627], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 51 / 176], [train main loss -2.234216], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 52 / 176], [train main loss -2.211367], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 53 / 176], [train main loss -2.196165], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 54 / 176], [train main loss -2.201281], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 55 / 176], [train main loss -2.196011], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 56 / 176], [train main loss -2.198418], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 57 / 176], [train main loss -2.237818], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 58 / 176], [train main loss -2.254736], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 59 / 176], [train main loss -2.208697], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 60 / 176], [train main loss -2.208167], [lr 0.001943] [batchtime 0.427]
[epoch 141], [iter 61 / 176], [train main loss -2.205605], [lr 0.001943] [batchtime 0.426]
[epoch 141], [iter 62 / 176], [train main loss -2.147569], [lr 0.001943] [batchtime 0.426]
[epoch 141], [iter 63 / 176], [train main loss -2.127276], [lr 0.001943] [batchtime 0.425]
[epoch 141], [iter 64 / 176], [train main loss -2.126394], [lr 0.001943] [batchtime 0.425]
[epoch 141], [iter 65 / 176], [train main loss -2.096374], [lr 0.001943] [batchtime 0.446]
[epoch 141], [iter 66 / 176], [train main loss -2.080936], [lr 0.001943] [batchtime 0.445]
[epoch 141], [iter 67 / 176], [train main loss -2.047570], [lr 0.001943] [batchtime 0.444]
[epoch 141], [iter 68 / 176], [train main loss -2.061669], [lr 0.001943] [batchtime 0.443]
[epoch 141], [iter 69 / 176], [train main loss -2.022111], [lr 0.001943] [batchtime 0.442]
[epoch 141], [iter 70 / 176], [train main loss -2.007883], [lr 0.001943] [batchtime 0.441]
[epoch 141], [iter 71 / 176], [train main loss -2.025483], [lr 0.001943] [batchtime 0.44]
[epoch 141], [iter 72 / 176], [train main loss -2.057861], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 73 / 176], [train main loss -2.089651], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 74 / 176], [train main loss -2.104338], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 75 / 176], [train main loss -2.144962], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 76 / 176], [train main loss -2.135474], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 77 / 176], [train main loss -2.123508], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 78 / 176], [train main loss -2.105035], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 79 / 176], [train main loss -2.098245], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 80 / 176], [train main loss -2.113718], [lr 0.001943] [batchtime 0.446]
[epoch 141], [iter 81 / 176], [train main loss -2.089363], [lr 0.001943] [batchtime 0.448]
[epoch 141], [iter 82 / 176], [train main loss -2.077912], [lr 0.001943] [batchtime 0.447]
[epoch 141], [iter 83 / 176], [train main loss -2.056437], [lr 0.001943] [batchtime 0.447]
[epoch 141], [iter 84 / 176], [train main loss -2.046949], [lr 0.001943] [batchtime 0.446]
[epoch 141], [iter 85 / 176], [train main loss -2.022128], [lr 0.001943] [batchtime 0.445]
[epoch 141], [iter 86 / 176], [train main loss -2.016731], [lr 0.001943] [batchtime 0.445]
[epoch 141], [iter 87 / 176], [train main loss -1.981544], [lr 0.001943] [batchtime 0.444]
[epoch 141], [iter 88 / 176], [train main loss -1.985064], [lr 0.001943] [batchtime 0.443]
[epoch 141], [iter 89 / 176], [train main loss -1.995119], [lr 0.001943] [batchtime 0.443]
[epoch 141], [iter 90 / 176], [train main loss -2.042119], [lr 0.001943] [batchtime 0.442]
[epoch 141], [iter 91 / 176], [train main loss -2.046014], [lr 0.001943] [batchtime 0.441]
[epoch 141], [iter 92 / 176], [train main loss -2.051067], [lr 0.001943] [batchtime 0.441]
[epoch 141], [iter 93 / 176], [train main loss -2.058677], [lr 0.001943] [batchtime 0.44]
[epoch 141], [iter 94 / 176], [train main loss -2.075580], [lr 0.001943] [batchtime 0.44]
[epoch 141], [iter 95 / 176], [train main loss -2.059855], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 96 / 176], [train main loss -2.062606], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 97 / 176], [train main loss -2.090707], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 98 / 176], [train main loss -2.094976], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 99 / 176], [train main loss -2.107033], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 100 / 176], [train main loss -2.099979], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 101 / 176], [train main loss -2.095095], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 102 / 176], [train main loss -2.107628], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 103 / 176], [train main loss -2.094757], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 104 / 176], [train main loss -2.094735], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 105 / 176], [train main loss -2.093262], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 106 / 176], [train main loss -2.085413], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 107 / 176], [train main loss -2.068505], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 108 / 176], [train main loss -2.091844], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 109 / 176], [train main loss -2.061939], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 110 / 176], [train main loss -2.054086], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 111 / 176], [train main loss -2.046887], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 112 / 176], [train main loss -2.060577], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 113 / 176], [train main loss -2.051223], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 114 / 176], [train main loss -2.043328], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 115 / 176], [train main loss -2.041657], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 116 / 176], [train main loss -2.052630], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 117 / 176], [train main loss -2.044043], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 118 / 176], [train main loss -2.052894], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 119 / 176], [train main loss -2.084326], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 120 / 176], [train main loss -2.104422], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 121 / 176], [train main loss -2.087177], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 122 / 176], [train main loss -2.110725], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 123 / 176], [train main loss -2.125935], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 124 / 176], [train main loss -2.132886], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 125 / 176], [train main loss -2.134083], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 126 / 176], [train main loss -2.125183], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 127 / 176], [train main loss -2.106989], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 128 / 176], [train main loss -2.106766], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 129 / 176], [train main loss -2.115084], [lr 0.001943] [batchtime 0.44]
[epoch 141], [iter 130 / 176], [train main loss -2.108434], [lr 0.001943] [batchtime 0.44]
[epoch 141], [iter 131 / 176], [train main loss -2.112348], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 132 / 176], [train main loss -2.116007], [lr 0.001943] [batchtime 0.439]
[epoch 141], [iter 133 / 176], [train main loss -2.127939], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 134 / 176], [train main loss -2.125637], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 135 / 176], [train main loss -2.125168], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 136 / 176], [train main loss -2.137027], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 137 / 176], [train main loss -2.147924], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 138 / 176], [train main loss -2.140375], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 139 / 176], [train main loss -2.141912], [lr 0.001943] [batchtime 0.438]
[epoch 141], [iter 140 / 176], [train main loss -2.132656], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 141 / 176], [train main loss -2.153217], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 142 / 176], [train main loss -2.148348], [lr 0.001943] [batchtime 0.437]
[epoch 141], [iter 143 / 176], [train main loss -2.158758], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 144 / 176], [train main loss -2.154718], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 145 / 176], [train main loss -2.140103], [lr 0.001943] [batchtime 0.436]
[epoch 141], [iter 146 / 176], [train main loss -2.137326], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 147 / 176], [train main loss -2.144021], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 148 / 176], [train main loss -2.129406], [lr 0.001943] [batchtime 0.435]
[epoch 141], [iter 149 / 176], [train main loss -2.133697], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 150 / 176], [train main loss -2.113955], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 151 / 176], [train main loss -2.100256], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 152 / 176], [train main loss -2.099219], [lr 0.001943] [batchtime 0.434]
[epoch 141], [iter 153 / 176], [train main loss -2.099066], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 154 / 176], [train main loss -2.096366], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 155 / 176], [train main loss -2.110854], [lr 0.001943] [batchtime 0.433]
[epoch 141], [iter 156 / 176], [train main loss -2.114674], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 157 / 176], [train main loss -2.109169], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 158 / 176], [train main loss -2.082741], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 159 / 176], [train main loss -2.064992], [lr 0.001943] [batchtime 0.432]
[epoch 141], [iter 160 / 176], [train main loss -2.066989], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 161 / 176], [train main loss -2.045950], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 162 / 176], [train main loss -2.048185], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 163 / 176], [train main loss -2.039678], [lr 0.001943] [batchtime 0.431]
[epoch 141], [iter 164 / 176], [train main loss -2.031195], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 165 / 176], [train main loss -2.020627], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 166 / 176], [train main loss -2.020042], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 167 / 176], [train main loss -2.044069], [lr 0.001943] [batchtime 0.43]
[epoch 141], [iter 168 / 176], [train main loss -2.045671], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 169 / 176], [train main loss -2.046959], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 170 / 176], [train main loss -2.053517], [lr 0.001943] [batchtime 0.429]
[epoch 141], [iter 171 / 176], [train main loss -2.060460], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 172 / 176], [train main loss -2.067072], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 173 / 176], [train main loss -2.057900], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 174 / 176], [train main loss -2.055110], [lr 0.001943] [batchtime 0.427]
[epoch 141], [iter 175 / 176], [train main loss -2.063160], [lr 0.001943] [batchtime 0.428]
[epoch 141], [iter 176 / 176], [train main loss -2.062237], [lr 0.001943] [batchtime 0.437]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.89  35.60   0.02  0.03         0.98      0.97
   1  sidewalk          70.19   5.24   0.26  0.17         0.80      0.86
   2  building          86.86  25.08   0.06  0.09         0.94      0.92
   3  wall              20.67   0.18   2.22  1.62         0.31      0.38
   4  fence             25.96   0.40   2.20  0.65         0.31      0.61
   5  pole              39.30   0.54   1.12  0.43         0.47      0.70
   6  traffic light     18.01   0.03   4.13  0.42         0.19      0.70
   7  traffic sign      24.58   0.14   2.88  0.19         0.26      0.84
   8  vegetation        84.05  11.63   0.06  0.13         0.94      0.89
   9  terrain           41.53   0.39   0.89  0.52         0.53      0.66
  10  sky               94.03   3.76   0.03  0.03         0.97      0.97
  11  person            54.74   1.05   0.45  0.37         0.69      0.73
  12  rider             13.51   0.01   5.48  0.92         0.15      0.52
  13  car               85.85   6.74   0.05  0.12         0.95      0.90
  14  truck              2.06   0.01  47.03  0.47         0.02      0.68
  15  bus               13.79   0.05   0.88  5.37         0.53      0.16
  16  train             25.48   0.06   1.93  0.99         0.34      0.50
  17  motorcycle         4.88   0.01  18.92  0.57         0.05      0.64
  18  bicycle           38.09   0.27   0.43  1.20         0.70      0.46
Mean: 44.13
-----------------------------------------------------------------------------------------------------------
this : [epoch 141], [val loss 0.29667], [acc 0.91206], [acc_cls 0.53399], [mean_iu 0.44131], [fwavacc 0.84759]
best : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 142], [iter 1 / 176], [train main loss -2.783058], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 2 / 176], [train main loss -1.529471], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 3 / 176], [train main loss -0.450514], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 4 / 176], [train main loss -0.634299], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 5 / 176], [train main loss -1.552192], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 6 / 176], [train main loss -1.561666], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 7 / 176], [train main loss -1.649359], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 8 / 176], [train main loss -1.912936], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 9 / 176], [train main loss -1.850071], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 10 / 176], [train main loss -1.932908], [lr 0.001886] [batchtime 0]
[epoch 142], [iter 11 / 176], [train main loss -2.045342], [lr 0.001886] [batchtime 0.361]
[epoch 142], [iter 12 / 176], [train main loss -2.194085], [lr 0.001886] [batchtime 0.377]
[epoch 142], [iter 13 / 176], [train main loss -2.150897], [lr 0.001886] [batchtime 0.386]
[epoch 142], [iter 14 / 176], [train main loss -2.273332], [lr 0.001886] [batchtime 0.392]
[epoch 142], [iter 15 / 176], [train main loss -2.128180], [lr 0.001886] [batchtime 0.393]
[epoch 142], [iter 16 / 176], [train main loss -1.949180], [lr 0.001886] [batchtime 0.394]
[epoch 142], [iter 17 / 176], [train main loss -1.862269], [lr 0.001886] [batchtime 0.395]
[epoch 142], [iter 18 / 176], [train main loss -1.924354], [lr 0.001886] [batchtime 0.398]
[epoch 142], [iter 19 / 176], [train main loss -1.889495], [lr 0.001886] [batchtime 0.398]
[epoch 142], [iter 20 / 176], [train main loss -1.895899], [lr 0.001886] [batchtime 0.398]
[epoch 142], [iter 21 / 176], [train main loss -2.130399], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 22 / 176], [train main loss -2.161231], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 23 / 176], [train main loss -2.164174], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 24 / 176], [train main loss -2.075102], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 25 / 176], [train main loss -2.119105], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 26 / 176], [train main loss -1.995601], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 27 / 176], [train main loss -1.912851], [lr 0.001886] [batchtime 0.4]
[epoch 142], [iter 28 / 176], [train main loss -1.864641], [lr 0.001886] [batchtime 0.399]
[epoch 142], [iter 29 / 176], [train main loss -1.884239], [lr 0.001886] [batchtime 0.4]
[epoch 142], [iter 30 / 176], [train main loss -1.837233], [lr 0.001886] [batchtime 0.449]
[epoch 142], [iter 31 / 176], [train main loss -1.836337], [lr 0.001886] [batchtime 0.455]
[epoch 142], [iter 32 / 176], [train main loss -1.827852], [lr 0.001886] [batchtime 0.452]
[epoch 142], [iter 33 / 176], [train main loss -1.820510], [lr 0.001886] [batchtime 0.449]
[epoch 142], [iter 34 / 176], [train main loss -1.992814], [lr 0.001886] [batchtime 0.447]
[epoch 142], [iter 35 / 176], [train main loss -2.016815], [lr 0.001886] [batchtime 0.444]
[epoch 142], [iter 36 / 176], [train main loss -2.012211], [lr 0.001886] [batchtime 0.443]
[epoch 142], [iter 37 / 176], [train main loss -2.040681], [lr 0.001886] [batchtime 0.441]
[epoch 142], [iter 38 / 176], [train main loss -1.983770], [lr 0.001886] [batchtime 0.44]
[epoch 142], [iter 39 / 176], [train main loss -1.981900], [lr 0.001886] [batchtime 0.438]
[epoch 142], [iter 40 / 176], [train main loss -1.956744], [lr 0.001886] [batchtime 0.437]
[epoch 142], [iter 41 / 176], [train main loss -2.004246], [lr 0.001886] [batchtime 0.436]
[epoch 142], [iter 42 / 176], [train main loss -1.968350], [lr 0.001886] [batchtime 0.434]
[epoch 142], [iter 43 / 176], [train main loss -1.936770], [lr 0.001886] [batchtime 0.433]
[epoch 142], [iter 44 / 176], [train main loss -1.907382], [lr 0.001886] [batchtime 0.432]
[epoch 142], [iter 45 / 176], [train main loss -1.892158], [lr 0.001886] [batchtime 0.431]
[epoch 142], [iter 46 / 176], [train main loss -1.957306], [lr 0.001886] [batchtime 0.43]
[epoch 142], [iter 47 / 176], [train main loss -1.947332], [lr 0.001886] [batchtime 0.429]
[epoch 142], [iter 48 / 176], [train main loss -1.935363], [lr 0.001886] [batchtime 0.429]
[epoch 142], [iter 49 / 176], [train main loss -1.949496], [lr 0.001886] [batchtime 0.428]
[epoch 142], [iter 50 / 176], [train main loss -1.929948], [lr 0.001886] [batchtime 0.427]
[epoch 142], [iter 51 / 176], [train main loss -1.966682], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 52 / 176], [train main loss -1.969584], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 53 / 176], [train main loss -1.979109], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 54 / 176], [train main loss -1.968138], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 55 / 176], [train main loss -2.015893], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 56 / 176], [train main loss -2.052174], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 57 / 176], [train main loss -2.048770], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 58 / 176], [train main loss -2.060426], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 59 / 176], [train main loss -2.140151], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 60 / 176], [train main loss -2.137640], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 61 / 176], [train main loss -2.162777], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 62 / 176], [train main loss -2.184792], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 63 / 176], [train main loss -2.187905], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 64 / 176], [train main loss -2.202541], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 65 / 176], [train main loss -2.201601], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 66 / 176], [train main loss -2.228029], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 67 / 176], [train main loss -2.204952], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 68 / 176], [train main loss -2.180875], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 69 / 176], [train main loss -2.205764], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 70 / 176], [train main loss -2.201217], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 71 / 176], [train main loss -2.214458], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 72 / 176], [train main loss -2.232053], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 73 / 176], [train main loss -2.248186], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 74 / 176], [train main loss -2.253503], [lr 0.001886] [batchtime 0.416]
[epoch 142], [iter 75 / 176], [train main loss -2.274548], [lr 0.001886] [batchtime 0.416]
[epoch 142], [iter 76 / 176], [train main loss -2.279691], [lr 0.001886] [batchtime 0.416]
[epoch 142], [iter 77 / 176], [train main loss -2.243575], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 78 / 176], [train main loss -2.220155], [lr 0.001886] [batchtime 0.43]
[epoch 142], [iter 79 / 176], [train main loss -2.244265], [lr 0.001886] [batchtime 0.43]
[epoch 142], [iter 80 / 176], [train main loss -2.221017], [lr 0.001886] [batchtime 0.429]
[epoch 142], [iter 81 / 176], [train main loss -2.237545], [lr 0.001886] [batchtime 0.428]
[epoch 142], [iter 82 / 176], [train main loss -2.252027], [lr 0.001886] [batchtime 0.428]
[epoch 142], [iter 83 / 176], [train main loss -2.229828], [lr 0.001886] [batchtime 0.427]
[epoch 142], [iter 84 / 176], [train main loss -2.218297], [lr 0.001886] [batchtime 0.427]
[epoch 142], [iter 85 / 176], [train main loss -2.195723], [lr 0.001886] [batchtime 0.427]
[epoch 142], [iter 86 / 176], [train main loss -2.187815], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 87 / 176], [train main loss -2.219267], [lr 0.001886] [batchtime 0.427]
[epoch 142], [iter 88 / 176], [train main loss -2.208089], [lr 0.001886] [batchtime 0.427]
[epoch 142], [iter 89 / 176], [train main loss -2.216996], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 90 / 176], [train main loss -2.237489], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 91 / 176], [train main loss -2.229652], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 92 / 176], [train main loss -2.212214], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 93 / 176], [train main loss -2.255711], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 94 / 176], [train main loss -2.258229], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 95 / 176], [train main loss -2.283668], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 96 / 176], [train main loss -2.301644], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 97 / 176], [train main loss -2.283866], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 98 / 176], [train main loss -2.258163], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 99 / 176], [train main loss -2.254279], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 100 / 176], [train main loss -2.248275], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 101 / 176], [train main loss -2.274086], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 102 / 176], [train main loss -2.284939], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 103 / 176], [train main loss -2.259831], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 104 / 176], [train main loss -2.255047], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 105 / 176], [train main loss -2.262501], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 106 / 176], [train main loss -2.253911], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 107 / 176], [train main loss -2.235561], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 108 / 176], [train main loss -2.221218], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 109 / 176], [train main loss -2.209504], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 110 / 176], [train main loss -2.222432], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 111 / 176], [train main loss -2.198183], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 112 / 176], [train main loss -2.181186], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 113 / 176], [train main loss -2.191216], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 114 / 176], [train main loss -2.215788], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 115 / 176], [train main loss -2.229212], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 116 / 176], [train main loss -2.249207], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 117 / 176], [train main loss -2.257166], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 118 / 176], [train main loss -2.270750], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 119 / 176], [train main loss -2.265327], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 120 / 176], [train main loss -2.268056], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 121 / 176], [train main loss -2.272474], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 122 / 176], [train main loss -2.278361], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 123 / 176], [train main loss -2.285581], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 124 / 176], [train main loss -2.292278], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 125 / 176], [train main loss -2.311946], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 126 / 176], [train main loss -2.295179], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 127 / 176], [train main loss -2.298385], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 128 / 176], [train main loss -2.300344], [lr 0.001886] [batchtime 0.426]
[epoch 142], [iter 129 / 176], [train main loss -2.308999], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 130 / 176], [train main loss -2.306319], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 131 / 176], [train main loss -2.289651], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 132 / 176], [train main loss -2.272935], [lr 0.001886] [batchtime 0.425]
[epoch 142], [iter 133 / 176], [train main loss -2.265459], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 134 / 176], [train main loss -2.248209], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 135 / 176], [train main loss -2.238558], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 136 / 176], [train main loss -2.229728], [lr 0.001886] [batchtime 0.424]
[epoch 142], [iter 137 / 176], [train main loss -2.262729], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 138 / 176], [train main loss -2.262907], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 139 / 176], [train main loss -2.274937], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 140 / 176], [train main loss -2.261651], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 141 / 176], [train main loss -2.262584], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 142 / 176], [train main loss -2.256849], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 143 / 176], [train main loss -2.254968], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 144 / 176], [train main loss -2.259342], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 145 / 176], [train main loss -2.250108], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 146 / 176], [train main loss -2.261922], [lr 0.001886] [batchtime 0.422]
[epoch 142], [iter 147 / 176], [train main loss -2.267185], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 148 / 176], [train main loss -2.277042], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 149 / 176], [train main loss -2.281192], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 150 / 176], [train main loss -2.274938], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 151 / 176], [train main loss -2.270209], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 152 / 176], [train main loss -2.282454], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 153 / 176], [train main loss -2.285241], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 154 / 176], [train main loss -2.284898], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 155 / 176], [train main loss -2.276502], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 156 / 176], [train main loss -2.269846], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 157 / 176], [train main loss -2.275532], [lr 0.001886] [batchtime 0.42]
[epoch 142], [iter 158 / 176], [train main loss -2.295647], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 159 / 176], [train main loss -2.308155], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 160 / 176], [train main loss -2.324427], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 161 / 176], [train main loss -2.322311], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 162 / 176], [train main loss -2.311668], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 163 / 176], [train main loss -2.308099], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 164 / 176], [train main loss -2.314360], [lr 0.001886] [batchtime 0.419]
[epoch 142], [iter 165 / 176], [train main loss -2.315719], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 166 / 176], [train main loss -2.313390], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 167 / 176], [train main loss -2.319551], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 168 / 176], [train main loss -2.330224], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 169 / 176], [train main loss -2.326754], [lr 0.001886] [batchtime 0.418]
[epoch 142], [iter 170 / 176], [train main loss -2.315554], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 171 / 176], [train main loss -2.315915], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 172 / 176], [train main loss -2.319527], [lr 0.001886] [batchtime 0.417]
[epoch 142], [iter 173 / 176], [train main loss -2.318941], [lr 0.001886] [batchtime 0.421]
[epoch 142], [iter 174 / 176], [train main loss -2.307785], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 175 / 176], [train main loss -2.316112], [lr 0.001886] [batchtime 0.423]
[epoch 142], [iter 176 / 176], [train main loss -2.305693], [lr 0.001886] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.85  35.58   0.02  0.03         0.98      0.97
   1  sidewalk          69.83   5.33   0.24  0.19         0.81      0.84
   2  building          85.96  24.35   0.09  0.07         0.92      0.93
   3  wall              17.34   0.14   3.11  1.65         0.24      0.38
   4  fence             27.22   0.46   1.75  0.92         0.36      0.52
   5  pole              40.36   0.60   0.88  0.60         0.53      0.63
   6  traffic light     20.31   0.03   3.34  0.59         0.23      0.63
   7  traffic sign      28.99   0.18   2.17  0.28         0.32      0.78
   8  vegetation        82.59  11.81   0.05  0.16         0.96      0.86
   9  terrain           40.06   0.37   1.00  0.50         0.50      0.67
  10  sky               93.91   3.75   0.03  0.03         0.97      0.97
  11  person            55.19   1.14   0.34  0.47         0.75      0.68
  12  rider             12.28   0.01   6.17  0.98         0.14      0.51
  13  car               86.37   6.73   0.05  0.11         0.95      0.90
  14  truck              2.71   0.01  35.30  0.64         0.03      0.61
  15  bus               13.20   0.03   1.57  5.01         0.39      0.17
  16  train             33.37   0.09   0.95  1.04         0.51      0.49
  17  motorcycle         4.51   0.01  20.45  0.70         0.05      0.59
  18  bicycle           39.15   0.27   0.47  1.09         0.68      0.48
Mean: 44.64
-----------------------------------------------------------------------------------------------------------
this : [epoch 142], [val loss 0.30328], [acc 0.90897], [acc_cls 0.54240], [mean_iu 0.44642], [fwavacc 0.84384]
best : [epoch 137], [val loss 0.30557], [acc 0.91184], [acc_cls 0.53714], [mean_iu 0.44911], [fwavacc 0.84702]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 143], [iter 1 / 176], [train main loss -2.058986], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 2 / 176], [train main loss -2.756956], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 3 / 176], [train main loss -1.746122], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 4 / 176], [train main loss -1.758067], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 5 / 176], [train main loss -1.245958], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 6 / 176], [train main loss -1.286685], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 7 / 176], [train main loss -1.754249], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 8 / 176], [train main loss -1.899314], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 9 / 176], [train main loss -2.011023], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 10 / 176], [train main loss -1.925626], [lr 0.001829] [batchtime 0]
[epoch 143], [iter 11 / 176], [train main loss -2.031904], [lr 0.001829] [batchtime 0.376]
[epoch 143], [iter 12 / 176], [train main loss -2.201634], [lr 0.001829] [batchtime 0.389]
[epoch 143], [iter 13 / 176], [train main loss -2.115231], [lr 0.001829] [batchtime 0.391]
[epoch 143], [iter 14 / 176], [train main loss -2.107755], [lr 0.001829] [batchtime 0.391]
[epoch 143], [iter 15 / 176], [train main loss -2.237832], [lr 0.001829] [batchtime 0.391]
[epoch 143], [iter 16 / 176], [train main loss -2.323753], [lr 0.001829] [batchtime 0.392]
[epoch 143], [iter 17 / 176], [train main loss -2.368325], [lr 0.001829] [batchtime 0.394]
[epoch 143], [iter 18 / 176], [train main loss -2.386404], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 19 / 176], [train main loss -2.415996], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 20 / 176], [train main loss -2.368259], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 21 / 176], [train main loss -2.339958], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 22 / 176], [train main loss -2.291761], [lr 0.001829] [batchtime 0.396]
[epoch 143], [iter 23 / 176], [train main loss -2.327482], [lr 0.001829] [batchtime 0.396]
[epoch 143], [iter 24 / 176], [train main loss -2.281369], [lr 0.001829] [batchtime 0.396]
[epoch 143], [iter 25 / 176], [train main loss -2.253690], [lr 0.001829] [batchtime 0.396]
[epoch 143], [iter 26 / 176], [train main loss -2.237651], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 27 / 176], [train main loss -2.335438], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 28 / 176], [train main loss -2.336325], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 29 / 176], [train main loss -2.307821], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 30 / 176], [train main loss -2.337251], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 31 / 176], [train main loss -2.291996], [lr 0.001829] [batchtime 0.395]
[epoch 143], [iter 32 / 176], [train main loss -2.271213], [lr 0.001829] [batchtime 0.394]
[epoch 143], [iter 33 / 176], [train main loss -2.284600], [lr 0.001829] [batchtime 0.401]
[epoch 143], [iter 34 / 176], [train main loss -2.375344], [lr 0.001829] [batchtime 0.412]
[epoch 143], [iter 35 / 176], [train main loss -2.309045], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 36 / 176], [train main loss -2.296448], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 37 / 176], [train main loss -2.240482], [lr 0.001829] [batchtime 0.41]
[epoch 143], [iter 38 / 176], [train main loss -2.287715], [lr 0.001829] [batchtime 0.41]
[epoch 143], [iter 39 / 176], [train main loss -2.264291], [lr 0.001829] [batchtime 0.409]
[epoch 143], [iter 40 / 176], [train main loss -2.289698], [lr 0.001829] [batchtime 0.409]
[epoch 143], [iter 41 / 176], [train main loss -2.287934], [lr 0.001829] [batchtime 0.408]
[epoch 143], [iter 42 / 176], [train main loss -2.260792], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 43 / 176], [train main loss -2.242942], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 44 / 176], [train main loss -2.240376], [lr 0.001829] [batchtime 0.409]
[epoch 143], [iter 45 / 176], [train main loss -2.257441], [lr 0.001829] [batchtime 0.408]
[epoch 143], [iter 46 / 176], [train main loss -2.196401], [lr 0.001829] [batchtime 0.408]
[epoch 143], [iter 47 / 176], [train main loss -2.144585], [lr 0.001829] [batchtime 0.408]
[epoch 143], [iter 48 / 176], [train main loss -2.141127], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 49 / 176], [train main loss -2.167741], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 50 / 176], [train main loss -2.174016], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 51 / 176], [train main loss -2.197239], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 52 / 176], [train main loss -2.217850], [lr 0.001829] [batchtime 0.407]
[epoch 143], [iter 53 / 176], [train main loss -2.149919], [lr 0.001829] [batchtime 0.406]
[epoch 143], [iter 54 / 176], [train main loss -2.159666], [lr 0.001829] [batchtime 0.406]
[epoch 143], [iter 55 / 176], [train main loss -2.129603], [lr 0.001829] [batchtime 0.406]
[epoch 143], [iter 56 / 176], [train main loss -2.147225], [lr 0.001829] [batchtime 0.406]
[epoch 143], [iter 57 / 176], [train main loss -2.155277], [lr 0.001829] [batchtime 0.406]
[epoch 143], [iter 58 / 176], [train main loss -2.195386], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 59 / 176], [train main loss -2.232192], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 60 / 176], [train main loss -2.208109], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 61 / 176], [train main loss -2.220203], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 62 / 176], [train main loss -2.223823], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 63 / 176], [train main loss -2.198711], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 64 / 176], [train main loss -2.212334], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 65 / 176], [train main loss -2.218909], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 66 / 176], [train main loss -2.221108], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 67 / 176], [train main loss -2.229339], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 68 / 176], [train main loss -2.243745], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 69 / 176], [train main loss -2.298784], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 70 / 176], [train main loss -2.314500], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 71 / 176], [train main loss -2.348352], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 72 / 176], [train main loss -2.343233], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 73 / 176], [train main loss -2.354880], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 74 / 176], [train main loss -2.392135], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 75 / 176], [train main loss -2.392309], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 76 / 176], [train main loss -2.372731], [lr 0.001829] [batchtime 0.404]
[epoch 143], [iter 77 / 176], [train main loss -2.387806], [lr 0.001829] [batchtime 0.403]
[epoch 143], [iter 78 / 176], [train main loss -2.372442], [lr 0.001829] [batchtime 0.403]
[epoch 143], [iter 79 / 176], [train main loss -2.344861], [lr 0.001829] [batchtime 0.403]
[epoch 143], [iter 80 / 176], [train main loss -2.358350], [lr 0.001829] [batchtime 0.403]
[epoch 143], [iter 81 / 176], [train main loss -2.360380], [lr 0.001829] [batchtime 0.403]
[epoch 143], [iter 82 / 176], [train main loss -2.352758], [lr 0.001829] [batchtime 0.405]
[epoch 143], [iter 83 / 176], [train main loss -2.358037], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 84 / 176], [train main loss -2.407453], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 85 / 176], [train main loss -2.378950], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 86 / 176], [train main loss -2.409028], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 87 / 176], [train main loss -2.410694], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 88 / 176], [train main loss -2.397019], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 89 / 176], [train main loss -2.384882], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 90 / 176], [train main loss -2.352404], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 91 / 176], [train main loss -2.355033], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 92 / 176], [train main loss -2.339880], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 93 / 176], [train main loss -2.313237], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 94 / 176], [train main loss -2.321331], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 95 / 176], [train main loss -2.306305], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 96 / 176], [train main loss -2.280521], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 97 / 176], [train main loss -2.295174], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 98 / 176], [train main loss -2.306077], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 99 / 176], [train main loss -2.284758], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 100 / 176], [train main loss -2.292578], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 101 / 176], [train main loss -2.277863], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 102 / 176], [train main loss -2.271060], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 103 / 176], [train main loss -2.257291], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 104 / 176], [train main loss -2.240071], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 105 / 176], [train main loss -2.264164], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 106 / 176], [train main loss -2.271166], [lr 0.001829] [batchtime 0.414]
[epoch 143], [iter 107 / 176], [train main loss -2.257356], [lr 0.001829] [batchtime 0.414]
[epoch 143], [iter 108 / 176], [train main loss -2.275392], [lr 0.001829] [batchtime 0.414]
[epoch 143], [iter 109 / 176], [train main loss -2.272938], [lr 0.001829] [batchtime 0.414]
[epoch 143], [iter 110 / 176], [train main loss -2.283743], [lr 0.001829] [batchtime 0.413]
[epoch 143], [iter 111 / 176], [train main loss -2.298338], [lr 0.001829] [batchtime 0.413]
[epoch 143], [iter 112 / 176], [train main loss -2.280515], [lr 0.001829] [batchtime 0.413]
[epoch 143], [iter 113 / 176], [train main loss -2.276753], [lr 0.001829] [batchtime 0.413]
[epoch 143], [iter 114 / 176], [train main loss -2.262751], [lr 0.001829] [batchtime 0.413]
[epoch 143], [iter 115 / 176], [train main loss -2.265190], [lr 0.001829] [batchtime 0.412]
[epoch 143], [iter 116 / 176], [train main loss -2.257781], [lr 0.001829] [batchtime 0.412]
[epoch 143], [iter 117 / 176], [train main loss -2.268963], [lr 0.001829] [batchtime 0.412]
[epoch 143], [iter 118 / 176], [train main loss -2.287333], [lr 0.001829] [batchtime 0.412]
[epoch 143], [iter 119 / 176], [train main loss -2.275077], [lr 0.001829] [batchtime 0.412]
[epoch 143], [iter 120 / 176], [train main loss -2.285700], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 121 / 176], [train main loss -2.262791], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 122 / 176], [train main loss -2.302932], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 123 / 176], [train main loss -2.311758], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 124 / 176], [train main loss -2.300917], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 125 / 176], [train main loss -2.296589], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 126 / 176], [train main loss -2.289512], [lr 0.001829] [batchtime 0.411]
[epoch 143], [iter 127 / 176], [train main loss -2.278888], [lr 0.001829] [batchtime 0.41]
[epoch 143], [iter 128 / 176], [train main loss -2.266498], [lr 0.001829] [batchtime 0.41]
[epoch 143], [iter 129 / 176], [train main loss -2.274809], [lr 0.001829] [batchtime 0.41]
[epoch 143], [iter 130 / 176], [train main loss -2.272203], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 131 / 176], [train main loss -2.272475], [lr 0.001829] [batchtime 0.423]
[epoch 143], [iter 132 / 176], [train main loss -2.272805], [lr 0.001829] [batchtime 0.423]
[epoch 143], [iter 133 / 176], [train main loss -2.288247], [lr 0.001829] [batchtime 0.422]
[epoch 143], [iter 134 / 176], [train main loss -2.282207], [lr 0.001829] [batchtime 0.422]
[epoch 143], [iter 135 / 176], [train main loss -2.266693], [lr 0.001829] [batchtime 0.422]
[epoch 143], [iter 136 / 176], [train main loss -2.283551], [lr 0.001829] [batchtime 0.422]
[epoch 143], [iter 137 / 176], [train main loss -2.268199], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 138 / 176], [train main loss -2.270876], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 139 / 176], [train main loss -2.272966], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 140 / 176], [train main loss -2.280089], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 141 / 176], [train main loss -2.293739], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 142 / 176], [train main loss -2.290254], [lr 0.001829] [batchtime 0.421]
[epoch 143], [iter 143 / 176], [train main loss -2.289778], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 144 / 176], [train main loss -2.299311], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 145 / 176], [train main loss -2.296662], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 146 / 176], [train main loss -2.283234], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 147 / 176], [train main loss -2.273597], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 148 / 176], [train main loss -2.278486], [lr 0.001829] [batchtime 0.42]
[epoch 143], [iter 149 / 176], [train main loss -2.276538], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 150 / 176], [train main loss -2.276445], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 151 / 176], [train main loss -2.274221], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 152 / 176], [train main loss -2.289677], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 153 / 176], [train main loss -2.279819], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 154 / 176], [train main loss -2.262509], [lr 0.001829] [batchtime 0.419]
[epoch 143], [iter 155 / 176], [train main loss -2.255126], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 156 / 176], [train main loss -2.262962], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 157 / 176], [train main loss -2.258540], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 158 / 176], [train main loss -2.253315], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 159 / 176], [train main loss -2.240806], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 160 / 176], [train main loss -2.245703], [lr 0.001829] [batchtime 0.418]
[epoch 143], [iter 161 / 176], [train main loss -2.248345], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 162 / 176], [train main loss -2.250351], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 163 / 176], [train main loss -2.241203], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 164 / 176], [train main loss -2.247052], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 165 / 176], [train main loss -2.244780], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 166 / 176], [train main loss -2.231803], [lr 0.001829] [batchtime 0.417]
[epoch 143], [iter 167 / 176], [train main loss -2.221832], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 168 / 176], [train main loss -2.227658], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 169 / 176], [train main loss -2.252300], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 170 / 176], [train main loss -2.264756], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 171 / 176], [train main loss -2.262944], [lr 0.001829] [batchtime 0.416]
[epoch 143], [iter 172 / 176], [train main loss -2.251770], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 173 / 176], [train main loss -2.240601], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 174 / 176], [train main loss -2.250394], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 175 / 176], [train main loss -2.262318], [lr 0.001829] [batchtime 0.415]
[epoch 143], [iter 176 / 176], [train main loss -2.246383], [lr 0.001829] [batchtime 0.414]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.66  35.69   0.02  0.04         0.98      0.96
   1  sidewalk          69.06   5.14   0.28  0.17         0.78      0.86
   2  building          86.46  25.01   0.06  0.09         0.94      0.91
   3  wall              16.74   0.13   3.62  1.35         0.22      0.43
   4  fence             24.95   0.37   2.46  0.55         0.29      0.65
   5  pole              39.87   0.56   1.02  0.49         0.50      0.67
   6  traffic light     19.98   0.03   3.41  0.60         0.23      0.63
   7  traffic sign      27.92   0.17   2.34  0.24         0.30      0.81
   8  vegetation        83.73  11.74   0.05  0.14         0.95      0.88
   9  terrain           41.22   0.39   0.89  0.54         0.53      0.65
  10  sky               93.31   3.76   0.03  0.04         0.97      0.96
  11  person            54.32   1.03   0.49  0.35         0.67      0.74
  12  rider             12.84   0.01   5.79  1.00         0.15      0.50
  13  car               85.87   6.73   0.05  0.11         0.95      0.90
  14  truck              2.85   0.01  33.61  0.52         0.03      0.66
  15  bus               16.77   0.03   1.52  3.44         0.40      0.23
  16  train             43.04   0.10   0.74  0.58         0.57      0.63
  17  motorcycle         4.73   0.01  19.59  0.53         0.05      0.65
  18  bicycle           40.36   0.26   0.52  0.96         0.66      0.51
Mean: 45.19
-----------------------------------------------------------------------------------------------------------
this : [epoch 143], [val loss 0.31124], [acc 0.91160], [acc_cls 0.53467], [mean_iu 0.45195], [fwavacc 0.84457]
best : [epoch 143], [val loss 0.31124], [acc 0.91160], [acc_cls 0.53467], [mean_iu 0.45195], [fwavacc 0.84457]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 144], [iter 1 / 176], [train main loss -1.068007], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 2 / 176], [train main loss -2.001825], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 3 / 176], [train main loss -2.074090], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 4 / 176], [train main loss -2.620448], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 5 / 176], [train main loss -3.092033], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 6 / 176], [train main loss -2.918028], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 7 / 176], [train main loss -2.785718], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 8 / 176], [train main loss -3.091369], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 9 / 176], [train main loss -3.132237], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 10 / 176], [train main loss -3.046642], [lr 0.001771] [batchtime 0]
[epoch 144], [iter 11 / 176], [train main loss -2.837507], [lr 0.001771] [batchtime 0.365]
[epoch 144], [iter 12 / 176], [train main loss -2.774421], [lr 0.001771] [batchtime 0.38]
[epoch 144], [iter 13 / 176], [train main loss -2.722488], [lr 0.001771] [batchtime 0.386]
[epoch 144], [iter 14 / 176], [train main loss -2.847586], [lr 0.001771] [batchtime 0.391]
[epoch 144], [iter 15 / 176], [train main loss -2.678277], [lr 0.001771] [batchtime 0.392]
[epoch 144], [iter 16 / 176], [train main loss -2.562200], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 17 / 176], [train main loss -2.519506], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 18 / 176], [train main loss -2.598729], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 19 / 176], [train main loss -2.576019], [lr 0.001771] [batchtime 0.392]
[epoch 144], [iter 20 / 176], [train main loss -2.427597], [lr 0.001771] [batchtime 0.392]
[epoch 144], [iter 21 / 176], [train main loss -2.326193], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 22 / 176], [train main loss -2.376845], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 23 / 176], [train main loss -2.332856], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 24 / 176], [train main loss -2.280889], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 25 / 176], [train main loss -2.260518], [lr 0.001771] [batchtime 0.394]
[epoch 144], [iter 26 / 176], [train main loss -2.184475], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 27 / 176], [train main loss -2.096075], [lr 0.001771] [batchtime 0.393]
[epoch 144], [iter 28 / 176], [train main loss -2.121825], [lr 0.001771] [batchtime 0.455]
[epoch 144], [iter 29 / 176], [train main loss -2.105027], [lr 0.001771] [batchtime 0.464]
[epoch 144], [iter 30 / 176], [train main loss -2.033843], [lr 0.001771] [batchtime 0.46]
[epoch 144], [iter 31 / 176], [train main loss -2.032175], [lr 0.001771] [batchtime 0.457]
[epoch 144], [iter 32 / 176], [train main loss -2.056376], [lr 0.001771] [batchtime 0.453]
[epoch 144], [iter 33 / 176], [train main loss -2.115718], [lr 0.001771] [batchtime 0.45]
[epoch 144], [iter 34 / 176], [train main loss -2.117974], [lr 0.001771] [batchtime 0.448]
[epoch 144], [iter 35 / 176], [train main loss -2.135990], [lr 0.001771] [batchtime 0.446]
[epoch 144], [iter 36 / 176], [train main loss -2.124101], [lr 0.001771] [batchtime 0.444]
[epoch 144], [iter 37 / 176], [train main loss -2.105371], [lr 0.001771] [batchtime 0.442]
[epoch 144], [iter 38 / 176], [train main loss -2.109185], [lr 0.001771] [batchtime 0.44]
[epoch 144], [iter 39 / 176], [train main loss -2.115283], [lr 0.001771] [batchtime 0.438]
[epoch 144], [iter 40 / 176], [train main loss -2.199425], [lr 0.001771] [batchtime 0.437]
[epoch 144], [iter 41 / 176], [train main loss -2.165592], [lr 0.001771] [batchtime 0.435]
[epoch 144], [iter 42 / 176], [train main loss -2.078377], [lr 0.001771] [batchtime 0.434]
[epoch 144], [iter 43 / 176], [train main loss -2.077990], [lr 0.001771] [batchtime 0.433]
[epoch 144], [iter 44 / 176], [train main loss -2.030410], [lr 0.001771] [batchtime 0.431]
[epoch 144], [iter 45 / 176], [train main loss -2.076376], [lr 0.001771] [batchtime 0.43]
[epoch 144], [iter 46 / 176], [train main loss -2.029361], [lr 0.001771] [batchtime 0.429]
[epoch 144], [iter 47 / 176], [train main loss -2.007663], [lr 0.001771] [batchtime 0.428]
[epoch 144], [iter 48 / 176], [train main loss -1.996291], [lr 0.001771] [batchtime 0.427]
[epoch 144], [iter 49 / 176], [train main loss -2.019979], [lr 0.001771] [batchtime 0.426]
[epoch 144], [iter 50 / 176], [train main loss -2.018128], [lr 0.001771] [batchtime 0.425]
[epoch 144], [iter 51 / 176], [train main loss -2.048361], [lr 0.001771] [batchtime 0.424]
[epoch 144], [iter 52 / 176], [train main loss -2.067847], [lr 0.001771] [batchtime 0.424]
[epoch 144], [iter 53 / 176], [train main loss -2.122053], [lr 0.001771] [batchtime 0.423]
[epoch 144], [iter 54 / 176], [train main loss -2.125271], [lr 0.001771] [batchtime 0.422]
[epoch 144], [iter 55 / 176], [train main loss -2.143571], [lr 0.001771] [batchtime 0.422]
[epoch 144], [iter 56 / 176], [train main loss -2.146115], [lr 0.001771] [batchtime 0.421]
[epoch 144], [iter 57 / 176], [train main loss -2.159667], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 58 / 176], [train main loss -2.197149], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 59 / 176], [train main loss -2.181901], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 60 / 176], [train main loss -2.169234], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 61 / 176], [train main loss -2.185566], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 62 / 176], [train main loss -2.169338], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 63 / 176], [train main loss -2.147389], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 64 / 176], [train main loss -2.134591], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 65 / 176], [train main loss -2.131034], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 66 / 176], [train main loss -2.112347], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 67 / 176], [train main loss -2.128980], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 68 / 176], [train main loss -2.166032], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 69 / 176], [train main loss -2.186324], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 70 / 176], [train main loss -2.136783], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 71 / 176], [train main loss -2.114819], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 72 / 176], [train main loss -2.113948], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 73 / 176], [train main loss -2.098456], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 74 / 176], [train main loss -2.115038], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 75 / 176], [train main loss -2.122052], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 76 / 176], [train main loss -2.122879], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 77 / 176], [train main loss -2.106650], [lr 0.001771] [batchtime 0.421]
[epoch 144], [iter 78 / 176], [train main loss -2.106218], [lr 0.001771] [batchtime 0.421]
[epoch 144], [iter 79 / 176], [train main loss -2.107434], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 80 / 176], [train main loss -2.103514], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 81 / 176], [train main loss -2.145359], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 82 / 176], [train main loss -2.125528], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 83 / 176], [train main loss -2.128199], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 84 / 176], [train main loss -2.129516], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 85 / 176], [train main loss -2.136196], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 86 / 176], [train main loss -2.098659], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 87 / 176], [train main loss -2.102461], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 88 / 176], [train main loss -2.093629], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 89 / 176], [train main loss -2.107527], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 90 / 176], [train main loss -2.063880], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 91 / 176], [train main loss -2.084339], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 92 / 176], [train main loss -2.112699], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 93 / 176], [train main loss -2.137791], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 94 / 176], [train main loss -2.144308], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 95 / 176], [train main loss -2.159202], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 96 / 176], [train main loss -2.175200], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 97 / 176], [train main loss -2.170353], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 98 / 176], [train main loss -2.185123], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 99 / 176], [train main loss -2.167946], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 100 / 176], [train main loss -2.162555], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 101 / 176], [train main loss -2.151473], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 102 / 176], [train main loss -2.149615], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 103 / 176], [train main loss -2.169918], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 104 / 176], [train main loss -2.166930], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 105 / 176], [train main loss -2.167080], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 106 / 176], [train main loss -2.141927], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 107 / 176], [train main loss -2.150575], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 108 / 176], [train main loss -2.137305], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 109 / 176], [train main loss -2.152654], [lr 0.001771] [batchtime 0.411]
[epoch 144], [iter 110 / 176], [train main loss -2.156287], [lr 0.001771] [batchtime 0.411]
[epoch 144], [iter 111 / 176], [train main loss -2.152329], [lr 0.001771] [batchtime 0.411]
[epoch 144], [iter 112 / 176], [train main loss -2.134261], [lr 0.001771] [batchtime 0.411]
[epoch 144], [iter 113 / 176], [train main loss -2.145558], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 114 / 176], [train main loss -2.149719], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 115 / 176], [train main loss -2.129128], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 116 / 176], [train main loss -2.127655], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 117 / 176], [train main loss -2.110811], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 118 / 176], [train main loss -2.105244], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 119 / 176], [train main loss -2.111401], [lr 0.001771] [batchtime 0.409]
[epoch 144], [iter 120 / 176], [train main loss -2.118150], [lr 0.001771] [batchtime 0.409]
[epoch 144], [iter 121 / 176], [train main loss -2.126027], [lr 0.001771] [batchtime 0.409]
[epoch 144], [iter 122 / 176], [train main loss -2.142190], [lr 0.001771] [batchtime 0.409]
[epoch 144], [iter 123 / 176], [train main loss -2.123601], [lr 0.001771] [batchtime 0.409]
[epoch 144], [iter 124 / 176], [train main loss -2.099648], [lr 0.001771] [batchtime 0.409]
[epoch 144], [iter 125 / 176], [train main loss -2.105548], [lr 0.001771] [batchtime 0.41]
[epoch 144], [iter 126 / 176], [train main loss -2.113643], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 127 / 176], [train main loss -2.120027], [lr 0.001771] [batchtime 0.42]
[epoch 144], [iter 128 / 176], [train main loss -2.138077], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 129 / 176], [train main loss -2.117523], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 130 / 176], [train main loss -2.132898], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 131 / 176], [train main loss -2.122308], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 132 / 176], [train main loss -2.115803], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 133 / 176], [train main loss -2.120016], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 134 / 176], [train main loss -2.129399], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 135 / 176], [train main loss -2.112463], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 136 / 176], [train main loss -2.115887], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 137 / 176], [train main loss -2.106402], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 138 / 176], [train main loss -2.121378], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 139 / 176], [train main loss -2.121440], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 140 / 176], [train main loss -2.105563], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 141 / 176], [train main loss -2.113170], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 142 / 176], [train main loss -2.093494], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 143 / 176], [train main loss -2.090185], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 144 / 176], [train main loss -2.063713], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 145 / 176], [train main loss -2.060926], [lr 0.001771] [batchtime 0.417]
[epoch 144], [iter 146 / 176], [train main loss -2.057241], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 147 / 176], [train main loss -2.057231], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 148 / 176], [train main loss -2.060754], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 149 / 176], [train main loss -2.049969], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 150 / 176], [train main loss -2.055233], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 151 / 176], [train main loss -2.072886], [lr 0.001771] [batchtime 0.416]
[epoch 144], [iter 152 / 176], [train main loss -2.076905], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 153 / 176], [train main loss -2.071042], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 154 / 176], [train main loss -2.073913], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 155 / 176], [train main loss -2.069686], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 156 / 176], [train main loss -2.059980], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 157 / 176], [train main loss -2.087852], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 158 / 176], [train main loss -2.076599], [lr 0.001771] [batchtime 0.415]
[epoch 144], [iter 159 / 176], [train main loss -2.078727], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 160 / 176], [train main loss -2.089060], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 161 / 176], [train main loss -2.099774], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 162 / 176], [train main loss -2.105797], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 163 / 176], [train main loss -2.108792], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 164 / 176], [train main loss -2.134339], [lr 0.001771] [batchtime 0.414]
[epoch 144], [iter 165 / 176], [train main loss -2.137266], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 166 / 176], [train main loss -2.140778], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 167 / 176], [train main loss -2.140808], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 168 / 176], [train main loss -2.153460], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 169 / 176], [train main loss -2.153251], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 170 / 176], [train main loss -2.159957], [lr 0.001771] [batchtime 0.413]
[epoch 144], [iter 171 / 176], [train main loss -2.158844], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 172 / 176], [train main loss -2.163813], [lr 0.001771] [batchtime 0.412]
[epoch 144], [iter 173 / 176], [train main loss -2.149367], [lr 0.001771] [batchtime 0.418]
[epoch 144], [iter 174 / 176], [train main loss -2.161412], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 175 / 176], [train main loss -2.161807], [lr 0.001771] [batchtime 0.419]
[epoch 144], [iter 176 / 176], [train main loss -2.170571], [lr 0.001771] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.73  35.68   0.02  0.04         0.98      0.96
   1  sidewalk          69.24   5.17   0.27  0.17         0.79      0.85
   2  building          86.66  24.75   0.07  0.08         0.93      0.93
   3  wall              19.49   0.16   2.62  1.51         0.28      0.40
   4  fence             25.58   0.38   2.32  0.59         0.30      0.63
   5  pole              40.01   0.59   0.93  0.56         0.52      0.64
   6  traffic light     18.07   0.03   4.08  0.45         0.20      0.69
   7  traffic sign      28.27   0.17   2.28  0.26         0.31      0.79
   8  vegetation        83.37  11.75   0.05  0.15         0.95      0.87
   9  terrain           42.50   0.42   0.77  0.59         0.57      0.63
  10  sky               93.74   3.76   0.03  0.04         0.97      0.97
  11  person            55.47   1.08   0.43  0.38         0.70      0.73
  12  rider             12.82   0.01   5.78  1.03         0.15      0.49
  13  car               85.75   6.76   0.05  0.12         0.96      0.89
  14  truck              3.95   0.01  23.68  0.61         0.04      0.62
  15  bus               15.48   0.04   1.42  4.04         0.41      0.20
  16  train             36.35   0.09   0.97  0.78         0.51      0.56
  17  motorcycle         5.33   0.01  17.04  0.73         0.06      0.58
  18  bicycle           39.77   0.27   0.46  1.06         0.69      0.49
Mean: 45.08
-----------------------------------------------------------------------------------------------------------
this : [epoch 144], [val loss 0.30481], [acc 0.91124], [acc_cls 0.54136], [mean_iu 0.45083], [fwavacc 0.84554]
best : [epoch 143], [val loss 0.31124], [acc 0.91160], [acc_cls 0.53467], [mean_iu 0.45195], [fwavacc 0.84457]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 145], [iter 1 / 176], [train main loss -1.299965], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 2 / 176], [train main loss 0.073216], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 3 / 176], [train main loss -0.973322], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 4 / 176], [train main loss -1.490237], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 5 / 176], [train main loss -1.310314], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 6 / 176], [train main loss -1.156385], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 7 / 176], [train main loss -1.388383], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 8 / 176], [train main loss -2.155580], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 9 / 176], [train main loss -1.855396], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 10 / 176], [train main loss -1.930141], [lr 0.001714] [batchtime 0]
[epoch 145], [iter 11 / 176], [train main loss -1.851006], [lr 0.001714] [batchtime 0.385]
[epoch 145], [iter 12 / 176], [train main loss -1.937814], [lr 0.001714] [batchtime 0.397]
[epoch 145], [iter 13 / 176], [train main loss -1.793165], [lr 0.001714] [batchtime 0.399]
[epoch 145], [iter 14 / 176], [train main loss -2.013406], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 15 / 176], [train main loss -1.992749], [lr 0.001714] [batchtime 0.402]
[epoch 145], [iter 16 / 176], [train main loss -1.977487], [lr 0.001714] [batchtime 0.403]
[epoch 145], [iter 17 / 176], [train main loss -2.166046], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 18 / 176], [train main loss -2.191496], [lr 0.001714] [batchtime 0.399]
[epoch 145], [iter 19 / 176], [train main loss -2.235073], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 20 / 176], [train main loss -2.304901], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 21 / 176], [train main loss -2.162458], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 22 / 176], [train main loss -2.189280], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 23 / 176], [train main loss -2.150428], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 24 / 176], [train main loss -2.147541], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 25 / 176], [train main loss -2.209094], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 26 / 176], [train main loss -2.323165], [lr 0.001714] [batchtime 0.401]
[epoch 145], [iter 27 / 176], [train main loss -2.311537], [lr 0.001714] [batchtime 0.401]
[epoch 145], [iter 28 / 176], [train main loss -2.391709], [lr 0.001714] [batchtime 0.4]
[epoch 145], [iter 29 / 176], [train main loss -2.329559], [lr 0.001714] [batchtime 0.409]
[epoch 145], [iter 30 / 176], [train main loss -2.338455], [lr 0.001714] [batchtime 0.472]
[epoch 145], [iter 31 / 176], [train main loss -2.389097], [lr 0.001714] [batchtime 0.468]
[epoch 145], [iter 32 / 176], [train main loss -2.371999], [lr 0.001714] [batchtime 0.464]
[epoch 145], [iter 33 / 176], [train main loss -2.343779], [lr 0.001714] [batchtime 0.461]
[epoch 145], [iter 34 / 176], [train main loss -2.288753], [lr 0.001714] [batchtime 0.459]
[epoch 145], [iter 35 / 176], [train main loss -2.282309], [lr 0.001714] [batchtime 0.457]
[epoch 145], [iter 36 / 176], [train main loss -2.229748], [lr 0.001714] [batchtime 0.455]
[epoch 145], [iter 37 / 176], [train main loss -2.201036], [lr 0.001714] [batchtime 0.453]
[epoch 145], [iter 38 / 176], [train main loss -2.228714], [lr 0.001714] [batchtime 0.451]
[epoch 145], [iter 39 / 176], [train main loss -2.272608], [lr 0.001714] [batchtime 0.449]
[epoch 145], [iter 40 / 176], [train main loss -2.199749], [lr 0.001714] [batchtime 0.447]
[epoch 145], [iter 41 / 176], [train main loss -2.160776], [lr 0.001714] [batchtime 0.446]
[epoch 145], [iter 42 / 176], [train main loss -2.126754], [lr 0.001714] [batchtime 0.444]
[epoch 145], [iter 43 / 176], [train main loss -2.121477], [lr 0.001714] [batchtime 0.443]
[epoch 145], [iter 44 / 176], [train main loss -2.154561], [lr 0.001714] [batchtime 0.442]
[epoch 145], [iter 45 / 176], [train main loss -2.170070], [lr 0.001714] [batchtime 0.44]
[epoch 145], [iter 46 / 176], [train main loss -2.165825], [lr 0.001714] [batchtime 0.439]
[epoch 145], [iter 47 / 176], [train main loss -2.161728], [lr 0.001714] [batchtime 0.438]
[epoch 145], [iter 48 / 176], [train main loss -2.107429], [lr 0.001714] [batchtime 0.437]
[epoch 145], [iter 49 / 176], [train main loss -2.099266], [lr 0.001714] [batchtime 0.436]
[epoch 145], [iter 50 / 176], [train main loss -2.108711], [lr 0.001714] [batchtime 0.435]
[epoch 145], [iter 51 / 176], [train main loss -2.107081], [lr 0.001714] [batchtime 0.435]
[epoch 145], [iter 52 / 176], [train main loss -2.056657], [lr 0.001714] [batchtime 0.434]
[epoch 145], [iter 53 / 176], [train main loss -2.042207], [lr 0.001714] [batchtime 0.433]
[epoch 145], [iter 54 / 176], [train main loss -2.004347], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 55 / 176], [train main loss -2.044111], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 56 / 176], [train main loss -2.025908], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 57 / 176], [train main loss -2.038261], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 58 / 176], [train main loss -2.082580], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 59 / 176], [train main loss -2.130458], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 60 / 176], [train main loss -2.107489], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 61 / 176], [train main loss -2.094412], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 62 / 176], [train main loss -2.139141], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 63 / 176], [train main loss -2.158448], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 64 / 176], [train main loss -2.167814], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 65 / 176], [train main loss -2.157940], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 66 / 176], [train main loss -2.188837], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 67 / 176], [train main loss -2.174470], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 68 / 176], [train main loss -2.187143], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 69 / 176], [train main loss -2.134145], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 70 / 176], [train main loss -2.153486], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 71 / 176], [train main loss -2.137206], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 72 / 176], [train main loss -2.136242], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 73 / 176], [train main loss -2.132644], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 74 / 176], [train main loss -2.147452], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 75 / 176], [train main loss -2.147275], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 76 / 176], [train main loss -2.106046], [lr 0.001714] [batchtime 0.441]
[epoch 145], [iter 77 / 176], [train main loss -2.131962], [lr 0.001714] [batchtime 0.445]
[epoch 145], [iter 78 / 176], [train main loss -2.137049], [lr 0.001714] [batchtime 0.444]
[epoch 145], [iter 79 / 176], [train main loss -2.134638], [lr 0.001714] [batchtime 0.443]
[epoch 145], [iter 80 / 176], [train main loss -2.122090], [lr 0.001714] [batchtime 0.443]
[epoch 145], [iter 81 / 176], [train main loss -2.118917], [lr 0.001714] [batchtime 0.442]
[epoch 145], [iter 82 / 176], [train main loss -2.102752], [lr 0.001714] [batchtime 0.441]
[epoch 145], [iter 83 / 176], [train main loss -2.148763], [lr 0.001714] [batchtime 0.441]
[epoch 145], [iter 84 / 176], [train main loss -2.123805], [lr 0.001714] [batchtime 0.44]
[epoch 145], [iter 85 / 176], [train main loss -2.140526], [lr 0.001714] [batchtime 0.44]
[epoch 145], [iter 86 / 176], [train main loss -2.139472], [lr 0.001714] [batchtime 0.439]
[epoch 145], [iter 87 / 176], [train main loss -2.132884], [lr 0.001714] [batchtime 0.438]
[epoch 145], [iter 88 / 176], [train main loss -2.133073], [lr 0.001714] [batchtime 0.438]
[epoch 145], [iter 89 / 176], [train main loss -2.113488], [lr 0.001714] [batchtime 0.437]
[epoch 145], [iter 90 / 176], [train main loss -2.104911], [lr 0.001714] [batchtime 0.436]
[epoch 145], [iter 91 / 176], [train main loss -2.123448], [lr 0.001714] [batchtime 0.436]
[epoch 145], [iter 92 / 176], [train main loss -2.108535], [lr 0.001714] [batchtime 0.436]
[epoch 145], [iter 93 / 176], [train main loss -2.115074], [lr 0.001714] [batchtime 0.435]
[epoch 145], [iter 94 / 176], [train main loss -2.093061], [lr 0.001714] [batchtime 0.435]
[epoch 145], [iter 95 / 176], [train main loss -2.089214], [lr 0.001714] [batchtime 0.434]
[epoch 145], [iter 96 / 176], [train main loss -2.106331], [lr 0.001714] [batchtime 0.434]
[epoch 145], [iter 97 / 176], [train main loss -2.099327], [lr 0.001714] [batchtime 0.434]
[epoch 145], [iter 98 / 176], [train main loss -2.144702], [lr 0.001714] [batchtime 0.433]
[epoch 145], [iter 99 / 176], [train main loss -2.160035], [lr 0.001714] [batchtime 0.433]
[epoch 145], [iter 100 / 176], [train main loss -2.175401], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 101 / 176], [train main loss -2.184337], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 102 / 176], [train main loss -2.166319], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 103 / 176], [train main loss -2.147212], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 104 / 176], [train main loss -2.165700], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 105 / 176], [train main loss -2.179722], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 106 / 176], [train main loss -2.193625], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 107 / 176], [train main loss -2.183311], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 108 / 176], [train main loss -2.174994], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 109 / 176], [train main loss -2.148870], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 110 / 176], [train main loss -2.151124], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 111 / 176], [train main loss -2.151822], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 112 / 176], [train main loss -2.155801], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 113 / 176], [train main loss -2.155869], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 114 / 176], [train main loss -2.154278], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 115 / 176], [train main loss -2.192396], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 116 / 176], [train main loss -2.192170], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 117 / 176], [train main loss -2.192057], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 118 / 176], [train main loss -2.180630], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 119 / 176], [train main loss -2.174724], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 120 / 176], [train main loss -2.172298], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 121 / 176], [train main loss -2.167281], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 122 / 176], [train main loss -2.154420], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 123 / 176], [train main loss -2.164279], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 124 / 176], [train main loss -2.159505], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 125 / 176], [train main loss -2.154748], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 126 / 176], [train main loss -2.157609], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 127 / 176], [train main loss -2.175261], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 128 / 176], [train main loss -2.193134], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 129 / 176], [train main loss -2.216405], [lr 0.001714] [batchtime 0.43]
[epoch 145], [iter 130 / 176], [train main loss -2.238984], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 131 / 176], [train main loss -2.263954], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 132 / 176], [train main loss -2.240455], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 133 / 176], [train main loss -2.244084], [lr 0.001714] [batchtime 0.429]
[epoch 145], [iter 134 / 176], [train main loss -2.234388], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 135 / 176], [train main loss -2.241489], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 136 / 176], [train main loss -2.238761], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 137 / 176], [train main loss -2.252361], [lr 0.001714] [batchtime 0.428]
[epoch 145], [iter 138 / 176], [train main loss -2.236222], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 139 / 176], [train main loss -2.231915], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 140 / 176], [train main loss -2.225040], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 141 / 176], [train main loss -2.233621], [lr 0.001714] [batchtime 0.427]
[epoch 145], [iter 142 / 176], [train main loss -2.228921], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 143 / 176], [train main loss -2.226545], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 144 / 176], [train main loss -2.242960], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 145 / 176], [train main loss -2.247555], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 146 / 176], [train main loss -2.255846], [lr 0.001714] [batchtime 0.426]
[epoch 145], [iter 147 / 176], [train main loss -2.249842], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 148 / 176], [train main loss -2.251801], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 149 / 176], [train main loss -2.242314], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 150 / 176], [train main loss -2.253565], [lr 0.001714] [batchtime 0.425]
[epoch 145], [iter 151 / 176], [train main loss -2.255828], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 152 / 176], [train main loss -2.272881], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 153 / 176], [train main loss -2.276234], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 154 / 176], [train main loss -2.272865], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 155 / 176], [train main loss -2.251276], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 156 / 176], [train main loss -2.250775], [lr 0.001714] [batchtime 0.424]
[epoch 145], [iter 157 / 176], [train main loss -2.251993], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 158 / 176], [train main loss -2.255283], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 159 / 176], [train main loss -2.277087], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 160 / 176], [train main loss -2.277555], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 161 / 176], [train main loss -2.283638], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 162 / 176], [train main loss -2.268616], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 163 / 176], [train main loss -2.264861], [lr 0.001714] [batchtime 0.423]
[epoch 145], [iter 164 / 176], [train main loss -2.273428], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 165 / 176], [train main loss -2.274302], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 166 / 176], [train main loss -2.275366], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 167 / 176], [train main loss -2.289066], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 168 / 176], [train main loss -2.300410], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 169 / 176], [train main loss -2.281524], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 170 / 176], [train main loss -2.289029], [lr 0.001714] [batchtime 0.421]
[epoch 145], [iter 171 / 176], [train main loss -2.287765], [lr 0.001714] [batchtime 0.422]
[epoch 145], [iter 172 / 176], [train main loss -2.299097], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 173 / 176], [train main loss -2.296626], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 174 / 176], [train main loss -2.301566], [lr 0.001714] [batchtime 0.432]
[epoch 145], [iter 175 / 176], [train main loss -2.307317], [lr 0.001714] [batchtime 0.431]
[epoch 145], [iter 176 / 176], [train main loss -2.293910], [lr 0.001714] [batchtime 0.431]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.05  35.52   0.02  0.03         0.98      0.97
   1  sidewalk          71.31   5.45   0.21  0.19         0.83      0.84
   2  building          86.85  24.97   0.06  0.09         0.94      0.92
   3  wall              19.24   0.16   2.79  1.40         0.26      0.42
   4  fence             26.93   0.42   1.99  0.72         0.33      0.58
   5  pole              40.22   0.57   0.98  0.51         0.51      0.66
   6  traffic light     19.55   0.03   3.68  0.44         0.21      0.70
   7  traffic sign      28.98   0.17   2.20  0.25         0.31      0.80
   8  vegetation        83.76  11.73   0.05  0.14         0.95      0.88
   9  terrain           41.37   0.39   0.90  0.52         0.53      0.66
  10  sky               93.78   3.74   0.04  0.03         0.97      0.97
  11  person            54.95   1.04   0.48  0.34         0.68      0.75
  12  rider             11.58   0.01   6.78  0.86         0.13      0.54
  13  car               86.49   6.72   0.05  0.10         0.95      0.91
  14  truck              1.79   0.01  54.46  0.45         0.02      0.69
  15  bus               15.99   0.04   1.11  4.14         0.47      0.19
  16  train             42.28   0.10   0.78  0.59         0.56      0.63
  17  motorcycle         4.03   0.00  23.18  0.62         0.04      0.62
  18  bicycle           39.91   0.27   0.43  1.07         0.70      0.48
Mean: 45.48
-----------------------------------------------------------------------------------------------------------
this : [epoch 145], [val loss 0.29018], [acc 0.91352], [acc_cls 0.54531], [mean_iu 0.45477], [fwavacc 0.84969]
best : [epoch 145], [val loss 0.29018], [acc 0.91352], [acc_cls 0.54531], [mean_iu 0.45477], [fwavacc 0.84969]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 146], [iter 1 / 176], [train main loss -3.898432], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 2 / 176], [train main loss -3.491120], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 3 / 176], [train main loss -3.216055], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 4 / 176], [train main loss -2.932638], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 5 / 176], [train main loss -2.366208], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 6 / 176], [train main loss -2.131317], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 7 / 176], [train main loss -2.437703], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 8 / 176], [train main loss -2.320864], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 9 / 176], [train main loss -2.383078], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 10 / 176], [train main loss -2.595412], [lr 0.001657] [batchtime 0]
[epoch 146], [iter 11 / 176], [train main loss -2.764833], [lr 0.001657] [batchtime 0.369]
[epoch 146], [iter 12 / 176], [train main loss -2.674156], [lr 0.001657] [batchtime 0.382]
[epoch 146], [iter 13 / 176], [train main loss -2.694326], [lr 0.001657] [batchtime 0.387]
[epoch 146], [iter 14 / 176], [train main loss -2.635634], [lr 0.001657] [batchtime 0.389]
[epoch 146], [iter 15 / 176], [train main loss -2.465779], [lr 0.001657] [batchtime 0.392]
[epoch 146], [iter 16 / 176], [train main loss -2.248421], [lr 0.001657] [batchtime 0.395]
[epoch 146], [iter 17 / 176], [train main loss -2.313149], [lr 0.001657] [batchtime 0.404]
[epoch 146], [iter 18 / 176], [train main loss -2.335380], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 19 / 176], [train main loss -2.314722], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 20 / 176], [train main loss -2.248742], [lr 0.001657] [batchtime 0.415]
[epoch 146], [iter 21 / 176], [train main loss -2.231711], [lr 0.001657] [batchtime 0.414]
[epoch 146], [iter 22 / 176], [train main loss -2.253761], [lr 0.001657] [batchtime 0.412]
[epoch 146], [iter 23 / 176], [train main loss -2.373673], [lr 0.001657] [batchtime 0.411]
[epoch 146], [iter 24 / 176], [train main loss -2.344010], [lr 0.001657] [batchtime 0.41]
[epoch 146], [iter 25 / 176], [train main loss -2.332381], [lr 0.001657] [batchtime 0.409]
[epoch 146], [iter 26 / 176], [train main loss -2.266241], [lr 0.001657] [batchtime 0.408]
[epoch 146], [iter 27 / 176], [train main loss -2.276726], [lr 0.001657] [batchtime 0.414]
[epoch 146], [iter 28 / 176], [train main loss -2.267031], [lr 0.001657] [batchtime 0.413]
[epoch 146], [iter 29 / 176], [train main loss -2.219202], [lr 0.001657] [batchtime 0.412]
[epoch 146], [iter 30 / 176], [train main loss -2.226646], [lr 0.001657] [batchtime 0.411]
[epoch 146], [iter 31 / 176], [train main loss -2.185834], [lr 0.001657] [batchtime 0.411]
[epoch 146], [iter 32 / 176], [train main loss -2.165587], [lr 0.001657] [batchtime 0.411]
[epoch 146], [iter 33 / 176], [train main loss -2.196500], [lr 0.001657] [batchtime 0.41]
[epoch 146], [iter 34 / 176], [train main loss -2.216641], [lr 0.001657] [batchtime 0.409]
[epoch 146], [iter 35 / 176], [train main loss -2.253369], [lr 0.001657] [batchtime 0.409]
[epoch 146], [iter 36 / 176], [train main loss -2.238463], [lr 0.001657] [batchtime 0.409]
[epoch 146], [iter 37 / 176], [train main loss -2.234990], [lr 0.001657] [batchtime 0.408]
[epoch 146], [iter 38 / 176], [train main loss -2.252235], [lr 0.001657] [batchtime 0.408]
[epoch 146], [iter 39 / 176], [train main loss -2.325714], [lr 0.001657] [batchtime 0.408]
[epoch 146], [iter 40 / 176], [train main loss -2.333988], [lr 0.001657] [batchtime 0.408]
[epoch 146], [iter 41 / 176], [train main loss -2.330719], [lr 0.001657] [batchtime 0.407]
[epoch 146], [iter 42 / 176], [train main loss -2.354498], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 43 / 176], [train main loss -2.293565], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 44 / 176], [train main loss -2.284681], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 45 / 176], [train main loss -2.316062], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 46 / 176], [train main loss -2.358751], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 47 / 176], [train main loss -2.335153], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 48 / 176], [train main loss -2.351523], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 49 / 176], [train main loss -2.322471], [lr 0.001657] [batchtime 0.418]
[epoch 146], [iter 50 / 176], [train main loss -2.291460], [lr 0.001657] [batchtime 0.418]
[epoch 146], [iter 51 / 176], [train main loss -2.230860], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 52 / 176], [train main loss -2.256219], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 53 / 176], [train main loss -2.269299], [lr 0.001657] [batchtime 0.416]
[epoch 146], [iter 54 / 176], [train main loss -2.263930], [lr 0.001657] [batchtime 0.416]
[epoch 146], [iter 55 / 176], [train main loss -2.272196], [lr 0.001657] [batchtime 0.415]
[epoch 146], [iter 56 / 176], [train main loss -2.281358], [lr 0.001657] [batchtime 0.415]
[epoch 146], [iter 57 / 176], [train main loss -2.286468], [lr 0.001657] [batchtime 0.415]
[epoch 146], [iter 58 / 176], [train main loss -2.291376], [lr 0.001657] [batchtime 0.415]
[epoch 146], [iter 59 / 176], [train main loss -2.329201], [lr 0.001657] [batchtime 0.414]
[epoch 146], [iter 60 / 176], [train main loss -2.353896], [lr 0.001657] [batchtime 0.414]
[epoch 146], [iter 61 / 176], [train main loss -2.358343], [lr 0.001657] [batchtime 0.414]
[epoch 146], [iter 62 / 176], [train main loss -2.369710], [lr 0.001657] [batchtime 0.414]
[epoch 146], [iter 63 / 176], [train main loss -2.349870], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 64 / 176], [train main loss -2.360807], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 65 / 176], [train main loss -2.398450], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 66 / 176], [train main loss -2.364499], [lr 0.001657] [batchtime 0.423]
[epoch 146], [iter 67 / 176], [train main loss -2.319286], [lr 0.001657] [batchtime 0.423]
[epoch 146], [iter 68 / 176], [train main loss -2.330533], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 69 / 176], [train main loss -2.330021], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 70 / 176], [train main loss -2.348177], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 71 / 176], [train main loss -2.368866], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 72 / 176], [train main loss -2.372694], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 73 / 176], [train main loss -2.328373], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 74 / 176], [train main loss -2.357864], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 75 / 176], [train main loss -2.343390], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 76 / 176], [train main loss -2.333317], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 77 / 176], [train main loss -2.358154], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 78 / 176], [train main loss -2.359784], [lr 0.001657] [batchtime 0.418]
[epoch 146], [iter 79 / 176], [train main loss -2.385982], [lr 0.001657] [batchtime 0.418]
[epoch 146], [iter 80 / 176], [train main loss -2.414181], [lr 0.001657] [batchtime 0.418]
[epoch 146], [iter 81 / 176], [train main loss -2.417691], [lr 0.001657] [batchtime 0.418]
[epoch 146], [iter 82 / 176], [train main loss -2.420948], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 83 / 176], [train main loss -2.424363], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 84 / 176], [train main loss -2.425550], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 85 / 176], [train main loss -2.425037], [lr 0.001657] [batchtime 0.416]
[epoch 146], [iter 86 / 176], [train main loss -2.433362], [lr 0.001657] [batchtime 0.416]
[epoch 146], [iter 87 / 176], [train main loss -2.438701], [lr 0.001657] [batchtime 0.416]
[epoch 146], [iter 88 / 176], [train main loss -2.421208], [lr 0.001657] [batchtime 0.416]
[epoch 146], [iter 89 / 176], [train main loss -2.420720], [lr 0.001657] [batchtime 0.417]
[epoch 146], [iter 90 / 176], [train main loss -2.423874], [lr 0.001657] [batchtime 0.432]
[epoch 146], [iter 91 / 176], [train main loss -2.439632], [lr 0.001657] [batchtime 0.432]
[epoch 146], [iter 92 / 176], [train main loss -2.466783], [lr 0.001657] [batchtime 0.431]
[epoch 146], [iter 93 / 176], [train main loss -2.463193], [lr 0.001657] [batchtime 0.431]
[epoch 146], [iter 94 / 176], [train main loss -2.460786], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 95 / 176], [train main loss -2.470032], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 96 / 176], [train main loss -2.466268], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 97 / 176], [train main loss -2.423773], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 98 / 176], [train main loss -2.422370], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 99 / 176], [train main loss -2.415925], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 100 / 176], [train main loss -2.393459], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 101 / 176], [train main loss -2.405920], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 102 / 176], [train main loss -2.398674], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 103 / 176], [train main loss -2.386653], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 104 / 176], [train main loss -2.375259], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 105 / 176], [train main loss -2.363764], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 106 / 176], [train main loss -2.365015], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 107 / 176], [train main loss -2.357159], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 108 / 176], [train main loss -2.367190], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 109 / 176], [train main loss -2.345927], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 110 / 176], [train main loss -2.346050], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 111 / 176], [train main loss -2.320927], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 112 / 176], [train main loss -2.282183], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 113 / 176], [train main loss -2.264171], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 114 / 176], [train main loss -2.256898], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 115 / 176], [train main loss -2.255300], [lr 0.001657] [batchtime 0.424]
[epoch 146], [iter 116 / 176], [train main loss -2.244858], [lr 0.001657] [batchtime 0.423]
[epoch 146], [iter 117 / 176], [train main loss -2.234601], [lr 0.001657] [batchtime 0.423]
[epoch 146], [iter 118 / 176], [train main loss -2.225371], [lr 0.001657] [batchtime 0.423]
[epoch 146], [iter 119 / 176], [train main loss -2.225952], [lr 0.001657] [batchtime 0.423]
[epoch 146], [iter 120 / 176], [train main loss -2.211861], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 121 / 176], [train main loss -2.205180], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 122 / 176], [train main loss -2.224664], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 123 / 176], [train main loss -2.235167], [lr 0.001657] [batchtime 0.422]
[epoch 146], [iter 124 / 176], [train main loss -2.235499], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 125 / 176], [train main loss -2.217272], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 126 / 176], [train main loss -2.205489], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 127 / 176], [train main loss -2.179090], [lr 0.001657] [batchtime 0.421]
[epoch 146], [iter 128 / 176], [train main loss -2.181907], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 129 / 176], [train main loss -2.171162], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 130 / 176], [train main loss -2.181636], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 131 / 176], [train main loss -2.169112], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 132 / 176], [train main loss -2.174714], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 133 / 176], [train main loss -2.175427], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 134 / 176], [train main loss -2.178762], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 135 / 176], [train main loss -2.169072], [lr 0.001657] [batchtime 0.419]
[epoch 146], [iter 136 / 176], [train main loss -2.154287], [lr 0.001657] [batchtime 0.42]
[epoch 146], [iter 137 / 176], [train main loss -2.158829], [lr 0.001657] [batchtime 0.431]
[epoch 146], [iter 138 / 176], [train main loss -2.173153], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 139 / 176], [train main loss -2.173694], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 140 / 176], [train main loss -2.168266], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 141 / 176], [train main loss -2.170199], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 142 / 176], [train main loss -2.180514], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 143 / 176], [train main loss -2.206852], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 144 / 176], [train main loss -2.205888], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 145 / 176], [train main loss -2.215970], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 146 / 176], [train main loss -2.210402], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 147 / 176], [train main loss -2.206290], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 148 / 176], [train main loss -2.186711], [lr 0.001657] [batchtime 0.428]
[epoch 146], [iter 149 / 176], [train main loss -2.188595], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 150 / 176], [train main loss -2.163490], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 151 / 176], [train main loss -2.162922], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 152 / 176], [train main loss -2.136062], [lr 0.001657] [batchtime 0.427]
[epoch 146], [iter 153 / 176], [train main loss -2.139218], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 154 / 176], [train main loss -2.135859], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 155 / 176], [train main loss -2.157293], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 156 / 176], [train main loss -2.143222], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 157 / 176], [train main loss -2.147603], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 158 / 176], [train main loss -2.143169], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 159 / 176], [train main loss -2.140077], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 160 / 176], [train main loss -2.149825], [lr 0.001657] [batchtime 0.426]
[epoch 146], [iter 161 / 176], [train main loss -2.144600], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 162 / 176], [train main loss -2.143924], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 163 / 176], [train main loss -2.148578], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 164 / 176], [train main loss -2.161260], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 165 / 176], [train main loss -2.165608], [lr 0.001657] [batchtime 0.425]
[epoch 146], [iter 166 / 176], [train main loss -2.169584], [lr 0.001657] [batchtime 0.432]
[epoch 146], [iter 167 / 176], [train main loss -2.185732], [lr 0.001657] [batchtime 0.431]
[epoch 146], [iter 168 / 176], [train main loss -2.197152], [lr 0.001657] [batchtime 0.431]
[epoch 146], [iter 169 / 176], [train main loss -2.191120], [lr 0.001657] [batchtime 0.431]
[epoch 146], [iter 170 / 176], [train main loss -2.203112], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 171 / 176], [train main loss -2.226184], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 172 / 176], [train main loss -2.201810], [lr 0.001657] [batchtime 0.43]
[epoch 146], [iter 173 / 176], [train main loss -2.200307], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 174 / 176], [train main loss -2.191305], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 175 / 176], [train main loss -2.194446], [lr 0.001657] [batchtime 0.429]
[epoch 146], [iter 176 / 176], [train main loss -2.212685], [lr 0.001657] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.97  35.44   0.03  0.03         0.97      0.97
   1  sidewalk          71.31   5.53   0.19  0.21         0.84      0.83
   2  building          86.87  25.13   0.06  0.09         0.95      0.91
   3  wall              17.35   0.13   3.38  1.38         0.23      0.42
   4  fence             26.50   0.41   2.11  0.66         0.32      0.60
   5  pole              39.77   0.55   1.05  0.46         0.49      0.69
   6  traffic light     17.14   0.03   4.45  0.38         0.18      0.72
   7  traffic sign      27.32   0.16   2.44  0.22         0.29      0.82
   8  vegetation        84.14  11.72   0.05  0.13         0.95      0.88
   9  terrain           40.00   0.36   1.02  0.48         0.49      0.68
  10  sky               93.91   3.74   0.04  0.03         0.97      0.97
  11  person            55.05   1.04   0.47  0.34         0.68      0.74
  12  rider             15.37   0.02   4.59  0.92         0.18      0.52
  13  car               86.66   6.71   0.05  0.10         0.95      0.91
  14  truck              2.54   0.01  37.87  0.53         0.03      0.66
  15  bus               16.22   0.04   1.43  3.74         0.41      0.21
  16  train             41.48   0.10   0.80  0.61         0.56      0.62
  17  motorcycle         4.09   0.00  22.87  0.58         0.04      0.63
  18  bicycle           40.77   0.27   0.42  1.03         0.70      0.49
Mean: 45.34
-----------------------------------------------------------------------------------------------------------
this : [epoch 146], [val loss 0.29294], [acc 0.91400], [acc_cls 0.53804], [mean_iu 0.45340], [fwavacc 0.84973]
best : [epoch 145], [val loss 0.29018], [acc 0.91352], [acc_cls 0.54531], [mean_iu 0.45477], [fwavacc 0.84969]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 147], [iter 1 / 176], [train main loss -3.339703], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 2 / 176], [train main loss -1.309299], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 3 / 176], [train main loss -2.553686], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 4 / 176], [train main loss -2.397317], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 5 / 176], [train main loss -2.805100], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 6 / 176], [train main loss -2.589267], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 7 / 176], [train main loss -2.500043], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 8 / 176], [train main loss -2.402896], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 9 / 176], [train main loss -2.242606], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 10 / 176], [train main loss -2.249434], [lr 0.001600] [batchtime 0]
[epoch 147], [iter 11 / 176], [train main loss -2.187221], [lr 0.001600] [batchtime 0.37]
[epoch 147], [iter 12 / 176], [train main loss -2.272121], [lr 0.001600] [batchtime 0.382]
[epoch 147], [iter 13 / 176], [train main loss -2.173518], [lr 0.001600] [batchtime 0.387]
[epoch 147], [iter 14 / 176], [train main loss -2.321844], [lr 0.001600] [batchtime 0.391]
[epoch 147], [iter 15 / 176], [train main loss -2.418578], [lr 0.001600] [batchtime 0.392]
[epoch 147], [iter 16 / 176], [train main loss -2.379195], [lr 0.001600] [batchtime 0.395]
[epoch 147], [iter 17 / 176], [train main loss -2.368963], [lr 0.001600] [batchtime 0.395]
[epoch 147], [iter 18 / 176], [train main loss -2.218306], [lr 0.001600] [batchtime 0.394]
[epoch 147], [iter 19 / 176], [train main loss -2.418413], [lr 0.001600] [batchtime 0.395]
[epoch 147], [iter 20 / 176], [train main loss -2.343517], [lr 0.001600] [batchtime 0.395]
[epoch 147], [iter 21 / 176], [train main loss -2.305016], [lr 0.001600] [batchtime 0.396]
[epoch 147], [iter 22 / 176], [train main loss -2.225548], [lr 0.001600] [batchtime 0.396]
[epoch 147], [iter 23 / 176], [train main loss -2.185369], [lr 0.001600] [batchtime 0.396]
[epoch 147], [iter 24 / 176], [train main loss -2.139586], [lr 0.001600] [batchtime 0.396]
[epoch 147], [iter 25 / 176], [train main loss -2.063773], [lr 0.001600] [batchtime 0.397]
[epoch 147], [iter 26 / 176], [train main loss -2.101754], [lr 0.001600] [batchtime 0.397]
[epoch 147], [iter 27 / 176], [train main loss -2.106199], [lr 0.001600] [batchtime 0.397]
[epoch 147], [iter 28 / 176], [train main loss -2.128072], [lr 0.001600] [batchtime 0.397]
[epoch 147], [iter 29 / 176], [train main loss -1.944959], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 30 / 176], [train main loss -1.969374], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 31 / 176], [train main loss -1.988181], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 32 / 176], [train main loss -1.953693], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 33 / 176], [train main loss -1.929229], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 34 / 176], [train main loss -2.001763], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 35 / 176], [train main loss -1.957086], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 36 / 176], [train main loss -1.962462], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 37 / 176], [train main loss -1.977013], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 38 / 176], [train main loss -2.034448], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 39 / 176], [train main loss -2.018146], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 40 / 176], [train main loss -2.056580], [lr 0.001600] [batchtime 0.398]
[epoch 147], [iter 41 / 176], [train main loss -2.056057], [lr 0.001600] [batchtime 0.403]
[epoch 147], [iter 42 / 176], [train main loss -2.095359], [lr 0.001600] [batchtime 0.447]
[epoch 147], [iter 43 / 176], [train main loss -2.014468], [lr 0.001600] [batchtime 0.445]
[epoch 147], [iter 44 / 176], [train main loss -1.985353], [lr 0.001600] [batchtime 0.444]
[epoch 147], [iter 45 / 176], [train main loss -2.018137], [lr 0.001600] [batchtime 0.442]
[epoch 147], [iter 46 / 176], [train main loss -2.069239], [lr 0.001600] [batchtime 0.441]
[epoch 147], [iter 47 / 176], [train main loss -2.093475], [lr 0.001600] [batchtime 0.44]
[epoch 147], [iter 48 / 176], [train main loss -2.183238], [lr 0.001600] [batchtime 0.439]
[epoch 147], [iter 49 / 176], [train main loss -2.169016], [lr 0.001600] [batchtime 0.438]
[epoch 147], [iter 50 / 176], [train main loss -2.167097], [lr 0.001600] [batchtime 0.436]
[epoch 147], [iter 51 / 176], [train main loss -2.149875], [lr 0.001600] [batchtime 0.436]
[epoch 147], [iter 52 / 176], [train main loss -2.143647], [lr 0.001600] [batchtime 0.435]
[epoch 147], [iter 53 / 176], [train main loss -2.139829], [lr 0.001600] [batchtime 0.434]
[epoch 147], [iter 54 / 176], [train main loss -2.151190], [lr 0.001600] [batchtime 0.433]
[epoch 147], [iter 55 / 176], [train main loss -2.155594], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 56 / 176], [train main loss -2.116960], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 57 / 176], [train main loss -2.127153], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 58 / 176], [train main loss -2.156113], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 59 / 176], [train main loss -2.147566], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 60 / 176], [train main loss -2.199832], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 61 / 176], [train main loss -2.230903], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 62 / 176], [train main loss -2.241752], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 63 / 176], [train main loss -2.279185], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 64 / 176], [train main loss -2.254217], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 65 / 176], [train main loss -2.296971], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 66 / 176], [train main loss -2.274486], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 67 / 176], [train main loss -2.263423], [lr 0.001600] [batchtime 0.424]
[epoch 147], [iter 68 / 176], [train main loss -2.250737], [lr 0.001600] [batchtime 0.424]
[epoch 147], [iter 69 / 176], [train main loss -2.272639], [lr 0.001600] [batchtime 0.423]
[epoch 147], [iter 70 / 176], [train main loss -2.289124], [lr 0.001600] [batchtime 0.423]
[epoch 147], [iter 71 / 176], [train main loss -2.315333], [lr 0.001600] [batchtime 0.423]
[epoch 147], [iter 72 / 176], [train main loss -2.293287], [lr 0.001600] [batchtime 0.422]
[epoch 147], [iter 73 / 176], [train main loss -2.311916], [lr 0.001600] [batchtime 0.421]
[epoch 147], [iter 74 / 176], [train main loss -2.332905], [lr 0.001600] [batchtime 0.421]
[epoch 147], [iter 75 / 176], [train main loss -2.307731], [lr 0.001600] [batchtime 0.421]
[epoch 147], [iter 76 / 176], [train main loss -2.289576], [lr 0.001600] [batchtime 0.42]
[epoch 147], [iter 77 / 176], [train main loss -2.301482], [lr 0.001600] [batchtime 0.42]
[epoch 147], [iter 78 / 176], [train main loss -2.297472], [lr 0.001600] [batchtime 0.42]
[epoch 147], [iter 79 / 176], [train main loss -2.334640], [lr 0.001600] [batchtime 0.419]
[epoch 147], [iter 80 / 176], [train main loss -2.329568], [lr 0.001600] [batchtime 0.419]
[epoch 147], [iter 81 / 176], [train main loss -2.321274], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 82 / 176], [train main loss -2.291473], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 83 / 176], [train main loss -2.265594], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 84 / 176], [train main loss -2.264615], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 85 / 176], [train main loss -2.257665], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 86 / 176], [train main loss -2.254326], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 87 / 176], [train main loss -2.241802], [lr 0.001600] [batchtime 0.418]
[epoch 147], [iter 88 / 176], [train main loss -2.268489], [lr 0.001600] [batchtime 0.433]
[epoch 147], [iter 89 / 176], [train main loss -2.281187], [lr 0.001600] [batchtime 0.436]
[epoch 147], [iter 90 / 176], [train main loss -2.283668], [lr 0.001600] [batchtime 0.435]
[epoch 147], [iter 91 / 176], [train main loss -2.266328], [lr 0.001600] [batchtime 0.435]
[epoch 147], [iter 92 / 176], [train main loss -2.257659], [lr 0.001600] [batchtime 0.434]
[epoch 147], [iter 93 / 176], [train main loss -2.244889], [lr 0.001600] [batchtime 0.434]
[epoch 147], [iter 94 / 176], [train main loss -2.237841], [lr 0.001600] [batchtime 0.433]
[epoch 147], [iter 95 / 176], [train main loss -2.240606], [lr 0.001600] [batchtime 0.433]
[epoch 147], [iter 96 / 176], [train main loss -2.253583], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 97 / 176], [train main loss -2.233155], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 98 / 176], [train main loss -2.227136], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 99 / 176], [train main loss -2.216320], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 100 / 176], [train main loss -2.214720], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 101 / 176], [train main loss -2.207091], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 102 / 176], [train main loss -2.218266], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 103 / 176], [train main loss -2.197285], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 104 / 176], [train main loss -2.190872], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 105 / 176], [train main loss -2.199308], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 106 / 176], [train main loss -2.158643], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 107 / 176], [train main loss -2.167786], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 108 / 176], [train main loss -2.173261], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 109 / 176], [train main loss -2.198978], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 110 / 176], [train main loss -2.226755], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 111 / 176], [train main loss -2.232002], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 112 / 176], [train main loss -2.229806], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 113 / 176], [train main loss -2.235153], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 114 / 176], [train main loss -2.224890], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 115 / 176], [train main loss -2.202928], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 116 / 176], [train main loss -2.212803], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 117 / 176], [train main loss -2.226376], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 118 / 176], [train main loss -2.224684], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 119 / 176], [train main loss -2.214429], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 120 / 176], [train main loss -2.225571], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 121 / 176], [train main loss -2.212119], [lr 0.001600] [batchtime 0.434]
[epoch 147], [iter 122 / 176], [train main loss -2.203427], [lr 0.001600] [batchtime 0.433]
[epoch 147], [iter 123 / 176], [train main loss -2.202679], [lr 0.001600] [batchtime 0.433]
[epoch 147], [iter 124 / 176], [train main loss -2.201714], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 125 / 176], [train main loss -2.203504], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 126 / 176], [train main loss -2.224954], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 127 / 176], [train main loss -2.214603], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 128 / 176], [train main loss -2.209305], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 129 / 176], [train main loss -2.214018], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 130 / 176], [train main loss -2.217937], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 131 / 176], [train main loss -2.223574], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 132 / 176], [train main loss -2.222417], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 133 / 176], [train main loss -2.223072], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 134 / 176], [train main loss -2.232759], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 135 / 176], [train main loss -2.223630], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 136 / 176], [train main loss -2.196724], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 137 / 176], [train main loss -2.193107], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 138 / 176], [train main loss -2.194058], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 139 / 176], [train main loss -2.217647], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 140 / 176], [train main loss -2.222291], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 141 / 176], [train main loss -2.221437], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 142 / 176], [train main loss -2.219903], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 143 / 176], [train main loss -2.228928], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 144 / 176], [train main loss -2.237745], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 145 / 176], [train main loss -2.229740], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 146 / 176], [train main loss -2.237222], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 147 / 176], [train main loss -2.237180], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 148 / 176], [train main loss -2.232274], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 149 / 176], [train main loss -2.224348], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 150 / 176], [train main loss -2.214722], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 151 / 176], [train main loss -2.219878], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 152 / 176], [train main loss -2.238100], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 153 / 176], [train main loss -2.245260], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 154 / 176], [train main loss -2.224967], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 155 / 176], [train main loss -2.227837], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 156 / 176], [train main loss -2.234999], [lr 0.001600] [batchtime 0.425]
[epoch 147], [iter 157 / 176], [train main loss -2.216171], [lr 0.001600] [batchtime 0.426]
[epoch 147], [iter 158 / 176], [train main loss -2.221642], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 159 / 176], [train main loss -2.237067], [lr 0.001600] [batchtime 0.432]
[epoch 147], [iter 160 / 176], [train main loss -2.233638], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 161 / 176], [train main loss -2.232271], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 162 / 176], [train main loss -2.237137], [lr 0.001600] [batchtime 0.431]
[epoch 147], [iter 163 / 176], [train main loss -2.219997], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 164 / 176], [train main loss -2.210295], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 165 / 176], [train main loss -2.213884], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 166 / 176], [train main loss -2.203623], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 167 / 176], [train main loss -2.203557], [lr 0.001600] [batchtime 0.43]
[epoch 147], [iter 168 / 176], [train main loss -2.198201], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 169 / 176], [train main loss -2.188195], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 170 / 176], [train main loss -2.179618], [lr 0.001600] [batchtime 0.429]
[epoch 147], [iter 171 / 176], [train main loss -2.167151], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 172 / 176], [train main loss -2.159988], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 173 / 176], [train main loss -2.164399], [lr 0.001600] [batchtime 0.428]
[epoch 147], [iter 174 / 176], [train main loss -2.177317], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 175 / 176], [train main loss -2.180722], [lr 0.001600] [batchtime 0.427]
[epoch 147], [iter 176 / 176], [train main loss -2.169001], [lr 0.001600] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.93  35.61   0.02  0.03         0.98      0.97
   1  sidewalk          70.74   5.34   0.23  0.18         0.81      0.85
   2  building          86.85  25.01   0.06  0.09         0.94      0.92
   3  wall              18.77   0.15   3.01  1.32         0.25      0.43
   4  fence             26.09   0.39   2.26  0.57         0.31      0.64
   5  pole              40.49   0.58   0.96  0.51         0.51      0.66
   6  traffic light     21.08   0.04   3.17  0.57         0.24      0.64
   7  traffic sign      29.29   0.18   2.16  0.26         0.32      0.79
   8  vegetation        83.61  11.74   0.05  0.14         0.95      0.87
   9  terrain           41.67   0.39   0.90  0.50         0.53      0.67
  10  sky               93.86   3.75   0.03  0.03         0.97      0.97
  11  person            56.17   1.10   0.40  0.38         0.72      0.72
  12  rider             13.63   0.01   5.36  0.98         0.16      0.51
  13  car               86.75   6.72   0.05  0.10         0.95      0.91
  14  truck              1.76   0.01  55.54  0.38         0.02      0.72
  15  bus               17.31   0.04   1.07  3.71         0.48      0.21
  16  train             38.14   0.08   1.22  0.40         0.45      0.72
  17  motorcycle         5.76   0.01  15.80  0.55         0.06      0.64
  18  bicycle           42.95   0.26   0.49  0.83         0.67      0.54
Mean: 45.78
-----------------------------------------------------------------------------------------------------------
this : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 148], [iter 1 / 176], [train main loss -1.229098], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 2 / 176], [train main loss -1.380338], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 3 / 176], [train main loss -0.690872], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 4 / 176], [train main loss -0.493283], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 5 / 176], [train main loss -0.645379], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 6 / 176], [train main loss -1.119823], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 7 / 176], [train main loss -1.435732], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 8 / 176], [train main loss -1.383533], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 9 / 176], [train main loss -1.394220], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 10 / 176], [train main loss -1.420150], [lr 0.001543] [batchtime 0]
[epoch 148], [iter 11 / 176], [train main loss -1.583580], [lr 0.001543] [batchtime 0.381]
[epoch 148], [iter 12 / 176], [train main loss -1.640800], [lr 0.001543] [batchtime 0.382]
[epoch 148], [iter 13 / 176], [train main loss -1.530298], [lr 0.001543] [batchtime 0.385]
[epoch 148], [iter 14 / 176], [train main loss -1.648964], [lr 0.001543] [batchtime 0.388]
[epoch 148], [iter 15 / 176], [train main loss -1.751451], [lr 0.001543] [batchtime 0.392]
[epoch 148], [iter 16 / 176], [train main loss -1.725966], [lr 0.001543] [batchtime 0.395]
[epoch 148], [iter 17 / 176], [train main loss -1.850481], [lr 0.001543] [batchtime 0.394]
[epoch 148], [iter 18 / 176], [train main loss -1.889588], [lr 0.001543] [batchtime 0.395]
[epoch 148], [iter 19 / 176], [train main loss -1.892981], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 20 / 176], [train main loss -2.015910], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 21 / 176], [train main loss -1.861060], [lr 0.001543] [batchtime 0.395]
[epoch 148], [iter 22 / 176], [train main loss -1.935703], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 23 / 176], [train main loss -1.955345], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 24 / 176], [train main loss -1.968032], [lr 0.001543] [batchtime 0.397]
[epoch 148], [iter 25 / 176], [train main loss -1.929565], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 26 / 176], [train main loss -1.920652], [lr 0.001543] [batchtime 0.397]
[epoch 148], [iter 27 / 176], [train main loss -1.933414], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 28 / 176], [train main loss -2.005182], [lr 0.001543] [batchtime 0.396]
[epoch 148], [iter 29 / 176], [train main loss -2.041839], [lr 0.001543] [batchtime 0.461]
[epoch 148], [iter 30 / 176], [train main loss -1.948649], [lr 0.001543] [batchtime 0.472]
[epoch 148], [iter 31 / 176], [train main loss -1.978426], [lr 0.001543] [batchtime 0.468]
[epoch 148], [iter 32 / 176], [train main loss -2.078640], [lr 0.001543] [batchtime 0.464]
[epoch 148], [iter 33 / 176], [train main loss -1.958277], [lr 0.001543] [batchtime 0.461]
[epoch 148], [iter 34 / 176], [train main loss -1.999202], [lr 0.001543] [batchtime 0.458]
[epoch 148], [iter 35 / 176], [train main loss -1.956633], [lr 0.001543] [batchtime 0.455]
[epoch 148], [iter 36 / 176], [train main loss -1.962670], [lr 0.001543] [batchtime 0.453]
[epoch 148], [iter 37 / 176], [train main loss -1.989365], [lr 0.001543] [batchtime 0.451]
[epoch 148], [iter 38 / 176], [train main loss -1.987136], [lr 0.001543] [batchtime 0.449]
[epoch 148], [iter 39 / 176], [train main loss -2.051517], [lr 0.001543] [batchtime 0.448]
[epoch 148], [iter 40 / 176], [train main loss -2.110840], [lr 0.001543] [batchtime 0.446]
[epoch 148], [iter 41 / 176], [train main loss -2.083082], [lr 0.001543] [batchtime 0.444]
[epoch 148], [iter 42 / 176], [train main loss -2.038240], [lr 0.001543] [batchtime 0.443]
[epoch 148], [iter 43 / 176], [train main loss -2.031712], [lr 0.001543] [batchtime 0.442]
[epoch 148], [iter 44 / 176], [train main loss -2.067117], [lr 0.001543] [batchtime 0.44]
[epoch 148], [iter 45 / 176], [train main loss -2.117487], [lr 0.001543] [batchtime 0.439]
[epoch 148], [iter 46 / 176], [train main loss -2.105716], [lr 0.001543] [batchtime 0.438]
[epoch 148], [iter 47 / 176], [train main loss -2.080821], [lr 0.001543] [batchtime 0.437]
[epoch 148], [iter 48 / 176], [train main loss -2.089337], [lr 0.001543] [batchtime 0.436]
[epoch 148], [iter 49 / 176], [train main loss -2.086125], [lr 0.001543] [batchtime 0.435]
[epoch 148], [iter 50 / 176], [train main loss -2.118796], [lr 0.001543] [batchtime 0.434]
[epoch 148], [iter 51 / 176], [train main loss -2.181779], [lr 0.001543] [batchtime 0.437]
[epoch 148], [iter 52 / 176], [train main loss -2.208983], [lr 0.001543] [batchtime 0.436]
[epoch 148], [iter 53 / 176], [train main loss -2.153073], [lr 0.001543] [batchtime 0.435]
[epoch 148], [iter 54 / 176], [train main loss -2.217890], [lr 0.001543] [batchtime 0.434]
[epoch 148], [iter 55 / 176], [train main loss -2.206938], [lr 0.001543] [batchtime 0.433]
[epoch 148], [iter 56 / 176], [train main loss -2.200550], [lr 0.001543] [batchtime 0.433]
[epoch 148], [iter 57 / 176], [train main loss -2.269525], [lr 0.001543] [batchtime 0.432]
[epoch 148], [iter 58 / 176], [train main loss -2.228464], [lr 0.001543] [batchtime 0.431]
[epoch 148], [iter 59 / 176], [train main loss -2.263240], [lr 0.001543] [batchtime 0.432]
[epoch 148], [iter 60 / 176], [train main loss -2.294039], [lr 0.001543] [batchtime 0.432]
[epoch 148], [iter 61 / 176], [train main loss -2.313215], [lr 0.001543] [batchtime 0.431]
[epoch 148], [iter 62 / 176], [train main loss -2.309263], [lr 0.001543] [batchtime 0.43]
[epoch 148], [iter 63 / 176], [train main loss -2.306762], [lr 0.001543] [batchtime 0.43]
[epoch 148], [iter 64 / 176], [train main loss -2.317627], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 65 / 176], [train main loss -2.332991], [lr 0.001543] [batchtime 0.428]
[epoch 148], [iter 66 / 176], [train main loss -2.337946], [lr 0.001543] [batchtime 0.428]
[epoch 148], [iter 67 / 176], [train main loss -2.296782], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 68 / 176], [train main loss -2.288234], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 69 / 176], [train main loss -2.273355], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 70 / 176], [train main loss -2.249590], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 71 / 176], [train main loss -2.258293], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 72 / 176], [train main loss -2.263289], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 73 / 176], [train main loss -2.258735], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 74 / 176], [train main loss -2.268648], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 75 / 176], [train main loss -2.287788], [lr 0.001543] [batchtime 0.431]
[epoch 148], [iter 76 / 176], [train main loss -2.260338], [lr 0.001543] [batchtime 0.433]
[epoch 148], [iter 77 / 176], [train main loss -2.263566], [lr 0.001543] [batchtime 0.432]
[epoch 148], [iter 78 / 176], [train main loss -2.211356], [lr 0.001543] [batchtime 0.432]
[epoch 148], [iter 79 / 176], [train main loss -2.235367], [lr 0.001543] [batchtime 0.431]
[epoch 148], [iter 80 / 176], [train main loss -2.231819], [lr 0.001543] [batchtime 0.431]
[epoch 148], [iter 81 / 176], [train main loss -2.225412], [lr 0.001543] [batchtime 0.43]
[epoch 148], [iter 82 / 176], [train main loss -2.226354], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 83 / 176], [train main loss -2.221101], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 84 / 176], [train main loss -2.181105], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 85 / 176], [train main loss -2.181154], [lr 0.001543] [batchtime 0.428]
[epoch 148], [iter 86 / 176], [train main loss -2.174018], [lr 0.001543] [batchtime 0.428]
[epoch 148], [iter 87 / 176], [train main loss -2.162911], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 88 / 176], [train main loss -2.204018], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 89 / 176], [train main loss -2.200017], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 90 / 176], [train main loss -2.184476], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 91 / 176], [train main loss -2.177945], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 92 / 176], [train main loss -2.183867], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 93 / 176], [train main loss -2.174889], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 94 / 176], [train main loss -2.178038], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 95 / 176], [train main loss -2.167326], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 96 / 176], [train main loss -2.163419], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 97 / 176], [train main loss -2.188645], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 98 / 176], [train main loss -2.185779], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 99 / 176], [train main loss -2.176365], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 100 / 176], [train main loss -2.155600], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 101 / 176], [train main loss -2.157706], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 102 / 176], [train main loss -2.173276], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 103 / 176], [train main loss -2.163027], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 104 / 176], [train main loss -2.190743], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 105 / 176], [train main loss -2.184064], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 106 / 176], [train main loss -2.177036], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 107 / 176], [train main loss -2.195613], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 108 / 176], [train main loss -2.203541], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 109 / 176], [train main loss -2.199476], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 110 / 176], [train main loss -2.208467], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 111 / 176], [train main loss -2.186645], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 112 / 176], [train main loss -2.186389], [lr 0.001543] [batchtime 0.42]
[epoch 148], [iter 113 / 176], [train main loss -2.168926], [lr 0.001543] [batchtime 0.42]
[epoch 148], [iter 114 / 176], [train main loss -2.172117], [lr 0.001543] [batchtime 0.42]
[epoch 148], [iter 115 / 176], [train main loss -2.162382], [lr 0.001543] [batchtime 0.419]
[epoch 148], [iter 116 / 176], [train main loss -2.180217], [lr 0.001543] [batchtime 0.419]
[epoch 148], [iter 117 / 176], [train main loss -2.166531], [lr 0.001543] [batchtime 0.419]
[epoch 148], [iter 118 / 176], [train main loss -2.159419], [lr 0.001543] [batchtime 0.419]
[epoch 148], [iter 119 / 176], [train main loss -2.159034], [lr 0.001543] [batchtime 0.418]
[epoch 148], [iter 120 / 176], [train main loss -2.124899], [lr 0.001543] [batchtime 0.418]
[epoch 148], [iter 121 / 176], [train main loss -2.117154], [lr 0.001543] [batchtime 0.418]
[epoch 148], [iter 122 / 176], [train main loss -2.114407], [lr 0.001543] [batchtime 0.418]
[epoch 148], [iter 123 / 176], [train main loss -2.125262], [lr 0.001543] [batchtime 0.418]
[epoch 148], [iter 124 / 176], [train main loss -2.130209], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 125 / 176], [train main loss -2.116796], [lr 0.001543] [batchtime 0.428]
[epoch 148], [iter 126 / 176], [train main loss -2.130008], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 127 / 176], [train main loss -2.113153], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 128 / 176], [train main loss -2.116427], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 129 / 176], [train main loss -2.111404], [lr 0.001543] [batchtime 0.427]
[epoch 148], [iter 130 / 176], [train main loss -2.120223], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 131 / 176], [train main loss -2.123897], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 132 / 176], [train main loss -2.126242], [lr 0.001543] [batchtime 0.426]
[epoch 148], [iter 133 / 176], [train main loss -2.130463], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 134 / 176], [train main loss -2.133312], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 135 / 176], [train main loss -2.140386], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 136 / 176], [train main loss -2.125231], [lr 0.001543] [batchtime 0.425]
[epoch 148], [iter 137 / 176], [train main loss -2.103196], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 138 / 176], [train main loss -2.107996], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 139 / 176], [train main loss -2.091991], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 140 / 176], [train main loss -2.088118], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 141 / 176], [train main loss -2.086341], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 142 / 176], [train main loss -2.086425], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 143 / 176], [train main loss -2.089033], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 144 / 176], [train main loss -2.082988], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 145 / 176], [train main loss -2.095284], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 146 / 176], [train main loss -2.112787], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 147 / 176], [train main loss -2.120595], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 148 / 176], [train main loss -2.124544], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 149 / 176], [train main loss -2.131668], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 150 / 176], [train main loss -2.138123], [lr 0.001543] [batchtime 0.424]
[epoch 148], [iter 151 / 176], [train main loss -2.132960], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 152 / 176], [train main loss -2.151484], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 153 / 176], [train main loss -2.169997], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 154 / 176], [train main loss -2.157484], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 155 / 176], [train main loss -2.150915], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 156 / 176], [train main loss -2.147240], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 157 / 176], [train main loss -2.164477], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 158 / 176], [train main loss -2.152407], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 159 / 176], [train main loss -2.142638], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 160 / 176], [train main loss -2.144346], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 161 / 176], [train main loss -2.150489], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 162 / 176], [train main loss -2.140101], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 163 / 176], [train main loss -2.114961], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 164 / 176], [train main loss -2.113629], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 165 / 176], [train main loss -2.112100], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 166 / 176], [train main loss -2.109457], [lr 0.001543] [batchtime 0.421]
[epoch 148], [iter 167 / 176], [train main loss -2.108776], [lr 0.001543] [batchtime 0.42]
[epoch 148], [iter 168 / 176], [train main loss -2.119773], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 169 / 176], [train main loss -2.118643], [lr 0.001543] [batchtime 0.422]
[epoch 148], [iter 170 / 176], [train main loss -2.122689], [lr 0.001543] [batchtime 0.423]
[epoch 148], [iter 171 / 176], [train main loss -2.125760], [lr 0.001543] [batchtime 0.43]
[epoch 148], [iter 172 / 176], [train main loss -2.137248], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 173 / 176], [train main loss -2.132516], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 174 / 176], [train main loss -2.126301], [lr 0.001543] [batchtime 0.429]
[epoch 148], [iter 175 / 176], [train main loss -2.107193], [lr 0.001543] [batchtime 0.428]
[epoch 148], [iter 176 / 176], [train main loss -2.113713], [lr 0.001543] [batchtime 0.428]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.37  35.16   0.03  0.03         0.97      0.98
   1  sidewalk          69.49   5.43   0.21  0.23         0.82      0.82
   2  building          86.68  24.96   0.07  0.09         0.94      0.92
   3  wall              17.91   0.16   2.59  2.00         0.28      0.33
   4  fence             27.82   0.46   1.74  0.86         0.37      0.54
   5  pole              40.32   0.58   0.95  0.53         0.51      0.65
   6  traffic light     20.91   0.04   3.23  0.55         0.24      0.65
   7  traffic sign      31.39   0.19   1.87  0.31         0.35      0.76
   8  vegetation        84.03  11.70   0.06  0.13         0.95      0.88
   9  terrain           41.94   0.39   0.89  0.49         0.53      0.67
  10  sky               94.14   3.77   0.03  0.03         0.97      0.97
  11  person            54.95   1.04   0.47  0.35         0.68      0.74
  12  rider             13.58   0.01   5.33  1.04         0.16      0.49
  13  car               86.17   6.64   0.07  0.09         0.94      0.91
  14  truck              2.42   0.01  39.47  0.77         0.02      0.57
  15  bus               14.58   0.04   0.93  4.93         0.52      0.17
  16  train             35.67   0.11   0.69  1.11         0.59      0.47
  17  motorcycle         4.78   0.01  18.92  0.99         0.05      0.50
  18  bicycle           40.54   0.28   0.38  1.09         0.73      0.48
Mean: 45.35
-----------------------------------------------------------------------------------------------------------
this : [epoch 148], [val loss 0.28600], [acc 0.90991], [acc_cls 0.55833], [mean_iu 0.45352], [fwavacc 0.84595]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 149], [iter 1 / 176], [train main loss -4.886543], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 2 / 176], [train main loss -3.560965], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 3 / 176], [train main loss -2.882210], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 4 / 176], [train main loss -2.631279], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 5 / 176], [train main loss -2.276316], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 6 / 176], [train main loss -1.944084], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 7 / 176], [train main loss -2.346815], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 8 / 176], [train main loss -2.223978], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 9 / 176], [train main loss -2.086757], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 10 / 176], [train main loss -2.128867], [lr 0.001486] [batchtime 0]
[epoch 149], [iter 11 / 176], [train main loss -2.101249], [lr 0.001486] [batchtime 0.366]
[epoch 149], [iter 12 / 176], [train main loss -2.116406], [lr 0.001486] [batchtime 0.382]
[epoch 149], [iter 13 / 176], [train main loss -2.025198], [lr 0.001486] [batchtime 0.39]
[epoch 149], [iter 14 / 176], [train main loss -1.904920], [lr 0.001486] [batchtime 0.393]
[epoch 149], [iter 15 / 176], [train main loss -1.995537], [lr 0.001486] [batchtime 0.394]
[epoch 149], [iter 16 / 176], [train main loss -2.125727], [lr 0.001486] [batchtime 0.396]
[epoch 149], [iter 17 / 176], [train main loss -2.258675], [lr 0.001486] [batchtime 0.396]
[epoch 149], [iter 18 / 176], [train main loss -2.342632], [lr 0.001486] [batchtime 0.396]
[epoch 149], [iter 19 / 176], [train main loss -2.227509], [lr 0.001486] [batchtime 0.395]
[epoch 149], [iter 20 / 176], [train main loss -2.283417], [lr 0.001486] [batchtime 0.395]
[epoch 149], [iter 21 / 176], [train main loss -2.333181], [lr 0.001486] [batchtime 0.395]
[epoch 149], [iter 22 / 176], [train main loss -2.248708], [lr 0.001486] [batchtime 0.395]
[epoch 149], [iter 23 / 176], [train main loss -2.357666], [lr 0.001486] [batchtime 0.395]
[epoch 149], [iter 24 / 176], [train main loss -2.328726], [lr 0.001486] [batchtime 0.396]
[epoch 149], [iter 25 / 176], [train main loss -2.281645], [lr 0.001486] [batchtime 0.399]
[epoch 149], [iter 26 / 176], [train main loss -2.257366], [lr 0.001486] [batchtime 0.411]
[epoch 149], [iter 27 / 176], [train main loss -2.327951], [lr 0.001486] [batchtime 0.41]
[epoch 149], [iter 28 / 176], [train main loss -2.314479], [lr 0.001486] [batchtime 0.41]
[epoch 149], [iter 29 / 176], [train main loss -2.358928], [lr 0.001486] [batchtime 0.409]
[epoch 149], [iter 30 / 176], [train main loss -2.381186], [lr 0.001486] [batchtime 0.408]
[epoch 149], [iter 31 / 176], [train main loss -2.449077], [lr 0.001486] [batchtime 0.408]
[epoch 149], [iter 32 / 176], [train main loss -2.535789], [lr 0.001486] [batchtime 0.408]
[epoch 149], [iter 33 / 176], [train main loss -2.463680], [lr 0.001486] [batchtime 0.407]
[epoch 149], [iter 34 / 176], [train main loss -2.373298], [lr 0.001486] [batchtime 0.407]
[epoch 149], [iter 35 / 176], [train main loss -2.364660], [lr 0.001486] [batchtime 0.406]
[epoch 149], [iter 36 / 176], [train main loss -2.392171], [lr 0.001486] [batchtime 0.406]
[epoch 149], [iter 37 / 176], [train main loss -2.333953], [lr 0.001486] [batchtime 0.405]
[epoch 149], [iter 38 / 176], [train main loss -2.314903], [lr 0.001486] [batchtime 0.405]
[epoch 149], [iter 39 / 176], [train main loss -2.375484], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 40 / 176], [train main loss -2.367894], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 41 / 176], [train main loss -2.396176], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 42 / 176], [train main loss -2.421199], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 43 / 176], [train main loss -2.465674], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 44 / 176], [train main loss -2.425885], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 45 / 176], [train main loss -2.406898], [lr 0.001486] [batchtime 0.404]
[epoch 149], [iter 46 / 176], [train main loss -2.422252], [lr 0.001486] [batchtime 0.403]
[epoch 149], [iter 47 / 176], [train main loss -2.390472], [lr 0.001486] [batchtime 0.403]
[epoch 149], [iter 48 / 176], [train main loss -2.395743], [lr 0.001486] [batchtime 0.403]
[epoch 149], [iter 49 / 176], [train main loss -2.374934], [lr 0.001486] [batchtime 0.403]
[epoch 149], [iter 50 / 176], [train main loss -2.410851], [lr 0.001486] [batchtime 0.406]
[epoch 149], [iter 51 / 176], [train main loss -2.437965], [lr 0.001486] [batchtime 0.427]
[epoch 149], [iter 52 / 176], [train main loss -2.426922], [lr 0.001486] [batchtime 0.426]
[epoch 149], [iter 53 / 176], [train main loss -2.443017], [lr 0.001486] [batchtime 0.426]
[epoch 149], [iter 54 / 176], [train main loss -2.418429], [lr 0.001486] [batchtime 0.425]
[epoch 149], [iter 55 / 176], [train main loss -2.424054], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 56 / 176], [train main loss -2.425938], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 57 / 176], [train main loss -2.403053], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 58 / 176], [train main loss -2.430495], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 59 / 176], [train main loss -2.395416], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 60 / 176], [train main loss -2.418280], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 61 / 176], [train main loss -2.439338], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 62 / 176], [train main loss -2.455953], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 63 / 176], [train main loss -2.457244], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 64 / 176], [train main loss -2.438564], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 65 / 176], [train main loss -2.476231], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 66 / 176], [train main loss -2.451187], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 67 / 176], [train main loss -2.462095], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 68 / 176], [train main loss -2.493417], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 69 / 176], [train main loss -2.514275], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 70 / 176], [train main loss -2.504576], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 71 / 176], [train main loss -2.465043], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 72 / 176], [train main loss -2.467587], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 73 / 176], [train main loss -2.496048], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 74 / 176], [train main loss -2.496419], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 75 / 176], [train main loss -2.526427], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 76 / 176], [train main loss -2.473211], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 77 / 176], [train main loss -2.470020], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 78 / 176], [train main loss -2.455963], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 79 / 176], [train main loss -2.501506], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 80 / 176], [train main loss -2.518115], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 81 / 176], [train main loss -2.495031], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 82 / 176], [train main loss -2.466114], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 83 / 176], [train main loss -2.497965], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 84 / 176], [train main loss -2.491577], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 85 / 176], [train main loss -2.477941], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 86 / 176], [train main loss -2.478404], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 87 / 176], [train main loss -2.472516], [lr 0.001486] [batchtime 0.417]
[epoch 149], [iter 88 / 176], [train main loss -2.451264], [lr 0.001486] [batchtime 0.417]
[epoch 149], [iter 89 / 176], [train main loss -2.444547], [lr 0.001486] [batchtime 0.417]
[epoch 149], [iter 90 / 176], [train main loss -2.462793], [lr 0.001486] [batchtime 0.417]
[epoch 149], [iter 91 / 176], [train main loss -2.463303], [lr 0.001486] [batchtime 0.416]
[epoch 149], [iter 92 / 176], [train main loss -2.456318], [lr 0.001486] [batchtime 0.416]
[epoch 149], [iter 93 / 176], [train main loss -2.428586], [lr 0.001486] [batchtime 0.416]
[epoch 149], [iter 94 / 176], [train main loss -2.418635], [lr 0.001486] [batchtime 0.416]
[epoch 149], [iter 95 / 176], [train main loss -2.397110], [lr 0.001486] [batchtime 0.415]
[epoch 149], [iter 96 / 176], [train main loss -2.394198], [lr 0.001486] [batchtime 0.415]
[epoch 149], [iter 97 / 176], [train main loss -2.370383], [lr 0.001486] [batchtime 0.416]
[epoch 149], [iter 98 / 176], [train main loss -2.392044], [lr 0.001486] [batchtime 0.427]
[epoch 149], [iter 99 / 176], [train main loss -2.391691], [lr 0.001486] [batchtime 0.426]
[epoch 149], [iter 100 / 176], [train main loss -2.412194], [lr 0.001486] [batchtime 0.426]
[epoch 149], [iter 101 / 176], [train main loss -2.412562], [lr 0.001486] [batchtime 0.425]
[epoch 149], [iter 102 / 176], [train main loss -2.411723], [lr 0.001486] [batchtime 0.425]
[epoch 149], [iter 103 / 176], [train main loss -2.419432], [lr 0.001486] [batchtime 0.425]
[epoch 149], [iter 104 / 176], [train main loss -2.411872], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 105 / 176], [train main loss -2.454335], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 106 / 176], [train main loss -2.481572], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 107 / 176], [train main loss -2.481262], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 108 / 176], [train main loss -2.467772], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 109 / 176], [train main loss -2.467505], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 110 / 176], [train main loss -2.473121], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 111 / 176], [train main loss -2.485655], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 112 / 176], [train main loss -2.474315], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 113 / 176], [train main loss -2.465859], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 114 / 176], [train main loss -2.462594], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 115 / 176], [train main loss -2.434297], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 116 / 176], [train main loss -2.403401], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 117 / 176], [train main loss -2.406425], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 118 / 176], [train main loss -2.386674], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 119 / 176], [train main loss -2.386550], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 120 / 176], [train main loss -2.400859], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 121 / 176], [train main loss -2.390334], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 122 / 176], [train main loss -2.396343], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 123 / 176], [train main loss -2.385721], [lr 0.001486] [batchtime 0.424]
[epoch 149], [iter 124 / 176], [train main loss -2.374612], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 125 / 176], [train main loss -2.394593], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 126 / 176], [train main loss -2.420081], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 127 / 176], [train main loss -2.401370], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 128 / 176], [train main loss -2.402057], [lr 0.001486] [batchtime 0.423]
[epoch 149], [iter 129 / 176], [train main loss -2.394745], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 130 / 176], [train main loss -2.387241], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 131 / 176], [train main loss -2.381548], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 132 / 176], [train main loss -2.380853], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 133 / 176], [train main loss -2.387582], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 134 / 176], [train main loss -2.390130], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 135 / 176], [train main loss -2.397010], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 136 / 176], [train main loss -2.386115], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 137 / 176], [train main loss -2.413280], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 138 / 176], [train main loss -2.392833], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 139 / 176], [train main loss -2.377479], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 140 / 176], [train main loss -2.386670], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 141 / 176], [train main loss -2.388605], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 142 / 176], [train main loss -2.379912], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 143 / 176], [train main loss -2.377529], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 144 / 176], [train main loss -2.383201], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 145 / 176], [train main loss -2.373211], [lr 0.001486] [batchtime 0.422]
[epoch 149], [iter 146 / 176], [train main loss -2.367317], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 147 / 176], [train main loss -2.369180], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 148 / 176], [train main loss -2.374125], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 149 / 176], [train main loss -2.363733], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 150 / 176], [train main loss -2.363539], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 151 / 176], [train main loss -2.360639], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 152 / 176], [train main loss -2.377298], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 153 / 176], [train main loss -2.377240], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 154 / 176], [train main loss -2.374385], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 155 / 176], [train main loss -2.367423], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 156 / 176], [train main loss -2.358461], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 157 / 176], [train main loss -2.355175], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 158 / 176], [train main loss -2.373001], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 159 / 176], [train main loss -2.362693], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 160 / 176], [train main loss -2.354791], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 161 / 176], [train main loss -2.371269], [lr 0.001486] [batchtime 0.419]
[epoch 149], [iter 162 / 176], [train main loss -2.376021], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 163 / 176], [train main loss -2.380449], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 164 / 176], [train main loss -2.392946], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 165 / 176], [train main loss -2.388054], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 166 / 176], [train main loss -2.378588], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 167 / 176], [train main loss -2.386386], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 168 / 176], [train main loss -2.374917], [lr 0.001486] [batchtime 0.418]
[epoch 149], [iter 169 / 176], [train main loss -2.363771], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 170 / 176], [train main loss -2.365167], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 171 / 176], [train main loss -2.377079], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 172 / 176], [train main loss -2.374966], [lr 0.001486] [batchtime 0.421]
[epoch 149], [iter 173 / 176], [train main loss -2.350962], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 174 / 176], [train main loss -2.354750], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 175 / 176], [train main loss -2.355698], [lr 0.001486] [batchtime 0.42]
[epoch 149], [iter 176 / 176], [train main loss -2.334852], [lr 0.001486] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.99  35.60   0.02  0.03         0.98      0.97
   1  sidewalk          70.74   5.30   0.24  0.17         0.80      0.85
   2  building          86.85  24.97   0.06  0.09         0.94      0.92
   3  wall              20.35   0.17   2.43  1.49         0.29      0.40
   4  fence             26.52   0.41   2.11  0.67         0.32      0.60
   5  pole              39.97   0.56   1.02  0.48         0.49      0.68
   6  traffic light     19.81   0.03   3.63  0.42         0.22      0.70
   7  traffic sign      28.69   0.17   2.24  0.25         0.31      0.80
   8  vegetation        83.28  11.77   0.05  0.15         0.95      0.87
   9  terrain           41.72   0.39   0.88  0.51         0.53      0.66
  10  sky               93.83   3.75   0.03  0.03         0.97      0.97
  11  person            55.20   1.04   0.48  0.34         0.68      0.75
  12  rider             12.69   0.01   6.02  0.86         0.14      0.54
  13  car               86.65   6.72   0.05  0.10         0.95      0.91
  14  truck              1.78   0.01  54.76  0.51         0.02      0.66
  15  bus               16.46   0.04   0.98  4.09         0.50      0.20
  16  train             38.12   0.09   1.06  0.57         0.49      0.64
  17  motorcycle         5.64   0.01  16.16  0.56         0.06      0.64
  18  bicycle           40.62   0.27   0.44  1.02         0.69      0.50
Mean: 45.47
-----------------------------------------------------------------------------------------------------------
this : [epoch 149], [val loss 0.30513], [acc 0.91311], [acc_cls 0.54399], [mean_iu 0.45468], [fwavacc 0.84863]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 150], [iter 1 / 176], [train main loss -4.900723], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 2 / 176], [train main loss -2.851706], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 3 / 176], [train main loss -2.354825], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 4 / 176], [train main loss -2.917739], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 5 / 176], [train main loss -2.437372], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 6 / 176], [train main loss -1.955599], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 7 / 176], [train main loss -1.724592], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 8 / 176], [train main loss -1.375341], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 9 / 176], [train main loss -1.394210], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 10 / 176], [train main loss -1.676587], [lr 0.001429] [batchtime 0]
[epoch 150], [iter 11 / 176], [train main loss -1.962889], [lr 0.001429] [batchtime 0.364]
[epoch 150], [iter 12 / 176], [train main loss -2.004393], [lr 0.001429] [batchtime 0.381]
[epoch 150], [iter 13 / 176], [train main loss -1.900918], [lr 0.001429] [batchtime 0.386]
[epoch 150], [iter 14 / 176], [train main loss -1.976510], [lr 0.001429] [batchtime 0.389]
[epoch 150], [iter 15 / 176], [train main loss -2.204182], [lr 0.001429] [batchtime 0.394]
[epoch 150], [iter 16 / 176], [train main loss -2.140223], [lr 0.001429] [batchtime 0.394]
[epoch 150], [iter 17 / 176], [train main loss -2.017473], [lr 0.001429] [batchtime 0.395]
[epoch 150], [iter 18 / 176], [train main loss -1.947024], [lr 0.001429] [batchtime 0.396]
[epoch 150], [iter 19 / 176], [train main loss -1.994014], [lr 0.001429] [batchtime 0.396]
[epoch 150], [iter 20 / 176], [train main loss -2.039057], [lr 0.001429] [batchtime 0.397]
[epoch 150], [iter 21 / 176], [train main loss -1.949099], [lr 0.001429] [batchtime 0.396]
[epoch 150], [iter 22 / 176], [train main loss -1.984997], [lr 0.001429] [batchtime 0.396]
[epoch 150], [iter 23 / 176], [train main loss -2.046202], [lr 0.001429] [batchtime 0.397]
[epoch 150], [iter 24 / 176], [train main loss -1.990922], [lr 0.001429] [batchtime 0.4]
[epoch 150], [iter 25 / 176], [train main loss -2.093907], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 26 / 176], [train main loss -2.079948], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 27 / 176], [train main loss -2.093563], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 28 / 176], [train main loss -2.062763], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 29 / 176], [train main loss -2.156000], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 30 / 176], [train main loss -2.158126], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 31 / 176], [train main loss -2.236553], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 32 / 176], [train main loss -2.261619], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 33 / 176], [train main loss -2.187232], [lr 0.001429] [batchtime 0.4]
[epoch 150], [iter 34 / 176], [train main loss -2.254643], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 35 / 176], [train main loss -2.288810], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 36 / 176], [train main loss -2.296429], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 37 / 176], [train main loss -2.275799], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 38 / 176], [train main loss -2.280092], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 39 / 176], [train main loss -2.318545], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 40 / 176], [train main loss -2.336233], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 41 / 176], [train main loss -2.366441], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 42 / 176], [train main loss -2.353643], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 43 / 176], [train main loss -2.290300], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 44 / 176], [train main loss -2.331057], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 45 / 176], [train main loss -2.343344], [lr 0.001429] [batchtime 0.399]
[epoch 150], [iter 46 / 176], [train main loss -2.321711], [lr 0.001429] [batchtime 0.398]
[epoch 150], [iter 47 / 176], [train main loss -2.337144], [lr 0.001429] [batchtime 0.398]
[epoch 150], [iter 48 / 176], [train main loss -2.315534], [lr 0.001429] [batchtime 0.401]
[epoch 150], [iter 49 / 176], [train main loss -2.321670], [lr 0.001429] [batchtime 0.43]
[epoch 150], [iter 50 / 176], [train main loss -2.343749], [lr 0.001429] [batchtime 0.429]
[epoch 150], [iter 51 / 176], [train main loss -2.320261], [lr 0.001429] [batchtime 0.427]
[epoch 150], [iter 52 / 176], [train main loss -2.389220], [lr 0.001429] [batchtime 0.427]
[epoch 150], [iter 53 / 176], [train main loss -2.402580], [lr 0.001429] [batchtime 0.426]
[epoch 150], [iter 54 / 176], [train main loss -2.375594], [lr 0.001429] [batchtime 0.425]
[epoch 150], [iter 55 / 176], [train main loss -2.378613], [lr 0.001429] [batchtime 0.425]
[epoch 150], [iter 56 / 176], [train main loss -2.300652], [lr 0.001429] [batchtime 0.424]
[epoch 150], [iter 57 / 176], [train main loss -2.352072], [lr 0.001429] [batchtime 0.424]
[epoch 150], [iter 58 / 176], [train main loss -2.354779], [lr 0.001429] [batchtime 0.423]
[epoch 150], [iter 59 / 176], [train main loss -2.311727], [lr 0.001429] [batchtime 0.422]
[epoch 150], [iter 60 / 176], [train main loss -2.275542], [lr 0.001429] [batchtime 0.422]
[epoch 150], [iter 61 / 176], [train main loss -2.258344], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 62 / 176], [train main loss -2.234995], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 63 / 176], [train main loss -2.268961], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 64 / 176], [train main loss -2.225621], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 65 / 176], [train main loss -2.240089], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 66 / 176], [train main loss -2.216051], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 67 / 176], [train main loss -2.224864], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 68 / 176], [train main loss -2.260166], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 69 / 176], [train main loss -2.269276], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 70 / 176], [train main loss -2.266947], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 71 / 176], [train main loss -2.267963], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 72 / 176], [train main loss -2.239174], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 73 / 176], [train main loss -2.277514], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 74 / 176], [train main loss -2.262193], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 75 / 176], [train main loss -2.294258], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 76 / 176], [train main loss -2.263697], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 77 / 176], [train main loss -2.273581], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 78 / 176], [train main loss -2.281366], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 79 / 176], [train main loss -2.297992], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 80 / 176], [train main loss -2.296803], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 81 / 176], [train main loss -2.280693], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 82 / 176], [train main loss -2.278358], [lr 0.001429] [batchtime 0.413]
[epoch 150], [iter 83 / 176], [train main loss -2.252458], [lr 0.001429] [batchtime 0.413]
[epoch 150], [iter 84 / 176], [train main loss -2.268478], [lr 0.001429] [batchtime 0.413]
[epoch 150], [iter 85 / 176], [train main loss -2.271286], [lr 0.001429] [batchtime 0.413]
[epoch 150], [iter 86 / 176], [train main loss -2.289213], [lr 0.001429] [batchtime 0.412]
[epoch 150], [iter 87 / 176], [train main loss -2.289148], [lr 0.001429] [batchtime 0.412]
[epoch 150], [iter 88 / 176], [train main loss -2.266570], [lr 0.001429] [batchtime 0.412]
[epoch 150], [iter 89 / 176], [train main loss -2.239345], [lr 0.001429] [batchtime 0.412]
[epoch 150], [iter 90 / 176], [train main loss -2.250702], [lr 0.001429] [batchtime 0.411]
[epoch 150], [iter 91 / 176], [train main loss -2.222166], [lr 0.001429] [batchtime 0.411]
[epoch 150], [iter 92 / 176], [train main loss -2.191354], [lr 0.001429] [batchtime 0.411]
[epoch 150], [iter 93 / 176], [train main loss -2.162231], [lr 0.001429] [batchtime 0.411]
[epoch 150], [iter 94 / 176], [train main loss -2.150778], [lr 0.001429] [batchtime 0.41]
[epoch 150], [iter 95 / 176], [train main loss -2.160786], [lr 0.001429] [batchtime 0.41]
[epoch 150], [iter 96 / 176], [train main loss -2.182695], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 97 / 176], [train main loss -2.185095], [lr 0.001429] [batchtime 0.422]
[epoch 150], [iter 98 / 176], [train main loss -2.204223], [lr 0.001429] [batchtime 0.422]
[epoch 150], [iter 99 / 176], [train main loss -2.204479], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 100 / 176], [train main loss -2.214199], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 101 / 176], [train main loss -2.219377], [lr 0.001429] [batchtime 0.422]
[epoch 150], [iter 102 / 176], [train main loss -2.236255], [lr 0.001429] [batchtime 0.422]
[epoch 150], [iter 103 / 176], [train main loss -2.241608], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 104 / 176], [train main loss -2.237340], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 105 / 176], [train main loss -2.236175], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 106 / 176], [train main loss -2.227775], [lr 0.001429] [batchtime 0.421]
[epoch 150], [iter 107 / 176], [train main loss -2.259511], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 108 / 176], [train main loss -2.243025], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 109 / 176], [train main loss -2.240213], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 110 / 176], [train main loss -2.243666], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 111 / 176], [train main loss -2.221639], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 112 / 176], [train main loss -2.219094], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 113 / 176], [train main loss -2.224133], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 114 / 176], [train main loss -2.244485], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 115 / 176], [train main loss -2.212761], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 116 / 176], [train main loss -2.208898], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 117 / 176], [train main loss -2.209546], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 118 / 176], [train main loss -2.198955], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 119 / 176], [train main loss -2.201557], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 120 / 176], [train main loss -2.190983], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 121 / 176], [train main loss -2.196109], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 122 / 176], [train main loss -2.189915], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 123 / 176], [train main loss -2.200764], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 124 / 176], [train main loss -2.225961], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 125 / 176], [train main loss -2.252022], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 126 / 176], [train main loss -2.239367], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 127 / 176], [train main loss -2.245406], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 128 / 176], [train main loss -2.253825], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 129 / 176], [train main loss -2.247836], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 130 / 176], [train main loss -2.256928], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 131 / 176], [train main loss -2.252578], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 132 / 176], [train main loss -2.249899], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 133 / 176], [train main loss -2.247914], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 134 / 176], [train main loss -2.230629], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 135 / 176], [train main loss -2.245752], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 136 / 176], [train main loss -2.253586], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 137 / 176], [train main loss -2.253134], [lr 0.001429] [batchtime 0.415]
[epoch 150], [iter 138 / 176], [train main loss -2.239137], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 139 / 176], [train main loss -2.261637], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 140 / 176], [train main loss -2.247282], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 141 / 176], [train main loss -2.245446], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 142 / 176], [train main loss -2.262320], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 143 / 176], [train main loss -2.239142], [lr 0.001429] [batchtime 0.414]
[epoch 150], [iter 144 / 176], [train main loss -2.226692], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 145 / 176], [train main loss -2.227124], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 146 / 176], [train main loss -2.228715], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 147 / 176], [train main loss -2.231409], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 148 / 176], [train main loss -2.220898], [lr 0.001429] [batchtime 0.42]
[epoch 150], [iter 149 / 176], [train main loss -2.223144], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 150 / 176], [train main loss -2.219280], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 151 / 176], [train main loss -2.212302], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 152 / 176], [train main loss -2.216201], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 153 / 176], [train main loss -2.213769], [lr 0.001429] [batchtime 0.419]
[epoch 150], [iter 154 / 176], [train main loss -2.208420], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 155 / 176], [train main loss -2.206644], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 156 / 176], [train main loss -2.207209], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 157 / 176], [train main loss -2.228223], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 158 / 176], [train main loss -2.243750], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 159 / 176], [train main loss -2.239638], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 160 / 176], [train main loss -2.208726], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 161 / 176], [train main loss -2.192643], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 162 / 176], [train main loss -2.191169], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 163 / 176], [train main loss -2.183318], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 164 / 176], [train main loss -2.183475], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 165 / 176], [train main loss -2.178292], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 166 / 176], [train main loss -2.188481], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 167 / 176], [train main loss -2.190592], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 168 / 176], [train main loss -2.187869], [lr 0.001429] [batchtime 0.418]
[epoch 150], [iter 169 / 176], [train main loss -2.186707], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 170 / 176], [train main loss -2.182663], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 171 / 176], [train main loss -2.176985], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 172 / 176], [train main loss -2.166966], [lr 0.001429] [batchtime 0.417]
[epoch 150], [iter 173 / 176], [train main loss -2.178839], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 174 / 176], [train main loss -2.171025], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 175 / 176], [train main loss -2.156051], [lr 0.001429] [batchtime 0.416]
[epoch 150], [iter 176 / 176], [train main loss -2.144982], [lr 0.001429] [batchtime 0.416]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.90  35.36   0.03  0.03         0.97      0.98
   1  sidewalk          70.99   5.59   0.18  0.23         0.85      0.81
   2  building          86.94  24.93   0.07  0.08         0.94      0.92
   3  wall              20.14   0.18   2.33  1.64         0.30      0.38
   4  fence             25.41   0.39   2.28  0.66         0.31      0.60
   5  pole              40.76   0.62   0.82  0.63         0.55      0.61
   6  traffic light     20.99   0.04   3.16  0.61         0.24      0.62
   7  traffic sign      30.27   0.18   2.04  0.27         0.33      0.79
   8  vegetation        84.10  11.65   0.06  0.13         0.94      0.89
   9  terrain           40.57   0.37   0.99  0.47         0.50      0.68
  10  sky               93.92   3.74   0.03  0.03         0.97      0.97
  11  person            55.12   1.07   0.43  0.38         0.70      0.73
  12  rider             16.23   0.02   4.08  1.08         0.20      0.48
  13  car               86.93   6.71   0.05  0.10         0.95      0.91
  14  truck              2.00   0.01  48.66  0.36         0.02      0.74
  15  bus               16.96   0.05   0.90  4.00         0.53      0.20
  16  train             29.23   0.06   1.99  0.43         0.33      0.70
  17  motorcycle         6.37   0.01  13.92  0.79         0.07      0.56
  18  bicycle           38.10   0.30   0.32  1.30         0.76      0.43
Mean: 45.26
-----------------------------------------------------------------------------------------------------------
this : [epoch 150], [val loss 0.29193], [acc 0.91263], [acc_cls 0.54956], [mean_iu 0.45260], [fwavacc 0.84971]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 151], [iter 1 / 176], [train main loss -3.081208], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 2 / 176], [train main loss -1.850303], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 3 / 176], [train main loss -2.336359], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 4 / 176], [train main loss -2.268655], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 5 / 176], [train main loss -1.903220], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 6 / 176], [train main loss -1.699204], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 7 / 176], [train main loss -1.874556], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 8 / 176], [train main loss -1.711795], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 9 / 176], [train main loss -1.643683], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 10 / 176], [train main loss -1.344540], [lr 0.001371] [batchtime 0]
[epoch 151], [iter 11 / 176], [train main loss -1.331297], [lr 0.001371] [batchtime 0.368]
[epoch 151], [iter 12 / 176], [train main loss -1.502677], [lr 0.001371] [batchtime 0.388]
[epoch 151], [iter 13 / 176], [train main loss -1.522386], [lr 0.001371] [batchtime 0.39]
[epoch 151], [iter 14 / 176], [train main loss -1.315493], [lr 0.001371] [batchtime 0.395]
[epoch 151], [iter 15 / 176], [train main loss -1.532602], [lr 0.001371] [batchtime 0.396]
[epoch 151], [iter 16 / 176], [train main loss -1.412345], [lr 0.001371] [batchtime 0.395]
[epoch 151], [iter 17 / 176], [train main loss -1.593083], [lr 0.001371] [batchtime 0.396]
[epoch 151], [iter 18 / 176], [train main loss -1.613887], [lr 0.001371] [batchtime 0.395]
[epoch 151], [iter 19 / 176], [train main loss -1.711655], [lr 0.001371] [batchtime 0.396]
[epoch 151], [iter 20 / 176], [train main loss -1.688673], [lr 0.001371] [batchtime 0.397]
[epoch 151], [iter 21 / 176], [train main loss -1.790517], [lr 0.001371] [batchtime 0.398]
[epoch 151], [iter 22 / 176], [train main loss -1.736430], [lr 0.001371] [batchtime 0.398]
[epoch 151], [iter 23 / 176], [train main loss -1.755058], [lr 0.001371] [batchtime 0.398]
[epoch 151], [iter 24 / 176], [train main loss -1.694132], [lr 0.001371] [batchtime 0.398]
[epoch 151], [iter 25 / 176], [train main loss -1.703394], [lr 0.001371] [batchtime 0.406]
[epoch 151], [iter 26 / 176], [train main loss -1.741422], [lr 0.001371] [batchtime 0.416]
[epoch 151], [iter 27 / 176], [train main loss -1.800104], [lr 0.001371] [batchtime 0.415]
[epoch 151], [iter 28 / 176], [train main loss -1.826001], [lr 0.001371] [batchtime 0.415]
[epoch 151], [iter 29 / 176], [train main loss -1.861166], [lr 0.001371] [batchtime 0.414]
[epoch 151], [iter 30 / 176], [train main loss -1.817199], [lr 0.001371] [batchtime 0.413]
[epoch 151], [iter 31 / 176], [train main loss -1.769949], [lr 0.001371] [batchtime 0.412]
[epoch 151], [iter 32 / 176], [train main loss -1.786288], [lr 0.001371] [batchtime 0.412]
[epoch 151], [iter 33 / 176], [train main loss -1.748125], [lr 0.001371] [batchtime 0.412]
[epoch 151], [iter 34 / 176], [train main loss -1.721015], [lr 0.001371] [batchtime 0.411]
[epoch 151], [iter 35 / 176], [train main loss -1.672207], [lr 0.001371] [batchtime 0.411]
[epoch 151], [iter 36 / 176], [train main loss -1.642202], [lr 0.001371] [batchtime 0.41]
[epoch 151], [iter 37 / 176], [train main loss -1.650584], [lr 0.001371] [batchtime 0.409]
[epoch 151], [iter 38 / 176], [train main loss -1.665231], [lr 0.001371] [batchtime 0.409]
[epoch 151], [iter 39 / 176], [train main loss -1.689891], [lr 0.001371] [batchtime 0.409]
[epoch 151], [iter 40 / 176], [train main loss -1.665250], [lr 0.001371] [batchtime 0.408]
[epoch 151], [iter 41 / 176], [train main loss -1.681691], [lr 0.001371] [batchtime 0.408]
[epoch 151], [iter 42 / 176], [train main loss -1.667527], [lr 0.001371] [batchtime 0.407]
[epoch 151], [iter 43 / 176], [train main loss -1.674946], [lr 0.001371] [batchtime 0.407]
[epoch 151], [iter 44 / 176], [train main loss -1.623542], [lr 0.001371] [batchtime 0.407]
[epoch 151], [iter 45 / 176], [train main loss -1.670270], [lr 0.001371] [batchtime 0.407]
[epoch 151], [iter 46 / 176], [train main loss -1.673483], [lr 0.001371] [batchtime 0.406]
[epoch 151], [iter 47 / 176], [train main loss -1.706456], [lr 0.001371] [batchtime 0.406]
[epoch 151], [iter 48 / 176], [train main loss -1.719371], [lr 0.001371] [batchtime 0.406]
[epoch 151], [iter 49 / 176], [train main loss -1.749342], [lr 0.001371] [batchtime 0.41]
[epoch 151], [iter 50 / 176], [train main loss -1.776835], [lr 0.001371] [batchtime 0.44]
[epoch 151], [iter 51 / 176], [train main loss -1.782707], [lr 0.001371] [batchtime 0.438]
[epoch 151], [iter 52 / 176], [train main loss -1.782416], [lr 0.001371] [batchtime 0.437]
[epoch 151], [iter 53 / 176], [train main loss -1.782214], [lr 0.001371] [batchtime 0.44]
[epoch 151], [iter 54 / 176], [train main loss -1.780166], [lr 0.001371] [batchtime 0.439]
[epoch 151], [iter 55 / 176], [train main loss -1.795999], [lr 0.001371] [batchtime 0.438]
[epoch 151], [iter 56 / 176], [train main loss -1.825268], [lr 0.001371] [batchtime 0.437]
[epoch 151], [iter 57 / 176], [train main loss -1.817358], [lr 0.001371] [batchtime 0.436]
[epoch 151], [iter 58 / 176], [train main loss -1.869204], [lr 0.001371] [batchtime 0.435]
[epoch 151], [iter 59 / 176], [train main loss -1.869942], [lr 0.001371] [batchtime 0.434]
[epoch 151], [iter 60 / 176], [train main loss -1.850532], [lr 0.001371] [batchtime 0.434]
[epoch 151], [iter 61 / 176], [train main loss -1.909183], [lr 0.001371] [batchtime 0.433]
[epoch 151], [iter 62 / 176], [train main loss -1.923770], [lr 0.001371] [batchtime 0.433]
[epoch 151], [iter 63 / 176], [train main loss -1.912724], [lr 0.001371] [batchtime 0.432]
[epoch 151], [iter 64 / 176], [train main loss -1.878974], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 65 / 176], [train main loss -1.874825], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 66 / 176], [train main loss -1.864669], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 67 / 176], [train main loss -1.866798], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 68 / 176], [train main loss -1.837145], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 69 / 176], [train main loss -1.866739], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 70 / 176], [train main loss -1.864173], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 71 / 176], [train main loss -1.891620], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 72 / 176], [train main loss -1.907823], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 73 / 176], [train main loss -1.897891], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 74 / 176], [train main loss -1.876023], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 75 / 176], [train main loss -1.876047], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 76 / 176], [train main loss -1.901266], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 77 / 176], [train main loss -1.874566], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 78 / 176], [train main loss -1.862620], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 79 / 176], [train main loss -1.891995], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 80 / 176], [train main loss -1.904890], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 81 / 176], [train main loss -1.888061], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 82 / 176], [train main loss -1.907638], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 83 / 176], [train main loss -1.947173], [lr 0.001371] [batchtime 0.425]
[epoch 151], [iter 84 / 176], [train main loss -1.955509], [lr 0.001371] [batchtime 0.425]
[epoch 151], [iter 85 / 176], [train main loss -1.955706], [lr 0.001371] [batchtime 0.424]
[epoch 151], [iter 86 / 176], [train main loss -1.951132], [lr 0.001371] [batchtime 0.424]
[epoch 151], [iter 87 / 176], [train main loss -1.923954], [lr 0.001371] [batchtime 0.424]
[epoch 151], [iter 88 / 176], [train main loss -1.899525], [lr 0.001371] [batchtime 0.423]
[epoch 151], [iter 89 / 176], [train main loss -1.876179], [lr 0.001371] [batchtime 0.423]
[epoch 151], [iter 90 / 176], [train main loss -1.843753], [lr 0.001371] [batchtime 0.423]
[epoch 151], [iter 91 / 176], [train main loss -1.802467], [lr 0.001371] [batchtime 0.423]
[epoch 151], [iter 92 / 176], [train main loss -1.804904], [lr 0.001371] [batchtime 0.422]
[epoch 151], [iter 93 / 176], [train main loss -1.808571], [lr 0.001371] [batchtime 0.422]
[epoch 151], [iter 94 / 176], [train main loss -1.816786], [lr 0.001371] [batchtime 0.421]
[epoch 151], [iter 95 / 176], [train main loss -1.826308], [lr 0.001371] [batchtime 0.424]
[epoch 151], [iter 96 / 176], [train main loss -1.834051], [lr 0.001371] [batchtime 0.439]
[epoch 151], [iter 97 / 176], [train main loss -1.860486], [lr 0.001371] [batchtime 0.438]
[epoch 151], [iter 98 / 176], [train main loss -1.880483], [lr 0.001371] [batchtime 0.437]
[epoch 151], [iter 99 / 176], [train main loss -1.880004], [lr 0.001371] [batchtime 0.437]
[epoch 151], [iter 100 / 176], [train main loss -1.871422], [lr 0.001371] [batchtime 0.437]
[epoch 151], [iter 101 / 176], [train main loss -1.851629], [lr 0.001371] [batchtime 0.436]
[epoch 151], [iter 102 / 176], [train main loss -1.835719], [lr 0.001371] [batchtime 0.436]
[epoch 151], [iter 103 / 176], [train main loss -1.843370], [lr 0.001371] [batchtime 0.435]
[epoch 151], [iter 104 / 176], [train main loss -1.841920], [lr 0.001371] [batchtime 0.435]
[epoch 151], [iter 105 / 176], [train main loss -1.829434], [lr 0.001371] [batchtime 0.434]
[epoch 151], [iter 106 / 176], [train main loss -1.865132], [lr 0.001371] [batchtime 0.434]
[epoch 151], [iter 107 / 176], [train main loss -1.866841], [lr 0.001371] [batchtime 0.434]
[epoch 151], [iter 108 / 176], [train main loss -1.893341], [lr 0.001371] [batchtime 0.433]
[epoch 151], [iter 109 / 176], [train main loss -1.911291], [lr 0.001371] [batchtime 0.433]
[epoch 151], [iter 110 / 176], [train main loss -1.898411], [lr 0.001371] [batchtime 0.433]
[epoch 151], [iter 111 / 176], [train main loss -1.906113], [lr 0.001371] [batchtime 0.432]
[epoch 151], [iter 112 / 176], [train main loss -1.889232], [lr 0.001371] [batchtime 0.432]
[epoch 151], [iter 113 / 176], [train main loss -1.886168], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 114 / 176], [train main loss -1.879793], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 115 / 176], [train main loss -1.892272], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 116 / 176], [train main loss -1.886908], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 117 / 176], [train main loss -1.906676], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 118 / 176], [train main loss -1.922388], [lr 0.001371] [batchtime 0.432]
[epoch 151], [iter 119 / 176], [train main loss -1.931745], [lr 0.001371] [batchtime 0.432]
[epoch 151], [iter 120 / 176], [train main loss -1.934700], [lr 0.001371] [batchtime 0.432]
[epoch 151], [iter 121 / 176], [train main loss -1.939883], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 122 / 176], [train main loss -1.932318], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 123 / 176], [train main loss -1.908551], [lr 0.001371] [batchtime 0.431]
[epoch 151], [iter 124 / 176], [train main loss -1.900643], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 125 / 176], [train main loss -1.902273], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 126 / 176], [train main loss -1.918090], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 127 / 176], [train main loss -1.923243], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 128 / 176], [train main loss -1.917430], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 129 / 176], [train main loss -1.948146], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 130 / 176], [train main loss -1.932379], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 131 / 176], [train main loss -1.962479], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 132 / 176], [train main loss -1.964836], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 133 / 176], [train main loss -1.945019], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 134 / 176], [train main loss -1.958927], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 135 / 176], [train main loss -1.934194], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 136 / 176], [train main loss -1.941071], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 137 / 176], [train main loss -1.964716], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 138 / 176], [train main loss -1.960682], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 139 / 176], [train main loss -1.955772], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 140 / 176], [train main loss -1.968778], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 141 / 176], [train main loss -1.970901], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 142 / 176], [train main loss -1.991677], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 143 / 176], [train main loss -1.998137], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 144 / 176], [train main loss -1.987016], [lr 0.001371] [batchtime 0.43]
[epoch 151], [iter 145 / 176], [train main loss -1.976872], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 146 / 176], [train main loss -1.986244], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 147 / 176], [train main loss -1.977035], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 148 / 176], [train main loss -1.990505], [lr 0.001371] [batchtime 0.429]
[epoch 151], [iter 149 / 176], [train main loss -1.998040], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 150 / 176], [train main loss -1.993695], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 151 / 176], [train main loss -1.993330], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 152 / 176], [train main loss -1.991053], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 153 / 176], [train main loss -2.007886], [lr 0.001371] [batchtime 0.428]
[epoch 151], [iter 154 / 176], [train main loss -1.994762], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 155 / 176], [train main loss -2.004686], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 156 / 176], [train main loss -2.016510], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 157 / 176], [train main loss -2.012870], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 158 / 176], [train main loss -2.027948], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 159 / 176], [train main loss -2.036986], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 160 / 176], [train main loss -2.045358], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 161 / 176], [train main loss -2.032155], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 162 / 176], [train main loss -2.042640], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 163 / 176], [train main loss -2.053733], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 164 / 176], [train main loss -2.055558], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 165 / 176], [train main loss -2.073037], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 166 / 176], [train main loss -2.081535], [lr 0.001371] [batchtime 0.427]
[epoch 151], [iter 167 / 176], [train main loss -2.091359], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 168 / 176], [train main loss -2.094339], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 169 / 176], [train main loss -2.104365], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 170 / 176], [train main loss -2.101525], [lr 0.001371] [batchtime 0.426]
[epoch 151], [iter 171 / 176], [train main loss -2.087999], [lr 0.001371] [batchtime 0.425]
[epoch 151], [iter 172 / 176], [train main loss -2.102715], [lr 0.001371] [batchtime 0.425]
[epoch 151], [iter 173 / 176], [train main loss -2.082683], [lr 0.001371] [batchtime 0.425]
[epoch 151], [iter 174 / 176], [train main loss -2.071429], [lr 0.001371] [batchtime 0.424]
[epoch 151], [iter 175 / 176], [train main loss -2.067485], [lr 0.001371] [batchtime 0.424]
[epoch 151], [iter 176 / 176], [train main loss -2.050466], [lr 0.001371] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.82  35.50   0.02  0.03         0.98      0.97
   1  sidewalk          70.40   5.40   0.22  0.20         0.82      0.83
   2  building          86.94  24.99   0.06  0.09         0.94      0.92
   3  wall              19.24   0.15   2.84  1.36         0.26      0.42
   4  fence             27.36   0.43   1.97  0.69         0.34      0.59
   5  pole              40.16   0.56   1.01  0.47         0.50      0.68
   6  traffic light     20.86   0.04   3.24  0.56         0.24      0.64
   7  traffic sign      29.54   0.18   2.11  0.27         0.32      0.79
   8  vegetation        84.19  11.72   0.05  0.13         0.95      0.88
   9  terrain           42.11   0.39   0.86  0.51         0.54      0.66
  10  sky               93.94   3.75   0.03  0.03         0.97      0.97
  11  person            56.60   1.09   0.40  0.36         0.71      0.73
  12  rider             15.16   0.02   4.59  1.00         0.18      0.50
  13  car               86.68   6.71   0.05  0.10         0.95      0.91
  14  truck              1.63   0.01  59.91  0.60         0.02      0.62
  15  bus               15.04   0.05   0.76  4.88         0.57      0.17
  16  train             25.26   0.06   1.96  1.00         0.34      0.50
  17  motorcycle         6.98   0.01  12.75  0.58         0.07      0.63
  18  bicycle           42.21   0.26   0.49  0.88         0.67      0.53
Mean: 45.22
-----------------------------------------------------------------------------------------------------------
this : [epoch 151], [val loss 0.28819], [acc 0.91328], [acc_cls 0.54456], [mean_iu 0.45217], [fwavacc 0.84944]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 152], [iter 1 / 176], [train main loss -2.599012], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 2 / 176], [train main loss -1.827790], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 3 / 176], [train main loss -2.372986], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 4 / 176], [train main loss -2.301308], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 5 / 176], [train main loss -2.425082], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 6 / 176], [train main loss -1.972670], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 7 / 176], [train main loss -1.605932], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 8 / 176], [train main loss -1.476924], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 9 / 176], [train main loss -1.545868], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 10 / 176], [train main loss -1.583949], [lr 0.001314] [batchtime 0]
[epoch 152], [iter 11 / 176], [train main loss -1.575231], [lr 0.001314] [batchtime 0.369]
[epoch 152], [iter 12 / 176], [train main loss -1.599583], [lr 0.001314] [batchtime 0.384]
[epoch 152], [iter 13 / 176], [train main loss -1.774332], [lr 0.001314] [batchtime 0.39]
[epoch 152], [iter 14 / 176], [train main loss -1.789712], [lr 0.001314] [batchtime 0.391]
[epoch 152], [iter 15 / 176], [train main loss -1.795461], [lr 0.001314] [batchtime 0.393]
[epoch 152], [iter 16 / 176], [train main loss -1.881387], [lr 0.001314] [batchtime 0.394]
[epoch 152], [iter 17 / 176], [train main loss -2.031179], [lr 0.001314] [batchtime 0.394]
[epoch 152], [iter 18 / 176], [train main loss -2.104531], [lr 0.001314] [batchtime 0.395]
[epoch 152], [iter 19 / 176], [train main loss -2.068780], [lr 0.001314] [batchtime 0.396]
[epoch 152], [iter 20 / 176], [train main loss -1.989147], [lr 0.001314] [batchtime 0.397]
[epoch 152], [iter 21 / 176], [train main loss -2.008223], [lr 0.001314] [batchtime 0.397]
[epoch 152], [iter 22 / 176], [train main loss -1.941099], [lr 0.001314] [batchtime 0.397]
[epoch 152], [iter 23 / 176], [train main loss -1.955914], [lr 0.001314] [batchtime 0.398]
[epoch 152], [iter 24 / 176], [train main loss -2.007183], [lr 0.001314] [batchtime 0.404]
[epoch 152], [iter 25 / 176], [train main loss -1.973788], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 26 / 176], [train main loss -1.959560], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 27 / 176], [train main loss -2.005891], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 28 / 176], [train main loss -1.984613], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 29 / 176], [train main loss -1.909049], [lr 0.001314] [batchtime 0.412]
[epoch 152], [iter 30 / 176], [train main loss -1.884618], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 31 / 176], [train main loss -1.886204], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 32 / 176], [train main loss -1.834602], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 33 / 176], [train main loss -1.835170], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 34 / 176], [train main loss -1.793411], [lr 0.001314] [batchtime 0.41]
[epoch 152], [iter 35 / 176], [train main loss -1.825712], [lr 0.001314] [batchtime 0.41]
[epoch 152], [iter 36 / 176], [train main loss -1.944019], [lr 0.001314] [batchtime 0.41]
[epoch 152], [iter 37 / 176], [train main loss -1.928303], [lr 0.001314] [batchtime 0.409]
[epoch 152], [iter 38 / 176], [train main loss -1.916019], [lr 0.001314] [batchtime 0.408]
[epoch 152], [iter 39 / 176], [train main loss -1.907046], [lr 0.001314] [batchtime 0.408]
[epoch 152], [iter 40 / 176], [train main loss -1.936853], [lr 0.001314] [batchtime 0.408]
[epoch 152], [iter 41 / 176], [train main loss -1.962361], [lr 0.001314] [batchtime 0.408]
[epoch 152], [iter 42 / 176], [train main loss -1.946060], [lr 0.001314] [batchtime 0.407]
[epoch 152], [iter 43 / 176], [train main loss -2.012264], [lr 0.001314] [batchtime 0.407]
[epoch 152], [iter 44 / 176], [train main loss -2.093206], [lr 0.001314] [batchtime 0.407]
[epoch 152], [iter 45 / 176], [train main loss -2.043061], [lr 0.001314] [batchtime 0.407]
[epoch 152], [iter 46 / 176], [train main loss -2.041655], [lr 0.001314] [batchtime 0.407]
[epoch 152], [iter 47 / 176], [train main loss -2.043950], [lr 0.001314] [batchtime 0.406]
[epoch 152], [iter 48 / 176], [train main loss -2.063960], [lr 0.001314] [batchtime 0.408]
[epoch 152], [iter 49 / 176], [train main loss -2.062667], [lr 0.001314] [batchtime 0.426]
[epoch 152], [iter 50 / 176], [train main loss -2.101302], [lr 0.001314] [batchtime 0.425]
[epoch 152], [iter 51 / 176], [train main loss -2.065586], [lr 0.001314] [batchtime 0.424]
[epoch 152], [iter 52 / 176], [train main loss -2.118165], [lr 0.001314] [batchtime 0.423]
[epoch 152], [iter 53 / 176], [train main loss -2.078292], [lr 0.001314] [batchtime 0.422]
[epoch 152], [iter 54 / 176], [train main loss -2.055308], [lr 0.001314] [batchtime 0.422]
[epoch 152], [iter 55 / 176], [train main loss -2.056327], [lr 0.001314] [batchtime 0.421]
[epoch 152], [iter 56 / 176], [train main loss -1.980625], [lr 0.001314] [batchtime 0.421]
[epoch 152], [iter 57 / 176], [train main loss -1.991276], [lr 0.001314] [batchtime 0.42]
[epoch 152], [iter 58 / 176], [train main loss -1.982787], [lr 0.001314] [batchtime 0.42]
[epoch 152], [iter 59 / 176], [train main loss -1.969785], [lr 0.001314] [batchtime 0.42]
[epoch 152], [iter 60 / 176], [train main loss -1.944388], [lr 0.001314] [batchtime 0.419]
[epoch 152], [iter 61 / 176], [train main loss -1.971777], [lr 0.001314] [batchtime 0.419]
[epoch 152], [iter 62 / 176], [train main loss -2.011174], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 63 / 176], [train main loss -2.020781], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 64 / 176], [train main loss -2.083354], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 65 / 176], [train main loss -2.113752], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 66 / 176], [train main loss -2.140110], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 67 / 176], [train main loss -2.119844], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 68 / 176], [train main loss -2.110770], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 69 / 176], [train main loss -2.128390], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 70 / 176], [train main loss -2.116223], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 71 / 176], [train main loss -2.074581], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 72 / 176], [train main loss -2.051216], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 73 / 176], [train main loss -2.078279], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 74 / 176], [train main loss -2.066122], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 75 / 176], [train main loss -2.080160], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 76 / 176], [train main loss -2.086164], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 77 / 176], [train main loss -2.087119], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 78 / 176], [train main loss -2.075545], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 79 / 176], [train main loss -2.074453], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 80 / 176], [train main loss -2.050569], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 81 / 176], [train main loss -2.020648], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 82 / 176], [train main loss -1.990330], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 83 / 176], [train main loss -2.009739], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 84 / 176], [train main loss -1.992508], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 85 / 176], [train main loss -1.997263], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 86 / 176], [train main loss -2.016042], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 87 / 176], [train main loss -1.999430], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 88 / 176], [train main loss -1.963838], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 89 / 176], [train main loss -1.967015], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 90 / 176], [train main loss -1.931311], [lr 0.001314] [batchtime 0.412]
[epoch 152], [iter 91 / 176], [train main loss -1.931169], [lr 0.001314] [batchtime 0.412]
[epoch 152], [iter 92 / 176], [train main loss -1.943654], [lr 0.001314] [batchtime 0.412]
[epoch 152], [iter 93 / 176], [train main loss -1.930139], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 94 / 176], [train main loss -1.921997], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 95 / 176], [train main loss -1.899422], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 96 / 176], [train main loss -1.893731], [lr 0.001314] [batchtime 0.411]
[epoch 152], [iter 97 / 176], [train main loss -1.882569], [lr 0.001314] [batchtime 0.421]
[epoch 152], [iter 98 / 176], [train main loss -1.899376], [lr 0.001314] [batchtime 0.421]
[epoch 152], [iter 99 / 176], [train main loss -1.939758], [lr 0.001314] [batchtime 0.42]
[epoch 152], [iter 100 / 176], [train main loss -1.929035], [lr 0.001314] [batchtime 0.42]
[epoch 152], [iter 101 / 176], [train main loss -1.918739], [lr 0.001314] [batchtime 0.42]
[epoch 152], [iter 102 / 176], [train main loss -1.906073], [lr 0.001314] [batchtime 0.419]
[epoch 152], [iter 103 / 176], [train main loss -1.911591], [lr 0.001314] [batchtime 0.419]
[epoch 152], [iter 104 / 176], [train main loss -1.902876], [lr 0.001314] [batchtime 0.419]
[epoch 152], [iter 105 / 176], [train main loss -1.912192], [lr 0.001314] [batchtime 0.419]
[epoch 152], [iter 106 / 176], [train main loss -1.929119], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 107 / 176], [train main loss -1.941101], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 108 / 176], [train main loss -1.963311], [lr 0.001314] [batchtime 0.418]
[epoch 152], [iter 109 / 176], [train main loss -1.987285], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 110 / 176], [train main loss -1.966600], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 111 / 176], [train main loss -1.972837], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 112 / 176], [train main loss -1.954768], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 113 / 176], [train main loss -1.975662], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 114 / 176], [train main loss -1.961862], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 115 / 176], [train main loss -1.966122], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 116 / 176], [train main loss -1.940654], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 117 / 176], [train main loss -1.945203], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 118 / 176], [train main loss -1.951512], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 119 / 176], [train main loss -1.942327], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 120 / 176], [train main loss -1.931058], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 121 / 176], [train main loss -1.927328], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 122 / 176], [train main loss -1.918069], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 123 / 176], [train main loss -1.933846], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 124 / 176], [train main loss -1.928734], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 125 / 176], [train main loss -1.918417], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 126 / 176], [train main loss -1.900373], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 127 / 176], [train main loss -1.872608], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 128 / 176], [train main loss -1.889890], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 129 / 176], [train main loss -1.882168], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 130 / 176], [train main loss -1.879071], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 131 / 176], [train main loss -1.884127], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 132 / 176], [train main loss -1.884420], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 133 / 176], [train main loss -1.878791], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 134 / 176], [train main loss -1.886316], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 135 / 176], [train main loss -1.883261], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 136 / 176], [train main loss -1.882409], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 137 / 176], [train main loss -1.868649], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 138 / 176], [train main loss -1.857400], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 139 / 176], [train main loss -1.865585], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 140 / 176], [train main loss -1.884467], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 141 / 176], [train main loss -1.894220], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 142 / 176], [train main loss -1.888280], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 143 / 176], [train main loss -1.913672], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 144 / 176], [train main loss -1.939567], [lr 0.001314] [batchtime 0.412]
[epoch 152], [iter 145 / 176], [train main loss -1.941178], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 146 / 176], [train main loss -1.948257], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 147 / 176], [train main loss -1.956178], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 148 / 176], [train main loss -1.974286], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 149 / 176], [train main loss -1.974814], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 150 / 176], [train main loss -1.950741], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 151 / 176], [train main loss -1.942562], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 152 / 176], [train main loss -1.968789], [lr 0.001314] [batchtime 0.417]
[epoch 152], [iter 153 / 176], [train main loss -1.952781], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 154 / 176], [train main loss -1.970864], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 155 / 176], [train main loss -1.961304], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 156 / 176], [train main loss -1.956365], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 157 / 176], [train main loss -1.956703], [lr 0.001314] [batchtime 0.416]
[epoch 152], [iter 158 / 176], [train main loss -1.961620], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 159 / 176], [train main loss -1.965947], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 160 / 176], [train main loss -1.952853], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 161 / 176], [train main loss -1.953827], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 162 / 176], [train main loss -1.945767], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 163 / 176], [train main loss -1.947335], [lr 0.001314] [batchtime 0.415]
[epoch 152], [iter 164 / 176], [train main loss -1.971661], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 165 / 176], [train main loss -1.966901], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 166 / 176], [train main loss -1.962328], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 167 / 176], [train main loss -1.953935], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 168 / 176], [train main loss -1.957439], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 169 / 176], [train main loss -1.957393], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 170 / 176], [train main loss -1.940408], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 171 / 176], [train main loss -1.944680], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 172 / 176], [train main loss -1.943680], [lr 0.001314] [batchtime 0.414]
[epoch 152], [iter 173 / 176], [train main loss -1.943732], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 174 / 176], [train main loss -1.946603], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 175 / 176], [train main loss -1.942616], [lr 0.001314] [batchtime 0.413]
[epoch 152], [iter 176 / 176], [train main loss -1.932544], [lr 0.001314] [batchtime 0.413]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.89  35.60   0.02  0.03         0.98      0.97
   1  sidewalk          70.40   5.32   0.24  0.18         0.81      0.85
   2  building          87.04  25.23   0.05  0.10         0.95      0.91
   3  wall              18.79   0.16   2.78  1.54         0.26      0.39
   4  fence             27.05   0.41   2.08  0.62         0.32      0.62
   5  pole              40.12   0.57   0.99  0.50         0.50      0.67
   6  traffic light     20.32   0.03   3.48  0.44         0.22      0.70
   7  traffic sign      27.98   0.17   2.36  0.21         0.30      0.82
   8  vegetation        84.79  11.64   0.06  0.12         0.94      0.90
   9  terrain           40.79   0.37   0.97  0.48         0.51      0.67
  10  sky               93.95   3.77   0.03  0.04         0.97      0.96
  11  person            56.09   1.08   0.42  0.36         0.70      0.74
  12  rider             12.98   0.01   5.82  0.89         0.15      0.53
  13  car               87.04   6.68   0.06  0.09         0.94      0.92
  14  truck              1.29   0.00  76.08  0.57         0.01      0.64
  15  bus               16.40   0.05   0.89  4.21         0.53      0.19
  16  train             37.73   0.08   1.11  0.54         0.47      0.65
  17  motorcycle         5.33   0.01  17.25  0.51         0.05      0.66
  18  bicycle           42.49   0.27   0.45  0.91         0.69      0.52
Mean: 45.55
-----------------------------------------------------------------------------------------------------------
this : [epoch 152], [val loss 0.28623], [acc 0.91458], [acc_cls 0.54352], [mean_iu 0.45550], [fwavacc 0.85081]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 153], [iter 1 / 176], [train main loss -2.949018], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 2 / 176], [train main loss -3.245374], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 3 / 176], [train main loss -2.552371], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 4 / 176], [train main loss -2.095562], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 5 / 176], [train main loss -2.228393], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 6 / 176], [train main loss -2.461475], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 7 / 176], [train main loss -2.437697], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 8 / 176], [train main loss -2.430398], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 9 / 176], [train main loss -2.450884], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 10 / 176], [train main loss -2.380752], [lr 0.001257] [batchtime 0]
[epoch 153], [iter 11 / 176], [train main loss -2.227244], [lr 0.001257] [batchtime 0.377]
[epoch 153], [iter 12 / 176], [train main loss -2.345975], [lr 0.001257] [batchtime 0.386]
[epoch 153], [iter 13 / 176], [train main loss -2.375501], [lr 0.001257] [batchtime 0.39]
[epoch 153], [iter 14 / 176], [train main loss -2.441525], [lr 0.001257] [batchtime 0.397]
[epoch 153], [iter 15 / 176], [train main loss -2.325762], [lr 0.001257] [batchtime 0.396]
[epoch 153], [iter 16 / 176], [train main loss -2.423152], [lr 0.001257] [batchtime 0.395]
[epoch 153], [iter 17 / 176], [train main loss -2.331187], [lr 0.001257] [batchtime 0.395]
[epoch 153], [iter 18 / 176], [train main loss -2.298619], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 19 / 176], [train main loss -2.271268], [lr 0.001257] [batchtime 0.399]
[epoch 153], [iter 20 / 176], [train main loss -2.478754], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 21 / 176], [train main loss -2.573439], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 22 / 176], [train main loss -2.370303], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 23 / 176], [train main loss -2.393872], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 24 / 176], [train main loss -2.385523], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 25 / 176], [train main loss -2.320565], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 26 / 176], [train main loss -2.382952], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 27 / 176], [train main loss -2.270297], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 28 / 176], [train main loss -2.204979], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 29 / 176], [train main loss -2.275774], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 30 / 176], [train main loss -2.334665], [lr 0.001257] [batchtime 0.398]
[epoch 153], [iter 31 / 176], [train main loss -2.440216], [lr 0.001257] [batchtime 0.417]
[epoch 153], [iter 32 / 176], [train main loss -2.488381], [lr 0.001257] [batchtime 0.423]
[epoch 153], [iter 33 / 176], [train main loss -2.475773], [lr 0.001257] [batchtime 0.422]
[epoch 153], [iter 34 / 176], [train main loss -2.478840], [lr 0.001257] [batchtime 0.421]
[epoch 153], [iter 35 / 176], [train main loss -2.550593], [lr 0.001257] [batchtime 0.419]
[epoch 153], [iter 36 / 176], [train main loss -2.565848], [lr 0.001257] [batchtime 0.418]
[epoch 153], [iter 37 / 176], [train main loss -2.519750], [lr 0.001257] [batchtime 0.418]
[epoch 153], [iter 38 / 176], [train main loss -2.561516], [lr 0.001257] [batchtime 0.417]
[epoch 153], [iter 39 / 176], [train main loss -2.559258], [lr 0.001257] [batchtime 0.416]
[epoch 153], [iter 40 / 176], [train main loss -2.500457], [lr 0.001257] [batchtime 0.416]
[epoch 153], [iter 41 / 176], [train main loss -2.496459], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 42 / 176], [train main loss -2.504324], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 43 / 176], [train main loss -2.456653], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 44 / 176], [train main loss -2.450283], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 45 / 176], [train main loss -2.446895], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 46 / 176], [train main loss -2.442673], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 47 / 176], [train main loss -2.447902], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 48 / 176], [train main loss -2.430860], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 49 / 176], [train main loss -2.415618], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 50 / 176], [train main loss -2.444472], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 51 / 176], [train main loss -2.443359], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 52 / 176], [train main loss -2.416651], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 53 / 176], [train main loss -2.398547], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 54 / 176], [train main loss -2.393785], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 55 / 176], [train main loss -2.364013], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 56 / 176], [train main loss -2.372380], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 57 / 176], [train main loss -2.362515], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 58 / 176], [train main loss -2.319658], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 59 / 176], [train main loss -2.380159], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 60 / 176], [train main loss -2.373806], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 61 / 176], [train main loss -2.405633], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 62 / 176], [train main loss -2.398290], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 63 / 176], [train main loss -2.393150], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 64 / 176], [train main loss -2.420428], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 65 / 176], [train main loss -2.413011], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 66 / 176], [train main loss -2.390788], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 67 / 176], [train main loss -2.392165], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 68 / 176], [train main loss -2.400979], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 69 / 176], [train main loss -2.368210], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 70 / 176], [train main loss -2.358903], [lr 0.001257] [batchtime 0.407]
[epoch 153], [iter 71 / 176], [train main loss -2.387093], [lr 0.001257] [batchtime 0.407]
[epoch 153], [iter 72 / 176], [train main loss -2.369434], [lr 0.001257] [batchtime 0.407]
[epoch 153], [iter 73 / 176], [train main loss -2.404542], [lr 0.001257] [batchtime 0.407]
[epoch 153], [iter 74 / 176], [train main loss -2.410557], [lr 0.001257] [batchtime 0.407]
[epoch 153], [iter 75 / 176], [train main loss -2.399074], [lr 0.001257] [batchtime 0.407]
[epoch 153], [iter 76 / 176], [train main loss -2.404697], [lr 0.001257] [batchtime 0.406]
[epoch 153], [iter 77 / 176], [train main loss -2.386107], [lr 0.001257] [batchtime 0.406]
[epoch 153], [iter 78 / 176], [train main loss -2.378452], [lr 0.001257] [batchtime 0.406]
[epoch 153], [iter 79 / 176], [train main loss -2.366159], [lr 0.001257] [batchtime 0.406]
[epoch 153], [iter 80 / 176], [train main loss -2.315179], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 81 / 176], [train main loss -2.332770], [lr 0.001257] [batchtime 0.417]
[epoch 153], [iter 82 / 176], [train main loss -2.309903], [lr 0.001257] [batchtime 0.416]
[epoch 153], [iter 83 / 176], [train main loss -2.312204], [lr 0.001257] [batchtime 0.416]
[epoch 153], [iter 84 / 176], [train main loss -2.306539], [lr 0.001257] [batchtime 0.416]
[epoch 153], [iter 85 / 176], [train main loss -2.295877], [lr 0.001257] [batchtime 0.416]
[epoch 153], [iter 86 / 176], [train main loss -2.313316], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 87 / 176], [train main loss -2.301256], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 88 / 176], [train main loss -2.311150], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 89 / 176], [train main loss -2.301988], [lr 0.001257] [batchtime 0.415]
[epoch 153], [iter 90 / 176], [train main loss -2.300755], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 91 / 176], [train main loss -2.300700], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 92 / 176], [train main loss -2.299733], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 93 / 176], [train main loss -2.292566], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 94 / 176], [train main loss -2.279235], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 95 / 176], [train main loss -2.320563], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 96 / 176], [train main loss -2.314903], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 97 / 176], [train main loss -2.276277], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 98 / 176], [train main loss -2.274891], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 99 / 176], [train main loss -2.285020], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 100 / 176], [train main loss -2.271521], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 101 / 176], [train main loss -2.270262], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 102 / 176], [train main loss -2.245469], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 103 / 176], [train main loss -2.249165], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 104 / 176], [train main loss -2.246192], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 105 / 176], [train main loss -2.242234], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 106 / 176], [train main loss -2.253470], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 107 / 176], [train main loss -2.264617], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 108 / 176], [train main loss -2.279721], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 109 / 176], [train main loss -2.290214], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 110 / 176], [train main loss -2.276436], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 111 / 176], [train main loss -2.266985], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 112 / 176], [train main loss -2.255249], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 113 / 176], [train main loss -2.254255], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 114 / 176], [train main loss -2.289850], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 115 / 176], [train main loss -2.286176], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 116 / 176], [train main loss -2.284887], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 117 / 176], [train main loss -2.288620], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 118 / 176], [train main loss -2.279172], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 119 / 176], [train main loss -2.274877], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 120 / 176], [train main loss -2.269718], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 121 / 176], [train main loss -2.293334], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 122 / 176], [train main loss -2.308842], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 123 / 176], [train main loss -2.320488], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 124 / 176], [train main loss -2.326767], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 125 / 176], [train main loss -2.319278], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 126 / 176], [train main loss -2.303033], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 127 / 176], [train main loss -2.266951], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 128 / 176], [train main loss -2.278835], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 129 / 176], [train main loss -2.282351], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 130 / 176], [train main loss -2.281680], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 131 / 176], [train main loss -2.292674], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 132 / 176], [train main loss -2.296935], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 133 / 176], [train main loss -2.293139], [lr 0.001257] [batchtime 0.414]
[epoch 153], [iter 134 / 176], [train main loss -2.281432], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 135 / 176], [train main loss -2.272621], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 136 / 176], [train main loss -2.276995], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 137 / 176], [train main loss -2.272078], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 138 / 176], [train main loss -2.269937], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 139 / 176], [train main loss -2.273838], [lr 0.001257] [batchtime 0.413]
[epoch 153], [iter 140 / 176], [train main loss -2.272259], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 141 / 176], [train main loss -2.280665], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 142 / 176], [train main loss -2.268604], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 143 / 176], [train main loss -2.260358], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 144 / 176], [train main loss -2.272384], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 145 / 176], [train main loss -2.287954], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 146 / 176], [train main loss -2.290494], [lr 0.001257] [batchtime 0.412]
[epoch 153], [iter 147 / 176], [train main loss -2.287472], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 148 / 176], [train main loss -2.283124], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 149 / 176], [train main loss -2.285550], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 150 / 176], [train main loss -2.264675], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 151 / 176], [train main loss -2.243160], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 152 / 176], [train main loss -2.244467], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 153 / 176], [train main loss -2.254408], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 154 / 176], [train main loss -2.249731], [lr 0.001257] [batchtime 0.411]
[epoch 153], [iter 155 / 176], [train main loss -2.234507], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 156 / 176], [train main loss -2.212948], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 157 / 176], [train main loss -2.205214], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 158 / 176], [train main loss -2.217431], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 159 / 176], [train main loss -2.215020], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 160 / 176], [train main loss -2.208612], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 161 / 176], [train main loss -2.215562], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 162 / 176], [train main loss -2.226597], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 163 / 176], [train main loss -2.243341], [lr 0.001257] [batchtime 0.41]
[epoch 153], [iter 164 / 176], [train main loss -2.238921], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 165 / 176], [train main loss -2.245849], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 166 / 176], [train main loss -2.248275], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 167 / 176], [train main loss -2.240556], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 168 / 176], [train main loss -2.244848], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 169 / 176], [train main loss -2.245419], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 170 / 176], [train main loss -2.257741], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 171 / 176], [train main loss -2.260545], [lr 0.001257] [batchtime 0.409]
[epoch 153], [iter 172 / 176], [train main loss -2.254151], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 173 / 176], [train main loss -2.253013], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 174 / 176], [train main loss -2.248560], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 175 / 176], [train main loss -2.239047], [lr 0.001257] [batchtime 0.408]
[epoch 153], [iter 176 / 176], [train main loss -2.226960], [lr 0.001257] [batchtime 0.408]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.99  35.65   0.02  0.03         0.98      0.97
   1  sidewalk          70.59   5.35   0.23  0.19         0.81      0.84
   2  building          87.10  25.02   0.06  0.09         0.94      0.92
   3  wall              20.24   0.18   2.34  1.60         0.30      0.39
   4  fence             27.05   0.41   2.10  0.60         0.32      0.63
   5  pole              40.56   0.58   0.97  0.49         0.51      0.67
   6  traffic light     19.87   0.03   3.62  0.41         0.22      0.71
   7  traffic sign      29.56   0.18   2.14  0.25         0.32      0.80
   8  vegetation        84.42  11.66   0.06  0.12         0.94      0.89
   9  terrain           40.67   0.38   0.94  0.51         0.51      0.66
  10  sky               94.01   3.77   0.03  0.04         0.97      0.97
  11  person            55.28   1.04   0.47  0.34         0.68      0.75
  12  rider             15.38   0.02   4.45  1.06         0.18      0.49
  13  car               86.53   6.75   0.05  0.11         0.95      0.90
  14  truck              1.06   0.00  93.16  0.40         0.01      0.71
  15  bus               15.72   0.05   0.91  4.45         0.52      0.18
  16  train             29.59   0.06   1.81  0.57         0.36      0.64
  17  motorcycle         6.63   0.01  13.34  0.75         0.07      0.57
  18  bicycle           39.68   0.27   0.44  1.08         0.69      0.48
Mean: 45.21
-----------------------------------------------------------------------------------------------------------
this : [epoch 153], [val loss 0.28542], [acc 0.91405], [acc_cls 0.54214], [mean_iu 0.45206], [fwavacc 0.85051]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 154], [iter 1 / 176], [train main loss -3.032533], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 2 / 176], [train main loss -1.530959], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 3 / 176], [train main loss -1.998520], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 4 / 176], [train main loss -2.523711], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 5 / 176], [train main loss -2.735073], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 6 / 176], [train main loss -2.701752], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 7 / 176], [train main loss -2.661451], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 8 / 176], [train main loss -2.985294], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 9 / 176], [train main loss -2.938390], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 10 / 176], [train main loss -2.869583], [lr 0.001200] [batchtime 0]
[epoch 154], [iter 11 / 176], [train main loss -2.650160], [lr 0.001200] [batchtime 0.366]
[epoch 154], [iter 12 / 176], [train main loss -2.635299], [lr 0.001200] [batchtime 0.39]
[epoch 154], [iter 13 / 176], [train main loss -2.412327], [lr 0.001200] [batchtime 0.393]
[epoch 154], [iter 14 / 176], [train main loss -2.199228], [lr 0.001200] [batchtime 0.395]
[epoch 154], [iter 15 / 176], [train main loss -2.347033], [lr 0.001200] [batchtime 0.397]
[epoch 154], [iter 16 / 176], [train main loss -2.445962], [lr 0.001200] [batchtime 0.397]
[epoch 154], [iter 17 / 176], [train main loss -2.452014], [lr 0.001200] [batchtime 0.398]
[epoch 154], [iter 18 / 176], [train main loss -2.498432], [lr 0.001200] [batchtime 0.401]
[epoch 154], [iter 19 / 176], [train main loss -2.429152], [lr 0.001200] [batchtime 0.4]
[epoch 154], [iter 20 / 176], [train main loss -2.387998], [lr 0.001200] [batchtime 0.401]
[epoch 154], [iter 21 / 176], [train main loss -2.410027], [lr 0.001200] [batchtime 0.402]
[epoch 154], [iter 22 / 176], [train main loss -2.385106], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 23 / 176], [train main loss -2.534604], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 24 / 176], [train main loss -2.509975], [lr 0.001200] [batchtime 0.402]
[epoch 154], [iter 25 / 176], [train main loss -2.458166], [lr 0.001200] [batchtime 0.402]
[epoch 154], [iter 26 / 176], [train main loss -2.504136], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 27 / 176], [train main loss -2.443923], [lr 0.001200] [batchtime 0.404]
[epoch 154], [iter 28 / 176], [train main loss -2.490524], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 29 / 176], [train main loss -2.503157], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 30 / 176], [train main loss -2.496515], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 31 / 176], [train main loss -2.495100], [lr 0.001200] [batchtime 0.404]
[epoch 154], [iter 32 / 176], [train main loss -2.473451], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 33 / 176], [train main loss -2.426244], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 34 / 176], [train main loss -2.378256], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 35 / 176], [train main loss -2.397328], [lr 0.001200] [batchtime 0.403]
[epoch 154], [iter 36 / 176], [train main loss -2.397691], [lr 0.001200] [batchtime 0.435]
[epoch 154], [iter 37 / 176], [train main loss -2.411641], [lr 0.001200] [batchtime 0.439]
[epoch 154], [iter 38 / 176], [train main loss -2.382941], [lr 0.001200] [batchtime 0.437]
[epoch 154], [iter 39 / 176], [train main loss -2.367153], [lr 0.001200] [batchtime 0.436]
[epoch 154], [iter 40 / 176], [train main loss -2.409058], [lr 0.001200] [batchtime 0.434]
[epoch 154], [iter 41 / 176], [train main loss -2.333792], [lr 0.001200] [batchtime 0.433]
[epoch 154], [iter 42 / 176], [train main loss -2.286400], [lr 0.001200] [batchtime 0.432]
[epoch 154], [iter 43 / 176], [train main loss -2.289343], [lr 0.001200] [batchtime 0.431]
[epoch 154], [iter 44 / 176], [train main loss -2.268101], [lr 0.001200] [batchtime 0.43]
[epoch 154], [iter 45 / 176], [train main loss -2.280803], [lr 0.001200] [batchtime 0.429]
[epoch 154], [iter 46 / 176], [train main loss -2.270888], [lr 0.001200] [batchtime 0.429]
[epoch 154], [iter 47 / 176], [train main loss -2.278813], [lr 0.001200] [batchtime 0.428]
[epoch 154], [iter 48 / 176], [train main loss -2.310112], [lr 0.001200] [batchtime 0.427]
[epoch 154], [iter 49 / 176], [train main loss -2.281676], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 50 / 176], [train main loss -2.212525], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 51 / 176], [train main loss -2.213063], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 52 / 176], [train main loss -2.228072], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 53 / 176], [train main loss -2.241820], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 54 / 176], [train main loss -2.228193], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 55 / 176], [train main loss -2.174127], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 56 / 176], [train main loss -2.198353], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 57 / 176], [train main loss -2.177300], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 58 / 176], [train main loss -2.227795], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 59 / 176], [train main loss -2.192590], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 60 / 176], [train main loss -2.175475], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 61 / 176], [train main loss -2.152815], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 62 / 176], [train main loss -2.193814], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 63 / 176], [train main loss -2.167321], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 64 / 176], [train main loss -2.166300], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 65 / 176], [train main loss -2.201145], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 66 / 176], [train main loss -2.224867], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 67 / 176], [train main loss -2.217084], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 68 / 176], [train main loss -2.217341], [lr 0.001200] [batchtime 0.418]
[epoch 154], [iter 69 / 176], [train main loss -2.212127], [lr 0.001200] [batchtime 0.433]
[epoch 154], [iter 70 / 176], [train main loss -2.216088], [lr 0.001200] [batchtime 0.432]
[epoch 154], [iter 71 / 176], [train main loss -2.231011], [lr 0.001200] [batchtime 0.432]
[epoch 154], [iter 72 / 176], [train main loss -2.241861], [lr 0.001200] [batchtime 0.431]
[epoch 154], [iter 73 / 176], [train main loss -2.196976], [lr 0.001200] [batchtime 0.431]
[epoch 154], [iter 74 / 176], [train main loss -2.186565], [lr 0.001200] [batchtime 0.43]
[epoch 154], [iter 75 / 176], [train main loss -2.177543], [lr 0.001200] [batchtime 0.43]
[epoch 154], [iter 76 / 176], [train main loss -2.177017], [lr 0.001200] [batchtime 0.429]
[epoch 154], [iter 77 / 176], [train main loss -2.164818], [lr 0.001200] [batchtime 0.429]
[epoch 154], [iter 78 / 176], [train main loss -2.155961], [lr 0.001200] [batchtime 0.428]
[epoch 154], [iter 79 / 176], [train main loss -2.139378], [lr 0.001200] [batchtime 0.428]
[epoch 154], [iter 80 / 176], [train main loss -2.140870], [lr 0.001200] [batchtime 0.427]
[epoch 154], [iter 81 / 176], [train main loss -2.171830], [lr 0.001200] [batchtime 0.433]
[epoch 154], [iter 82 / 176], [train main loss -2.184867], [lr 0.001200] [batchtime 0.434]
[epoch 154], [iter 83 / 176], [train main loss -2.186572], [lr 0.001200] [batchtime 0.433]
[epoch 154], [iter 84 / 176], [train main loss -2.178366], [lr 0.001200] [batchtime 0.432]
[epoch 154], [iter 85 / 176], [train main loss -2.162784], [lr 0.001200] [batchtime 0.432]
[epoch 154], [iter 86 / 176], [train main loss -2.136889], [lr 0.001200] [batchtime 0.431]
[epoch 154], [iter 87 / 176], [train main loss -2.132962], [lr 0.001200] [batchtime 0.431]
[epoch 154], [iter 88 / 176], [train main loss -2.128975], [lr 0.001200] [batchtime 0.43]
[epoch 154], [iter 89 / 176], [train main loss -2.158435], [lr 0.001200] [batchtime 0.43]
[epoch 154], [iter 90 / 176], [train main loss -2.154783], [lr 0.001200] [batchtime 0.43]
[epoch 154], [iter 91 / 176], [train main loss -2.181381], [lr 0.001200] [batchtime 0.429]
[epoch 154], [iter 92 / 176], [train main loss -2.192407], [lr 0.001200] [batchtime 0.429]
[epoch 154], [iter 93 / 176], [train main loss -2.144406], [lr 0.001200] [batchtime 0.428]
[epoch 154], [iter 94 / 176], [train main loss -2.151373], [lr 0.001200] [batchtime 0.428]
[epoch 154], [iter 95 / 176], [train main loss -2.185148], [lr 0.001200] [batchtime 0.427]
[epoch 154], [iter 96 / 176], [train main loss -2.215752], [lr 0.001200] [batchtime 0.427]
[epoch 154], [iter 97 / 176], [train main loss -2.214627], [lr 0.001200] [batchtime 0.427]
[epoch 154], [iter 98 / 176], [train main loss -2.225299], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 99 / 176], [train main loss -2.230334], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 100 / 176], [train main loss -2.203531], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 101 / 176], [train main loss -2.182413], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 102 / 176], [train main loss -2.199894], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 103 / 176], [train main loss -2.222422], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 104 / 176], [train main loss -2.206848], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 105 / 176], [train main loss -2.204125], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 106 / 176], [train main loss -2.194834], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 107 / 176], [train main loss -2.237456], [lr 0.001200] [batchtime 0.426]
[epoch 154], [iter 108 / 176], [train main loss -2.225480], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 109 / 176], [train main loss -2.222349], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 110 / 176], [train main loss -2.202844], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 111 / 176], [train main loss -2.216961], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 112 / 176], [train main loss -2.217231], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 113 / 176], [train main loss -2.214796], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 114 / 176], [train main loss -2.242799], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 115 / 176], [train main loss -2.235459], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 116 / 176], [train main loss -2.202257], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 117 / 176], [train main loss -2.207500], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 118 / 176], [train main loss -2.211968], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 119 / 176], [train main loss -2.201606], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 120 / 176], [train main loss -2.204846], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 121 / 176], [train main loss -2.218906], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 122 / 176], [train main loss -2.211255], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 123 / 176], [train main loss -2.220921], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 124 / 176], [train main loss -2.214620], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 125 / 176], [train main loss -2.212814], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 126 / 176], [train main loss -2.219323], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 127 / 176], [train main loss -2.228682], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 128 / 176], [train main loss -2.215921], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 129 / 176], [train main loss -2.187860], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 130 / 176], [train main loss -2.187631], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 131 / 176], [train main loss -2.204564], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 132 / 176], [train main loss -2.203443], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 133 / 176], [train main loss -2.199147], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 134 / 176], [train main loss -2.210216], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 135 / 176], [train main loss -2.196733], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 136 / 176], [train main loss -2.197604], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 137 / 176], [train main loss -2.181998], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 138 / 176], [train main loss -2.176732], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 139 / 176], [train main loss -2.197775], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 140 / 176], [train main loss -2.223181], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 141 / 176], [train main loss -2.226414], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 142 / 176], [train main loss -2.237948], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 143 / 176], [train main loss -2.237050], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 144 / 176], [train main loss -2.254970], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 145 / 176], [train main loss -2.248828], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 146 / 176], [train main loss -2.239032], [lr 0.001200] [batchtime 0.421]
[epoch 154], [iter 147 / 176], [train main loss -2.246069], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 148 / 176], [train main loss -2.233734], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 149 / 176], [train main loss -2.235185], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 150 / 176], [train main loss -2.242842], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 151 / 176], [train main loss -2.232364], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 152 / 176], [train main loss -2.220593], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 153 / 176], [train main loss -2.203332], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 154 / 176], [train main loss -2.205982], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 155 / 176], [train main loss -2.195885], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 156 / 176], [train main loss -2.198967], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 157 / 176], [train main loss -2.199008], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 158 / 176], [train main loss -2.196864], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 159 / 176], [train main loss -2.191603], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 160 / 176], [train main loss -2.181883], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 161 / 176], [train main loss -2.171022], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 162 / 176], [train main loss -2.190553], [lr 0.001200] [batchtime 0.419]
[epoch 154], [iter 163 / 176], [train main loss -2.185612], [lr 0.001200] [batchtime 0.42]
[epoch 154], [iter 164 / 176], [train main loss -2.208527], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 165 / 176], [train main loss -2.207701], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 166 / 176], [train main loss -2.199010], [lr 0.001200] [batchtime 0.425]
[epoch 154], [iter 167 / 176], [train main loss -2.203248], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 168 / 176], [train main loss -2.207152], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 169 / 176], [train main loss -2.196216], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 170 / 176], [train main loss -2.200860], [lr 0.001200] [batchtime 0.424]
[epoch 154], [iter 171 / 176], [train main loss -2.199322], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 172 / 176], [train main loss -2.199888], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 173 / 176], [train main loss -2.176912], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 174 / 176], [train main loss -2.184340], [lr 0.001200] [batchtime 0.423]
[epoch 154], [iter 175 / 176], [train main loss -2.187122], [lr 0.001200] [batchtime 0.422]
[epoch 154], [iter 176 / 176], [train main loss -2.199633], [lr 0.001200] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.81  35.42   0.03  0.03         0.97      0.97
   1  sidewalk          70.39   5.46   0.21  0.21         0.83      0.82
   2  building          86.85  24.93   0.07  0.09         0.94      0.92
   3  wall              18.53   0.16   2.81  1.59         0.26      0.39
   4  fence             25.36   0.38   2.30  0.64         0.30      0.61
   5  pole              39.33   0.55   1.08  0.46         0.48      0.68
   6  traffic light     19.04   0.03   3.86  0.39         0.21      0.72
   7  traffic sign      27.13   0.16   2.47  0.21         0.29      0.83
   8  vegetation        83.75  11.76   0.05  0.14         0.95      0.88
   9  terrain           40.53   0.37   0.99  0.48         0.50      0.68
  10  sky               93.88   3.75   0.03  0.03         0.97      0.97
  11  person            55.70   1.08   0.42  0.37         0.70      0.73
  12  rider             13.67   0.01   5.34  0.98         0.16      0.51
  13  car               86.18   6.72   0.05  0.11         0.95      0.90
  14  truck              1.26   0.00  77.86  0.55         0.01      0.65
  15  bus               14.41   0.05   0.84  5.11         0.54      0.16
  16  train             22.90   0.06   2.18  1.19         0.31      0.46
  17  motorcycle         5.48   0.01  16.51  0.74         0.06      0.57
  18  bicycle           39.79   0.28   0.41  1.10         0.71      0.48
Mean: 44.16
-----------------------------------------------------------------------------------------------------------
this : [epoch 154], [val loss 0.29290], [acc 0.91176], [acc_cls 0.53431], [mean_iu 0.44157], [fwavacc 0.84725]
best : [epoch 147], [val loss 0.29544], [acc 0.91388], [acc_cls 0.54199], [mean_iu 0.45781], [fwavacc 0.84911]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 155], [iter 1 / 176], [train main loss -1.736481], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 2 / 176], [train main loss -3.628363], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 3 / 176], [train main loss -3.968685], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 4 / 176], [train main loss -3.324381], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 5 / 176], [train main loss -2.926741], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 6 / 176], [train main loss -2.723936], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 7 / 176], [train main loss -2.713385], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 8 / 176], [train main loss -2.296308], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 9 / 176], [train main loss -2.311257], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 10 / 176], [train main loss -2.379736], [lr 0.001143] [batchtime 0]
[epoch 155], [iter 11 / 176], [train main loss -2.523061], [lr 0.001143] [batchtime 0.372]
[epoch 155], [iter 12 / 176], [train main loss -2.355231], [lr 0.001143] [batchtime 0.619]
[epoch 155], [iter 13 / 176], [train main loss -2.611818], [lr 0.001143] [batchtime 0.542]
[epoch 155], [iter 14 / 176], [train main loss -2.602481], [lr 0.001143] [batchtime 0.545]
[epoch 155], [iter 15 / 176], [train main loss -2.662992], [lr 0.001143] [batchtime 0.515]
[epoch 155], [iter 16 / 176], [train main loss -2.812170], [lr 0.001143] [batchtime 0.496]
[epoch 155], [iter 17 / 176], [train main loss -2.666092], [lr 0.001143] [batchtime 0.481]
[epoch 155], [iter 18 / 176], [train main loss -2.625706], [lr 0.001143] [batchtime 0.47]
[epoch 155], [iter 19 / 176], [train main loss -2.629552], [lr 0.001143] [batchtime 0.462]
[epoch 155], [iter 20 / 176], [train main loss -2.580189], [lr 0.001143] [batchtime 0.456]
[epoch 155], [iter 21 / 176], [train main loss -2.415339], [lr 0.001143] [batchtime 0.451]
[epoch 155], [iter 22 / 176], [train main loss -2.349149], [lr 0.001143] [batchtime 0.447]
[epoch 155], [iter 23 / 176], [train main loss -2.292796], [lr 0.001143] [batchtime 0.443]
[epoch 155], [iter 24 / 176], [train main loss -2.256434], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 25 / 176], [train main loss -2.123980], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 26 / 176], [train main loss -2.201232], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 27 / 176], [train main loss -2.075461], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 28 / 176], [train main loss -2.192469], [lr 0.001143] [batchtime 0.43]
[epoch 155], [iter 29 / 176], [train main loss -2.123464], [lr 0.001143] [batchtime 0.428]
[epoch 155], [iter 30 / 176], [train main loss -2.062142], [lr 0.001143] [batchtime 0.426]
[epoch 155], [iter 31 / 176], [train main loss -2.117117], [lr 0.001143] [batchtime 0.425]
[epoch 155], [iter 32 / 176], [train main loss -2.052866], [lr 0.001143] [batchtime 0.424]
[epoch 155], [iter 33 / 176], [train main loss -1.985789], [lr 0.001143] [batchtime 0.423]
[epoch 155], [iter 34 / 176], [train main loss -1.965255], [lr 0.001143] [batchtime 0.457]
[epoch 155], [iter 35 / 176], [train main loss -1.983057], [lr 0.001143] [batchtime 0.464]
[epoch 155], [iter 36 / 176], [train main loss -2.026851], [lr 0.001143] [batchtime 0.461]
[epoch 155], [iter 37 / 176], [train main loss -1.985912], [lr 0.001143] [batchtime 0.459]
[epoch 155], [iter 38 / 176], [train main loss -1.977238], [lr 0.001143] [batchtime 0.456]
[epoch 155], [iter 39 / 176], [train main loss -1.954790], [lr 0.001143] [batchtime 0.454]
[epoch 155], [iter 40 / 176], [train main loss -2.055428], [lr 0.001143] [batchtime 0.452]
[epoch 155], [iter 41 / 176], [train main loss -2.019473], [lr 0.001143] [batchtime 0.45]
[epoch 155], [iter 42 / 176], [train main loss -2.014522], [lr 0.001143] [batchtime 0.448]
[epoch 155], [iter 43 / 176], [train main loss -1.995932], [lr 0.001143] [batchtime 0.447]
[epoch 155], [iter 44 / 176], [train main loss -1.954493], [lr 0.001143] [batchtime 0.445]
[epoch 155], [iter 45 / 176], [train main loss -1.935400], [lr 0.001143] [batchtime 0.444]
[epoch 155], [iter 46 / 176], [train main loss -2.030866], [lr 0.001143] [batchtime 0.442]
[epoch 155], [iter 47 / 176], [train main loss -2.021102], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 48 / 176], [train main loss -1.975842], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 49 / 176], [train main loss -1.972652], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 50 / 176], [train main loss -2.005416], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 51 / 176], [train main loss -2.004308], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 52 / 176], [train main loss -1.982258], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 53 / 176], [train main loss -1.944935], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 54 / 176], [train main loss -1.945806], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 55 / 176], [train main loss -1.904165], [lr 0.001143] [batchtime 0.446]
[epoch 155], [iter 56 / 176], [train main loss -1.854192], [lr 0.001143] [batchtime 0.445]
[epoch 155], [iter 57 / 176], [train main loss -1.837225], [lr 0.001143] [batchtime 0.444]
[epoch 155], [iter 58 / 176], [train main loss -1.824135], [lr 0.001143] [batchtime 0.443]
[epoch 155], [iter 59 / 176], [train main loss -1.809796], [lr 0.001143] [batchtime 0.442]
[epoch 155], [iter 60 / 176], [train main loss -1.860865], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 61 / 176], [train main loss -1.925055], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 62 / 176], [train main loss -1.959338], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 63 / 176], [train main loss -1.949084], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 64 / 176], [train main loss -1.921869], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 65 / 176], [train main loss -1.921960], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 66 / 176], [train main loss -1.945943], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 67 / 176], [train main loss -1.899650], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 68 / 176], [train main loss -1.908227], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 69 / 176], [train main loss -1.873219], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 70 / 176], [train main loss -1.859522], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 71 / 176], [train main loss -1.859772], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 72 / 176], [train main loss -1.829862], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 73 / 176], [train main loss -1.809574], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 74 / 176], [train main loss -1.809613], [lr 0.001143] [batchtime 0.432]
[epoch 155], [iter 75 / 176], [train main loss -1.828820], [lr 0.001143] [batchtime 0.432]
[epoch 155], [iter 76 / 176], [train main loss -1.807195], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 77 / 176], [train main loss -1.800584], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 78 / 176], [train main loss -1.797913], [lr 0.001143] [batchtime 0.43]
[epoch 155], [iter 79 / 176], [train main loss -1.858114], [lr 0.001143] [batchtime 0.43]
[epoch 155], [iter 80 / 176], [train main loss -1.867400], [lr 0.001143] [batchtime 0.432]
[epoch 155], [iter 81 / 176], [train main loss -1.858115], [lr 0.001143] [batchtime 0.452]
[epoch 155], [iter 82 / 176], [train main loss -1.827686], [lr 0.001143] [batchtime 0.451]
[epoch 155], [iter 83 / 176], [train main loss -1.847198], [lr 0.001143] [batchtime 0.45]
[epoch 155], [iter 84 / 176], [train main loss -1.871605], [lr 0.001143] [batchtime 0.449]
[epoch 155], [iter 85 / 176], [train main loss -1.876956], [lr 0.001143] [batchtime 0.448]
[epoch 155], [iter 86 / 176], [train main loss -1.893648], [lr 0.001143] [batchtime 0.448]
[epoch 155], [iter 87 / 176], [train main loss -1.861315], [lr 0.001143] [batchtime 0.447]
[epoch 155], [iter 88 / 176], [train main loss -1.850345], [lr 0.001143] [batchtime 0.446]
[epoch 155], [iter 89 / 176], [train main loss -1.883449], [lr 0.001143] [batchtime 0.446]
[epoch 155], [iter 90 / 176], [train main loss -1.881755], [lr 0.001143] [batchtime 0.445]
[epoch 155], [iter 91 / 176], [train main loss -1.890829], [lr 0.001143] [batchtime 0.445]
[epoch 155], [iter 92 / 176], [train main loss -1.886267], [lr 0.001143] [batchtime 0.444]
[epoch 155], [iter 93 / 176], [train main loss -1.874179], [lr 0.001143] [batchtime 0.444]
[epoch 155], [iter 94 / 176], [train main loss -1.887630], [lr 0.001143] [batchtime 0.443]
[epoch 155], [iter 95 / 176], [train main loss -1.898050], [lr 0.001143] [batchtime 0.443]
[epoch 155], [iter 96 / 176], [train main loss -1.924058], [lr 0.001143] [batchtime 0.442]
[epoch 155], [iter 97 / 176], [train main loss -1.940822], [lr 0.001143] [batchtime 0.442]
[epoch 155], [iter 98 / 176], [train main loss -1.945667], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 99 / 176], [train main loss -1.977404], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 100 / 176], [train main loss -1.942188], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 101 / 176], [train main loss -1.960541], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 102 / 176], [train main loss -1.967792], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 103 / 176], [train main loss -1.985753], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 104 / 176], [train main loss -1.991513], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 105 / 176], [train main loss -2.006545], [lr 0.001143] [batchtime 0.442]
[epoch 155], [iter 106 / 176], [train main loss -2.019663], [lr 0.001143] [batchtime 0.442]
[epoch 155], [iter 107 / 176], [train main loss -2.011109], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 108 / 176], [train main loss -2.018378], [lr 0.001143] [batchtime 0.441]
[epoch 155], [iter 109 / 176], [train main loss -2.023106], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 110 / 176], [train main loss -2.019312], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 111 / 176], [train main loss -2.020728], [lr 0.001143] [batchtime 0.44]
[epoch 155], [iter 112 / 176], [train main loss -2.024046], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 113 / 176], [train main loss -2.022823], [lr 0.001143] [batchtime 0.439]
[epoch 155], [iter 114 / 176], [train main loss -2.021536], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 115 / 176], [train main loss -2.029210], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 116 / 176], [train main loss -2.036924], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 117 / 176], [train main loss -2.056585], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 118 / 176], [train main loss -2.050890], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 119 / 176], [train main loss -2.040332], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 120 / 176], [train main loss -2.042917], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 121 / 176], [train main loss -2.030797], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 122 / 176], [train main loss -2.049639], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 123 / 176], [train main loss -2.070119], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 124 / 176], [train main loss -2.053292], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 125 / 176], [train main loss -2.060653], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 126 / 176], [train main loss -2.064361], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 127 / 176], [train main loss -2.067972], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 128 / 176], [train main loss -2.052302], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 129 / 176], [train main loss -2.045989], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 130 / 176], [train main loss -2.055349], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 131 / 176], [train main loss -2.066165], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 132 / 176], [train main loss -2.065454], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 133 / 176], [train main loss -2.049262], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 134 / 176], [train main loss -2.047028], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 135 / 176], [train main loss -2.049254], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 136 / 176], [train main loss -2.059366], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 137 / 176], [train main loss -2.051015], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 138 / 176], [train main loss -2.056980], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 139 / 176], [train main loss -2.063947], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 140 / 176], [train main loss -2.064737], [lr 0.001143] [batchtime 0.432]
[epoch 155], [iter 141 / 176], [train main loss -2.061006], [lr 0.001143] [batchtime 0.432]
[epoch 155], [iter 142 / 176], [train main loss -2.063279], [lr 0.001143] [batchtime 0.432]
[epoch 155], [iter 143 / 176], [train main loss -2.066153], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 144 / 176], [train main loss -2.068353], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 145 / 176], [train main loss -2.050069], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 146 / 176], [train main loss -2.044096], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 147 / 176], [train main loss -2.026956], [lr 0.001143] [batchtime 0.431]
[epoch 155], [iter 148 / 176], [train main loss -2.037143], [lr 0.001143] [batchtime 0.43]
[epoch 155], [iter 149 / 176], [train main loss -2.041989], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 150 / 176], [train main loss -2.033330], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 151 / 176], [train main loss -2.039088], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 152 / 176], [train main loss -2.036635], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 153 / 176], [train main loss -2.041292], [lr 0.001143] [batchtime 0.438]
[epoch 155], [iter 154 / 176], [train main loss -2.041872], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 155 / 176], [train main loss -2.053085], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 156 / 176], [train main loss -2.053045], [lr 0.001143] [batchtime 0.437]
[epoch 155], [iter 157 / 176], [train main loss -2.046469], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 158 / 176], [train main loss -2.059300], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 159 / 176], [train main loss -2.075872], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 160 / 176], [train main loss -2.065516], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 161 / 176], [train main loss -2.073984], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 162 / 176], [train main loss -2.070892], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 163 / 176], [train main loss -2.078789], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 164 / 176], [train main loss -2.059401], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 165 / 176], [train main loss -2.058276], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 166 / 176], [train main loss -2.065606], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 167 / 176], [train main loss -2.077059], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 168 / 176], [train main loss -2.070368], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 169 / 176], [train main loss -2.078208], [lr 0.001143] [batchtime 0.434]
[epoch 155], [iter 170 / 176], [train main loss -2.083336], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 171 / 176], [train main loss -2.073368], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 172 / 176], [train main loss -2.088790], [lr 0.001143] [batchtime 0.433]
[epoch 155], [iter 173 / 176], [train main loss -2.099231], [lr 0.001143] [batchtime 0.436]
[epoch 155], [iter 174 / 176], [train main loss -2.104553], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 175 / 176], [train main loss -2.115096], [lr 0.001143] [batchtime 0.435]
[epoch 155], [iter 176 / 176], [train main loss -2.110829], [lr 0.001143] [batchtime 0.435]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP      FP    FN    Precision    Recall
----  -------------  --------  -----  ------  ----  -----------  --------
   0  road              95.12  35.62    0.02  0.03         0.98      0.97
   1  sidewalk          71.14   5.43    0.21  0.19         0.82      0.84
   2  building          86.88  25.14    0.06  0.09         0.95      0.91
   3  wall              19.41   0.16    2.67  1.49         0.27      0.40
   4  fence             26.02   0.39    2.27  0.58         0.31      0.63
   5  pole              40.35   0.58    0.97  0.50         0.51      0.66
   6  traffic light     21.16   0.04    3.17  0.56         0.24      0.64
   7  traffic sign      29.49   0.18    2.13  0.26         0.32      0.79
   8  vegetation        84.26  11.67    0.06  0.13         0.94      0.89
   9  terrain           40.91   0.37    0.96  0.48         0.51      0.68
  10  sky               93.84   3.74    0.04  0.03         0.96      0.97
  11  person            55.19   1.04    0.48  0.34         0.68      0.75
  12  rider             15.27   0.02    4.56  0.99         0.18      0.50
  13  car               87.09   6.68    0.06  0.09         0.94      0.92
  14  truck              0.91   0.00  108.35  0.47         0.01      0.68
  15  bus               16.26   0.05    0.86  4.29         0.54      0.19
  16  train             39.40   0.09    1.05  0.49         0.49      0.67
  17  motorcycle         6.24   0.01   14.34  0.68         0.07      0.60
  18  bicycle           41.91   0.27    0.46  0.93         0.69      0.52
Mean: 45.83
-----------------------------------------------------------------------------------------------------------
this : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 156], [iter 1 / 176], [train main loss -5.812260], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 2 / 176], [train main loss -3.777603], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 3 / 176], [train main loss -3.077341], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 4 / 176], [train main loss -3.075237], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 5 / 176], [train main loss -3.732005], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 6 / 176], [train main loss -3.177157], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 7 / 176], [train main loss -2.963540], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 8 / 176], [train main loss -3.146462], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 9 / 176], [train main loss -3.272309], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 10 / 176], [train main loss -3.355438], [lr 0.001086] [batchtime 0]
[epoch 156], [iter 11 / 176], [train main loss -3.181645], [lr 0.001086] [batchtime 0.368]
[epoch 156], [iter 12 / 176], [train main loss -3.239610], [lr 0.001086] [batchtime 0.381]
[epoch 156], [iter 13 / 176], [train main loss -2.944535], [lr 0.001086] [batchtime 0.385]
[epoch 156], [iter 14 / 176], [train main loss -2.905723], [lr 0.001086] [batchtime 0.39]
[epoch 156], [iter 15 / 176], [train main loss -2.842568], [lr 0.001086] [batchtime 0.392]
[epoch 156], [iter 16 / 176], [train main loss -2.643343], [lr 0.001086] [batchtime 0.394]
[epoch 156], [iter 17 / 176], [train main loss -2.585358], [lr 0.001086] [batchtime 0.395]
[epoch 156], [iter 18 / 176], [train main loss -2.508108], [lr 0.001086] [batchtime 0.396]
[epoch 156], [iter 19 / 176], [train main loss -2.572973], [lr 0.001086] [batchtime 0.396]
[epoch 156], [iter 20 / 176], [train main loss -2.596673], [lr 0.001086] [batchtime 0.396]
[epoch 156], [iter 21 / 176], [train main loss -2.613813], [lr 0.001086] [batchtime 0.397]
[epoch 156], [iter 22 / 176], [train main loss -2.458802], [lr 0.001086] [batchtime 0.397]
[epoch 156], [iter 23 / 176], [train main loss -2.529440], [lr 0.001086] [batchtime 0.398]
[epoch 156], [iter 24 / 176], [train main loss -2.522685], [lr 0.001086] [batchtime 0.398]
[epoch 156], [iter 25 / 176], [train main loss -2.588297], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 26 / 176], [train main loss -2.583435], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 27 / 176], [train main loss -2.578696], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 28 / 176], [train main loss -2.468874], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 29 / 176], [train main loss -2.423160], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 30 / 176], [train main loss -2.515381], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 31 / 176], [train main loss -2.528896], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 32 / 176], [train main loss -2.533738], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 33 / 176], [train main loss -2.561286], [lr 0.001086] [batchtime 0.416]
[epoch 156], [iter 34 / 176], [train main loss -2.554262], [lr 0.001086] [batchtime 0.415]
[epoch 156], [iter 35 / 176], [train main loss -2.543941], [lr 0.001086] [batchtime 0.415]
[epoch 156], [iter 36 / 176], [train main loss -2.517010], [lr 0.001086] [batchtime 0.414]
[epoch 156], [iter 37 / 176], [train main loss -2.414687], [lr 0.001086] [batchtime 0.414]
[epoch 156], [iter 38 / 176], [train main loss -2.420986], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 39 / 176], [train main loss -2.390275], [lr 0.001086] [batchtime 0.412]
[epoch 156], [iter 40 / 176], [train main loss -2.325278], [lr 0.001086] [batchtime 0.412]
[epoch 156], [iter 41 / 176], [train main loss -2.279209], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 42 / 176], [train main loss -2.137538], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 43 / 176], [train main loss -2.113180], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 44 / 176], [train main loss -2.161276], [lr 0.001086] [batchtime 0.41]
[epoch 156], [iter 45 / 176], [train main loss -2.193396], [lr 0.001086] [batchtime 0.41]
[epoch 156], [iter 46 / 176], [train main loss -2.183169], [lr 0.001086] [batchtime 0.41]
[epoch 156], [iter 47 / 176], [train main loss -2.202925], [lr 0.001086] [batchtime 0.41]
[epoch 156], [iter 48 / 176], [train main loss -2.225377], [lr 0.001086] [batchtime 0.409]
[epoch 156], [iter 49 / 176], [train main loss -2.182110], [lr 0.001086] [batchtime 0.409]
[epoch 156], [iter 50 / 176], [train main loss -2.176837], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 51 / 176], [train main loss -2.202782], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 52 / 176], [train main loss -2.199426], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 53 / 176], [train main loss -2.183739], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 54 / 176], [train main loss -2.203577], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 55 / 176], [train main loss -2.215537], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 56 / 176], [train main loss -2.234642], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 57 / 176], [train main loss -2.253789], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 58 / 176], [train main loss -2.232594], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 59 / 176], [train main loss -2.218482], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 60 / 176], [train main loss -2.221767], [lr 0.001086] [batchtime 0.421]
[epoch 156], [iter 61 / 176], [train main loss -2.197152], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 62 / 176], [train main loss -2.209164], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 63 / 176], [train main loss -2.205993], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 64 / 176], [train main loss -2.174005], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 65 / 176], [train main loss -2.157116], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 66 / 176], [train main loss -2.167594], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 67 / 176], [train main loss -2.134106], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 68 / 176], [train main loss -2.139487], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 69 / 176], [train main loss -2.111636], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 70 / 176], [train main loss -2.085230], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 71 / 176], [train main loss -2.054605], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 72 / 176], [train main loss -2.037104], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 73 / 176], [train main loss -1.991950], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 74 / 176], [train main loss -1.994851], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 75 / 176], [train main loss -2.008655], [lr 0.001086] [batchtime 0.417]
[epoch 156], [iter 76 / 176], [train main loss -2.016432], [lr 0.001086] [batchtime 0.416]
[epoch 156], [iter 77 / 176], [train main loss -2.046723], [lr 0.001086] [batchtime 0.416]
[epoch 156], [iter 78 / 176], [train main loss -2.050807], [lr 0.001086] [batchtime 0.416]
[epoch 156], [iter 79 / 176], [train main loss -2.073995], [lr 0.001086] [batchtime 0.415]
[epoch 156], [iter 80 / 176], [train main loss -2.047850], [lr 0.001086] [batchtime 0.415]
[epoch 156], [iter 81 / 176], [train main loss -2.091376], [lr 0.001086] [batchtime 0.415]
[epoch 156], [iter 82 / 176], [train main loss -2.069494], [lr 0.001086] [batchtime 0.414]
[epoch 156], [iter 83 / 176], [train main loss -2.074481], [lr 0.001086] [batchtime 0.414]
[epoch 156], [iter 84 / 176], [train main loss -2.093226], [lr 0.001086] [batchtime 0.414]
[epoch 156], [iter 85 / 176], [train main loss -2.083234], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 86 / 176], [train main loss -2.079681], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 87 / 176], [train main loss -2.078996], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 88 / 176], [train main loss -2.071908], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 89 / 176], [train main loss -2.088746], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 90 / 176], [train main loss -2.099847], [lr 0.001086] [batchtime 0.412]
[epoch 156], [iter 91 / 176], [train main loss -2.086705], [lr 0.001086] [batchtime 0.412]
[epoch 156], [iter 92 / 176], [train main loss -2.056346], [lr 0.001086] [batchtime 0.412]
[epoch 156], [iter 93 / 176], [train main loss -2.075021], [lr 0.001086] [batchtime 0.412]
[epoch 156], [iter 94 / 176], [train main loss -2.116876], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 95 / 176], [train main loss -2.116596], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 96 / 176], [train main loss -2.106230], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 97 / 176], [train main loss -2.087252], [lr 0.001086] [batchtime 0.411]
[epoch 156], [iter 98 / 176], [train main loss -2.077997], [lr 0.001086] [batchtime 0.413]
[epoch 156], [iter 99 / 176], [train main loss -2.082721], [lr 0.001086] [batchtime 0.429]
[epoch 156], [iter 100 / 176], [train main loss -2.081657], [lr 0.001086] [batchtime 0.428]
[epoch 156], [iter 101 / 176], [train main loss -2.069856], [lr 0.001086] [batchtime 0.428]
[epoch 156], [iter 102 / 176], [train main loss -2.082648], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 103 / 176], [train main loss -2.061612], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 104 / 176], [train main loss -2.051530], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 105 / 176], [train main loss -2.071533], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 106 / 176], [train main loss -2.046076], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 107 / 176], [train main loss -2.060788], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 108 / 176], [train main loss -2.043828], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 109 / 176], [train main loss -2.040623], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 110 / 176], [train main loss -2.038663], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 111 / 176], [train main loss -2.051837], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 112 / 176], [train main loss -2.047319], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 113 / 176], [train main loss -2.054180], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 114 / 176], [train main loss -2.079487], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 115 / 176], [train main loss -2.078208], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 116 / 176], [train main loss -2.089433], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 117 / 176], [train main loss -2.096540], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 118 / 176], [train main loss -2.093808], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 119 / 176], [train main loss -2.090818], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 120 / 176], [train main loss -2.089698], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 121 / 176], [train main loss -2.107737], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 122 / 176], [train main loss -2.116345], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 123 / 176], [train main loss -2.104882], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 124 / 176], [train main loss -2.100638], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 125 / 176], [train main loss -2.106599], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 126 / 176], [train main loss -2.090557], [lr 0.001086] [batchtime 0.421]
[epoch 156], [iter 127 / 176], [train main loss -2.076962], [lr 0.001086] [batchtime 0.421]
[epoch 156], [iter 128 / 176], [train main loss -2.062047], [lr 0.001086] [batchtime 0.421]
[epoch 156], [iter 129 / 176], [train main loss -2.067103], [lr 0.001086] [batchtime 0.421]
[epoch 156], [iter 130 / 176], [train main loss -2.041960], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 131 / 176], [train main loss -2.038122], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 132 / 176], [train main loss -2.051585], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 133 / 176], [train main loss -2.042746], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 134 / 176], [train main loss -2.040861], [lr 0.001086] [batchtime 0.42]
[epoch 156], [iter 135 / 176], [train main loss -2.023049], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 136 / 176], [train main loss -2.009516], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 137 / 176], [train main loss -1.996143], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 138 / 176], [train main loss -1.993796], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 139 / 176], [train main loss -2.005206], [lr 0.001086] [batchtime 0.419]
[epoch 156], [iter 140 / 176], [train main loss -2.014231], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 141 / 176], [train main loss -1.998626], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 142 / 176], [train main loss -1.982924], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 143 / 176], [train main loss -1.977843], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 144 / 176], [train main loss -1.979408], [lr 0.001086] [batchtime 0.418]
[epoch 156], [iter 145 / 176], [train main loss -1.974446], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 146 / 176], [train main loss -1.982260], [lr 0.001086] [batchtime 0.428]
[epoch 156], [iter 147 / 176], [train main loss -1.990884], [lr 0.001086] [batchtime 0.428]
[epoch 156], [iter 148 / 176], [train main loss -1.989270], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 149 / 176], [train main loss -2.003141], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 150 / 176], [train main loss -1.996122], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 151 / 176], [train main loss -2.012617], [lr 0.001086] [batchtime 0.427]
[epoch 156], [iter 152 / 176], [train main loss -1.990264], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 153 / 176], [train main loss -1.994181], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 154 / 176], [train main loss -2.015263], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 155 / 176], [train main loss -2.019014], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 156 / 176], [train main loss -2.040945], [lr 0.001086] [batchtime 0.426]
[epoch 156], [iter 157 / 176], [train main loss -2.046038], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 158 / 176], [train main loss -2.055387], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 159 / 176], [train main loss -2.051455], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 160 / 176], [train main loss -2.065650], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 161 / 176], [train main loss -2.052222], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 162 / 176], [train main loss -2.051456], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 163 / 176], [train main loss -2.046585], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 164 / 176], [train main loss -2.059631], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 165 / 176], [train main loss -2.057278], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 166 / 176], [train main loss -2.043471], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 167 / 176], [train main loss -2.056239], [lr 0.001086] [batchtime 0.425]
[epoch 156], [iter 168 / 176], [train main loss -2.058122], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 169 / 176], [train main loss -2.052753], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 170 / 176], [train main loss -2.030515], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 171 / 176], [train main loss -2.026508], [lr 0.001086] [batchtime 0.424]
[epoch 156], [iter 172 / 176], [train main loss -2.026198], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 173 / 176], [train main loss -2.024683], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 174 / 176], [train main loss -2.027547], [lr 0.001086] [batchtime 0.423]
[epoch 156], [iter 175 / 176], [train main loss -2.029432], [lr 0.001086] [batchtime 0.422]
[epoch 156], [iter 176 / 176], [train main loss -2.026883], [lr 0.001086] [batchtime 0.422]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.84  35.70   0.02  0.04         0.98      0.97
   1  sidewalk          69.48   5.24   0.26  0.18         0.80      0.85
   2  building          86.75  24.82   0.07  0.08         0.93      0.92
   3  wall              20.77   0.18   2.26  1.55         0.31      0.39
   4  fence             27.29   0.43   1.93  0.74         0.34      0.58
   5  pole              40.58   0.60   0.90  0.56         0.53      0.64
   6  traffic light     18.00   0.03   4.11  0.45         0.20      0.69
   7  traffic sign      28.89   0.17   2.23  0.23         0.31      0.81
   8  vegetation        83.89  11.73   0.05  0.14         0.95      0.88
   9  terrain           41.87   0.40   0.84  0.55         0.54      0.65
  10  sky               93.62   3.75   0.03  0.04         0.97      0.96
  11  person            55.75   1.04   0.47  0.32         0.68      0.76
  12  rider             13.53   0.01   5.52  0.86         0.15      0.54
  13  car               86.69   6.73   0.05  0.10         0.95      0.91
  14  truck              1.52   0.00  64.25  0.39         0.02      0.72
  15  bus               17.17   0.04   1.07  3.76         0.48      0.21
  16  train             39.15   0.09   1.04  0.51         0.49      0.66
  17  motorcycle         5.55   0.01  16.45  0.58         0.06      0.63
  18  bicycle           39.91   0.28   0.42  1.09         0.71      0.48
Mean: 45.54
-----------------------------------------------------------------------------------------------------------
this : [epoch 156], [val loss 0.29954], [acc 0.91246], [acc_cls 0.54655], [mean_iu 0.45540], [fwavacc 0.84797]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 157], [iter 1 / 176], [train main loss -3.286081], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 2 / 176], [train main loss -3.883688], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 3 / 176], [train main loss -3.183295], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 4 / 176], [train main loss -2.263124], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 5 / 176], [train main loss -1.943625], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 6 / 176], [train main loss -2.064763], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 7 / 176], [train main loss -2.222463], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 8 / 176], [train main loss -1.975367], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 9 / 176], [train main loss -2.095508], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 10 / 176], [train main loss -1.921383], [lr 0.001029] [batchtime 0]
[epoch 157], [iter 11 / 176], [train main loss -2.176971], [lr 0.001029] [batchtime 0.372]
[epoch 157], [iter 12 / 176], [train main loss -2.208847], [lr 0.001029] [batchtime 0.385]
[epoch 157], [iter 13 / 176], [train main loss -2.122226], [lr 0.001029] [batchtime 0.389]
[epoch 157], [iter 14 / 176], [train main loss -1.878051], [lr 0.001029] [batchtime 0.388]
[epoch 157], [iter 15 / 176], [train main loss -1.996418], [lr 0.001029] [batchtime 0.39]
[epoch 157], [iter 16 / 176], [train main loss -1.857754], [lr 0.001029] [batchtime 0.392]
[epoch 157], [iter 17 / 176], [train main loss -1.940099], [lr 0.001029] [batchtime 0.394]
[epoch 157], [iter 18 / 176], [train main loss -1.849008], [lr 0.001029] [batchtime 0.395]
[epoch 157], [iter 19 / 176], [train main loss -1.905008], [lr 0.001029] [batchtime 0.395]
[epoch 157], [iter 20 / 176], [train main loss -1.857793], [lr 0.001029] [batchtime 0.397]
[epoch 157], [iter 21 / 176], [train main loss -1.931633], [lr 0.001029] [batchtime 0.396]
[epoch 157], [iter 22 / 176], [train main loss -1.967884], [lr 0.001029] [batchtime 0.396]
[epoch 157], [iter 23 / 176], [train main loss -2.035550], [lr 0.001029] [batchtime 0.396]
[epoch 157], [iter 24 / 176], [train main loss -2.001318], [lr 0.001029] [batchtime 0.396]
[epoch 157], [iter 25 / 176], [train main loss -1.935754], [lr 0.001029] [batchtime 0.396]
[epoch 157], [iter 26 / 176], [train main loss -1.986829], [lr 0.001029] [batchtime 0.396]
[epoch 157], [iter 27 / 176], [train main loss -1.899633], [lr 0.001029] [batchtime 0.395]
[epoch 157], [iter 28 / 176], [train main loss -1.881810], [lr 0.001029] [batchtime 0.404]
[epoch 157], [iter 29 / 176], [train main loss -1.929514], [lr 0.001029] [batchtime 0.474]
[epoch 157], [iter 30 / 176], [train main loss -1.866608], [lr 0.001029] [batchtime 0.469]
[epoch 157], [iter 31 / 176], [train main loss -1.884479], [lr 0.001029] [batchtime 0.465]
[epoch 157], [iter 32 / 176], [train main loss -1.896977], [lr 0.001029] [batchtime 0.461]
[epoch 157], [iter 33 / 176], [train main loss -1.878676], [lr 0.001029] [batchtime 0.458]
[epoch 157], [iter 34 / 176], [train main loss -2.033147], [lr 0.001029] [batchtime 0.455]
[epoch 157], [iter 35 / 176], [train main loss -2.124780], [lr 0.001029] [batchtime 0.453]
[epoch 157], [iter 36 / 176], [train main loss -2.106735], [lr 0.001029] [batchtime 0.451]
[epoch 157], [iter 37 / 176], [train main loss -2.046862], [lr 0.001029] [batchtime 0.449]
[epoch 157], [iter 38 / 176], [train main loss -1.995520], [lr 0.001029] [batchtime 0.447]
[epoch 157], [iter 39 / 176], [train main loss -1.974886], [lr 0.001029] [batchtime 0.445]
[epoch 157], [iter 40 / 176], [train main loss -2.057385], [lr 0.001029] [batchtime 0.444]
[epoch 157], [iter 41 / 176], [train main loss -2.045024], [lr 0.001029] [batchtime 0.442]
[epoch 157], [iter 42 / 176], [train main loss -2.031579], [lr 0.001029] [batchtime 0.44]
[epoch 157], [iter 43 / 176], [train main loss -1.987822], [lr 0.001029] [batchtime 0.439]
[epoch 157], [iter 44 / 176], [train main loss -1.985133], [lr 0.001029] [batchtime 0.438]
[epoch 157], [iter 45 / 176], [train main loss -1.968278], [lr 0.001029] [batchtime 0.437]
[epoch 157], [iter 46 / 176], [train main loss -1.982158], [lr 0.001029] [batchtime 0.436]
[epoch 157], [iter 47 / 176], [train main loss -1.967015], [lr 0.001029] [batchtime 0.434]
[epoch 157], [iter 48 / 176], [train main loss -2.058881], [lr 0.001029] [batchtime 0.434]
[epoch 157], [iter 49 / 176], [train main loss -2.129437], [lr 0.001029] [batchtime 0.433]
[epoch 157], [iter 50 / 176], [train main loss -2.143375], [lr 0.001029] [batchtime 0.432]
[epoch 157], [iter 51 / 176], [train main loss -2.094695], [lr 0.001029] [batchtime 0.431]
[epoch 157], [iter 52 / 176], [train main loss -2.073620], [lr 0.001029] [batchtime 0.43]
[epoch 157], [iter 53 / 176], [train main loss -2.044944], [lr 0.001029] [batchtime 0.429]
[epoch 157], [iter 54 / 176], [train main loss -1.992953], [lr 0.001029] [batchtime 0.429]
[epoch 157], [iter 55 / 176], [train main loss -1.987916], [lr 0.001029] [batchtime 0.429]
[epoch 157], [iter 56 / 176], [train main loss -1.985813], [lr 0.001029] [batchtime 0.428]
[epoch 157], [iter 57 / 176], [train main loss -2.023822], [lr 0.001029] [batchtime 0.427]
[epoch 157], [iter 58 / 176], [train main loss -2.022185], [lr 0.001029] [batchtime 0.427]
[epoch 157], [iter 59 / 176], [train main loss -2.058633], [lr 0.001029] [batchtime 0.426]
[epoch 157], [iter 60 / 176], [train main loss -2.083815], [lr 0.001029] [batchtime 0.425]
[epoch 157], [iter 61 / 176], [train main loss -2.084552], [lr 0.001029] [batchtime 0.425]
[epoch 157], [iter 62 / 176], [train main loss -2.081010], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 63 / 176], [train main loss -2.035161], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 64 / 176], [train main loss -2.053276], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 65 / 176], [train main loss -2.045847], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 66 / 176], [train main loss -2.039205], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 67 / 176], [train main loss -2.046565], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 68 / 176], [train main loss -2.025998], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 69 / 176], [train main loss -2.025549], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 70 / 176], [train main loss -2.001759], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 71 / 176], [train main loss -2.029000], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 72 / 176], [train main loss -2.047714], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 73 / 176], [train main loss -2.049487], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 74 / 176], [train main loss -2.052320], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 75 / 176], [train main loss -2.047673], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 76 / 176], [train main loss -2.022320], [lr 0.001029] [batchtime 0.429]
[epoch 157], [iter 77 / 176], [train main loss -2.033855], [lr 0.001029] [batchtime 0.428]
[epoch 157], [iter 78 / 176], [train main loss -2.047358], [lr 0.001029] [batchtime 0.427]
[epoch 157], [iter 79 / 176], [train main loss -2.066229], [lr 0.001029] [batchtime 0.427]
[epoch 157], [iter 80 / 176], [train main loss -2.050137], [lr 0.001029] [batchtime 0.426]
[epoch 157], [iter 81 / 176], [train main loss -2.071821], [lr 0.001029] [batchtime 0.426]
[epoch 157], [iter 82 / 176], [train main loss -2.038677], [lr 0.001029] [batchtime 0.426]
[epoch 157], [iter 83 / 176], [train main loss -2.046474], [lr 0.001029] [batchtime 0.425]
[epoch 157], [iter 84 / 176], [train main loss -2.036843], [lr 0.001029] [batchtime 0.425]
[epoch 157], [iter 85 / 176], [train main loss -2.028721], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 86 / 176], [train main loss -2.042632], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 87 / 176], [train main loss -2.028647], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 88 / 176], [train main loss -2.004605], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 89 / 176], [train main loss -2.014666], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 90 / 176], [train main loss -1.998805], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 91 / 176], [train main loss -2.019146], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 92 / 176], [train main loss -2.026256], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 93 / 176], [train main loss -2.020006], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 94 / 176], [train main loss -1.993641], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 95 / 176], [train main loss -2.007494], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 96 / 176], [train main loss -2.001230], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 97 / 176], [train main loss -2.016961], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 98 / 176], [train main loss -2.045953], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 99 / 176], [train main loss -2.055488], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 100 / 176], [train main loss -2.050492], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 101 / 176], [train main loss -2.053134], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 102 / 176], [train main loss -2.079940], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 103 / 176], [train main loss -2.097313], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 104 / 176], [train main loss -2.122445], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 105 / 176], [train main loss -2.115565], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 106 / 176], [train main loss -2.129503], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 107 / 176], [train main loss -2.134827], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 108 / 176], [train main loss -2.150571], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 109 / 176], [train main loss -2.164184], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 110 / 176], [train main loss -2.186848], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 111 / 176], [train main loss -2.189718], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 112 / 176], [train main loss -2.187508], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 113 / 176], [train main loss -2.179656], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 114 / 176], [train main loss -2.179460], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 115 / 176], [train main loss -2.175092], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 116 / 176], [train main loss -2.152846], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 117 / 176], [train main loss -2.137330], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 118 / 176], [train main loss -2.129632], [lr 0.001029] [batchtime 0.415]
[epoch 157], [iter 119 / 176], [train main loss -2.112732], [lr 0.001029] [batchtime 0.415]
[epoch 157], [iter 120 / 176], [train main loss -2.126916], [lr 0.001029] [batchtime 0.415]
[epoch 157], [iter 121 / 176], [train main loss -2.145738], [lr 0.001029] [batchtime 0.415]
[epoch 157], [iter 122 / 176], [train main loss -2.158882], [lr 0.001029] [batchtime 0.415]
[epoch 157], [iter 123 / 176], [train main loss -2.148597], [lr 0.001029] [batchtime 0.414]
[epoch 157], [iter 124 / 176], [train main loss -2.148353], [lr 0.001029] [batchtime 0.415]
[epoch 157], [iter 125 / 176], [train main loss -2.141895], [lr 0.001029] [batchtime 0.426]
[epoch 157], [iter 126 / 176], [train main loss -2.137344], [lr 0.001029] [batchtime 0.425]
[epoch 157], [iter 127 / 176], [train main loss -2.139498], [lr 0.001029] [batchtime 0.425]
[epoch 157], [iter 128 / 176], [train main loss -2.144864], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 129 / 176], [train main loss -2.135702], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 130 / 176], [train main loss -2.145601], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 131 / 176], [train main loss -2.149423], [lr 0.001029] [batchtime 0.424]
[epoch 157], [iter 132 / 176], [train main loss -2.138888], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 133 / 176], [train main loss -2.132685], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 134 / 176], [train main loss -2.141438], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 135 / 176], [train main loss -2.140645], [lr 0.001029] [batchtime 0.423]
[epoch 157], [iter 136 / 176], [train main loss -2.142906], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 137 / 176], [train main loss -2.162468], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 138 / 176], [train main loss -2.154320], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 139 / 176], [train main loss -2.152054], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 140 / 176], [train main loss -2.142650], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 141 / 176], [train main loss -2.129731], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 142 / 176], [train main loss -2.135469], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 143 / 176], [train main loss -2.132141], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 144 / 176], [train main loss -2.140627], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 145 / 176], [train main loss -2.128069], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 146 / 176], [train main loss -2.118509], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 147 / 176], [train main loss -2.125166], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 148 / 176], [train main loss -2.131722], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 149 / 176], [train main loss -2.126420], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 150 / 176], [train main loss -2.152176], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 151 / 176], [train main loss -2.145233], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 152 / 176], [train main loss -2.151627], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 153 / 176], [train main loss -2.138979], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 154 / 176], [train main loss -2.132096], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 155 / 176], [train main loss -2.119689], [lr 0.001029] [batchtime 0.419]
[epoch 157], [iter 156 / 176], [train main loss -2.131605], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 157 / 176], [train main loss -2.140110], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 158 / 176], [train main loss -2.150087], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 159 / 176], [train main loss -2.170229], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 160 / 176], [train main loss -2.152982], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 161 / 176], [train main loss -2.157474], [lr 0.001029] [batchtime 0.418]
[epoch 157], [iter 162 / 176], [train main loss -2.163175], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 163 / 176], [train main loss -2.166297], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 164 / 176], [train main loss -2.161392], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 165 / 176], [train main loss -2.159729], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 166 / 176], [train main loss -2.157045], [lr 0.001029] [batchtime 0.417]
[epoch 157], [iter 167 / 176], [train main loss -2.159416], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 168 / 176], [train main loss -2.172401], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 169 / 176], [train main loss -2.161419], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 170 / 176], [train main loss -2.147615], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 171 / 176], [train main loss -2.151827], [lr 0.001029] [batchtime 0.416]
[epoch 157], [iter 172 / 176], [train main loss -2.149254], [lr 0.001029] [batchtime 0.42]
[epoch 157], [iter 173 / 176], [train main loss -2.152166], [lr 0.001029] [batchtime 0.422]
[epoch 157], [iter 174 / 176], [train main loss -2.163632], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 175 / 176], [train main loss -2.173759], [lr 0.001029] [batchtime 0.421]
[epoch 157], [iter 176 / 176], [train main loss -2.174626], [lr 0.001029] [batchtime 0.421]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.98  35.69   0.02  0.03         0.98      0.97
   1  sidewalk          70.20   5.30   0.24  0.18         0.80      0.85
   2  building          86.94  24.95   0.07  0.08         0.94      0.92
   3  wall              18.16   0.14   3.25  1.25         0.24      0.44
   4  fence             25.45   0.37   2.39  0.54         0.30      0.65
   5  pole              40.14   0.57   1.01  0.48         0.50      0.67
   6  traffic light     19.00   0.03   3.79  0.47         0.21      0.68
   7  traffic sign      29.51   0.18   2.15  0.24         0.32      0.81
   8  vegetation        83.73  11.77   0.05  0.14         0.95      0.87
   9  terrain           42.25   0.40   0.85  0.52         0.54      0.66
  10  sky               94.02   3.76   0.03  0.03         0.97      0.97
  11  person            56.31   1.08   0.42  0.36         0.71      0.74
  12  rider             14.32   0.01   5.09  0.89         0.16      0.53
  13  car               86.62   6.73   0.05  0.10         0.95      0.91
  14  truck              2.31   0.01  41.74  0.46         0.02      0.69
  15  bus               16.81   0.05   0.92  4.03         0.52      0.20
  16  train             32.73   0.07   1.52  0.54         0.40      0.65
  17  motorcycle         5.15   0.01  17.82  0.59         0.05      0.63
  18  bicycle           40.70   0.27   0.46  0.99         0.68      0.50
Mean: 45.23
-----------------------------------------------------------------------------------------------------------
this : [epoch 157], [val loss 0.29653], [acc 0.91380], [acc_cls 0.53911], [mean_iu 0.45228], [fwavacc 0.84902]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 158], [iter 1 / 176], [train main loss -5.842404], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 2 / 176], [train main loss -4.512543], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 3 / 176], [train main loss -2.875369], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 4 / 176], [train main loss -2.221118], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 5 / 176], [train main loss -2.628337], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 6 / 176], [train main loss -2.676837], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 7 / 176], [train main loss -2.910974], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 8 / 176], [train main loss -2.896954], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 9 / 176], [train main loss -2.716060], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 10 / 176], [train main loss -2.590872], [lr 0.000971] [batchtime 0]
[epoch 158], [iter 11 / 176], [train main loss -2.430003], [lr 0.000971] [batchtime 0.38]
[epoch 158], [iter 12 / 176], [train main loss -2.200511], [lr 0.000971] [batchtime 0.39]
[epoch 158], [iter 13 / 176], [train main loss -2.181486], [lr 0.000971] [batchtime 0.399]
[epoch 158], [iter 14 / 176], [train main loss -2.328113], [lr 0.000971] [batchtime 0.396]
[epoch 158], [iter 15 / 176], [train main loss -2.357029], [lr 0.000971] [batchtime 0.395]
[epoch 158], [iter 16 / 176], [train main loss -2.356808], [lr 0.000971] [batchtime 0.396]
[epoch 158], [iter 17 / 176], [train main loss -2.272596], [lr 0.000971] [batchtime 0.396]
[epoch 158], [iter 18 / 176], [train main loss -2.227956], [lr 0.000971] [batchtime 0.397]
[epoch 158], [iter 19 / 176], [train main loss -2.137487], [lr 0.000971] [batchtime 0.398]
[epoch 158], [iter 20 / 176], [train main loss -2.108696], [lr 0.000971] [batchtime 0.397]
[epoch 158], [iter 21 / 176], [train main loss -2.152889], [lr 0.000971] [batchtime 0.396]
[epoch 158], [iter 22 / 176], [train main loss -2.244111], [lr 0.000971] [batchtime 0.396]
[epoch 158], [iter 23 / 176], [train main loss -2.131723], [lr 0.000971] [batchtime 0.396]
[epoch 158], [iter 24 / 176], [train main loss -2.175988], [lr 0.000971] [batchtime 0.397]
[epoch 158], [iter 25 / 176], [train main loss -2.235498], [lr 0.000971] [batchtime 0.4]
[epoch 158], [iter 26 / 176], [train main loss -2.182703], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 27 / 176], [train main loss -2.279191], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 28 / 176], [train main loss -2.323531], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 29 / 176], [train main loss -2.341526], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 30 / 176], [train main loss -2.374882], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 31 / 176], [train main loss -2.279392], [lr 0.000971] [batchtime 0.409]
[epoch 158], [iter 32 / 176], [train main loss -2.181454], [lr 0.000971] [batchtime 0.408]
[epoch 158], [iter 33 / 176], [train main loss -2.150960], [lr 0.000971] [batchtime 0.408]
[epoch 158], [iter 34 / 176], [train main loss -2.064290], [lr 0.000971] [batchtime 0.408]
[epoch 158], [iter 35 / 176], [train main loss -2.032933], [lr 0.000971] [batchtime 0.408]
[epoch 158], [iter 36 / 176], [train main loss -1.943536], [lr 0.000971] [batchtime 0.407]
[epoch 158], [iter 37 / 176], [train main loss -1.996629], [lr 0.000971] [batchtime 0.407]
[epoch 158], [iter 38 / 176], [train main loss -2.007729], [lr 0.000971] [batchtime 0.407]
[epoch 158], [iter 39 / 176], [train main loss -1.964022], [lr 0.000971] [batchtime 0.407]
[epoch 158], [iter 40 / 176], [train main loss -1.994606], [lr 0.000971] [batchtime 0.407]
[epoch 158], [iter 41 / 176], [train main loss -2.006668], [lr 0.000971] [batchtime 0.407]
[epoch 158], [iter 42 / 176], [train main loss -1.994785], [lr 0.000971] [batchtime 0.406]
[epoch 158], [iter 43 / 176], [train main loss -2.034929], [lr 0.000971] [batchtime 0.406]
[epoch 158], [iter 44 / 176], [train main loss -2.046684], [lr 0.000971] [batchtime 0.406]
[epoch 158], [iter 45 / 176], [train main loss -2.026624], [lr 0.000971] [batchtime 0.405]
[epoch 158], [iter 46 / 176], [train main loss -2.001859], [lr 0.000971] [batchtime 0.405]
[epoch 158], [iter 47 / 176], [train main loss -2.020289], [lr 0.000971] [batchtime 0.405]
[epoch 158], [iter 48 / 176], [train main loss -2.034247], [lr 0.000971] [batchtime 0.404]
[epoch 158], [iter 49 / 176], [train main loss -2.103993], [lr 0.000971] [batchtime 0.404]
[epoch 158], [iter 50 / 176], [train main loss -2.094189], [lr 0.000971] [batchtime 0.424]
[epoch 158], [iter 51 / 176], [train main loss -2.068643], [lr 0.000971] [batchtime 0.427]
[epoch 158], [iter 52 / 176], [train main loss -2.068199], [lr 0.000971] [batchtime 0.426]
[epoch 158], [iter 53 / 176], [train main loss -2.068777], [lr 0.000971] [batchtime 0.425]
[epoch 158], [iter 54 / 176], [train main loss -2.041101], [lr 0.000971] [batchtime 0.424]
[epoch 158], [iter 55 / 176], [train main loss -2.102684], [lr 0.000971] [batchtime 0.424]
[epoch 158], [iter 56 / 176], [train main loss -2.074120], [lr 0.000971] [batchtime 0.423]
[epoch 158], [iter 57 / 176], [train main loss -2.079494], [lr 0.000971] [batchtime 0.422]
[epoch 158], [iter 58 / 176], [train main loss -2.082700], [lr 0.000971] [batchtime 0.422]
[epoch 158], [iter 59 / 176], [train main loss -2.092764], [lr 0.000971] [batchtime 0.421]
[epoch 158], [iter 60 / 176], [train main loss -2.116492], [lr 0.000971] [batchtime 0.421]
[epoch 158], [iter 61 / 176], [train main loss -2.079777], [lr 0.000971] [batchtime 0.42]
[epoch 158], [iter 62 / 176], [train main loss -2.085461], [lr 0.000971] [batchtime 0.42]
[epoch 158], [iter 63 / 176], [train main loss -2.058349], [lr 0.000971] [batchtime 0.419]
[epoch 158], [iter 64 / 176], [train main loss -2.061691], [lr 0.000971] [batchtime 0.419]
[epoch 158], [iter 65 / 176], [train main loss -2.022886], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 66 / 176], [train main loss -2.035562], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 67 / 176], [train main loss -2.025680], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 68 / 176], [train main loss -1.992697], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 69 / 176], [train main loss -1.981971], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 70 / 176], [train main loss -2.026829], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 71 / 176], [train main loss -2.032455], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 72 / 176], [train main loss -2.030266], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 73 / 176], [train main loss -2.063321], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 74 / 176], [train main loss -2.065313], [lr 0.000971] [batchtime 0.419]
[epoch 158], [iter 75 / 176], [train main loss -2.086601], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 76 / 176], [train main loss -2.088536], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 77 / 176], [train main loss -2.137184], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 78 / 176], [train main loss -2.126535], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 79 / 176], [train main loss -2.099185], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 80 / 176], [train main loss -2.100383], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 81 / 176], [train main loss -2.082605], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 82 / 176], [train main loss -2.049334], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 83 / 176], [train main loss -2.055993], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 84 / 176], [train main loss -2.071327], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 85 / 176], [train main loss -2.066583], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 86 / 176], [train main loss -2.081608], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 87 / 176], [train main loss -2.075602], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 88 / 176], [train main loss -2.058937], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 89 / 176], [train main loss -2.066239], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 90 / 176], [train main loss -2.040640], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 91 / 176], [train main loss -2.032407], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 92 / 176], [train main loss -2.094020], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 93 / 176], [train main loss -2.087062], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 94 / 176], [train main loss -2.076698], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 95 / 176], [train main loss -2.086872], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 96 / 176], [train main loss -2.110061], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 97 / 176], [train main loss -2.090782], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 98 / 176], [train main loss -2.078603], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 99 / 176], [train main loss -2.066213], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 100 / 176], [train main loss -2.067296], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 101 / 176], [train main loss -2.073541], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 102 / 176], [train main loss -2.059496], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 103 / 176], [train main loss -2.068469], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 104 / 176], [train main loss -2.069249], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 105 / 176], [train main loss -2.051669], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 106 / 176], [train main loss -2.063931], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 107 / 176], [train main loss -2.078928], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 108 / 176], [train main loss -2.063545], [lr 0.000971] [batchtime 0.414]
[epoch 158], [iter 109 / 176], [train main loss -2.065285], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 110 / 176], [train main loss -2.063278], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 111 / 176], [train main loss -2.061024], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 112 / 176], [train main loss -2.054355], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 113 / 176], [train main loss -2.066583], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 114 / 176], [train main loss -2.078552], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 115 / 176], [train main loss -2.086005], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 116 / 176], [train main loss -2.077959], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 117 / 176], [train main loss -2.068963], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 118 / 176], [train main loss -2.096311], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 119 / 176], [train main loss -2.110241], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 120 / 176], [train main loss -2.107727], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 121 / 176], [train main loss -2.107331], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 122 / 176], [train main loss -2.142086], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 123 / 176], [train main loss -2.162458], [lr 0.000971] [batchtime 0.413]
[epoch 158], [iter 124 / 176], [train main loss -2.175292], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 125 / 176], [train main loss -2.165843], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 126 / 176], [train main loss -2.167959], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 127 / 176], [train main loss -2.172051], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 128 / 176], [train main loss -2.154173], [lr 0.000971] [batchtime 0.412]
[epoch 158], [iter 129 / 176], [train main loss -2.160240], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 130 / 176], [train main loss -2.197707], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 131 / 176], [train main loss -2.183485], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 132 / 176], [train main loss -2.197780], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 133 / 176], [train main loss -2.193651], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 134 / 176], [train main loss -2.180471], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 135 / 176], [train main loss -2.176834], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 136 / 176], [train main loss -2.178400], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 137 / 176], [train main loss -2.189407], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 138 / 176], [train main loss -2.189493], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 139 / 176], [train main loss -2.187550], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 140 / 176], [train main loss -2.172767], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 141 / 176], [train main loss -2.187658], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 142 / 176], [train main loss -2.181786], [lr 0.000971] [batchtime 0.41]
[epoch 158], [iter 143 / 176], [train main loss -2.172015], [lr 0.000971] [batchtime 0.409]
[epoch 158], [iter 144 / 176], [train main loss -2.163880], [lr 0.000971] [batchtime 0.409]
[epoch 158], [iter 145 / 176], [train main loss -2.164010], [lr 0.000971] [batchtime 0.409]
[epoch 158], [iter 146 / 176], [train main loss -2.161898], [lr 0.000971] [batchtime 0.409]
[epoch 158], [iter 147 / 176], [train main loss -2.172044], [lr 0.000971] [batchtime 0.411]
[epoch 158], [iter 148 / 176], [train main loss -2.168112], [lr 0.000971] [batchtime 0.419]
[epoch 158], [iter 149 / 176], [train main loss -2.169338], [lr 0.000971] [batchtime 0.419]
[epoch 158], [iter 150 / 176], [train main loss -2.169730], [lr 0.000971] [batchtime 0.419]
[epoch 158], [iter 151 / 176], [train main loss -2.185915], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 152 / 176], [train main loss -2.158331], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 153 / 176], [train main loss -2.141205], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 154 / 176], [train main loss -2.135948], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 155 / 176], [train main loss -2.135411], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 156 / 176], [train main loss -2.159723], [lr 0.000971] [batchtime 0.418]
[epoch 158], [iter 157 / 176], [train main loss -2.141433], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 158 / 176], [train main loss -2.133610], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 159 / 176], [train main loss -2.142579], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 160 / 176], [train main loss -2.155087], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 161 / 176], [train main loss -2.156672], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 162 / 176], [train main loss -2.164706], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 163 / 176], [train main loss -2.169044], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 164 / 176], [train main loss -2.173359], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 165 / 176], [train main loss -2.171852], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 166 / 176], [train main loss -2.176504], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 167 / 176], [train main loss -2.164974], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 168 / 176], [train main loss -2.151066], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 169 / 176], [train main loss -2.146767], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 170 / 176], [train main loss -2.143234], [lr 0.000971] [batchtime 0.417]
[epoch 158], [iter 171 / 176], [train main loss -2.141447], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 172 / 176], [train main loss -2.145522], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 173 / 176], [train main loss -2.146207], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 174 / 176], [train main loss -2.135135], [lr 0.000971] [batchtime 0.416]
[epoch 158], [iter 175 / 176], [train main loss -2.144473], [lr 0.000971] [batchtime 0.415]
[epoch 158], [iter 176 / 176], [train main loss -2.154903], [lr 0.000971] [batchtime 0.415]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.12  35.50   0.02  0.03         0.98      0.97
   1  sidewalk          71.65   5.50   0.20  0.20         0.83      0.83
   2  building          86.97  24.95   0.07  0.08         0.94      0.92
   3  wall              19.13   0.16   2.81  1.42         0.26      0.41
   4  fence             27.12   0.41   2.07  0.62         0.33      0.62
   5  pole              40.65   0.60   0.89  0.57         0.53      0.64
   6  traffic light     20.77   0.04   3.21  0.61         0.24      0.62
   7  traffic sign      31.08   0.19   1.92  0.30         0.34      0.77
   8  vegetation        84.21  11.72   0.05  0.13         0.95      0.88
   9  terrain           41.53   0.38   0.93  0.48         0.52      0.68
  10  sky               93.46   3.77   0.03  0.04         0.97      0.96
  11  person            55.94   1.06   0.45  0.34         0.69      0.75
  12  rider             15.98   0.02   4.28  0.98         0.19      0.50
  13  car               86.65   6.74   0.05  0.10         0.95      0.91
  14  truck              1.50   0.00  65.21  0.50         0.02      0.67
  15  bus               16.15   0.05   0.87  4.32         0.53      0.19
  16  train             34.93   0.09   1.10  0.76         0.48      0.57
  17  motorcycle         6.30   0.01  14.20  0.68         0.07      0.60
  18  bicycle           41.19   0.27   0.45  0.98         0.69      0.51
Mean: 45.81
-----------------------------------------------------------------------------------------------------------
this : [epoch 158], [val loss 0.29040], [acc 0.91443], [acc_cls 0.55253], [mean_iu 0.45807], [fwavacc 0.85137]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 159], [iter 1 / 176], [train main loss -0.634169], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 2 / 176], [train main loss -2.303152], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 3 / 176], [train main loss -2.872479], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 4 / 176], [train main loss -2.858706], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 5 / 176], [train main loss -3.369265], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 6 / 176], [train main loss -3.515516], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 7 / 176], [train main loss -3.510143], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 8 / 176], [train main loss -3.382247], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 9 / 176], [train main loss -3.304454], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 10 / 176], [train main loss -3.632248], [lr 0.000914] [batchtime 0]
[epoch 159], [iter 11 / 176], [train main loss -3.833272], [lr 0.000914] [batchtime 0.377]
[epoch 159], [iter 12 / 176], [train main loss -3.644008], [lr 0.000914] [batchtime 0.391]
[epoch 159], [iter 13 / 176], [train main loss -3.469162], [lr 0.000914] [batchtime 0.403]
[epoch 159], [iter 14 / 176], [train main loss -3.423144], [lr 0.000914] [batchtime 0.399]
[epoch 159], [iter 15 / 176], [train main loss -3.291276], [lr 0.000914] [batchtime 0.397]
[epoch 159], [iter 16 / 176], [train main loss -3.257583], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 17 / 176], [train main loss -3.152929], [lr 0.000914] [batchtime 0.397]
[epoch 159], [iter 18 / 176], [train main loss -3.046064], [lr 0.000914] [batchtime 0.397]
[epoch 159], [iter 19 / 176], [train main loss -3.054920], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 20 / 176], [train main loss -2.951145], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 21 / 176], [train main loss -3.000742], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 22 / 176], [train main loss -2.832061], [lr 0.000914] [batchtime 0.395]
[epoch 159], [iter 23 / 176], [train main loss -2.778996], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 24 / 176], [train main loss -2.741244], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 25 / 176], [train main loss -2.778417], [lr 0.000914] [batchtime 0.396]
[epoch 159], [iter 26 / 176], [train main loss -2.803053], [lr 0.000914] [batchtime 0.398]
[epoch 159], [iter 27 / 176], [train main loss -2.738273], [lr 0.000914] [batchtime 0.41]
[epoch 159], [iter 28 / 176], [train main loss -2.700987], [lr 0.000914] [batchtime 0.409]
[epoch 159], [iter 29 / 176], [train main loss -2.654271], [lr 0.000914] [batchtime 0.408]
[epoch 159], [iter 30 / 176], [train main loss -2.665832], [lr 0.000914] [batchtime 0.407]
[epoch 159], [iter 31 / 176], [train main loss -2.638357], [lr 0.000914] [batchtime 0.406]
[epoch 159], [iter 32 / 176], [train main loss -2.635256], [lr 0.000914] [batchtime 0.406]
[epoch 159], [iter 33 / 176], [train main loss -2.546618], [lr 0.000914] [batchtime 0.406]
[epoch 159], [iter 34 / 176], [train main loss -2.514222], [lr 0.000914] [batchtime 0.405]
[epoch 159], [iter 35 / 176], [train main loss -2.501873], [lr 0.000914] [batchtime 0.405]
[epoch 159], [iter 36 / 176], [train main loss -2.464915], [lr 0.000914] [batchtime 0.405]
[epoch 159], [iter 37 / 176], [train main loss -2.447164], [lr 0.000914] [batchtime 0.404]
[epoch 159], [iter 38 / 176], [train main loss -2.446328], [lr 0.000914] [batchtime 0.404]
[epoch 159], [iter 39 / 176], [train main loss -2.400100], [lr 0.000914] [batchtime 0.404]
[epoch 159], [iter 40 / 176], [train main loss -2.406762], [lr 0.000914] [batchtime 0.404]
[epoch 159], [iter 41 / 176], [train main loss -2.421348], [lr 0.000914] [batchtime 0.404]
[epoch 159], [iter 42 / 176], [train main loss -2.386421], [lr 0.000914] [batchtime 0.403]
[epoch 159], [iter 43 / 176], [train main loss -2.366678], [lr 0.000914] [batchtime 0.403]
[epoch 159], [iter 44 / 176], [train main loss -2.320258], [lr 0.000914] [batchtime 0.403]
[epoch 159], [iter 45 / 176], [train main loss -2.288949], [lr 0.000914] [batchtime 0.402]
[epoch 159], [iter 46 / 176], [train main loss -2.229370], [lr 0.000914] [batchtime 0.402]
[epoch 159], [iter 47 / 176], [train main loss -2.240192], [lr 0.000914] [batchtime 0.402]
[epoch 159], [iter 48 / 176], [train main loss -2.248814], [lr 0.000914] [batchtime 0.402]
[epoch 159], [iter 49 / 176], [train main loss -2.182772], [lr 0.000914] [batchtime 0.402]
[epoch 159], [iter 50 / 176], [train main loss -2.176950], [lr 0.000914] [batchtime 0.402]
[epoch 159], [iter 51 / 176], [train main loss -2.172274], [lr 0.000914] [batchtime 0.427]
[epoch 159], [iter 52 / 176], [train main loss -2.212346], [lr 0.000914] [batchtime 0.43]
[epoch 159], [iter 53 / 176], [train main loss -2.201280], [lr 0.000914] [batchtime 0.429]
[epoch 159], [iter 54 / 176], [train main loss -2.185730], [lr 0.000914] [batchtime 0.428]
[epoch 159], [iter 55 / 176], [train main loss -2.162633], [lr 0.000914] [batchtime 0.428]
[epoch 159], [iter 56 / 176], [train main loss -2.186687], [lr 0.000914] [batchtime 0.427]
[epoch 159], [iter 57 / 176], [train main loss -2.182228], [lr 0.000914] [batchtime 0.427]
[epoch 159], [iter 58 / 176], [train main loss -2.167989], [lr 0.000914] [batchtime 0.426]
[epoch 159], [iter 59 / 176], [train main loss -2.186585], [lr 0.000914] [batchtime 0.425]
[epoch 159], [iter 60 / 176], [train main loss -2.174615], [lr 0.000914] [batchtime 0.425]
[epoch 159], [iter 61 / 176], [train main loss -2.169408], [lr 0.000914] [batchtime 0.424]
[epoch 159], [iter 62 / 176], [train main loss -2.170252], [lr 0.000914] [batchtime 0.424]
[epoch 159], [iter 63 / 176], [train main loss -2.219880], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 64 / 176], [train main loss -2.211684], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 65 / 176], [train main loss -2.242441], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 66 / 176], [train main loss -2.275483], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 67 / 176], [train main loss -2.240124], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 68 / 176], [train main loss -2.249597], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 69 / 176], [train main loss -2.245414], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 70 / 176], [train main loss -2.274883], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 71 / 176], [train main loss -2.289743], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 72 / 176], [train main loss -2.298646], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 73 / 176], [train main loss -2.285629], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 74 / 176], [train main loss -2.273878], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 75 / 176], [train main loss -2.275161], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 76 / 176], [train main loss -2.273484], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 77 / 176], [train main loss -2.296355], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 78 / 176], [train main loss -2.284224], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 79 / 176], [train main loss -2.305615], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 80 / 176], [train main loss -2.311069], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 81 / 176], [train main loss -2.318901], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 82 / 176], [train main loss -2.311874], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 83 / 176], [train main loss -2.346315], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 84 / 176], [train main loss -2.355644], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 85 / 176], [train main loss -2.336068], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 86 / 176], [train main loss -2.331212], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 87 / 176], [train main loss -2.337362], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 88 / 176], [train main loss -2.343959], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 89 / 176], [train main loss -2.324431], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 90 / 176], [train main loss -2.320173], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 91 / 176], [train main loss -2.298109], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 92 / 176], [train main loss -2.318585], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 93 / 176], [train main loss -2.308838], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 94 / 176], [train main loss -2.310205], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 95 / 176], [train main loss -2.357191], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 96 / 176], [train main loss -2.331928], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 97 / 176], [train main loss -2.331220], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 98 / 176], [train main loss -2.318551], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 99 / 176], [train main loss -2.320684], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 100 / 176], [train main loss -2.313809], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 101 / 176], [train main loss -2.330133], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 102 / 176], [train main loss -2.322339], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 103 / 176], [train main loss -2.324232], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 104 / 176], [train main loss -2.324254], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 105 / 176], [train main loss -2.332621], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 106 / 176], [train main loss -2.322497], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 107 / 176], [train main loss -2.317540], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 108 / 176], [train main loss -2.281973], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 109 / 176], [train main loss -2.288381], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 110 / 176], [train main loss -2.288051], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 111 / 176], [train main loss -2.255041], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 112 / 176], [train main loss -2.263701], [lr 0.000914] [batchtime 0.419]
[epoch 159], [iter 113 / 176], [train main loss -2.254213], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 114 / 176], [train main loss -2.264951], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 115 / 176], [train main loss -2.251678], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 116 / 176], [train main loss -2.250590], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 117 / 176], [train main loss -2.237880], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 118 / 176], [train main loss -2.238754], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 119 / 176], [train main loss -2.254476], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 120 / 176], [train main loss -2.265481], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 121 / 176], [train main loss -2.270955], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 122 / 176], [train main loss -2.270902], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 123 / 176], [train main loss -2.284299], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 124 / 176], [train main loss -2.276559], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 125 / 176], [train main loss -2.292776], [lr 0.000914] [batchtime 0.418]
[epoch 159], [iter 126 / 176], [train main loss -2.272426], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 127 / 176], [train main loss -2.278090], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 128 / 176], [train main loss -2.300155], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 129 / 176], [train main loss -2.263456], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 130 / 176], [train main loss -2.249739], [lr 0.000914] [batchtime 0.417]
[epoch 159], [iter 131 / 176], [train main loss -2.255724], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 132 / 176], [train main loss -2.239067], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 133 / 176], [train main loss -2.234870], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 134 / 176], [train main loss -2.244540], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 135 / 176], [train main loss -2.261594], [lr 0.000914] [batchtime 0.416]
[epoch 159], [iter 136 / 176], [train main loss -2.257947], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 137 / 176], [train main loss -2.261414], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 138 / 176], [train main loss -2.246539], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 139 / 176], [train main loss -2.227438], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 140 / 176], [train main loss -2.216501], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 141 / 176], [train main loss -2.214485], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 142 / 176], [train main loss -2.211536], [lr 0.000914] [batchtime 0.415]
[epoch 159], [iter 143 / 176], [train main loss -2.204590], [lr 0.000914] [batchtime 0.414]
[epoch 159], [iter 144 / 176], [train main loss -2.212741], [lr 0.000914] [batchtime 0.414]
[epoch 159], [iter 145 / 176], [train main loss -2.219163], [lr 0.000914] [batchtime 0.414]
[epoch 159], [iter 146 / 176], [train main loss -2.211843], [lr 0.000914] [batchtime 0.414]
[epoch 159], [iter 147 / 176], [train main loss -2.212150], [lr 0.000914] [batchtime 0.424]
[epoch 159], [iter 148 / 176], [train main loss -2.203661], [lr 0.000914] [batchtime 0.424]
[epoch 159], [iter 149 / 176], [train main loss -2.191188], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 150 / 176], [train main loss -2.189088], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 151 / 176], [train main loss -2.190251], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 152 / 176], [train main loss -2.179085], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 153 / 176], [train main loss -2.174215], [lr 0.000914] [batchtime 0.423]
[epoch 159], [iter 154 / 176], [train main loss -2.181661], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 155 / 176], [train main loss -2.182361], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 156 / 176], [train main loss -2.167436], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 157 / 176], [train main loss -2.160889], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 158 / 176], [train main loss -2.181904], [lr 0.000914] [batchtime 0.422]
[epoch 159], [iter 159 / 176], [train main loss -2.192974], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 160 / 176], [train main loss -2.192389], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 161 / 176], [train main loss -2.182130], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 162 / 176], [train main loss -2.189933], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 163 / 176], [train main loss -2.199838], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 164 / 176], [train main loss -2.199752], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 165 / 176], [train main loss -2.200072], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 166 / 176], [train main loss -2.201950], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 167 / 176], [train main loss -2.216710], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 168 / 176], [train main loss -2.219025], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 169 / 176], [train main loss -2.207509], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 170 / 176], [train main loss -2.195592], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 171 / 176], [train main loss -2.191760], [lr 0.000914] [batchtime 0.421]
[epoch 159], [iter 172 / 176], [train main loss -2.176482], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 173 / 176], [train main loss -2.190780], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 174 / 176], [train main loss -2.197753], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 175 / 176], [train main loss -2.190767], [lr 0.000914] [batchtime 0.42]
[epoch 159], [iter 176 / 176], [train main loss -2.192102], [lr 0.000914] [batchtime 0.419]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.87  35.75   0.02  0.04         0.98      0.96
   1  sidewalk          69.72   5.20   0.27  0.17         0.79      0.86
   2  building          87.18  25.19   0.06  0.09         0.95      0.92
   3  wall              19.00   0.15   2.97  1.29         0.25      0.44
   4  fence             27.11   0.41   2.07  0.62         0.33      0.62
   5  pole              40.73   0.59   0.92  0.53         0.52      0.65
   6  traffic light     19.90   0.03   3.57  0.45         0.22      0.69
   7  traffic sign      28.78   0.17   2.25  0.22         0.31      0.82
   8  vegetation        84.82  11.64   0.06  0.12         0.94      0.90
   9  terrain           41.89   0.39   0.90  0.48         0.53      0.67
  10  sky               94.03   3.75   0.03  0.03         0.97      0.97
  11  person            55.70   1.05   0.46  0.34         0.69      0.75
  12  rider             13.24   0.01   5.64  0.91         0.15      0.52
  13  car               86.84   6.72   0.05  0.10         0.95      0.91
  14  truck              1.31   0.00  75.18  0.40         0.01      0.71
  15  bus               16.27   0.04   0.96  4.19         0.51      0.19
  16  train             36.89   0.08   1.19  0.52         0.46      0.66
  17  motorcycle         5.45   0.01  16.68  0.67         0.06      0.60
  18  bicycle           40.38   0.28   0.42  1.06         0.71      0.49
Mean: 45.48
-----------------------------------------------------------------------------------------------------------
this : [epoch 159], [val loss 0.29527], [acc 0.91466], [acc_cls 0.54249], [mean_iu 0.45479], [fwavacc 0.85066]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 160], [iter 1 / 176], [train main loss -2.124968], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 2 / 176], [train main loss -2.658223], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 3 / 176], [train main loss -3.061870], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 4 / 176], [train main loss -3.595779], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 5 / 176], [train main loss -3.503967], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 6 / 176], [train main loss -2.998090], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 7 / 176], [train main loss -3.076153], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 8 / 176], [train main loss -3.231941], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 9 / 176], [train main loss -3.416222], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 10 / 176], [train main loss -2.935815], [lr 0.000857] [batchtime 0]
[epoch 160], [iter 11 / 176], [train main loss -2.656336], [lr 0.000857] [batchtime 0.368]
[epoch 160], [iter 12 / 176], [train main loss -2.413824], [lr 0.000857] [batchtime 0.381]
[epoch 160], [iter 13 / 176], [train main loss -2.400918], [lr 0.000857] [batchtime 0.386]
[epoch 160], [iter 14 / 176], [train main loss -2.585546], [lr 0.000857] [batchtime 0.39]
[epoch 160], [iter 15 / 176], [train main loss -2.509561], [lr 0.000857] [batchtime 0.392]
[epoch 160], [iter 16 / 176], [train main loss -2.500395], [lr 0.000857] [batchtime 0.395]
[epoch 160], [iter 17 / 176], [train main loss -2.529673], [lr 0.000857] [batchtime 0.396]
[epoch 160], [iter 18 / 176], [train main loss -2.623355], [lr 0.000857] [batchtime 0.395]
[epoch 160], [iter 19 / 176], [train main loss -2.719757], [lr 0.000857] [batchtime 0.396]
[epoch 160], [iter 20 / 176], [train main loss -2.821570], [lr 0.000857] [batchtime 0.395]
[epoch 160], [iter 21 / 176], [train main loss -2.785481], [lr 0.000857] [batchtime 0.397]
[epoch 160], [iter 22 / 176], [train main loss -2.681472], [lr 0.000857] [batchtime 0.398]
[epoch 160], [iter 23 / 176], [train main loss -2.797464], [lr 0.000857] [batchtime 0.398]
[epoch 160], [iter 24 / 176], [train main loss -2.670854], [lr 0.000857] [batchtime 0.399]
[epoch 160], [iter 25 / 176], [train main loss -2.684280], [lr 0.000857] [batchtime 0.398]
[epoch 160], [iter 26 / 176], [train main loss -2.731432], [lr 0.000857] [batchtime 0.399]
[epoch 160], [iter 27 / 176], [train main loss -2.719161], [lr 0.000857] [batchtime 0.409]
[epoch 160], [iter 28 / 176], [train main loss -2.667146], [lr 0.000857] [batchtime 0.486]
[epoch 160], [iter 29 / 176], [train main loss -2.673993], [lr 0.000857] [batchtime 0.481]
[epoch 160], [iter 30 / 176], [train main loss -2.634411], [lr 0.000857] [batchtime 0.476]
[epoch 160], [iter 31 / 176], [train main loss -2.621078], [lr 0.000857] [batchtime 0.473]
[epoch 160], [iter 32 / 176], [train main loss -2.648027], [lr 0.000857] [batchtime 0.469]
[epoch 160], [iter 33 / 176], [train main loss -2.598598], [lr 0.000857] [batchtime 0.466]
[epoch 160], [iter 34 / 176], [train main loss -2.674927], [lr 0.000857] [batchtime 0.463]
[epoch 160], [iter 35 / 176], [train main loss -2.716595], [lr 0.000857] [batchtime 0.461]
[epoch 160], [iter 36 / 176], [train main loss -2.755442], [lr 0.000857] [batchtime 0.458]
[epoch 160], [iter 37 / 176], [train main loss -2.755840], [lr 0.000857] [batchtime 0.456]
[epoch 160], [iter 38 / 176], [train main loss -2.736791], [lr 0.000857] [batchtime 0.454]
[epoch 160], [iter 39 / 176], [train main loss -2.664687], [lr 0.000857] [batchtime 0.452]
[epoch 160], [iter 40 / 176], [train main loss -2.639212], [lr 0.000857] [batchtime 0.45]
[epoch 160], [iter 41 / 176], [train main loss -2.618999], [lr 0.000857] [batchtime 0.449]
[epoch 160], [iter 42 / 176], [train main loss -2.577269], [lr 0.000857] [batchtime 0.448]
[epoch 160], [iter 43 / 176], [train main loss -2.610835], [lr 0.000857] [batchtime 0.446]
[epoch 160], [iter 44 / 176], [train main loss -2.596849], [lr 0.000857] [batchtime 0.444]
[epoch 160], [iter 45 / 176], [train main loss -2.605362], [lr 0.000857] [batchtime 0.443]
[epoch 160], [iter 46 / 176], [train main loss -2.555505], [lr 0.000857] [batchtime 0.442]
[epoch 160], [iter 47 / 176], [train main loss -2.520562], [lr 0.000857] [batchtime 0.441]
[epoch 160], [iter 48 / 176], [train main loss -2.488179], [lr 0.000857] [batchtime 0.44]
[epoch 160], [iter 49 / 176], [train main loss -2.494963], [lr 0.000857] [batchtime 0.439]
[epoch 160], [iter 50 / 176], [train main loss -2.463323], [lr 0.000857] [batchtime 0.438]
[epoch 160], [iter 51 / 176], [train main loss -2.435143], [lr 0.000857] [batchtime 0.437]
[epoch 160], [iter 52 / 176], [train main loss -2.419117], [lr 0.000857] [batchtime 0.436]
[epoch 160], [iter 53 / 176], [train main loss -2.367062], [lr 0.000857] [batchtime 0.435]
[epoch 160], [iter 54 / 176], [train main loss -2.357475], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 55 / 176], [train main loss -2.289062], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 56 / 176], [train main loss -2.302783], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 57 / 176], [train main loss -2.254746], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 58 / 176], [train main loss -2.284762], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 59 / 176], [train main loss -2.279565], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 60 / 176], [train main loss -2.299933], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 61 / 176], [train main loss -2.276874], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 62 / 176], [train main loss -2.287631], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 63 / 176], [train main loss -2.264794], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 64 / 176], [train main loss -2.281549], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 65 / 176], [train main loss -2.315763], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 66 / 176], [train main loss -2.317039], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 67 / 176], [train main loss -2.298979], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 68 / 176], [train main loss -2.311737], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 69 / 176], [train main loss -2.302544], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 70 / 176], [train main loss -2.287903], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 71 / 176], [train main loss -2.282737], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 72 / 176], [train main loss -2.291036], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 73 / 176], [train main loss -2.361416], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 74 / 176], [train main loss -2.364367], [lr 0.000857] [batchtime 0.437]
[epoch 160], [iter 75 / 176], [train main loss -2.394291], [lr 0.000857] [batchtime 0.439]
[epoch 160], [iter 76 / 176], [train main loss -2.388272], [lr 0.000857] [batchtime 0.438]
[epoch 160], [iter 77 / 176], [train main loss -2.370512], [lr 0.000857] [batchtime 0.437]
[epoch 160], [iter 78 / 176], [train main loss -2.345217], [lr 0.000857] [batchtime 0.437]
[epoch 160], [iter 79 / 176], [train main loss -2.370028], [lr 0.000857] [batchtime 0.436]
[epoch 160], [iter 80 / 176], [train main loss -2.351160], [lr 0.000857] [batchtime 0.435]
[epoch 160], [iter 81 / 176], [train main loss -2.363589], [lr 0.000857] [batchtime 0.435]
[epoch 160], [iter 82 / 176], [train main loss -2.351783], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 83 / 176], [train main loss -2.360118], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 84 / 176], [train main loss -2.373247], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 85 / 176], [train main loss -2.327019], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 86 / 176], [train main loss -2.296685], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 87 / 176], [train main loss -2.306837], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 88 / 176], [train main loss -2.302471], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 89 / 176], [train main loss -2.309954], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 90 / 176], [train main loss -2.322359], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 91 / 176], [train main loss -2.324881], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 92 / 176], [train main loss -2.312142], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 93 / 176], [train main loss -2.311229], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 94 / 176], [train main loss -2.308488], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 95 / 176], [train main loss -2.291497], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 96 / 176], [train main loss -2.287686], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 97 / 176], [train main loss -2.283033], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 98 / 176], [train main loss -2.290206], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 99 / 176], [train main loss -2.296682], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 100 / 176], [train main loss -2.327069], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 101 / 176], [train main loss -2.297348], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 102 / 176], [train main loss -2.309531], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 103 / 176], [train main loss -2.309492], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 104 / 176], [train main loss -2.320990], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 105 / 176], [train main loss -2.331597], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 106 / 176], [train main loss -2.360859], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 107 / 176], [train main loss -2.337081], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 108 / 176], [train main loss -2.349043], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 109 / 176], [train main loss -2.352655], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 110 / 176], [train main loss -2.364875], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 111 / 176], [train main loss -2.378379], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 112 / 176], [train main loss -2.418264], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 113 / 176], [train main loss -2.431034], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 114 / 176], [train main loss -2.435780], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 115 / 176], [train main loss -2.424929], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 116 / 176], [train main loss -2.422866], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 117 / 176], [train main loss -2.414543], [lr 0.000857] [batchtime 0.423]
[epoch 160], [iter 118 / 176], [train main loss -2.408516], [lr 0.000857] [batchtime 0.423]
[epoch 160], [iter 119 / 176], [train main loss -2.410872], [lr 0.000857] [batchtime 0.423]
[epoch 160], [iter 120 / 176], [train main loss -2.405127], [lr 0.000857] [batchtime 0.423]
[epoch 160], [iter 121 / 176], [train main loss -2.431427], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 122 / 176], [train main loss -2.430587], [lr 0.000857] [batchtime 0.435]
[epoch 160], [iter 123 / 176], [train main loss -2.435886], [lr 0.000857] [batchtime 0.435]
[epoch 160], [iter 124 / 176], [train main loss -2.448141], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 125 / 176], [train main loss -2.471923], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 126 / 176], [train main loss -2.455490], [lr 0.000857] [batchtime 0.434]
[epoch 160], [iter 127 / 176], [train main loss -2.474155], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 128 / 176], [train main loss -2.467869], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 129 / 176], [train main loss -2.462071], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 130 / 176], [train main loss -2.486545], [lr 0.000857] [batchtime 0.433]
[epoch 160], [iter 131 / 176], [train main loss -2.502288], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 132 / 176], [train main loss -2.497851], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 133 / 176], [train main loss -2.515565], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 134 / 176], [train main loss -2.515491], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 135 / 176], [train main loss -2.511296], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 136 / 176], [train main loss -2.509841], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 137 / 176], [train main loss -2.487443], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 138 / 176], [train main loss -2.494989], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 139 / 176], [train main loss -2.489543], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 140 / 176], [train main loss -2.487036], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 141 / 176], [train main loss -2.490368], [lr 0.000857] [batchtime 0.43]
[epoch 160], [iter 142 / 176], [train main loss -2.475564], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 143 / 176], [train main loss -2.489544], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 144 / 176], [train main loss -2.495140], [lr 0.000857] [batchtime 0.429]
[epoch 160], [iter 145 / 176], [train main loss -2.498818], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 146 / 176], [train main loss -2.516677], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 147 / 176], [train main loss -2.525667], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 148 / 176], [train main loss -2.519457], [lr 0.000857] [batchtime 0.428]
[epoch 160], [iter 149 / 176], [train main loss -2.505434], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 150 / 176], [train main loss -2.501465], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 151 / 176], [train main loss -2.502006], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 152 / 176], [train main loss -2.502802], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 153 / 176], [train main loss -2.500911], [lr 0.000857] [batchtime 0.427]
[epoch 160], [iter 154 / 176], [train main loss -2.484583], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 155 / 176], [train main loss -2.461494], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 156 / 176], [train main loss -2.456395], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 157 / 176], [train main loss -2.454879], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 158 / 176], [train main loss -2.455740], [lr 0.000857] [batchtime 0.426]
[epoch 160], [iter 159 / 176], [train main loss -2.456331], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 160 / 176], [train main loss -2.462871], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 161 / 176], [train main loss -2.457433], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 162 / 176], [train main loss -2.463842], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 163 / 176], [train main loss -2.449877], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 164 / 176], [train main loss -2.434032], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 165 / 176], [train main loss -2.424057], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 166 / 176], [train main loss -2.418295], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 167 / 176], [train main loss -2.406802], [lr 0.000857] [batchtime 0.424]
[epoch 160], [iter 168 / 176], [train main loss -2.396765], [lr 0.000857] [batchtime 0.425]
[epoch 160], [iter 169 / 176], [train main loss -2.390714], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 170 / 176], [train main loss -2.391498], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 171 / 176], [train main loss -2.391048], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 172 / 176], [train main loss -2.393908], [lr 0.000857] [batchtime 0.432]
[epoch 160], [iter 173 / 176], [train main loss -2.384992], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 174 / 176], [train main loss -2.396337], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 175 / 176], [train main loss -2.392767], [lr 0.000857] [batchtime 0.431]
[epoch 160], [iter 176 / 176], [train main loss -2.407164], [lr 0.000857] [batchtime 0.43]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.14  35.56   0.02  0.03         0.98      0.97
   1  sidewalk          71.45   5.47   0.20  0.19         0.83      0.84
   2  building          87.05  25.06   0.06  0.09         0.94      0.92
   3  wall              18.36   0.14   3.13  1.32         0.24      0.43
   4  fence             27.91   0.44   1.91  0.67         0.34      0.60
   5  pole              40.92   0.59   0.93  0.52         0.52      0.66
   6  traffic light     19.60   0.03   3.62  0.49         0.22      0.67
   7  traffic sign      29.64   0.18   2.13  0.24         0.32      0.80
   8  vegetation        84.24  11.72   0.06  0.13         0.95      0.88
   9  terrain           40.91   0.37   1.01  0.43         0.50      0.70
  10  sky               93.96   3.74   0.03  0.03         0.97      0.97
  11  person            55.84   1.05   0.46  0.33         0.68      0.75
  12  rider             15.51   0.02   4.51  0.93         0.18      0.52
  13  car               86.80   6.72   0.05  0.10         0.95      0.91
  14  truck              1.47   0.00  66.66  0.40         0.01      0.71
  15  bus               15.27   0.04   0.95  4.60         0.51      0.18
  16  train             32.36   0.08   1.36  0.73         0.42      0.58
  17  motorcycle         5.49   0.01  16.59  0.63         0.06      0.61
  18  bicycle           40.69   0.27   0.42  1.03         0.70      0.49
Mean: 45.40
-----------------------------------------------------------------------------------------------------------
this : [epoch 160], [val loss 0.28678], [acc 0.91481], [acc_cls 0.54353], [mean_iu 0.45400], [fwavacc 0.85170]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 161], [iter 1 / 176], [train main loss -1.705915], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 2 / 176], [train main loss -1.548441], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 3 / 176], [train main loss -2.496569], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 4 / 176], [train main loss -2.367516], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 5 / 176], [train main loss -2.159612], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 6 / 176], [train main loss -1.814112], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 7 / 176], [train main loss -1.730102], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 8 / 176], [train main loss -1.643535], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 9 / 176], [train main loss -1.866533], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 10 / 176], [train main loss -1.909467], [lr 0.000800] [batchtime 0]
[epoch 161], [iter 11 / 176], [train main loss -1.781471], [lr 0.000800] [batchtime 0.368]
[epoch 161], [iter 12 / 176], [train main loss -1.801405], [lr 0.000800] [batchtime 0.379]
[epoch 161], [iter 13 / 176], [train main loss -2.028452], [lr 0.000800] [batchtime 0.386]
[epoch 161], [iter 14 / 176], [train main loss -2.145825], [lr 0.000800] [batchtime 0.387]
[epoch 161], [iter 15 / 176], [train main loss -2.283887], [lr 0.000800] [batchtime 0.392]
[epoch 161], [iter 16 / 176], [train main loss -2.304857], [lr 0.000800] [batchtime 0.393]
[epoch 161], [iter 17 / 176], [train main loss -2.457733], [lr 0.000800] [batchtime 0.392]
[epoch 161], [iter 18 / 176], [train main loss -2.357954], [lr 0.000800] [batchtime 0.392]
[epoch 161], [iter 19 / 176], [train main loss -2.319044], [lr 0.000800] [batchtime 0.392]
[epoch 161], [iter 20 / 176], [train main loss -2.410730], [lr 0.000800] [batchtime 0.393]
[epoch 161], [iter 21 / 176], [train main loss -2.341257], [lr 0.000800] [batchtime 0.393]
[epoch 161], [iter 22 / 176], [train main loss -2.303200], [lr 0.000800] [batchtime 0.393]
[epoch 161], [iter 23 / 176], [train main loss -2.289787], [lr 0.000800] [batchtime 0.393]
[epoch 161], [iter 24 / 176], [train main loss -2.292612], [lr 0.000800] [batchtime 0.393]
[epoch 161], [iter 25 / 176], [train main loss -2.361956], [lr 0.000800] [batchtime 0.399]
[epoch 161], [iter 26 / 176], [train main loss -2.429115], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 27 / 176], [train main loss -2.480653], [lr 0.000800] [batchtime 0.409]
[epoch 161], [iter 28 / 176], [train main loss -2.494676], [lr 0.000800] [batchtime 0.408]
[epoch 161], [iter 29 / 176], [train main loss -2.439637], [lr 0.000800] [batchtime 0.407]
[epoch 161], [iter 30 / 176], [train main loss -2.398406], [lr 0.000800] [batchtime 0.406]
[epoch 161], [iter 31 / 176], [train main loss -2.364363], [lr 0.000800] [batchtime 0.406]
[epoch 161], [iter 32 / 176], [train main loss -2.431906], [lr 0.000800] [batchtime 0.406]
[epoch 161], [iter 33 / 176], [train main loss -2.359241], [lr 0.000800] [batchtime 0.405]
[epoch 161], [iter 34 / 176], [train main loss -2.324735], [lr 0.000800] [batchtime 0.405]
[epoch 161], [iter 35 / 176], [train main loss -2.331468], [lr 0.000800] [batchtime 0.405]
[epoch 161], [iter 36 / 176], [train main loss -2.337147], [lr 0.000800] [batchtime 0.405]
[epoch 161], [iter 37 / 176], [train main loss -2.325463], [lr 0.000800] [batchtime 0.404]
[epoch 161], [iter 38 / 176], [train main loss -2.310735], [lr 0.000800] [batchtime 0.404]
[epoch 161], [iter 39 / 176], [train main loss -2.301577], [lr 0.000800] [batchtime 0.404]
[epoch 161], [iter 40 / 176], [train main loss -2.284517], [lr 0.000800] [batchtime 0.403]
[epoch 161], [iter 41 / 176], [train main loss -2.316542], [lr 0.000800] [batchtime 0.403]
[epoch 161], [iter 42 / 176], [train main loss -2.357119], [lr 0.000800] [batchtime 0.403]
[epoch 161], [iter 43 / 176], [train main loss -2.303602], [lr 0.000800] [batchtime 0.403]
[epoch 161], [iter 44 / 176], [train main loss -2.314965], [lr 0.000800] [batchtime 0.403]
[epoch 161], [iter 45 / 176], [train main loss -2.300063], [lr 0.000800] [batchtime 0.403]
[epoch 161], [iter 46 / 176], [train main loss -2.341403], [lr 0.000800] [batchtime 0.402]
[epoch 161], [iter 47 / 176], [train main loss -2.281805], [lr 0.000800] [batchtime 0.402]
[epoch 161], [iter 48 / 176], [train main loss -2.294453], [lr 0.000800] [batchtime 0.402]
[epoch 161], [iter 49 / 176], [train main loss -2.271971], [lr 0.000800] [batchtime 0.402]
[epoch 161], [iter 50 / 176], [train main loss -2.226417], [lr 0.000800] [batchtime 0.421]
[epoch 161], [iter 51 / 176], [train main loss -2.178687], [lr 0.000800] [batchtime 0.421]
[epoch 161], [iter 52 / 176], [train main loss -2.220348], [lr 0.000800] [batchtime 0.42]
[epoch 161], [iter 53 / 176], [train main loss -2.253892], [lr 0.000800] [batchtime 0.419]
[epoch 161], [iter 54 / 176], [train main loss -2.173979], [lr 0.000800] [batchtime 0.418]
[epoch 161], [iter 55 / 176], [train main loss -2.180766], [lr 0.000800] [batchtime 0.418]
[epoch 161], [iter 56 / 176], [train main loss -2.147003], [lr 0.000800] [batchtime 0.417]
[epoch 161], [iter 57 / 176], [train main loss -2.157295], [lr 0.000800] [batchtime 0.416]
[epoch 161], [iter 58 / 176], [train main loss -2.164074], [lr 0.000800] [batchtime 0.416]
[epoch 161], [iter 59 / 176], [train main loss -2.131771], [lr 0.000800] [batchtime 0.416]
[epoch 161], [iter 60 / 176], [train main loss -2.156107], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 61 / 176], [train main loss -2.157647], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 62 / 176], [train main loss -2.128403], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 63 / 176], [train main loss -2.116973], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 64 / 176], [train main loss -2.131487], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 65 / 176], [train main loss -2.171212], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 66 / 176], [train main loss -2.232576], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 67 / 176], [train main loss -2.228553], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 68 / 176], [train main loss -2.278603], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 69 / 176], [train main loss -2.261328], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 70 / 176], [train main loss -2.252269], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 71 / 176], [train main loss -2.276715], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 72 / 176], [train main loss -2.285897], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 73 / 176], [train main loss -2.298629], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 74 / 176], [train main loss -2.309741], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 75 / 176], [train main loss -2.291972], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 76 / 176], [train main loss -2.286639], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 77 / 176], [train main loss -2.315910], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 78 / 176], [train main loss -2.330935], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 79 / 176], [train main loss -2.356010], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 80 / 176], [train main loss -2.354913], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 81 / 176], [train main loss -2.325567], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 82 / 176], [train main loss -2.321832], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 83 / 176], [train main loss -2.328008], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 84 / 176], [train main loss -2.346114], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 85 / 176], [train main loss -2.351128], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 86 / 176], [train main loss -2.356428], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 87 / 176], [train main loss -2.352543], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 88 / 176], [train main loss -2.343801], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 89 / 176], [train main loss -2.330532], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 90 / 176], [train main loss -2.335700], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 91 / 176], [train main loss -2.335995], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 92 / 176], [train main loss -2.313939], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 93 / 176], [train main loss -2.311786], [lr 0.000800] [batchtime 0.409]
[epoch 161], [iter 94 / 176], [train main loss -2.302486], [lr 0.000800] [batchtime 0.409]
[epoch 161], [iter 95 / 176], [train main loss -2.307711], [lr 0.000800] [batchtime 0.409]
[epoch 161], [iter 96 / 176], [train main loss -2.298794], [lr 0.000800] [batchtime 0.409]
[epoch 161], [iter 97 / 176], [train main loss -2.272091], [lr 0.000800] [batchtime 0.409]
[epoch 161], [iter 98 / 176], [train main loss -2.278581], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 99 / 176], [train main loss -2.265856], [lr 0.000800] [batchtime 0.416]
[epoch 161], [iter 100 / 176], [train main loss -2.251183], [lr 0.000800] [batchtime 0.416]
[epoch 161], [iter 101 / 176], [train main loss -2.273150], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 102 / 176], [train main loss -2.276712], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 103 / 176], [train main loss -2.276284], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 104 / 176], [train main loss -2.302151], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 105 / 176], [train main loss -2.307932], [lr 0.000800] [batchtime 0.415]
[epoch 161], [iter 106 / 176], [train main loss -2.299798], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 107 / 176], [train main loss -2.282418], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 108 / 176], [train main loss -2.273277], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 109 / 176], [train main loss -2.261393], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 110 / 176], [train main loss -2.277889], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 111 / 176], [train main loss -2.268435], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 112 / 176], [train main loss -2.230011], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 113 / 176], [train main loss -2.230445], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 114 / 176], [train main loss -2.208581], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 115 / 176], [train main loss -2.221724], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 116 / 176], [train main loss -2.212703], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 117 / 176], [train main loss -2.245000], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 118 / 176], [train main loss -2.243248], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 119 / 176], [train main loss -2.228931], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 120 / 176], [train main loss -2.237023], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 121 / 176], [train main loss -2.227994], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 122 / 176], [train main loss -2.203490], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 123 / 176], [train main loss -2.185775], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 124 / 176], [train main loss -2.167156], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 125 / 176], [train main loss -2.174859], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 126 / 176], [train main loss -2.154172], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 127 / 176], [train main loss -2.161059], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 128 / 176], [train main loss -2.161294], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 129 / 176], [train main loss -2.177872], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 130 / 176], [train main loss -2.203042], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 131 / 176], [train main loss -2.238714], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 132 / 176], [train main loss -2.232032], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 133 / 176], [train main loss -2.226599], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 134 / 176], [train main loss -2.235419], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 135 / 176], [train main loss -2.231555], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 136 / 176], [train main loss -2.241965], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 137 / 176], [train main loss -2.242700], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 138 / 176], [train main loss -2.259236], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 139 / 176], [train main loss -2.258483], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 140 / 176], [train main loss -2.259651], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 141 / 176], [train main loss -2.267278], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 142 / 176], [train main loss -2.253088], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 143 / 176], [train main loss -2.254566], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 144 / 176], [train main loss -2.235230], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 145 / 176], [train main loss -2.255528], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 146 / 176], [train main loss -2.248141], [lr 0.000800] [batchtime 0.41]
[epoch 161], [iter 147 / 176], [train main loss -2.250995], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 148 / 176], [train main loss -2.264422], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 149 / 176], [train main loss -2.271326], [lr 0.000800] [batchtime 0.414]
[epoch 161], [iter 150 / 176], [train main loss -2.266092], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 151 / 176], [train main loss -2.264987], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 152 / 176], [train main loss -2.252774], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 153 / 176], [train main loss -2.252189], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 154 / 176], [train main loss -2.245817], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 155 / 176], [train main loss -2.249690], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 156 / 176], [train main loss -2.259833], [lr 0.000800] [batchtime 0.413]
[epoch 161], [iter 157 / 176], [train main loss -2.270270], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 158 / 176], [train main loss -2.284929], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 159 / 176], [train main loss -2.291470], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 160 / 176], [train main loss -2.293952], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 161 / 176], [train main loss -2.296361], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 162 / 176], [train main loss -2.300968], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 163 / 176], [train main loss -2.290831], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 164 / 176], [train main loss -2.291568], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 165 / 176], [train main loss -2.299575], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 166 / 176], [train main loss -2.315710], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 167 / 176], [train main loss -2.317986], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 168 / 176], [train main loss -2.312746], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 169 / 176], [train main loss -2.319547], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 170 / 176], [train main loss -2.315759], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 171 / 176], [train main loss -2.314521], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 172 / 176], [train main loss -2.324313], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 173 / 176], [train main loss -2.335631], [lr 0.000800] [batchtime 0.412]
[epoch 161], [iter 174 / 176], [train main loss -2.339436], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 175 / 176], [train main loss -2.339876], [lr 0.000800] [batchtime 0.411]
[epoch 161], [iter 176 / 176], [train main loss -2.335372], [lr 0.000800] [batchtime 0.411]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.22  35.51   0.02  0.03         0.98      0.97
   1  sidewalk          71.96   5.54   0.19  0.20         0.84      0.83
   2  building          87.09  25.11   0.06  0.09         0.94      0.92
   3  wall              18.85   0.15   2.91  1.40         0.26      0.42
   4  fence             27.35   0.42   2.01  0.64         0.33      0.61
   5  pole              40.10   0.58   0.97  0.52         0.51      0.66
   6  traffic light     19.49   0.03   3.71  0.42         0.21      0.70
   7  traffic sign      28.71   0.17   2.26  0.22         0.31      0.82
   8  vegetation        84.19  11.70   0.06  0.13         0.95      0.88
   9  terrain           40.74   0.38   0.94  0.52         0.52      0.66
  10  sky               94.02   3.74   0.03  0.03         0.97      0.97
  11  person            55.74   1.05   0.46  0.33         0.69      0.75
  12  rider             15.44   0.02   4.59  0.89         0.18      0.53
  13  car               86.88   6.71   0.05  0.10         0.95      0.91
  14  truck              1.72   0.01  56.91  0.34         0.02      0.75
  15  bus               15.14   0.04   1.18  4.43         0.46      0.18
  16  train             35.95   0.08   1.25  0.54         0.45      0.65
  17  motorcycle         4.86   0.01  18.93  0.65         0.05      0.60
  18  bicycle           40.53   0.28   0.41  1.06         0.71      0.49
Mean: 45.47
-----------------------------------------------------------------------------------------------------------
this : [epoch 161], [val loss 0.29068], [acc 0.91512], [acc_cls 0.54207], [mean_iu 0.45473], [fwavacc 0.85229]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 162], [iter 1 / 176], [train main loss -1.489005], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 2 / 176], [train main loss -1.308578], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 3 / 176], [train main loss -1.861924], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 4 / 176], [train main loss -1.983439], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 5 / 176], [train main loss -1.509834], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 6 / 176], [train main loss -2.150606], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 7 / 176], [train main loss -2.419652], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 8 / 176], [train main loss -2.431182], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 9 / 176], [train main loss -2.537455], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 10 / 176], [train main loss -2.462566], [lr 0.000743] [batchtime 0]
[epoch 162], [iter 11 / 176], [train main loss -2.504852], [lr 0.000743] [batchtime 0.369]
[epoch 162], [iter 12 / 176], [train main loss -2.449654], [lr 0.000743] [batchtime 0.389]
[epoch 162], [iter 13 / 176], [train main loss -2.285889], [lr 0.000743] [batchtime 0.396]
[epoch 162], [iter 14 / 176], [train main loss -2.345785], [lr 0.000743] [batchtime 0.395]
[epoch 162], [iter 15 / 176], [train main loss -2.190096], [lr 0.000743] [batchtime 0.394]
[epoch 162], [iter 16 / 176], [train main loss -2.217569], [lr 0.000743] [batchtime 0.395]
[epoch 162], [iter 17 / 176], [train main loss -2.147799], [lr 0.000743] [batchtime 0.394]
[epoch 162], [iter 18 / 176], [train main loss -2.284586], [lr 0.000743] [batchtime 0.395]
[epoch 162], [iter 19 / 176], [train main loss -2.243220], [lr 0.000743] [batchtime 0.395]
[epoch 162], [iter 20 / 176], [train main loss -2.173720], [lr 0.000743] [batchtime 0.395]
[epoch 162], [iter 21 / 176], [train main loss -2.220383], [lr 0.000743] [batchtime 0.396]
[epoch 162], [iter 22 / 176], [train main loss -2.129697], [lr 0.000743] [batchtime 0.397]
[epoch 162], [iter 23 / 176], [train main loss -2.020866], [lr 0.000743] [batchtime 0.396]
[epoch 162], [iter 24 / 176], [train main loss -2.038510], [lr 0.000743] [batchtime 0.396]
[epoch 162], [iter 25 / 176], [train main loss -2.016183], [lr 0.000743] [batchtime 0.396]
[epoch 162], [iter 26 / 176], [train main loss -1.992777], [lr 0.000743] [batchtime 0.4]
[epoch 162], [iter 27 / 176], [train main loss -1.973198], [lr 0.000743] [batchtime 0.432]
[epoch 162], [iter 28 / 176], [train main loss -2.059716], [lr 0.000743] [batchtime 0.43]
[epoch 162], [iter 29 / 176], [train main loss -2.083853], [lr 0.000743] [batchtime 0.427]
[epoch 162], [iter 30 / 176], [train main loss -2.077170], [lr 0.000743] [batchtime 0.425]
[epoch 162], [iter 31 / 176], [train main loss -2.038256], [lr 0.000743] [batchtime 0.424]
[epoch 162], [iter 32 / 176], [train main loss -2.020373], [lr 0.000743] [batchtime 0.422]
[epoch 162], [iter 33 / 176], [train main loss -2.006260], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 34 / 176], [train main loss -2.015546], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 35 / 176], [train main loss -2.049490], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 36 / 176], [train main loss -2.079417], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 37 / 176], [train main loss -2.107131], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 38 / 176], [train main loss -2.072167], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 39 / 176], [train main loss -2.074281], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 40 / 176], [train main loss -2.009468], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 41 / 176], [train main loss -1.943172], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 42 / 176], [train main loss -1.959371], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 43 / 176], [train main loss -2.014107], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 44 / 176], [train main loss -2.082541], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 45 / 176], [train main loss -2.127302], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 46 / 176], [train main loss -2.090394], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 47 / 176], [train main loss -2.087598], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 48 / 176], [train main loss -2.138000], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 49 / 176], [train main loss -2.151694], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 50 / 176], [train main loss -2.179192], [lr 0.000743] [batchtime 0.423]
[epoch 162], [iter 51 / 176], [train main loss -2.195720], [lr 0.000743] [batchtime 0.424]
[epoch 162], [iter 52 / 176], [train main loss -2.209783], [lr 0.000743] [batchtime 0.423]
[epoch 162], [iter 53 / 176], [train main loss -2.220693], [lr 0.000743] [batchtime 0.422]
[epoch 162], [iter 54 / 176], [train main loss -2.219283], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 55 / 176], [train main loss -2.202488], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 56 / 176], [train main loss -2.300437], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 57 / 176], [train main loss -2.292369], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 58 / 176], [train main loss -2.330565], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 59 / 176], [train main loss -2.290972], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 60 / 176], [train main loss -2.332971], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 61 / 176], [train main loss -2.330022], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 62 / 176], [train main loss -2.321918], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 63 / 176], [train main loss -2.305992], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 64 / 176], [train main loss -2.358554], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 65 / 176], [train main loss -2.368361], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 66 / 176], [train main loss -2.379704], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 67 / 176], [train main loss -2.396585], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 68 / 176], [train main loss -2.374652], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 69 / 176], [train main loss -2.382010], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 70 / 176], [train main loss -2.333259], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 71 / 176], [train main loss -2.330318], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 72 / 176], [train main loss -2.298673], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 73 / 176], [train main loss -2.307862], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 74 / 176], [train main loss -2.326581], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 75 / 176], [train main loss -2.315920], [lr 0.000743] [batchtime 0.424]
[epoch 162], [iter 76 / 176], [train main loss -2.290793], [lr 0.000743] [batchtime 0.423]
[epoch 162], [iter 77 / 176], [train main loss -2.335904], [lr 0.000743] [batchtime 0.422]
[epoch 162], [iter 78 / 176], [train main loss -2.338596], [lr 0.000743] [batchtime 0.422]
[epoch 162], [iter 79 / 176], [train main loss -2.338981], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 80 / 176], [train main loss -2.332747], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 81 / 176], [train main loss -2.333853], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 82 / 176], [train main loss -2.359116], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 83 / 176], [train main loss -2.343127], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 84 / 176], [train main loss -2.329091], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 85 / 176], [train main loss -2.312013], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 86 / 176], [train main loss -2.318964], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 87 / 176], [train main loss -2.330241], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 88 / 176], [train main loss -2.304006], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 89 / 176], [train main loss -2.279354], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 90 / 176], [train main loss -2.262396], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 91 / 176], [train main loss -2.226021], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 92 / 176], [train main loss -2.199375], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 93 / 176], [train main loss -2.177853], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 94 / 176], [train main loss -2.175477], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 95 / 176], [train main loss -2.164396], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 96 / 176], [train main loss -2.182294], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 97 / 176], [train main loss -2.178505], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 98 / 176], [train main loss -2.171583], [lr 0.000743] [batchtime 0.421]
[epoch 162], [iter 99 / 176], [train main loss -2.159747], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 100 / 176], [train main loss -2.160912], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 101 / 176], [train main loss -2.148340], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 102 / 176], [train main loss -2.147238], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 103 / 176], [train main loss -2.148350], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 104 / 176], [train main loss -2.136008], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 105 / 176], [train main loss -2.133454], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 106 / 176], [train main loss -2.151876], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 107 / 176], [train main loss -2.163079], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 108 / 176], [train main loss -2.157946], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 109 / 176], [train main loss -2.148032], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 110 / 176], [train main loss -2.145287], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 111 / 176], [train main loss -2.132749], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 112 / 176], [train main loss -2.134472], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 113 / 176], [train main loss -2.125165], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 114 / 176], [train main loss -2.121117], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 115 / 176], [train main loss -2.101361], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 116 / 176], [train main loss -2.123236], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 117 / 176], [train main loss -2.156267], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 118 / 176], [train main loss -2.150679], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 119 / 176], [train main loss -2.164673], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 120 / 176], [train main loss -2.163303], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 121 / 176], [train main loss -2.172346], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 122 / 176], [train main loss -2.191536], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 123 / 176], [train main loss -2.196538], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 124 / 176], [train main loss -2.197252], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 125 / 176], [train main loss -2.192816], [lr 0.000743] [batchtime 0.42]
[epoch 162], [iter 126 / 176], [train main loss -2.189771], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 127 / 176], [train main loss -2.180125], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 128 / 176], [train main loss -2.160163], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 129 / 176], [train main loss -2.157624], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 130 / 176], [train main loss -2.159880], [lr 0.000743] [batchtime 0.419]
[epoch 162], [iter 131 / 176], [train main loss -2.154677], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 132 / 176], [train main loss -2.160818], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 133 / 176], [train main loss -2.158008], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 134 / 176], [train main loss -2.154437], [lr 0.000743] [batchtime 0.418]
[epoch 162], [iter 135 / 176], [train main loss -2.163244], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 136 / 176], [train main loss -2.140094], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 137 / 176], [train main loss -2.148043], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 138 / 176], [train main loss -2.145819], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 139 / 176], [train main loss -2.150567], [lr 0.000743] [batchtime 0.417]
[epoch 162], [iter 140 / 176], [train main loss -2.159660], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 141 / 176], [train main loss -2.162638], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 142 / 176], [train main loss -2.139557], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 143 / 176], [train main loss -2.162889], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 144 / 176], [train main loss -2.155645], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 145 / 176], [train main loss -2.161487], [lr 0.000743] [batchtime 0.416]
[epoch 162], [iter 146 / 176], [train main loss -2.142978], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 147 / 176], [train main loss -2.123721], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 148 / 176], [train main loss -2.109256], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 149 / 176], [train main loss -2.115199], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 150 / 176], [train main loss -2.115741], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 151 / 176], [train main loss -2.139716], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 152 / 176], [train main loss -2.147179], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 153 / 176], [train main loss -2.163269], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 154 / 176], [train main loss -2.170667], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 155 / 176], [train main loss -2.167903], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 156 / 176], [train main loss -2.171299], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 157 / 176], [train main loss -2.169997], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 158 / 176], [train main loss -2.170455], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 159 / 176], [train main loss -2.171345], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 160 / 176], [train main loss -2.172468], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 161 / 176], [train main loss -2.177133], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 162 / 176], [train main loss -2.159935], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 163 / 176], [train main loss -2.165639], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 164 / 176], [train main loss -2.157127], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 165 / 176], [train main loss -2.139598], [lr 0.000743] [batchtime 0.413]
[epoch 162], [iter 166 / 176], [train main loss -2.125893], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 167 / 176], [train main loss -2.119240], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 168 / 176], [train main loss -2.106781], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 169 / 176], [train main loss -2.102766], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 170 / 176], [train main loss -2.101346], [lr 0.000743] [batchtime 0.412]
[epoch 162], [iter 171 / 176], [train main loss -2.099573], [lr 0.000743] [batchtime 0.411]
[epoch 162], [iter 172 / 176], [train main loss -2.089589], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 173 / 176], [train main loss -2.073420], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 174 / 176], [train main loss -2.069309], [lr 0.000743] [batchtime 0.415]
[epoch 162], [iter 175 / 176], [train main loss -2.048396], [lr 0.000743] [batchtime 0.414]
[epoch 162], [iter 176 / 176], [train main loss -2.062296], [lr 0.000743] [batchtime 0.414]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.04  35.71   0.02  0.03         0.98      0.97
   1  sidewalk          70.51   5.30   0.24  0.17         0.80      0.85
   2  building          87.04  24.93   0.07  0.08         0.94      0.92
   3  wall              18.93   0.15   2.94  1.35         0.25      0.43
   4  fence             27.06   0.42   2.05  0.65         0.33      0.61
   5  pole              40.94   0.60   0.89  0.55         0.53      0.64
   6  traffic light     20.40   0.03   3.43  0.48         0.23      0.68
   7  traffic sign      28.55   0.17   2.28  0.22         0.30      0.82
   8  vegetation        84.16  11.71   0.06  0.13         0.95      0.88
   9  terrain           41.89   0.40   0.84  0.54         0.54      0.65
  10  sky               93.78   3.76   0.03  0.04         0.97      0.96
  11  person            55.98   1.08   0.43  0.36         0.70      0.74
  12  rider             15.55   0.02   4.57  0.87         0.18      0.54
  13  car               86.75   6.74   0.05  0.10         0.95      0.91
  14  truck              1.77   0.01  54.95  0.45         0.02      0.69
  15  bus               16.46   0.04   0.98  4.10         0.51      0.20
  16  train             34.07   0.08   1.27  0.67         0.44      0.60
  17  motorcycle         5.64   0.01  16.12  0.61         0.06      0.62
  18  bicycle           40.68   0.27   0.42  1.03         0.70      0.49
Mean: 45.54
-----------------------------------------------------------------------------------------------------------
this : [epoch 162], [val loss 0.29612], [acc 0.91419], [acc_cls 0.54668], [mean_iu 0.45536], [fwavacc 0.85049]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 163], [iter 1 / 176], [train main loss -2.465272], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 2 / 176], [train main loss -1.927756], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 3 / 176], [train main loss -1.182692], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 4 / 176], [train main loss -1.937380], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 5 / 176], [train main loss -1.983196], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 6 / 176], [train main loss -1.919478], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 7 / 176], [train main loss -1.799612], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 8 / 176], [train main loss -1.672106], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 9 / 176], [train main loss -1.755268], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 10 / 176], [train main loss -1.987883], [lr 0.000686] [batchtime 0]
[epoch 163], [iter 11 / 176], [train main loss -2.140366], [lr 0.000686] [batchtime 0.373]
[epoch 163], [iter 12 / 176], [train main loss -2.116754], [lr 0.000686] [batchtime 0.387]
[epoch 163], [iter 13 / 176], [train main loss -2.093913], [lr 0.000686] [batchtime 0.391]
[epoch 163], [iter 14 / 176], [train main loss -2.125856], [lr 0.000686] [batchtime 0.392]
[epoch 163], [iter 15 / 176], [train main loss -2.109050], [lr 0.000686] [batchtime 0.395]
[epoch 163], [iter 16 / 176], [train main loss -2.155385], [lr 0.000686] [batchtime 0.396]
[epoch 163], [iter 17 / 176], [train main loss -2.220768], [lr 0.000686] [batchtime 0.396]
[epoch 163], [iter 18 / 176], [train main loss -2.166814], [lr 0.000686] [batchtime 0.396]
[epoch 163], [iter 19 / 176], [train main loss -2.177855], [lr 0.000686] [batchtime 0.396]
[epoch 163], [iter 20 / 176], [train main loss -2.228117], [lr 0.000686] [batchtime 0.396]
[epoch 163], [iter 21 / 176], [train main loss -2.199514], [lr 0.000686] [batchtime 0.397]
[epoch 163], [iter 22 / 176], [train main loss -2.145528], [lr 0.000686] [batchtime 0.397]
[epoch 163], [iter 23 / 176], [train main loss -2.248796], [lr 0.000686] [batchtime 0.398]
[epoch 163], [iter 24 / 176], [train main loss -2.137670], [lr 0.000686] [batchtime 0.397]
[epoch 163], [iter 25 / 176], [train main loss -2.002574], [lr 0.000686] [batchtime 0.397]
[epoch 163], [iter 26 / 176], [train main loss -2.010348], [lr 0.000686] [batchtime 0.397]
[epoch 163], [iter 27 / 176], [train main loss -1.935067], [lr 0.000686] [batchtime 0.398]
[epoch 163], [iter 28 / 176], [train main loss -1.811145], [lr 0.000686] [batchtime 0.398]
[epoch 163], [iter 29 / 176], [train main loss -1.753409], [lr 0.000686] [batchtime 0.398]
[epoch 163], [iter 30 / 176], [train main loss -1.769969], [lr 0.000686] [batchtime 0.398]
[epoch 163], [iter 31 / 176], [train main loss -1.766968], [lr 0.000686] [batchtime 0.405]
[epoch 163], [iter 32 / 176], [train main loss -1.823627], [lr 0.000686] [batchtime 0.47]
[epoch 163], [iter 33 / 176], [train main loss -1.765145], [lr 0.000686] [batchtime 0.466]
[epoch 163], [iter 34 / 176], [train main loss -1.837330], [lr 0.000686] [batchtime 0.463]
[epoch 163], [iter 35 / 176], [train main loss -1.832441], [lr 0.000686] [batchtime 0.46]
[epoch 163], [iter 36 / 176], [train main loss -1.821537], [lr 0.000686] [batchtime 0.457]
[epoch 163], [iter 37 / 176], [train main loss -1.792500], [lr 0.000686] [batchtime 0.455]
[epoch 163], [iter 38 / 176], [train main loss -1.743238], [lr 0.000686] [batchtime 0.453]
[epoch 163], [iter 39 / 176], [train main loss -1.771037], [lr 0.000686] [batchtime 0.45]
[epoch 163], [iter 40 / 176], [train main loss -1.684483], [lr 0.000686] [batchtime 0.449]
[epoch 163], [iter 41 / 176], [train main loss -1.716094], [lr 0.000686] [batchtime 0.447]
[epoch 163], [iter 42 / 176], [train main loss -1.742684], [lr 0.000686] [batchtime 0.462]
[epoch 163], [iter 43 / 176], [train main loss -1.694301], [lr 0.000686] [batchtime 0.46]
[epoch 163], [iter 44 / 176], [train main loss -1.677668], [lr 0.000686] [batchtime 0.458]
[epoch 163], [iter 45 / 176], [train main loss -1.722040], [lr 0.000686] [batchtime 0.456]
[epoch 163], [iter 46 / 176], [train main loss -1.718326], [lr 0.000686] [batchtime 0.455]
[epoch 163], [iter 47 / 176], [train main loss -1.728255], [lr 0.000686] [batchtime 0.453]
[epoch 163], [iter 48 / 176], [train main loss -1.733694], [lr 0.000686] [batchtime 0.452]
[epoch 163], [iter 49 / 176], [train main loss -1.757417], [lr 0.000686] [batchtime 0.45]
[epoch 163], [iter 50 / 176], [train main loss -1.763241], [lr 0.000686] [batchtime 0.449]
[epoch 163], [iter 51 / 176], [train main loss -1.809777], [lr 0.000686] [batchtime 0.448]
[epoch 163], [iter 52 / 176], [train main loss -1.812503], [lr 0.000686] [batchtime 0.447]
[epoch 163], [iter 53 / 176], [train main loss -1.821073], [lr 0.000686] [batchtime 0.449]
[epoch 163], [iter 54 / 176], [train main loss -1.787850], [lr 0.000686] [batchtime 0.452]
[epoch 163], [iter 55 / 176], [train main loss -1.776877], [lr 0.000686] [batchtime 0.451]
[epoch 163], [iter 56 / 176], [train main loss -1.771618], [lr 0.000686] [batchtime 0.449]
[epoch 163], [iter 57 / 176], [train main loss -1.749820], [lr 0.000686] [batchtime 0.448]
[epoch 163], [iter 58 / 176], [train main loss -1.754026], [lr 0.000686] [batchtime 0.447]
[epoch 163], [iter 59 / 176], [train main loss -1.731353], [lr 0.000686] [batchtime 0.446]
[epoch 163], [iter 60 / 176], [train main loss -1.750849], [lr 0.000686] [batchtime 0.445]
[epoch 163], [iter 61 / 176], [train main loss -1.779909], [lr 0.000686] [batchtime 0.444]
[epoch 163], [iter 62 / 176], [train main loss -1.779204], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 63 / 176], [train main loss -1.817611], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 64 / 176], [train main loss -1.840884], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 65 / 176], [train main loss -1.829569], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 66 / 176], [train main loss -1.829821], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 67 / 176], [train main loss -1.814204], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 68 / 176], [train main loss -1.820812], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 69 / 176], [train main loss -1.802352], [lr 0.000686] [batchtime 0.438]
[epoch 163], [iter 70 / 176], [train main loss -1.820314], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 71 / 176], [train main loss -1.847849], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 72 / 176], [train main loss -1.881459], [lr 0.000686] [batchtime 0.436]
[epoch 163], [iter 73 / 176], [train main loss -1.872600], [lr 0.000686] [batchtime 0.435]
[epoch 163], [iter 74 / 176], [train main loss -1.889583], [lr 0.000686] [batchtime 0.435]
[epoch 163], [iter 75 / 176], [train main loss -1.926510], [lr 0.000686] [batchtime 0.434]
[epoch 163], [iter 76 / 176], [train main loss -1.917180], [lr 0.000686] [batchtime 0.433]
[epoch 163], [iter 77 / 176], [train main loss -1.912536], [lr 0.000686] [batchtime 0.435]
[epoch 163], [iter 78 / 176], [train main loss -1.918645], [lr 0.000686] [batchtime 0.454]
[epoch 163], [iter 79 / 176], [train main loss -1.905734], [lr 0.000686] [batchtime 0.461]
[epoch 163], [iter 80 / 176], [train main loss -1.931623], [lr 0.000686] [batchtime 0.46]
[epoch 163], [iter 81 / 176], [train main loss -1.910508], [lr 0.000686] [batchtime 0.459]
[epoch 163], [iter 82 / 176], [train main loss -1.902087], [lr 0.000686] [batchtime 0.458]
[epoch 163], [iter 83 / 176], [train main loss -1.871618], [lr 0.000686] [batchtime 0.457]
[epoch 163], [iter 84 / 176], [train main loss -1.913282], [lr 0.000686] [batchtime 0.456]
[epoch 163], [iter 85 / 176], [train main loss -1.901225], [lr 0.000686] [batchtime 0.455]
[epoch 163], [iter 86 / 176], [train main loss -1.920098], [lr 0.000686] [batchtime 0.455]
[epoch 163], [iter 87 / 176], [train main loss -1.953627], [lr 0.000686] [batchtime 0.454]
[epoch 163], [iter 88 / 176], [train main loss -1.959152], [lr 0.000686] [batchtime 0.453]
[epoch 163], [iter 89 / 176], [train main loss -1.964259], [lr 0.000686] [batchtime 0.452]
[epoch 163], [iter 90 / 176], [train main loss -1.986802], [lr 0.000686] [batchtime 0.452]
[epoch 163], [iter 91 / 176], [train main loss -2.000191], [lr 0.000686] [batchtime 0.451]
[epoch 163], [iter 92 / 176], [train main loss -1.987846], [lr 0.000686] [batchtime 0.45]
[epoch 163], [iter 93 / 176], [train main loss -2.025339], [lr 0.000686] [batchtime 0.45]
[epoch 163], [iter 94 / 176], [train main loss -2.011599], [lr 0.000686] [batchtime 0.449]
[epoch 163], [iter 95 / 176], [train main loss -1.991124], [lr 0.000686] [batchtime 0.448]
[epoch 163], [iter 96 / 176], [train main loss -1.981352], [lr 0.000686] [batchtime 0.447]
[epoch 163], [iter 97 / 176], [train main loss -1.978610], [lr 0.000686] [batchtime 0.447]
[epoch 163], [iter 98 / 176], [train main loss -1.974261], [lr 0.000686] [batchtime 0.446]
[epoch 163], [iter 99 / 176], [train main loss -2.006184], [lr 0.000686] [batchtime 0.446]
[epoch 163], [iter 100 / 176], [train main loss -2.012143], [lr 0.000686] [batchtime 0.445]
[epoch 163], [iter 101 / 176], [train main loss -1.995416], [lr 0.000686] [batchtime 0.444]
[epoch 163], [iter 102 / 176], [train main loss -1.986035], [lr 0.000686] [batchtime 0.444]
[epoch 163], [iter 103 / 176], [train main loss -2.000549], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 104 / 176], [train main loss -1.988169], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 105 / 176], [train main loss -2.014692], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 106 / 176], [train main loss -1.990576], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 107 / 176], [train main loss -2.005011], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 108 / 176], [train main loss -2.006677], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 109 / 176], [train main loss -2.025200], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 110 / 176], [train main loss -2.014391], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 111 / 176], [train main loss -2.042569], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 112 / 176], [train main loss -2.039648], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 113 / 176], [train main loss -2.028319], [lr 0.000686] [batchtime 0.438]
[epoch 163], [iter 114 / 176], [train main loss -2.009194], [lr 0.000686] [batchtime 0.438]
[epoch 163], [iter 115 / 176], [train main loss -1.986377], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 116 / 176], [train main loss -1.976632], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 117 / 176], [train main loss -2.000581], [lr 0.000686] [batchtime 0.436]
[epoch 163], [iter 118 / 176], [train main loss -2.017723], [lr 0.000686] [batchtime 0.436]
[epoch 163], [iter 119 / 176], [train main loss -1.997599], [lr 0.000686] [batchtime 0.436]
[epoch 163], [iter 120 / 176], [train main loss -2.007134], [lr 0.000686] [batchtime 0.435]
[epoch 163], [iter 121 / 176], [train main loss -2.000344], [lr 0.000686] [batchtime 0.435]
[epoch 163], [iter 122 / 176], [train main loss -2.009479], [lr 0.000686] [batchtime 0.435]
[epoch 163], [iter 123 / 176], [train main loss -2.023635], [lr 0.000686] [batchtime 0.436]
[epoch 163], [iter 124 / 176], [train main loss -1.997636], [lr 0.000686] [batchtime 0.448]
[epoch 163], [iter 125 / 176], [train main loss -2.000133], [lr 0.000686] [batchtime 0.447]
[epoch 163], [iter 126 / 176], [train main loss -2.009905], [lr 0.000686] [batchtime 0.446]
[epoch 163], [iter 127 / 176], [train main loss -2.014630], [lr 0.000686] [batchtime 0.446]
[epoch 163], [iter 128 / 176], [train main loss -2.001166], [lr 0.000686] [batchtime 0.445]
[epoch 163], [iter 129 / 176], [train main loss -1.999041], [lr 0.000686] [batchtime 0.445]
[epoch 163], [iter 130 / 176], [train main loss -1.985219], [lr 0.000686] [batchtime 0.445]
[epoch 163], [iter 131 / 176], [train main loss -1.996647], [lr 0.000686] [batchtime 0.444]
[epoch 163], [iter 132 / 176], [train main loss -1.997587], [lr 0.000686] [batchtime 0.444]
[epoch 163], [iter 133 / 176], [train main loss -2.002940], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 134 / 176], [train main loss -1.986080], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 135 / 176], [train main loss -1.993508], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 136 / 176], [train main loss -1.991622], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 137 / 176], [train main loss -1.999458], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 138 / 176], [train main loss -1.997953], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 139 / 176], [train main loss -1.997636], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 140 / 176], [train main loss -1.981778], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 141 / 176], [train main loss -1.971084], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 142 / 176], [train main loss -1.994419], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 143 / 176], [train main loss -2.000491], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 144 / 176], [train main loss -2.004441], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 145 / 176], [train main loss -2.002913], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 146 / 176], [train main loss -1.985596], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 147 / 176], [train main loss -1.991739], [lr 0.000686] [batchtime 0.438]
[epoch 163], [iter 148 / 176], [train main loss -2.008673], [lr 0.000686] [batchtime 0.438]
[epoch 163], [iter 149 / 176], [train main loss -1.997327], [lr 0.000686] [batchtime 0.438]
[epoch 163], [iter 150 / 176], [train main loss -1.992706], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 151 / 176], [train main loss -2.011797], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 152 / 176], [train main loss -2.012408], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 153 / 176], [train main loss -2.021627], [lr 0.000686] [batchtime 0.437]
[epoch 163], [iter 154 / 176], [train main loss -2.019334], [lr 0.000686] [batchtime 0.444]
[epoch 163], [iter 155 / 176], [train main loss -2.028038], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 156 / 176], [train main loss -2.034513], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 157 / 176], [train main loss -2.042159], [lr 0.000686] [batchtime 0.443]
[epoch 163], [iter 158 / 176], [train main loss -2.051091], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 159 / 176], [train main loss -2.050933], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 160 / 176], [train main loss -2.058983], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 161 / 176], [train main loss -2.063928], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 162 / 176], [train main loss -2.065096], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 163 / 176], [train main loss -2.085276], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 164 / 176], [train main loss -2.103540], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 165 / 176], [train main loss -2.093584], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 166 / 176], [train main loss -2.088907], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 167 / 176], [train main loss -2.093591], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 168 / 176], [train main loss -2.088181], [lr 0.000686] [batchtime 0.442]
[epoch 163], [iter 169 / 176], [train main loss -2.077392], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 170 / 176], [train main loss -2.078754], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 171 / 176], [train main loss -2.062931], [lr 0.000686] [batchtime 0.441]
[epoch 163], [iter 172 / 176], [train main loss -2.066008], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 173 / 176], [train main loss -2.064504], [lr 0.000686] [batchtime 0.44]
[epoch 163], [iter 174 / 176], [train main loss -2.065394], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 175 / 176], [train main loss -2.063792], [lr 0.000686] [batchtime 0.439]
[epoch 163], [iter 176 / 176], [train main loss -2.057240], [lr 0.000686] [batchtime 0.439]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.85  35.51   0.02  0.03         0.98      0.97
   1  sidewalk          70.37   5.41   0.22  0.20         0.82      0.83
   2  building          87.00  24.90   0.07  0.08         0.94      0.92
   3  wall              18.33   0.15   2.98  1.47         0.25      0.40
   4  fence             27.16   0.42   2.04  0.64         0.33      0.61
   5  pole              40.63   0.58   0.94  0.52         0.51      0.66
   6  traffic light     20.36   0.03   3.38  0.53         0.23      0.65
   7  traffic sign      30.64   0.19   1.99  0.27         0.33      0.79
   8  vegetation        84.01  11.75   0.05  0.14         0.95      0.88
   9  terrain           39.83   0.37   0.98  0.53         0.50      0.65
  10  sky               93.97   3.74   0.03  0.03         0.97      0.97
  11  person            56.28   1.09   0.41  0.37         0.71      0.73
  12  rider             16.03   0.02   4.30  0.94         0.19      0.51
  13  car               86.67   6.72   0.05  0.10         0.95      0.91
  14  truck              2.01   0.01  48.38  0.41         0.02      0.71
  15  bus               14.49   0.04   0.95  4.95         0.51      0.17
  16  train             27.52   0.08   1.30  1.34         0.44      0.43
  17  motorcycle         5.85   0.01  15.44  0.67         0.06      0.60
  18  bicycle           40.76   0.27   0.46  1.00         0.69      0.50
Mean: 45.09
-----------------------------------------------------------------------------------------------------------
this : [epoch 163], [val loss 0.28639], [acc 0.91290], [acc_cls 0.54625], [mean_iu 0.45092], [fwavacc 0.84926]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 164], [iter 1 / 176], [train main loss -2.275221], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 2 / 176], [train main loss -3.128515], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 3 / 176], [train main loss -2.834321], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 4 / 176], [train main loss -2.740738], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 5 / 176], [train main loss -2.429406], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 6 / 176], [train main loss -1.785252], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 7 / 176], [train main loss -1.893010], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 8 / 176], [train main loss -1.909111], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 9 / 176], [train main loss -2.003308], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 10 / 176], [train main loss -2.046109], [lr 0.000629] [batchtime 0]
[epoch 164], [iter 11 / 176], [train main loss -1.581122], [lr 0.000629] [batchtime 0.37]
[epoch 164], [iter 12 / 176], [train main loss -1.488804], [lr 0.000629] [batchtime 0.387]
[epoch 164], [iter 13 / 176], [train main loss -1.531459], [lr 0.000629] [batchtime 0.392]
[epoch 164], [iter 14 / 176], [train main loss -1.621840], [lr 0.000629] [batchtime 0.392]
[epoch 164], [iter 15 / 176], [train main loss -1.790879], [lr 0.000629] [batchtime 0.392]
[epoch 164], [iter 16 / 176], [train main loss -1.802921], [lr 0.000629] [batchtime 0.395]
[epoch 164], [iter 17 / 176], [train main loss -1.700323], [lr 0.000629] [batchtime 0.396]
[epoch 164], [iter 18 / 176], [train main loss -1.718568], [lr 0.000629] [batchtime 0.452]
[epoch 164], [iter 19 / 176], [train main loss -1.780461], [lr 0.000629] [batchtime 0.446]
[epoch 164], [iter 20 / 176], [train main loss -1.906708], [lr 0.000629] [batchtime 0.44]
[epoch 164], [iter 21 / 176], [train main loss -1.897334], [lr 0.000629] [batchtime 0.437]
[epoch 164], [iter 22 / 176], [train main loss -1.882995], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 23 / 176], [train main loss -1.864771], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 24 / 176], [train main loss -1.849066], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 25 / 176], [train main loss -1.978142], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 26 / 176], [train main loss -1.924442], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 27 / 176], [train main loss -1.878038], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 28 / 176], [train main loss -1.832343], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 29 / 176], [train main loss -1.928872], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 30 / 176], [train main loss -1.960596], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 31 / 176], [train main loss -1.989037], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 32 / 176], [train main loss -2.029772], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 33 / 176], [train main loss -2.085025], [lr 0.000629] [batchtime 0.423]
[epoch 164], [iter 34 / 176], [train main loss -2.174993], [lr 0.000629] [batchtime 0.423]
[epoch 164], [iter 35 / 176], [train main loss -2.116160], [lr 0.000629] [batchtime 0.422]
[epoch 164], [iter 36 / 176], [train main loss -2.143652], [lr 0.000629] [batchtime 0.421]
[epoch 164], [iter 37 / 176], [train main loss -2.140659], [lr 0.000629] [batchtime 0.42]
[epoch 164], [iter 38 / 176], [train main loss -2.099651], [lr 0.000629] [batchtime 0.419]
[epoch 164], [iter 39 / 176], [train main loss -2.132841], [lr 0.000629] [batchtime 0.419]
[epoch 164], [iter 40 / 176], [train main loss -2.132573], [lr 0.000629] [batchtime 0.418]
[epoch 164], [iter 41 / 176], [train main loss -2.134987], [lr 0.000629] [batchtime 0.417]
[epoch 164], [iter 42 / 176], [train main loss -2.152513], [lr 0.000629] [batchtime 0.417]
[epoch 164], [iter 43 / 176], [train main loss -2.185200], [lr 0.000629] [batchtime 0.416]
[epoch 164], [iter 44 / 176], [train main loss -2.156475], [lr 0.000629] [batchtime 0.416]
[epoch 164], [iter 45 / 176], [train main loss -2.184310], [lr 0.000629] [batchtime 0.415]
[epoch 164], [iter 46 / 176], [train main loss -2.126647], [lr 0.000629] [batchtime 0.415]
[epoch 164], [iter 47 / 176], [train main loss -2.155924], [lr 0.000629] [batchtime 0.42]
[epoch 164], [iter 48 / 176], [train main loss -2.227034], [lr 0.000629] [batchtime 0.439]
[epoch 164], [iter 49 / 176], [train main loss -2.235890], [lr 0.000629] [batchtime 0.438]
[epoch 164], [iter 50 / 176], [train main loss -2.273074], [lr 0.000629] [batchtime 0.437]
[epoch 164], [iter 51 / 176], [train main loss -2.306736], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 52 / 176], [train main loss -2.229700], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 53 / 176], [train main loss -2.255760], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 54 / 176], [train main loss -2.258534], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 55 / 176], [train main loss -2.234281], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 56 / 176], [train main loss -2.220217], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 57 / 176], [train main loss -2.201145], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 58 / 176], [train main loss -2.190068], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 59 / 176], [train main loss -2.215709], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 60 / 176], [train main loss -2.194542], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 61 / 176], [train main loss -2.182895], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 62 / 176], [train main loss -2.202932], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 63 / 176], [train main loss -2.235280], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 64 / 176], [train main loss -2.204242], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 65 / 176], [train main loss -2.211912], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 66 / 176], [train main loss -2.207541], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 67 / 176], [train main loss -2.227406], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 68 / 176], [train main loss -2.233914], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 69 / 176], [train main loss -2.205535], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 70 / 176], [train main loss -2.211342], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 71 / 176], [train main loss -2.196028], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 72 / 176], [train main loss -2.166368], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 73 / 176], [train main loss -2.167390], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 74 / 176], [train main loss -2.149306], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 75 / 176], [train main loss -2.118171], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 76 / 176], [train main loss -2.122631], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 77 / 176], [train main loss -2.132467], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 78 / 176], [train main loss -2.139155], [lr 0.000629] [batchtime 0.425]
[epoch 164], [iter 79 / 176], [train main loss -2.138863], [lr 0.000629] [batchtime 0.425]
[epoch 164], [iter 80 / 176], [train main loss -2.144011], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 81 / 176], [train main loss -2.133443], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 82 / 176], [train main loss -2.133293], [lr 0.000629] [batchtime 0.423]
[epoch 164], [iter 83 / 176], [train main loss -2.141498], [lr 0.000629] [batchtime 0.423]
[epoch 164], [iter 84 / 176], [train main loss -2.144480], [lr 0.000629] [batchtime 0.422]
[epoch 164], [iter 85 / 176], [train main loss -2.150183], [lr 0.000629] [batchtime 0.422]
[epoch 164], [iter 86 / 176], [train main loss -2.133479], [lr 0.000629] [batchtime 0.422]
[epoch 164], [iter 87 / 176], [train main loss -2.137275], [lr 0.000629] [batchtime 0.421]
[epoch 164], [iter 88 / 176], [train main loss -2.142330], [lr 0.000629] [batchtime 0.421]
[epoch 164], [iter 89 / 176], [train main loss -2.161843], [lr 0.000629] [batchtime 0.421]
[epoch 164], [iter 90 / 176], [train main loss -2.156696], [lr 0.000629] [batchtime 0.42]
[epoch 164], [iter 91 / 176], [train main loss -2.169519], [lr 0.000629] [batchtime 0.42]
[epoch 164], [iter 92 / 176], [train main loss -2.184184], [lr 0.000629] [batchtime 0.42]
[epoch 164], [iter 93 / 176], [train main loss -2.173952], [lr 0.000629] [batchtime 0.419]
[epoch 164], [iter 94 / 176], [train main loss -2.183383], [lr 0.000629] [batchtime 0.419]
[epoch 164], [iter 95 / 176], [train main loss -2.214638], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 96 / 176], [train main loss -2.210298], [lr 0.000629] [batchtime 0.438]
[epoch 164], [iter 97 / 176], [train main loss -2.206723], [lr 0.000629] [batchtime 0.437]
[epoch 164], [iter 98 / 176], [train main loss -2.201810], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 99 / 176], [train main loss -2.179712], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 100 / 176], [train main loss -2.163440], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 101 / 176], [train main loss -2.155321], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 102 / 176], [train main loss -2.154685], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 103 / 176], [train main loss -2.177162], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 104 / 176], [train main loss -2.178883], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 105 / 176], [train main loss -2.184192], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 106 / 176], [train main loss -2.179259], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 107 / 176], [train main loss -2.179596], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 108 / 176], [train main loss -2.195516], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 109 / 176], [train main loss -2.197501], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 110 / 176], [train main loss -2.194928], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 111 / 176], [train main loss -2.211679], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 112 / 176], [train main loss -2.213740], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 113 / 176], [train main loss -2.225400], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 114 / 176], [train main loss -2.217094], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 115 / 176], [train main loss -2.188969], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 116 / 176], [train main loss -2.210178], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 117 / 176], [train main loss -2.205467], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 118 / 176], [train main loss -2.188516], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 119 / 176], [train main loss -2.174638], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 120 / 176], [train main loss -2.176555], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 121 / 176], [train main loss -2.190431], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 122 / 176], [train main loss -2.176371], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 123 / 176], [train main loss -2.183617], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 124 / 176], [train main loss -2.178478], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 125 / 176], [train main loss -2.183120], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 126 / 176], [train main loss -2.180973], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 127 / 176], [train main loss -2.167830], [lr 0.000629] [batchtime 0.427]
[epoch 164], [iter 128 / 176], [train main loss -2.180557], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 129 / 176], [train main loss -2.186133], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 130 / 176], [train main loss -2.184327], [lr 0.000629] [batchtime 0.426]
[epoch 164], [iter 131 / 176], [train main loss -2.174388], [lr 0.000629] [batchtime 0.425]
[epoch 164], [iter 132 / 176], [train main loss -2.176573], [lr 0.000629] [batchtime 0.425]
[epoch 164], [iter 133 / 176], [train main loss -2.191244], [lr 0.000629] [batchtime 0.425]
[epoch 164], [iter 134 / 176], [train main loss -2.190179], [lr 0.000629] [batchtime 0.425]
[epoch 164], [iter 135 / 176], [train main loss -2.192051], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 136 / 176], [train main loss -2.196273], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 137 / 176], [train main loss -2.193308], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 138 / 176], [train main loss -2.195775], [lr 0.000629] [batchtime 0.424]
[epoch 164], [iter 139 / 176], [train main loss -2.190151], [lr 0.000629] [batchtime 0.423]
[epoch 164], [iter 140 / 176], [train main loss -2.185335], [lr 0.000629] [batchtime 0.423]
[epoch 164], [iter 141 / 176], [train main loss -2.169752], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 142 / 176], [train main loss -2.178827], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 143 / 176], [train main loss -2.189614], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 144 / 176], [train main loss -2.197550], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 145 / 176], [train main loss -2.204432], [lr 0.000629] [batchtime 0.436]
[epoch 164], [iter 146 / 176], [train main loss -2.196559], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 147 / 176], [train main loss -2.186541], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 148 / 176], [train main loss -2.182699], [lr 0.000629] [batchtime 0.435]
[epoch 164], [iter 149 / 176], [train main loss -2.169753], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 150 / 176], [train main loss -2.152361], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 151 / 176], [train main loss -2.151590], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 152 / 176], [train main loss -2.158573], [lr 0.000629] [batchtime 0.434]
[epoch 164], [iter 153 / 176], [train main loss -2.161356], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 154 / 176], [train main loss -2.155753], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 155 / 176], [train main loss -2.140044], [lr 0.000629] [batchtime 0.433]
[epoch 164], [iter 156 / 176], [train main loss -2.142208], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 157 / 176], [train main loss -2.126506], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 158 / 176], [train main loss -2.143235], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 159 / 176], [train main loss -2.128039], [lr 0.000629] [batchtime 0.432]
[epoch 164], [iter 160 / 176], [train main loss -2.135835], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 161 / 176], [train main loss -2.141702], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 162 / 176], [train main loss -2.136489], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 163 / 176], [train main loss -2.123806], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 164 / 176], [train main loss -2.131524], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 165 / 176], [train main loss -2.142669], [lr 0.000629] [batchtime 0.431]
[epoch 164], [iter 166 / 176], [train main loss -2.148073], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 167 / 176], [train main loss -2.150671], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 168 / 176], [train main loss -2.159469], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 169 / 176], [train main loss -2.159877], [lr 0.000629] [batchtime 0.43]
[epoch 164], [iter 170 / 176], [train main loss -2.155363], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 171 / 176], [train main loss -2.154513], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 172 / 176], [train main loss -2.150146], [lr 0.000629] [batchtime 0.429]
[epoch 164], [iter 173 / 176], [train main loss -2.156961], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 174 / 176], [train main loss -2.146630], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 175 / 176], [train main loss -2.152184], [lr 0.000629] [batchtime 0.428]
[epoch 164], [iter 176 / 176], [train main loss -2.166596], [lr 0.000629] [batchtime 0.427]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.87  35.65   0.02  0.03         0.98      0.97
   1  sidewalk          69.90   5.29   0.24  0.19         0.80      0.84
   2  building          87.08  25.05   0.06  0.09         0.94      0.92
   3  wall              18.76   0.15   3.07  1.27         0.25      0.44
   4  fence             26.40   0.39   2.22  0.57         0.31      0.64
   5  pole              40.59   0.59   0.93  0.53         0.52      0.65
   6  traffic light     20.25   0.03   3.43  0.51         0.23      0.66
   7  traffic sign      30.60   0.19   2.00  0.27         0.33      0.79
   8  vegetation        84.46  11.70   0.06  0.13         0.95      0.89
   9  terrain           41.04   0.37   0.97  0.47         0.51      0.68
  10  sky               93.71   3.76   0.03  0.04         0.97      0.96
  11  person            56.33   1.08   0.42  0.35         0.70      0.74
  12  rider             15.69   0.02   4.42  0.96         0.18      0.51
  13  car               86.51   6.74   0.05  0.11         0.95      0.90
  14  truck              2.06   0.01  47.05  0.42         0.02      0.71
  15  bus               17.05   0.04   1.02  3.85         0.50      0.21
  16  train             37.01   0.08   1.15  0.55         0.46      0.64
  17  motorcycle         6.20   0.01  14.53  0.59         0.06      0.63
  18  bicycle           40.74   0.27   0.44  1.01         0.69      0.50
Mean: 45.75
-----------------------------------------------------------------------------------------------------------
this : [epoch 164], [val loss 0.29659], [acc 0.91419], [acc_cls 0.54543], [mean_iu 0.45750], [fwavacc 0.84981]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 165], [iter 1 / 176], [train main loss -4.391016], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 2 / 176], [train main loss -2.743558], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 3 / 176], [train main loss -3.052145], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 4 / 176], [train main loss -2.696759], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 5 / 176], [train main loss -3.096044], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 6 / 176], [train main loss -2.876058], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 7 / 176], [train main loss -2.864575], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 8 / 176], [train main loss -2.864721], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 9 / 176], [train main loss -2.855257], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 10 / 176], [train main loss -2.836035], [lr 0.000571] [batchtime 0]
[epoch 165], [iter 11 / 176], [train main loss -2.623146], [lr 0.000571] [batchtime 0.363]
[epoch 165], [iter 12 / 176], [train main loss -2.515661], [lr 0.000571] [batchtime 0.377]
[epoch 165], [iter 13 / 176], [train main loss -2.521827], [lr 0.000571] [batchtime 0.381]
[epoch 165], [iter 14 / 176], [train main loss -2.521678], [lr 0.000571] [batchtime 0.386]
[epoch 165], [iter 15 / 176], [train main loss -2.447295], [lr 0.000571] [batchtime 0.386]
[epoch 165], [iter 16 / 176], [train main loss -2.240986], [lr 0.000571] [batchtime 0.387]
[epoch 165], [iter 17 / 176], [train main loss -2.305798], [lr 0.000571] [batchtime 0.389]
[epoch 165], [iter 18 / 176], [train main loss -2.279585], [lr 0.000571] [batchtime 0.389]
[epoch 165], [iter 19 / 176], [train main loss -2.305417], [lr 0.000571] [batchtime 0.389]
[epoch 165], [iter 20 / 176], [train main loss -2.281858], [lr 0.000571] [batchtime 0.39]
[epoch 165], [iter 21 / 176], [train main loss -2.196047], [lr 0.000571] [batchtime 0.391]
[epoch 165], [iter 22 / 176], [train main loss -2.224024], [lr 0.000571] [batchtime 0.403]
[epoch 165], [iter 23 / 176], [train main loss -2.264447], [lr 0.000571] [batchtime 0.416]
[epoch 165], [iter 24 / 176], [train main loss -2.179195], [lr 0.000571] [batchtime 0.414]
[epoch 165], [iter 25 / 176], [train main loss -2.209006], [lr 0.000571] [batchtime 0.412]
[epoch 165], [iter 26 / 176], [train main loss -2.189549], [lr 0.000571] [batchtime 0.411]
[epoch 165], [iter 27 / 176], [train main loss -2.271616], [lr 0.000571] [batchtime 0.409]
[epoch 165], [iter 28 / 176], [train main loss -2.305712], [lr 0.000571] [batchtime 0.409]
[epoch 165], [iter 29 / 176], [train main loss -2.315819], [lr 0.000571] [batchtime 0.408]
[epoch 165], [iter 30 / 176], [train main loss -2.330896], [lr 0.000571] [batchtime 0.408]
[epoch 165], [iter 31 / 176], [train main loss -2.390661], [lr 0.000571] [batchtime 0.407]
[epoch 165], [iter 32 / 176], [train main loss -2.361078], [lr 0.000571] [batchtime 0.406]
[epoch 165], [iter 33 / 176], [train main loss -2.406606], [lr 0.000571] [batchtime 0.406]
[epoch 165], [iter 34 / 176], [train main loss -2.342581], [lr 0.000571] [batchtime 0.405]
[epoch 165], [iter 35 / 176], [train main loss -2.296474], [lr 0.000571] [batchtime 0.405]
[epoch 165], [iter 36 / 176], [train main loss -2.253503], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 37 / 176], [train main loss -2.232579], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 38 / 176], [train main loss -2.218121], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 39 / 176], [train main loss -2.283109], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 40 / 176], [train main loss -2.260803], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 41 / 176], [train main loss -2.309797], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 42 / 176], [train main loss -2.294158], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 43 / 176], [train main loss -2.332577], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 44 / 176], [train main loss -2.250760], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 45 / 176], [train main loss -2.250476], [lr 0.000571] [batchtime 0.404]
[epoch 165], [iter 46 / 176], [train main loss -2.253107], [lr 0.000571] [batchtime 0.407]
[epoch 165], [iter 47 / 176], [train main loss -2.171184], [lr 0.000571] [batchtime 0.442]
[epoch 165], [iter 48 / 176], [train main loss -2.225997], [lr 0.000571] [batchtime 0.441]
[epoch 165], [iter 49 / 176], [train main loss -2.243280], [lr 0.000571] [batchtime 0.439]
[epoch 165], [iter 50 / 176], [train main loss -2.296130], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 51 / 176], [train main loss -2.317420], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 52 / 176], [train main loss -2.303172], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 53 / 176], [train main loss -2.235494], [lr 0.000571] [batchtime 0.435]
[epoch 165], [iter 54 / 176], [train main loss -2.241283], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 55 / 176], [train main loss -2.250748], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 56 / 176], [train main loss -2.233466], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 57 / 176], [train main loss -2.236837], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 58 / 176], [train main loss -2.223200], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 59 / 176], [train main loss -2.216370], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 60 / 176], [train main loss -2.181407], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 61 / 176], [train main loss -2.218365], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 62 / 176], [train main loss -2.257367], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 63 / 176], [train main loss -2.295715], [lr 0.000571] [batchtime 0.428]
[epoch 165], [iter 64 / 176], [train main loss -2.338926], [lr 0.000571] [batchtime 0.427]
[epoch 165], [iter 65 / 176], [train main loss -2.340966], [lr 0.000571] [batchtime 0.427]
[epoch 165], [iter 66 / 176], [train main loss -2.333408], [lr 0.000571] [batchtime 0.426]
[epoch 165], [iter 67 / 176], [train main loss -2.328584], [lr 0.000571] [batchtime 0.426]
[epoch 165], [iter 68 / 176], [train main loss -2.340455], [lr 0.000571] [batchtime 0.426]
[epoch 165], [iter 69 / 176], [train main loss -2.320687], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 70 / 176], [train main loss -2.370195], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 71 / 176], [train main loss -2.395170], [lr 0.000571] [batchtime 0.428]
[epoch 165], [iter 72 / 176], [train main loss -2.358800], [lr 0.000571] [batchtime 0.427]
[epoch 165], [iter 73 / 176], [train main loss -2.368561], [lr 0.000571] [batchtime 0.427]
[epoch 165], [iter 74 / 176], [train main loss -2.388497], [lr 0.000571] [batchtime 0.426]
[epoch 165], [iter 75 / 176], [train main loss -2.434058], [lr 0.000571] [batchtime 0.426]
[epoch 165], [iter 76 / 176], [train main loss -2.424744], [lr 0.000571] [batchtime 0.425]
[epoch 165], [iter 77 / 176], [train main loss -2.432525], [lr 0.000571] [batchtime 0.425]
[epoch 165], [iter 78 / 176], [train main loss -2.427651], [lr 0.000571] [batchtime 0.425]
[epoch 165], [iter 79 / 176], [train main loss -2.448398], [lr 0.000571] [batchtime 0.424]
[epoch 165], [iter 80 / 176], [train main loss -2.461162], [lr 0.000571] [batchtime 0.424]
[epoch 165], [iter 81 / 176], [train main loss -2.447013], [lr 0.000571] [batchtime 0.424]
[epoch 165], [iter 82 / 176], [train main loss -2.466832], [lr 0.000571] [batchtime 0.423]
[epoch 165], [iter 83 / 176], [train main loss -2.470848], [lr 0.000571] [batchtime 0.423]
[epoch 165], [iter 84 / 176], [train main loss -2.467866], [lr 0.000571] [batchtime 0.422]
[epoch 165], [iter 85 / 176], [train main loss -2.465087], [lr 0.000571] [batchtime 0.422]
[epoch 165], [iter 86 / 176], [train main loss -2.470850], [lr 0.000571] [batchtime 0.422]
[epoch 165], [iter 87 / 176], [train main loss -2.448910], [lr 0.000571] [batchtime 0.421]
[epoch 165], [iter 88 / 176], [train main loss -2.441753], [lr 0.000571] [batchtime 0.421]
[epoch 165], [iter 89 / 176], [train main loss -2.414938], [lr 0.000571] [batchtime 0.421]
[epoch 165], [iter 90 / 176], [train main loss -2.468048], [lr 0.000571] [batchtime 0.42]
[epoch 165], [iter 91 / 176], [train main loss -2.485697], [lr 0.000571] [batchtime 0.42]
[epoch 165], [iter 92 / 176], [train main loss -2.475899], [lr 0.000571] [batchtime 0.424]
[epoch 165], [iter 93 / 176], [train main loss -2.481952], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 94 / 176], [train main loss -2.470705], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 95 / 176], [train main loss -2.453100], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 96 / 176], [train main loss -2.456267], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 97 / 176], [train main loss -2.454315], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 98 / 176], [train main loss -2.481118], [lr 0.000571] [batchtime 0.443]
[epoch 165], [iter 99 / 176], [train main loss -2.455834], [lr 0.000571] [batchtime 0.442]
[epoch 165], [iter 100 / 176], [train main loss -2.479008], [lr 0.000571] [batchtime 0.442]
[epoch 165], [iter 101 / 176], [train main loss -2.475888], [lr 0.000571] [batchtime 0.441]
[epoch 165], [iter 102 / 176], [train main loss -2.492487], [lr 0.000571] [batchtime 0.44]
[epoch 165], [iter 103 / 176], [train main loss -2.513606], [lr 0.000571] [batchtime 0.44]
[epoch 165], [iter 104 / 176], [train main loss -2.489218], [lr 0.000571] [batchtime 0.439]
[epoch 165], [iter 105 / 176], [train main loss -2.465561], [lr 0.000571] [batchtime 0.439]
[epoch 165], [iter 106 / 176], [train main loss -2.452542], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 107 / 176], [train main loss -2.456474], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 108 / 176], [train main loss -2.443762], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 109 / 176], [train main loss -2.417961], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 110 / 176], [train main loss -2.407882], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 111 / 176], [train main loss -2.401653], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 112 / 176], [train main loss -2.385204], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 113 / 176], [train main loss -2.379619], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 114 / 176], [train main loss -2.367145], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 115 / 176], [train main loss -2.358130], [lr 0.000571] [batchtime 0.435]
[epoch 165], [iter 116 / 176], [train main loss -2.349690], [lr 0.000571] [batchtime 0.435]
[epoch 165], [iter 117 / 176], [train main loss -2.336966], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 118 / 176], [train main loss -2.353952], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 119 / 176], [train main loss -2.348364], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 120 / 176], [train main loss -2.336784], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 121 / 176], [train main loss -2.332683], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 122 / 176], [train main loss -2.303498], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 123 / 176], [train main loss -2.299334], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 124 / 176], [train main loss -2.296162], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 125 / 176], [train main loss -2.296710], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 126 / 176], [train main loss -2.300369], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 127 / 176], [train main loss -2.288204], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 128 / 176], [train main loss -2.281083], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 129 / 176], [train main loss -2.296634], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 130 / 176], [train main loss -2.300378], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 131 / 176], [train main loss -2.282948], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 132 / 176], [train main loss -2.295795], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 133 / 176], [train main loss -2.277166], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 134 / 176], [train main loss -2.267276], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 135 / 176], [train main loss -2.263779], [lr 0.000571] [batchtime 0.428]
[epoch 165], [iter 136 / 176], [train main loss -2.241315], [lr 0.000571] [batchtime 0.428]
[epoch 165], [iter 137 / 176], [train main loss -2.257161], [lr 0.000571] [batchtime 0.428]
[epoch 165], [iter 138 / 176], [train main loss -2.242421], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 139 / 176], [train main loss -2.261800], [lr 0.000571] [batchtime 0.44]
[epoch 165], [iter 140 / 176], [train main loss -2.257774], [lr 0.000571] [batchtime 0.44]
[epoch 165], [iter 141 / 176], [train main loss -2.257769], [lr 0.000571] [batchtime 0.44]
[epoch 165], [iter 142 / 176], [train main loss -2.259506], [lr 0.000571] [batchtime 0.439]
[epoch 165], [iter 143 / 176], [train main loss -2.269882], [lr 0.000571] [batchtime 0.439]
[epoch 165], [iter 144 / 176], [train main loss -2.273819], [lr 0.000571] [batchtime 0.439]
[epoch 165], [iter 145 / 176], [train main loss -2.273059], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 146 / 176], [train main loss -2.289697], [lr 0.000571] [batchtime 0.438]
[epoch 165], [iter 147 / 176], [train main loss -2.288901], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 148 / 176], [train main loss -2.283467], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 149 / 176], [train main loss -2.302022], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 150 / 176], [train main loss -2.280738], [lr 0.000571] [batchtime 0.437]
[epoch 165], [iter 151 / 176], [train main loss -2.258285], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 152 / 176], [train main loss -2.265539], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 153 / 176], [train main loss -2.264553], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 154 / 176], [train main loss -2.266096], [lr 0.000571] [batchtime 0.436]
[epoch 165], [iter 155 / 176], [train main loss -2.255653], [lr 0.000571] [batchtime 0.435]
[epoch 165], [iter 156 / 176], [train main loss -2.265499], [lr 0.000571] [batchtime 0.435]
[epoch 165], [iter 157 / 176], [train main loss -2.267124], [lr 0.000571] [batchtime 0.435]
[epoch 165], [iter 158 / 176], [train main loss -2.265336], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 159 / 176], [train main loss -2.279145], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 160 / 176], [train main loss -2.265354], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 161 / 176], [train main loss -2.272932], [lr 0.000571] [batchtime 0.434]
[epoch 165], [iter 162 / 176], [train main loss -2.258447], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 163 / 176], [train main loss -2.242611], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 164 / 176], [train main loss -2.229560], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 165 / 176], [train main loss -2.222537], [lr 0.000571] [batchtime 0.433]
[epoch 165], [iter 166 / 176], [train main loss -2.225307], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 167 / 176], [train main loss -2.221508], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 168 / 176], [train main loss -2.228625], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 169 / 176], [train main loss -2.236327], [lr 0.000571] [batchtime 0.432]
[epoch 165], [iter 170 / 176], [train main loss -2.242940], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 171 / 176], [train main loss -2.225650], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 172 / 176], [train main loss -2.221650], [lr 0.000571] [batchtime 0.431]
[epoch 165], [iter 173 / 176], [train main loss -2.206797], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 174 / 176], [train main loss -2.221858], [lr 0.000571] [batchtime 0.43]
[epoch 165], [iter 175 / 176], [train main loss -2.225594], [lr 0.000571] [batchtime 0.429]
[epoch 165], [iter 176 / 176], [train main loss -2.227883], [lr 0.000571] [batchtime 0.429]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              94.91  35.63   0.02  0.03         0.98      0.97
   1  sidewalk          70.15   5.33   0.24  0.19         0.81      0.84
   2  building          87.03  25.02   0.06  0.09         0.94      0.92
   3  wall              19.48   0.15   2.84  1.29         0.26      0.44
   4  fence             26.72   0.41   2.10  0.64         0.32      0.61
   5  pole              40.74   0.59   0.93  0.52         0.52      0.66
   6  traffic light     20.60   0.03   3.35  0.51         0.23      0.66
   7  traffic sign      30.03   0.18   2.10  0.23         0.32      0.81
   8  vegetation        84.47  11.68   0.06  0.13         0.95      0.89
   9  terrain           40.80   0.37   0.98  0.47         0.50      0.68
  10  sky               93.83   3.76   0.03  0.04         0.97      0.97
  11  person            55.72   1.06   0.45  0.34         0.69      0.75
  12  rider             14.42   0.02   5.01  0.92         0.17      0.52
  13  car               86.36   6.75   0.05  0.11         0.95      0.90
  14  truck              1.97   0.01  49.19  0.49         0.02      0.67
  15  bus               16.25   0.04   0.97  4.18         0.51      0.19
  16  train             33.99   0.08   1.37  0.57         0.42      0.64
  17  motorcycle         5.63   0.01  16.14  0.62         0.06      0.62
  18  bicycle           39.65   0.28   0.40  1.12         0.71      0.47
Mean: 45.41
-----------------------------------------------------------------------------------------------------------
this : [epoch 165], [val loss 0.29159], [acc 0.91385], [acc_cls 0.54382], [mean_iu 0.45409], [fwavacc 0.84978]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 166], [iter 1 / 176], [train main loss -1.962122], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 2 / 176], [train main loss -2.330605], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 3 / 176], [train main loss -1.758687], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 4 / 176], [train main loss -1.349095], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 5 / 176], [train main loss -1.764933], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 6 / 176], [train main loss -1.989678], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 7 / 176], [train main loss -2.259979], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 8 / 176], [train main loss -1.866856], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 9 / 176], [train main loss -2.206597], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 10 / 176], [train main loss -2.283648], [lr 0.000514] [batchtime 0]
[epoch 166], [iter 11 / 176], [train main loss -2.354920], [lr 0.000514] [batchtime 0.387]
[epoch 166], [iter 12 / 176], [train main loss -2.524781], [lr 0.000514] [batchtime 0.394]
[epoch 166], [iter 13 / 176], [train main loss -2.723321], [lr 0.000514] [batchtime 0.393]
[epoch 166], [iter 14 / 176], [train main loss -2.607883], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 15 / 176], [train main loss -2.593112], [lr 0.000514] [batchtime 0.405]
[epoch 166], [iter 16 / 176], [train main loss -2.857112], [lr 0.000514] [batchtime 0.403]
[epoch 166], [iter 17 / 176], [train main loss -2.881641], [lr 0.000514] [batchtime 0.4]
[epoch 166], [iter 18 / 176], [train main loss -2.780095], [lr 0.000514] [batchtime 0.4]
[epoch 166], [iter 19 / 176], [train main loss -2.678639], [lr 0.000514] [batchtime 0.4]
[epoch 166], [iter 20 / 176], [train main loss -2.799774], [lr 0.000514] [batchtime 0.4]
[epoch 166], [iter 21 / 176], [train main loss -2.739493], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 22 / 176], [train main loss -2.648085], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 23 / 176], [train main loss -2.707344], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 24 / 176], [train main loss -2.733012], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 25 / 176], [train main loss -2.789797], [lr 0.000514] [batchtime 0.403]
[epoch 166], [iter 26 / 176], [train main loss -2.760931], [lr 0.000514] [batchtime 0.403]
[epoch 166], [iter 27 / 176], [train main loss -2.779497], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 28 / 176], [train main loss -2.716707], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 29 / 176], [train main loss -2.624181], [lr 0.000514] [batchtime 0.403]
[epoch 166], [iter 30 / 176], [train main loss -2.616929], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 31 / 176], [train main loss -2.689792], [lr 0.000514] [batchtime 0.403]
[epoch 166], [iter 32 / 176], [train main loss -2.689611], [lr 0.000514] [batchtime 0.403]
[epoch 166], [iter 33 / 176], [train main loss -2.639820], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 34 / 176], [train main loss -2.580596], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 35 / 176], [train main loss -2.532445], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 36 / 176], [train main loss -2.525894], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 37 / 176], [train main loss -2.519208], [lr 0.000514] [batchtime 0.402]
[epoch 166], [iter 38 / 176], [train main loss -2.530963], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 39 / 176], [train main loss -2.544500], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 40 / 176], [train main loss -2.503064], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 41 / 176], [train main loss -2.447764], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 42 / 176], [train main loss -2.463835], [lr 0.000514] [batchtime 0.401]
[epoch 166], [iter 43 / 176], [train main loss -2.391042], [lr 0.000514] [batchtime 0.405]
[epoch 166], [iter 44 / 176], [train main loss -2.400906], [lr 0.000514] [batchtime 0.442]
[epoch 166], [iter 45 / 176], [train main loss -2.443578], [lr 0.000514] [batchtime 0.451]
[epoch 166], [iter 46 / 176], [train main loss -2.399500], [lr 0.000514] [batchtime 0.449]
[epoch 166], [iter 47 / 176], [train main loss -2.366072], [lr 0.000514] [batchtime 0.447]
[epoch 166], [iter 48 / 176], [train main loss -2.348018], [lr 0.000514] [batchtime 0.446]
[epoch 166], [iter 49 / 176], [train main loss -2.316990], [lr 0.000514] [batchtime 0.445]
[epoch 166], [iter 50 / 176], [train main loss -2.277556], [lr 0.000514] [batchtime 0.444]
[epoch 166], [iter 51 / 176], [train main loss -2.299145], [lr 0.000514] [batchtime 0.443]
[epoch 166], [iter 52 / 176], [train main loss -2.308284], [lr 0.000514] [batchtime 0.442]
[epoch 166], [iter 53 / 176], [train main loss -2.372192], [lr 0.000514] [batchtime 0.441]
[epoch 166], [iter 54 / 176], [train main loss -2.348667], [lr 0.000514] [batchtime 0.44]
[epoch 166], [iter 55 / 176], [train main loss -2.356651], [lr 0.000514] [batchtime 0.439]
[epoch 166], [iter 56 / 176], [train main loss -2.320098], [lr 0.000514] [batchtime 0.438]
[epoch 166], [iter 57 / 176], [train main loss -2.333788], [lr 0.000514] [batchtime 0.437]
[epoch 166], [iter 58 / 176], [train main loss -2.336298], [lr 0.000514] [batchtime 0.436]
[epoch 166], [iter 59 / 176], [train main loss -2.366785], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 60 / 176], [train main loss -2.345255], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 61 / 176], [train main loss -2.351580], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 62 / 176], [train main loss -2.330873], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 63 / 176], [train main loss -2.324474], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 64 / 176], [train main loss -2.305380], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 65 / 176], [train main loss -2.333653], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 66 / 176], [train main loss -2.313759], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 67 / 176], [train main loss -2.320499], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 68 / 176], [train main loss -2.330764], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 69 / 176], [train main loss -2.312060], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 70 / 176], [train main loss -2.327354], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 71 / 176], [train main loss -2.317536], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 72 / 176], [train main loss -2.285405], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 73 / 176], [train main loss -2.268621], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 74 / 176], [train main loss -2.280261], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 75 / 176], [train main loss -2.283093], [lr 0.000514] [batchtime 0.426]
[epoch 166], [iter 76 / 176], [train main loss -2.256523], [lr 0.000514] [batchtime 0.426]
[epoch 166], [iter 77 / 176], [train main loss -2.238340], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 78 / 176], [train main loss -2.212747], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 79 / 176], [train main loss -2.204674], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 80 / 176], [train main loss -2.210302], [lr 0.000514] [batchtime 0.424]
[epoch 166], [iter 81 / 176], [train main loss -2.161756], [lr 0.000514] [batchtime 0.424]
[epoch 166], [iter 82 / 176], [train main loss -2.134076], [lr 0.000514] [batchtime 0.424]
[epoch 166], [iter 83 / 176], [train main loss -2.110490], [lr 0.000514] [batchtime 0.423]
[epoch 166], [iter 84 / 176], [train main loss -2.099781], [lr 0.000514] [batchtime 0.423]
[epoch 166], [iter 85 / 176], [train main loss -2.113668], [lr 0.000514] [batchtime 0.422]
[epoch 166], [iter 86 / 176], [train main loss -2.069751], [lr 0.000514] [batchtime 0.422]
[epoch 166], [iter 87 / 176], [train main loss -2.082625], [lr 0.000514] [batchtime 0.422]
[epoch 166], [iter 88 / 176], [train main loss -2.071651], [lr 0.000514] [batchtime 0.422]
[epoch 166], [iter 89 / 176], [train main loss -2.083558], [lr 0.000514] [batchtime 0.421]
[epoch 166], [iter 90 / 176], [train main loss -2.080349], [lr 0.000514] [batchtime 0.423]
[epoch 166], [iter 91 / 176], [train main loss -2.097817], [lr 0.000514] [batchtime 0.439]
[epoch 166], [iter 92 / 176], [train main loss -2.101590], [lr 0.000514] [batchtime 0.439]
[epoch 166], [iter 93 / 176], [train main loss -2.097226], [lr 0.000514] [batchtime 0.438]
[epoch 166], [iter 94 / 176], [train main loss -2.078071], [lr 0.000514] [batchtime 0.437]
[epoch 166], [iter 95 / 176], [train main loss -2.068446], [lr 0.000514] [batchtime 0.437]
[epoch 166], [iter 96 / 176], [train main loss -2.045272], [lr 0.000514] [batchtime 0.436]
[epoch 166], [iter 97 / 176], [train main loss -2.066562], [lr 0.000514] [batchtime 0.436]
[epoch 166], [iter 98 / 176], [train main loss -2.083612], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 99 / 176], [train main loss -2.065569], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 100 / 176], [train main loss -2.096067], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 101 / 176], [train main loss -2.097028], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 102 / 176], [train main loss -2.125558], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 103 / 176], [train main loss -2.117687], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 104 / 176], [train main loss -2.087724], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 105 / 176], [train main loss -2.095321], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 106 / 176], [train main loss -2.081757], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 107 / 176], [train main loss -2.084383], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 108 / 176], [train main loss -2.095345], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 109 / 176], [train main loss -2.084828], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 110 / 176], [train main loss -2.085798], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 111 / 176], [train main loss -2.092292], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 112 / 176], [train main loss -2.106103], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 113 / 176], [train main loss -2.086957], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 114 / 176], [train main loss -2.085776], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 115 / 176], [train main loss -2.096958], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 116 / 176], [train main loss -2.097973], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 117 / 176], [train main loss -2.087271], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 118 / 176], [train main loss -2.090704], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 119 / 176], [train main loss -2.084816], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 120 / 176], [train main loss -2.082230], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 121 / 176], [train main loss -2.075908], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 122 / 176], [train main loss -2.069827], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 123 / 176], [train main loss -2.088737], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 124 / 176], [train main loss -2.060852], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 125 / 176], [train main loss -2.059509], [lr 0.000514] [batchtime 0.426]
[epoch 166], [iter 126 / 176], [train main loss -2.078305], [lr 0.000514] [batchtime 0.426]
[epoch 166], [iter 127 / 176], [train main loss -2.069158], [lr 0.000514] [batchtime 0.426]
[epoch 166], [iter 128 / 176], [train main loss -2.075323], [lr 0.000514] [batchtime 0.426]
[epoch 166], [iter 129 / 176], [train main loss -2.092005], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 130 / 176], [train main loss -2.101582], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 131 / 176], [train main loss -2.092715], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 132 / 176], [train main loss -2.070670], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 133 / 176], [train main loss -2.087313], [lr 0.000514] [batchtime 0.425]
[epoch 166], [iter 134 / 176], [train main loss -2.084341], [lr 0.000514] [batchtime 0.424]
[epoch 166], [iter 135 / 176], [train main loss -2.072065], [lr 0.000514] [batchtime 0.424]
[epoch 166], [iter 136 / 176], [train main loss -2.075601], [lr 0.000514] [batchtime 0.424]
[epoch 166], [iter 137 / 176], [train main loss -2.056606], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 138 / 176], [train main loss -2.040855], [lr 0.000514] [batchtime 0.436]
[epoch 166], [iter 139 / 176], [train main loss -2.039809], [lr 0.000514] [batchtime 0.436]
[epoch 166], [iter 140 / 176], [train main loss -2.033395], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 141 / 176], [train main loss -2.034411], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 142 / 176], [train main loss -2.001186], [lr 0.000514] [batchtime 0.435]
[epoch 166], [iter 143 / 176], [train main loss -1.991723], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 144 / 176], [train main loss -1.990292], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 145 / 176], [train main loss -1.979001], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 146 / 176], [train main loss -1.987169], [lr 0.000514] [batchtime 0.434]
[epoch 166], [iter 147 / 176], [train main loss -1.992704], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 148 / 176], [train main loss -1.998508], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 149 / 176], [train main loss -1.996798], [lr 0.000514] [batchtime 0.433]
[epoch 166], [iter 150 / 176], [train main loss -2.012599], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 151 / 176], [train main loss -2.009003], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 152 / 176], [train main loss -2.009083], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 153 / 176], [train main loss -2.005380], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 154 / 176], [train main loss -2.014879], [lr 0.000514] [batchtime 0.432]
[epoch 166], [iter 155 / 176], [train main loss -2.019773], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 156 / 176], [train main loss -2.022194], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 157 / 176], [train main loss -2.020918], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 158 / 176], [train main loss -2.041206], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 159 / 176], [train main loss -2.018265], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 160 / 176], [train main loss -2.012342], [lr 0.000514] [batchtime 0.431]
[epoch 166], [iter 161 / 176], [train main loss -2.019984], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 162 / 176], [train main loss -2.026389], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 163 / 176], [train main loss -2.027906], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 164 / 176], [train main loss -2.033522], [lr 0.000514] [batchtime 0.43]
[epoch 166], [iter 165 / 176], [train main loss -2.026416], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 166 / 176], [train main loss -2.022661], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 167 / 176], [train main loss -2.014515], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 168 / 176], [train main loss -2.018402], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 169 / 176], [train main loss -2.034965], [lr 0.000514] [batchtime 0.429]
[epoch 166], [iter 170 / 176], [train main loss -2.041118], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 171 / 176], [train main loss -2.048863], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 172 / 176], [train main loss -2.038540], [lr 0.000514] [batchtime 0.428]
[epoch 166], [iter 173 / 176], [train main loss -2.039505], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 174 / 176], [train main loss -2.042536], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 175 / 176], [train main loss -2.022307], [lr 0.000514] [batchtime 0.427]
[epoch 166], [iter 176 / 176], [train main loss -2.023553], [lr 0.000514] [batchtime 0.426]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.07  35.52   0.02  0.03         0.98      0.97
   1  sidewalk          71.53   5.49   0.20  0.20         0.83      0.84
   2  building          87.10  25.08   0.06  0.09         0.94      0.92
   3  wall              19.20   0.16   2.74  1.47         0.27      0.40
   4  fence             25.64   0.39   2.28  0.62         0.30      0.62
   5  pole              40.81   0.59   0.93  0.52         0.52      0.66
   6  traffic light     19.76   0.03   3.65  0.41         0.21      0.71
   7  traffic sign      29.73   0.18   2.12  0.24         0.32      0.80
   8  vegetation        84.30  11.72   0.06  0.13         0.95      0.88
   9  terrain           40.71   0.37   0.99  0.47         0.50      0.68
  10  sky               93.97   3.75   0.03  0.03         0.97      0.97
  11  person            55.86   1.05   0.46  0.33         0.69      0.75
  12  rider             14.70   0.02   4.84  0.97         0.17      0.51
  13  car               87.08   6.72   0.05  0.10         0.95      0.91
  14  truck              1.58   0.01  61.95  0.46         0.02      0.68
  15  bus               17.60   0.05   0.82  3.86         0.55      0.21
  16  train             39.00   0.09   0.97  0.59         0.51      0.63
  17  motorcycle         5.45   0.01  16.67  0.67         0.06      0.60
  18  bicycle           40.90   0.28   0.38  1.07         0.73      0.48
Mean: 45.79
-----------------------------------------------------------------------------------------------------------
this : [epoch 166], [val loss 0.28120], [acc 0.91488], [acc_cls 0.55054], [mean_iu 0.45789], [fwavacc 0.85177]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 167], [iter 1 / 176], [train main loss -3.031467], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 2 / 176], [train main loss -3.466662], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 3 / 176], [train main loss -3.338279], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 4 / 176], [train main loss -2.149223], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 5 / 176], [train main loss -2.361219], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 6 / 176], [train main loss -2.740406], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 7 / 176], [train main loss -2.300248], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 8 / 176], [train main loss -2.367653], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 9 / 176], [train main loss -2.112711], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 10 / 176], [train main loss -2.194788], [lr 0.000457] [batchtime 0]
[epoch 167], [iter 11 / 176], [train main loss -2.151107], [lr 0.000457] [batchtime 0.361]
[epoch 167], [iter 12 / 176], [train main loss -2.285702], [lr 0.000457] [batchtime 0.378]
[epoch 167], [iter 13 / 176], [train main loss -2.226681], [lr 0.000457] [batchtime 0.383]
[epoch 167], [iter 14 / 176], [train main loss -2.085965], [lr 0.000457] [batchtime 0.386]
[epoch 167], [iter 15 / 176], [train main loss -1.911856], [lr 0.000457] [batchtime 0.39]
[epoch 167], [iter 16 / 176], [train main loss -1.707379], [lr 0.000457] [batchtime 0.389]
[epoch 167], [iter 17 / 176], [train main loss -1.698479], [lr 0.000457] [batchtime 0.389]
[epoch 167], [iter 18 / 176], [train main loss -1.806675], [lr 0.000457] [batchtime 0.392]
[epoch 167], [iter 19 / 176], [train main loss -1.710279], [lr 0.000457] [batchtime 0.393]
[epoch 167], [iter 20 / 176], [train main loss -1.921193], [lr 0.000457] [batchtime 0.393]
[epoch 167], [iter 21 / 176], [train main loss -2.018321], [lr 0.000457] [batchtime 0.393]
[epoch 167], [iter 22 / 176], [train main loss -2.206559], [lr 0.000457] [batchtime 0.394]
[epoch 167], [iter 23 / 176], [train main loss -2.254389], [lr 0.000457] [batchtime 0.395]
[epoch 167], [iter 24 / 176], [train main loss -2.234085], [lr 0.000457] [batchtime 0.395]
[epoch 167], [iter 25 / 176], [train main loss -2.120387], [lr 0.000457] [batchtime 0.396]
[epoch 167], [iter 26 / 176], [train main loss -2.103351], [lr 0.000457] [batchtime 0.396]
[epoch 167], [iter 27 / 176], [train main loss -1.984895], [lr 0.000457] [batchtime 0.396]
[epoch 167], [iter 28 / 176], [train main loss -2.001450], [lr 0.000457] [batchtime 0.396]
[epoch 167], [iter 29 / 176], [train main loss -2.046842], [lr 0.000457] [batchtime 0.396]
[epoch 167], [iter 30 / 176], [train main loss -2.086493], [lr 0.000457] [batchtime 0.396]
[epoch 167], [iter 31 / 176], [train main loss -2.113938], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 32 / 176], [train main loss -2.091610], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 33 / 176], [train main loss -2.051850], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 34 / 176], [train main loss -1.974098], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 35 / 176], [train main loss -2.013042], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 36 / 176], [train main loss -1.964585], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 37 / 176], [train main loss -2.010683], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 38 / 176], [train main loss -2.042701], [lr 0.000457] [batchtime 0.397]
[epoch 167], [iter 39 / 176], [train main loss -2.095761], [lr 0.000457] [batchtime 0.443]
[epoch 167], [iter 40 / 176], [train main loss -2.115227], [lr 0.000457] [batchtime 0.445]
[epoch 167], [iter 41 / 176], [train main loss -2.095795], [lr 0.000457] [batchtime 0.443]
[epoch 167], [iter 42 / 176], [train main loss -2.150701], [lr 0.000457] [batchtime 0.441]
[epoch 167], [iter 43 / 176], [train main loss -2.090268], [lr 0.000457] [batchtime 0.44]
[epoch 167], [iter 44 / 176], [train main loss -2.062432], [lr 0.000457] [batchtime 0.438]
[epoch 167], [iter 45 / 176], [train main loss -2.054486], [lr 0.000457] [batchtime 0.437]
[epoch 167], [iter 46 / 176], [train main loss -2.022370], [lr 0.000457] [batchtime 0.436]
[epoch 167], [iter 47 / 176], [train main loss -2.003137], [lr 0.000457] [batchtime 0.435]
[epoch 167], [iter 48 / 176], [train main loss -2.014518], [lr 0.000457] [batchtime 0.434]
[epoch 167], [iter 49 / 176], [train main loss -1.990637], [lr 0.000457] [batchtime 0.433]
[epoch 167], [iter 50 / 176], [train main loss -1.952807], [lr 0.000457] [batchtime 0.433]
[epoch 167], [iter 51 / 176], [train main loss -1.977270], [lr 0.000457] [batchtime 0.431]
[epoch 167], [iter 52 / 176], [train main loss -1.989982], [lr 0.000457] [batchtime 0.431]
[epoch 167], [iter 53 / 176], [train main loss -2.044847], [lr 0.000457] [batchtime 0.43]
[epoch 167], [iter 54 / 176], [train main loss -2.035519], [lr 0.000457] [batchtime 0.429]
[epoch 167], [iter 55 / 176], [train main loss -2.064390], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 56 / 176], [train main loss -2.035709], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 57 / 176], [train main loss -2.027984], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 58 / 176], [train main loss -2.045460], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 59 / 176], [train main loss -2.023775], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 60 / 176], [train main loss -2.003909], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 61 / 176], [train main loss -1.964142], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 62 / 176], [train main loss -1.993034], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 63 / 176], [train main loss -2.011634], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 64 / 176], [train main loss -2.024499], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 65 / 176], [train main loss -2.016796], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 66 / 176], [train main loss -2.012390], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 67 / 176], [train main loss -2.004909], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 68 / 176], [train main loss -1.998503], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 69 / 176], [train main loss -2.026570], [lr 0.000457] [batchtime 0.421]
[epoch 167], [iter 70 / 176], [train main loss -2.064105], [lr 0.000457] [batchtime 0.421]
[epoch 167], [iter 71 / 176], [train main loss -2.065446], [lr 0.000457] [batchtime 0.421]
[epoch 167], [iter 72 / 176], [train main loss -2.068169], [lr 0.000457] [batchtime 0.42]
[epoch 167], [iter 73 / 176], [train main loss -2.062240], [lr 0.000457] [batchtime 0.42]
[epoch 167], [iter 74 / 176], [train main loss -2.036069], [lr 0.000457] [batchtime 0.42]
[epoch 167], [iter 75 / 176], [train main loss -2.035109], [lr 0.000457] [batchtime 0.419]
[epoch 167], [iter 76 / 176], [train main loss -2.043377], [lr 0.000457] [batchtime 0.419]
[epoch 167], [iter 77 / 176], [train main loss -2.067963], [lr 0.000457] [batchtime 0.419]
[epoch 167], [iter 78 / 176], [train main loss -2.058051], [lr 0.000457] [batchtime 0.418]
[epoch 167], [iter 79 / 176], [train main loss -2.044488], [lr 0.000457] [batchtime 0.418]
[epoch 167], [iter 80 / 176], [train main loss -2.033450], [lr 0.000457] [batchtime 0.418]
[epoch 167], [iter 81 / 176], [train main loss -2.029988], [lr 0.000457] [batchtime 0.418]
[epoch 167], [iter 82 / 176], [train main loss -2.048142], [lr 0.000457] [batchtime 0.417]
[epoch 167], [iter 83 / 176], [train main loss -2.057940], [lr 0.000457] [batchtime 0.417]
[epoch 167], [iter 84 / 176], [train main loss -2.046764], [lr 0.000457] [batchtime 0.417]
[epoch 167], [iter 85 / 176], [train main loss -2.026856], [lr 0.000457] [batchtime 0.418]
[epoch 167], [iter 86 / 176], [train main loss -2.039061], [lr 0.000457] [batchtime 0.435]
[epoch 167], [iter 87 / 176], [train main loss -2.000032], [lr 0.000457] [batchtime 0.435]
[epoch 167], [iter 88 / 176], [train main loss -2.015575], [lr 0.000457] [batchtime 0.434]
[epoch 167], [iter 89 / 176], [train main loss -2.011290], [lr 0.000457] [batchtime 0.434]
[epoch 167], [iter 90 / 176], [train main loss -1.988474], [lr 0.000457] [batchtime 0.433]
[epoch 167], [iter 91 / 176], [train main loss -1.992492], [lr 0.000457] [batchtime 0.433]
[epoch 167], [iter 92 / 176], [train main loss -1.987378], [lr 0.000457] [batchtime 0.432]
[epoch 167], [iter 93 / 176], [train main loss -2.004841], [lr 0.000457] [batchtime 0.432]
[epoch 167], [iter 94 / 176], [train main loss -2.003765], [lr 0.000457] [batchtime 0.432]
[epoch 167], [iter 95 / 176], [train main loss -2.004364], [lr 0.000457] [batchtime 0.431]
[epoch 167], [iter 96 / 176], [train main loss -1.979590], [lr 0.000457] [batchtime 0.431]
[epoch 167], [iter 97 / 176], [train main loss -1.998028], [lr 0.000457] [batchtime 0.43]
[epoch 167], [iter 98 / 176], [train main loss -1.990609], [lr 0.000457] [batchtime 0.43]
[epoch 167], [iter 99 / 176], [train main loss -1.991742], [lr 0.000457] [batchtime 0.43]
[epoch 167], [iter 100 / 176], [train main loss -1.977108], [lr 0.000457] [batchtime 0.429]
[epoch 167], [iter 101 / 176], [train main loss -1.996760], [lr 0.000457] [batchtime 0.429]
[epoch 167], [iter 102 / 176], [train main loss -1.997679], [lr 0.000457] [batchtime 0.429]
[epoch 167], [iter 103 / 176], [train main loss -2.010060], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 104 / 176], [train main loss -2.007534], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 105 / 176], [train main loss -2.000528], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 106 / 176], [train main loss -2.018111], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 107 / 176], [train main loss -1.998433], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 108 / 176], [train main loss -2.021885], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 109 / 176], [train main loss -2.038068], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 110 / 176], [train main loss -2.058911], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 111 / 176], [train main loss -2.070210], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 112 / 176], [train main loss -2.064777], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 113 / 176], [train main loss -2.083627], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 114 / 176], [train main loss -2.071217], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 115 / 176], [train main loss -2.085958], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 116 / 176], [train main loss -2.083515], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 117 / 176], [train main loss -2.089486], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 118 / 176], [train main loss -2.090126], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 119 / 176], [train main loss -2.096902], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 120 / 176], [train main loss -2.104518], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 121 / 176], [train main loss -2.120665], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 122 / 176], [train main loss -2.099873], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 123 / 176], [train main loss -2.081816], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 124 / 176], [train main loss -2.097383], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 125 / 176], [train main loss -2.096027], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 126 / 176], [train main loss -2.092191], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 127 / 176], [train main loss -2.119846], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 128 / 176], [train main loss -2.101695], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 129 / 176], [train main loss -2.120941], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 130 / 176], [train main loss -2.125009], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 131 / 176], [train main loss -2.121291], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 132 / 176], [train main loss -2.126636], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 133 / 176], [train main loss -2.114804], [lr 0.000457] [batchtime 0.429]
[epoch 167], [iter 134 / 176], [train main loss -2.132679], [lr 0.000457] [batchtime 0.429]
[epoch 167], [iter 135 / 176], [train main loss -2.147460], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 136 / 176], [train main loss -2.136839], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 137 / 176], [train main loss -2.136260], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 138 / 176], [train main loss -2.145532], [lr 0.000457] [batchtime 0.428]
[epoch 167], [iter 139 / 176], [train main loss -2.138014], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 140 / 176], [train main loss -2.158488], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 141 / 176], [train main loss -2.167020], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 142 / 176], [train main loss -2.168559], [lr 0.000457] [batchtime 0.427]
[epoch 167], [iter 143 / 176], [train main loss -2.177293], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 144 / 176], [train main loss -2.169217], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 145 / 176], [train main loss -2.163579], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 146 / 176], [train main loss -2.170995], [lr 0.000457] [batchtime 0.426]
[epoch 167], [iter 147 / 176], [train main loss -2.148519], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 148 / 176], [train main loss -2.153853], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 149 / 176], [train main loss -2.159003], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 150 / 176], [train main loss -2.162506], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 151 / 176], [train main loss -2.168519], [lr 0.000457] [batchtime 0.425]
[epoch 167], [iter 152 / 176], [train main loss -2.192309], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 153 / 176], [train main loss -2.190625], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 154 / 176], [train main loss -2.188005], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 155 / 176], [train main loss -2.188093], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 156 / 176], [train main loss -2.197249], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 157 / 176], [train main loss -2.187065], [lr 0.000457] [batchtime 0.424]
[epoch 167], [iter 158 / 176], [train main loss -2.196638], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 159 / 176], [train main loss -2.187200], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 160 / 176], [train main loss -2.187339], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 161 / 176], [train main loss -2.197586], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 162 / 176], [train main loss -2.204708], [lr 0.000457] [batchtime 0.423]
[epoch 167], [iter 163 / 176], [train main loss -2.224452], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 164 / 176], [train main loss -2.220113], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 165 / 176], [train main loss -2.218923], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 166 / 176], [train main loss -2.219704], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 167 / 176], [train main loss -2.227651], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 168 / 176], [train main loss -2.223891], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 169 / 176], [train main loss -2.228222], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 170 / 176], [train main loss -2.233001], [lr 0.000457] [batchtime 0.422]
[epoch 167], [iter 171 / 176], [train main loss -2.230910], [lr 0.000457] [batchtime 0.421]
[epoch 167], [iter 172 / 176], [train main loss -2.217575], [lr 0.000457] [batchtime 0.421]
[epoch 167], [iter 173 / 176], [train main loss -2.231955], [lr 0.000457] [batchtime 0.421]
[epoch 167], [iter 174 / 176], [train main loss -2.228011], [lr 0.000457] [batchtime 0.42]
[epoch 167], [iter 175 / 176], [train main loss -2.220998], [lr 0.000457] [batchtime 0.42]
[epoch 167], [iter 176 / 176], [train main loss -2.235503], [lr 0.000457] [batchtime 0.42]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.00  35.61   0.02  0.03         0.98      0.97
   1  sidewalk          70.75   5.38   0.22  0.19         0.82      0.84
   2  building          87.06  25.10   0.06  0.09         0.94      0.92
   3  wall              18.87   0.15   2.96  1.34         0.25      0.43
   4  fence             27.09   0.41   2.08  0.61         0.32      0.62
   5  pole              40.75   0.59   0.93  0.53         0.52      0.66
   6  traffic light     19.67   0.03   3.55  0.53         0.22      0.65
   7  traffic sign      28.42   0.17   2.29  0.23         0.30      0.81
   8  vegetation        84.32  11.70   0.06  0.13         0.95      0.89
   9  terrain           39.38   0.35   1.09  0.44         0.48      0.69
  10  sky               93.78   3.75   0.03  0.03         0.97      0.97
  11  person            55.59   1.05   0.46  0.34         0.69      0.75
  12  rider             15.18   0.02   4.68  0.91         0.18      0.52
  13  car               86.91   6.72   0.05  0.10         0.95      0.91
  14  truck              2.12   0.01  45.61  0.54         0.02      0.65
  15  bus               18.12   0.04   0.95  3.57         0.51      0.22
  16  train             39.34   0.09   1.03  0.52         0.49      0.66
  17  motorcycle         5.19   0.01  17.64  0.64         0.05      0.61
  18  bicycle           40.96   0.28   0.41  1.03         0.71      0.49
Mean: 45.71
-----------------------------------------------------------------------------------------------------------
this : [epoch 167], [val loss 0.29117], [acc 0.91463], [acc_cls 0.54499], [mean_iu 0.45712], [fwavacc 0.85073]
best : [epoch 155], [val loss 0.30175], [acc 0.91458], [acc_cls 0.54732], [mean_iu 0.45834], [fwavacc 0.85098]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 168], [iter 1 / 176], [train main loss 0.620169], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 2 / 176], [train main loss -0.826009], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 3 / 176], [train main loss -0.945370], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 4 / 176], [train main loss -0.824248], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 5 / 176], [train main loss -0.886891], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 6 / 176], [train main loss -1.165005], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 7 / 176], [train main loss -1.268105], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 8 / 176], [train main loss -1.349977], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 9 / 176], [train main loss -1.346415], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 10 / 176], [train main loss -1.581782], [lr 0.000400] [batchtime 0]
[epoch 168], [iter 11 / 176], [train main loss -1.561434], [lr 0.000400] [batchtime 0.375]
[epoch 168], [iter 12 / 176], [train main loss -1.467903], [lr 0.000400] [batchtime 0.384]
[epoch 168], [iter 13 / 176], [train main loss -1.413844], [lr 0.000400] [batchtime 0.386]
[epoch 168], [iter 14 / 176], [train main loss -1.518912], [lr 0.000400] [batchtime 0.388]
[epoch 168], [iter 15 / 176], [train main loss -1.580631], [lr 0.000400] [batchtime 0.391]
[epoch 168], [iter 16 / 176], [train main loss -1.657743], [lr 0.000400] [batchtime 0.391]
[epoch 168], [iter 17 / 176], [train main loss -1.516974], [lr 0.000400] [batchtime 0.393]
[epoch 168], [iter 18 / 176], [train main loss -1.545786], [lr 0.000400] [batchtime 0.394]
[epoch 168], [iter 19 / 176], [train main loss -1.567100], [lr 0.000400] [batchtime 0.394]
[epoch 168], [iter 20 / 176], [train main loss -1.438959], [lr 0.000400] [batchtime 0.395]
[epoch 168], [iter 21 / 176], [train main loss -1.496441], [lr 0.000400] [batchtime 0.394]
[epoch 168], [iter 22 / 176], [train main loss -1.501665], [lr 0.000400] [batchtime 0.394]
[epoch 168], [iter 23 / 176], [train main loss -1.593229], [lr 0.000400] [batchtime 0.395]
[epoch 168], [iter 24 / 176], [train main loss -1.599327], [lr 0.000400] [batchtime 0.395]
[epoch 168], [iter 25 / 176], [train main loss -1.593017], [lr 0.000400] [batchtime 0.395]
[epoch 168], [iter 26 / 176], [train main loss -1.635504], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 27 / 176], [train main loss -1.628456], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 28 / 176], [train main loss -1.622678], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 29 / 176], [train main loss -1.589041], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 30 / 176], [train main loss -1.587164], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 31 / 176], [train main loss -1.581213], [lr 0.000400] [batchtime 0.397]
[epoch 168], [iter 32 / 176], [train main loss -1.482081], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 33 / 176], [train main loss -1.480521], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 34 / 176], [train main loss -1.483372], [lr 0.000400] [batchtime 0.397]
[epoch 168], [iter 35 / 176], [train main loss -1.510275], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 36 / 176], [train main loss -1.506225], [lr 0.000400] [batchtime 0.396]
[epoch 168], [iter 37 / 176], [train main loss -1.594649], [lr 0.000400] [batchtime 0.397]
[epoch 168], [iter 38 / 176], [train main loss -1.630636], [lr 0.000400] [batchtime 0.426]
[epoch 168], [iter 39 / 176], [train main loss -1.735154], [lr 0.000400] [batchtime 0.433]
[epoch 168], [iter 40 / 176], [train main loss -1.772797], [lr 0.000400] [batchtime 0.431]
[epoch 168], [iter 41 / 176], [train main loss -1.774538], [lr 0.000400] [batchtime 0.43]
[epoch 168], [iter 42 / 176], [train main loss -1.743084], [lr 0.000400] [batchtime 0.429]
[epoch 168], [iter 43 / 176], [train main loss -1.681426], [lr 0.000400] [batchtime 0.428]
[epoch 168], [iter 44 / 176], [train main loss -1.620573], [lr 0.000400] [batchtime 0.427]
[epoch 168], [iter 45 / 176], [train main loss -1.665263], [lr 0.000400] [batchtime 0.426]
[epoch 168], [iter 46 / 176], [train main loss -1.644857], [lr 0.000400] [batchtime 0.425]
[epoch 168], [iter 47 / 176], [train main loss -1.619548], [lr 0.000400] [batchtime 0.424]
[epoch 168], [iter 48 / 176], [train main loss -1.597700], [lr 0.000400] [batchtime 0.423]
[epoch 168], [iter 49 / 176], [train main loss -1.589160], [lr 0.000400] [batchtime 0.423]
[epoch 168], [iter 50 / 176], [train main loss -1.683814], [lr 0.000400] [batchtime 0.422]
[epoch 168], [iter 51 / 176], [train main loss -1.691519], [lr 0.000400] [batchtime 0.421]
[epoch 168], [iter 52 / 176], [train main loss -1.701586], [lr 0.000400] [batchtime 0.421]
[epoch 168], [iter 53 / 176], [train main loss -1.747865], [lr 0.000400] [batchtime 0.42]
[epoch 168], [iter 54 / 176], [train main loss -1.779186], [lr 0.000400] [batchtime 0.419]
[epoch 168], [iter 55 / 176], [train main loss -1.811833], [lr 0.000400] [batchtime 0.419]
[epoch 168], [iter 56 / 176], [train main loss -1.812473], [lr 0.000400] [batchtime 0.418]
[epoch 168], [iter 57 / 176], [train main loss -1.862583], [lr 0.000400] [batchtime 0.418]
[epoch 168], [iter 58 / 176], [train main loss -1.835644], [lr 0.000400] [batchtime 0.417]
[epoch 168], [iter 59 / 176], [train main loss -1.832434], [lr 0.000400] [batchtime 0.417]
[epoch 168], [iter 60 / 176], [train main loss -1.868643], [lr 0.000400] [batchtime 0.416]
[epoch 168], [iter 61 / 176], [train main loss -1.936882], [lr 0.000400] [batchtime 0.416]
[epoch 168], [iter 62 / 176], [train main loss -1.883432], [lr 0.000400] [batchtime 0.415]
[epoch 168], [iter 63 / 176], [train main loss -1.924549], [lr 0.000400] [batchtime 0.415]
[epoch 168], [iter 64 / 176], [train main loss -1.977819], [lr 0.000400] [batchtime 0.415]
[epoch 168], [iter 65 / 176], [train main loss -2.018552], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 66 / 176], [train main loss -1.982659], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 67 / 176], [train main loss -2.007612], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 68 / 176], [train main loss -2.021202], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 69 / 176], [train main loss -2.051301], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 70 / 176], [train main loss -2.081534], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 71 / 176], [train main loss -2.090379], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 72 / 176], [train main loss -2.071274], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 73 / 176], [train main loss -2.055551], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 74 / 176], [train main loss -2.058329], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 75 / 176], [train main loss -2.088155], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 76 / 176], [train main loss -2.101124], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 77 / 176], [train main loss -2.034432], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 78 / 176], [train main loss -2.018168], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 79 / 176], [train main loss -2.023334], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 80 / 176], [train main loss -2.047757], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 81 / 176], [train main loss -2.066035], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 82 / 176], [train main loss -2.080562], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 83 / 176], [train main loss -2.063132], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 84 / 176], [train main loss -2.037473], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 85 / 176], [train main loss -2.036247], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 86 / 176], [train main loss -2.003271], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 87 / 176], [train main loss -2.032076], [lr 0.000400] [batchtime 0.415]
[epoch 168], [iter 88 / 176], [train main loss -2.084433], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 89 / 176], [train main loss -2.075776], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 90 / 176], [train main loss -2.068820], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 91 / 176], [train main loss -2.057556], [lr 0.000400] [batchtime 0.414]
[epoch 168], [iter 92 / 176], [train main loss -2.073452], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 93 / 176], [train main loss -2.067803], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 94 / 176], [train main loss -2.072510], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 95 / 176], [train main loss -2.067306], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 96 / 176], [train main loss -2.061570], [lr 0.000400] [batchtime 0.413]
[epoch 168], [iter 97 / 176], [train main loss -2.101335], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 98 / 176], [train main loss -2.109695], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 99 / 176], [train main loss -2.110625], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 100 / 176], [train main loss -2.116130], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 101 / 176], [train main loss -2.122871], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 102 / 176], [train main loss -2.106409], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 103 / 176], [train main loss -2.097012], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 104 / 176], [train main loss -2.110664], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 105 / 176], [train main loss -2.096062], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 106 / 176], [train main loss -2.100106], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 107 / 176], [train main loss -2.076827], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 108 / 176], [train main loss -2.062633], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 109 / 176], [train main loss -2.047548], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 110 / 176], [train main loss -2.047015], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 111 / 176], [train main loss -2.043432], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 112 / 176], [train main loss -2.035685], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 113 / 176], [train main loss -2.028749], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 114 / 176], [train main loss -2.027877], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 115 / 176], [train main loss -2.033799], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 116 / 176], [train main loss -2.030027], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 117 / 176], [train main loss -2.037892], [lr 0.000400] [batchtime 0.409]
[epoch 168], [iter 118 / 176], [train main loss -2.024302], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 119 / 176], [train main loss -2.022865], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 120 / 176], [train main loss -2.025827], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 121 / 176], [train main loss -2.023791], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 122 / 176], [train main loss -2.034060], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 123 / 176], [train main loss -2.033791], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 124 / 176], [train main loss -2.040148], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 125 / 176], [train main loss -2.013863], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 126 / 176], [train main loss -2.036114], [lr 0.000400] [batchtime 0.408]
[epoch 168], [iter 127 / 176], [train main loss -2.025802], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 128 / 176], [train main loss -2.055282], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 129 / 176], [train main loss -2.042164], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 130 / 176], [train main loss -2.049211], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 131 / 176], [train main loss -2.048402], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 132 / 176], [train main loss -2.058451], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 133 / 176], [train main loss -2.054663], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 134 / 176], [train main loss -2.066085], [lr 0.000400] [batchtime 0.407]
[epoch 168], [iter 135 / 176], [train main loss -2.070854], [lr 0.000400] [batchtime 0.406]
[epoch 168], [iter 136 / 176], [train main loss -2.052896], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 137 / 176], [train main loss -2.058160], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 138 / 176], [train main loss -2.074278], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 139 / 176], [train main loss -2.099763], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 140 / 176], [train main loss -2.104555], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 141 / 176], [train main loss -2.101380], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 142 / 176], [train main loss -2.117295], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 143 / 176], [train main loss -2.113105], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 144 / 176], [train main loss -2.104598], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 145 / 176], [train main loss -2.110797], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 146 / 176], [train main loss -2.110134], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 147 / 176], [train main loss -2.090199], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 148 / 176], [train main loss -2.102720], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 149 / 176], [train main loss -2.101435], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 150 / 176], [train main loss -2.101862], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 151 / 176], [train main loss -2.115546], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 152 / 176], [train main loss -2.136826], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 153 / 176], [train main loss -2.123853], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 154 / 176], [train main loss -2.126826], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 155 / 176], [train main loss -2.131267], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 156 / 176], [train main loss -2.137926], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 157 / 176], [train main loss -2.149272], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 158 / 176], [train main loss -2.155415], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 159 / 176], [train main loss -2.148024], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 160 / 176], [train main loss -2.160996], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 161 / 176], [train main loss -2.157339], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 162 / 176], [train main loss -2.150818], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 163 / 176], [train main loss -2.151861], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 164 / 176], [train main loss -2.151863], [lr 0.000400] [batchtime 0.412]
[epoch 168], [iter 165 / 176], [train main loss -2.158051], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 166 / 176], [train main loss -2.156900], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 167 / 176], [train main loss -2.161440], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 168 / 176], [train main loss -2.148593], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 169 / 176], [train main loss -2.141197], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 170 / 176], [train main loss -2.156329], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 171 / 176], [train main loss -2.148379], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 172 / 176], [train main loss -2.147432], [lr 0.000400] [batchtime 0.411]
[epoch 168], [iter 173 / 176], [train main loss -2.130827], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 174 / 176], [train main loss -2.119523], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 175 / 176], [train main loss -2.115519], [lr 0.000400] [batchtime 0.41]
[epoch 168], [iter 176 / 176], [train main loss -2.113446], [lr 0.000400] [batchtime 0.41]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.10  35.58   0.02  0.03         0.98      0.97
   1  sidewalk          71.32   5.43   0.21  0.19         0.82      0.84
   2  building          87.09  25.17   0.06  0.09         0.95      0.92
   3  wall              19.26   0.16   2.81  1.38         0.26      0.42
   4  fence             25.79   0.38   2.32  0.56         0.30      0.64
   5  pole              40.71   0.59   0.93  0.52         0.52      0.66
   6  traffic light     19.74   0.03   3.67  0.39         0.21      0.72
   7  traffic sign      29.17   0.18   2.20  0.23         0.31      0.81
   8  vegetation        84.54  11.68   0.06  0.12         0.94      0.89
   9  terrain           41.29   0.37   0.97  0.45         0.51      0.69
  10  sky               93.95   3.75   0.03  0.03         0.97      0.97
  11  person            56.18   1.07   0.44  0.34         0.70      0.74
  12  rider             15.69   0.02   4.39  0.98         0.19      0.50
  13  car               87.09   6.71   0.05  0.09         0.95      0.91
  14  truck              2.08   0.01  46.52  0.55         0.02      0.64
  15  bus               17.22   0.04   1.11  3.70         0.47      0.21
  16  train             44.49   0.10   0.72  0.53         0.58      0.66
  17  motorcycle         5.64   0.01  16.11  0.62         0.06      0.62
  18  bicycle           41.40   0.28   0.39  1.02         0.72      0.49
Mean: 46.20
-----------------------------------------------------------------------------------------------------------
this : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 169], [iter 1 / 176], [train main loss 0.160290], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 2 / 176], [train main loss -0.713832], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 3 / 176], [train main loss -1.420912], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 4 / 176], [train main loss -0.833903], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 5 / 176], [train main loss -0.934117], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 6 / 176], [train main loss -1.226208], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 7 / 176], [train main loss -1.554611], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 8 / 176], [train main loss -1.645623], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 9 / 176], [train main loss -2.014632], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 10 / 176], [train main loss -1.996877], [lr 0.000343] [batchtime 0]
[epoch 169], [iter 11 / 176], [train main loss -2.084497], [lr 0.000343] [batchtime 0.365]
[epoch 169], [iter 12 / 176], [train main loss -1.867646], [lr 0.000343] [batchtime 0.381]
[epoch 169], [iter 13 / 176], [train main loss -2.058318], [lr 0.000343] [batchtime 0.385]
[epoch 169], [iter 14 / 176], [train main loss -1.883817], [lr 0.000343] [batchtime 0.388]
[epoch 169], [iter 15 / 176], [train main loss -1.850255], [lr 0.000343] [batchtime 0.39]
[epoch 169], [iter 16 / 176], [train main loss -1.663966], [lr 0.000343] [batchtime 0.394]
[epoch 169], [iter 17 / 176], [train main loss -1.654830], [lr 0.000343] [batchtime 0.396]
[epoch 169], [iter 18 / 176], [train main loss -1.528840], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 19 / 176], [train main loss -1.517370], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 20 / 176], [train main loss -1.398880], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 21 / 176], [train main loss -1.451099], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 22 / 176], [train main loss -1.502626], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 23 / 176], [train main loss -1.590992], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 24 / 176], [train main loss -1.588800], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 25 / 176], [train main loss -1.737612], [lr 0.000343] [batchtime 0.399]
[epoch 169], [iter 26 / 176], [train main loss -1.923588], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 27 / 176], [train main loss -1.970526], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 28 / 176], [train main loss -2.071435], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 29 / 176], [train main loss -2.045134], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 30 / 176], [train main loss -2.065016], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 31 / 176], [train main loss -2.002704], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 32 / 176], [train main loss -1.920843], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 33 / 176], [train main loss -1.969487], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 34 / 176], [train main loss -2.021267], [lr 0.000343] [batchtime 0.4]
[epoch 169], [iter 35 / 176], [train main loss -2.010174], [lr 0.000343] [batchtime 0.402]
[epoch 169], [iter 36 / 176], [train main loss -2.054550], [lr 0.000343] [batchtime 0.409]
[epoch 169], [iter 37 / 176], [train main loss -1.998001], [lr 0.000343] [batchtime 0.439]
[epoch 169], [iter 38 / 176], [train main loss -2.070520], [lr 0.000343] [batchtime 0.438]
[epoch 169], [iter 39 / 176], [train main loss -2.073940], [lr 0.000343] [batchtime 0.436]
[epoch 169], [iter 40 / 176], [train main loss -2.038222], [lr 0.000343] [batchtime 0.434]
[epoch 169], [iter 41 / 176], [train main loss -1.996448], [lr 0.000343] [batchtime 0.434]
[epoch 169], [iter 42 / 176], [train main loss -2.001792], [lr 0.000343] [batchtime 0.432]
[epoch 169], [iter 43 / 176], [train main loss -1.963617], [lr 0.000343] [batchtime 0.431]
[epoch 169], [iter 44 / 176], [train main loss -2.024068], [lr 0.000343] [batchtime 0.43]
[epoch 169], [iter 45 / 176], [train main loss -2.047409], [lr 0.000343] [batchtime 0.429]
[epoch 169], [iter 46 / 176], [train main loss -2.007845], [lr 0.000343] [batchtime 0.429]
[epoch 169], [iter 47 / 176], [train main loss -1.961443], [lr 0.000343] [batchtime 0.428]
[epoch 169], [iter 48 / 176], [train main loss -1.984221], [lr 0.000343] [batchtime 0.427]
[epoch 169], [iter 49 / 176], [train main loss -2.011507], [lr 0.000343] [batchtime 0.426]
[epoch 169], [iter 50 / 176], [train main loss -2.035169], [lr 0.000343] [batchtime 0.425]
[epoch 169], [iter 51 / 176], [train main loss -1.979131], [lr 0.000343] [batchtime 0.425]
[epoch 169], [iter 52 / 176], [train main loss -1.921884], [lr 0.000343] [batchtime 0.424]
[epoch 169], [iter 53 / 176], [train main loss -1.955337], [lr 0.000343] [batchtime 0.424]
[epoch 169], [iter 54 / 176], [train main loss -1.950247], [lr 0.000343] [batchtime 0.423]
[epoch 169], [iter 55 / 176], [train main loss -1.946947], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 56 / 176], [train main loss -1.949857], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 57 / 176], [train main loss -1.958453], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 58 / 176], [train main loss -1.940384], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 59 / 176], [train main loss -1.922941], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 60 / 176], [train main loss -1.973352], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 61 / 176], [train main loss -1.957971], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 62 / 176], [train main loss -1.991518], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 63 / 176], [train main loss -2.030357], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 64 / 176], [train main loss -2.019203], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 65 / 176], [train main loss -1.990011], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 66 / 176], [train main loss -1.992471], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 67 / 176], [train main loss -2.024991], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 68 / 176], [train main loss -1.995534], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 69 / 176], [train main loss -2.003458], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 70 / 176], [train main loss -2.004538], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 71 / 176], [train main loss -1.998938], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 72 / 176], [train main loss -1.996875], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 73 / 176], [train main loss -1.998464], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 74 / 176], [train main loss -1.957547], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 75 / 176], [train main loss -1.963362], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 76 / 176], [train main loss -1.959276], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 77 / 176], [train main loss -2.006840], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 78 / 176], [train main loss -2.005054], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 79 / 176], [train main loss -2.071513], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 80 / 176], [train main loss -2.080901], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 81 / 176], [train main loss -2.093251], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 82 / 176], [train main loss -2.092462], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 83 / 176], [train main loss -2.078246], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 84 / 176], [train main loss -2.080069], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 85 / 176], [train main loss -2.082534], [lr 0.000343] [batchtime 0.423]
[epoch 169], [iter 86 / 176], [train main loss -2.053169], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 87 / 176], [train main loss -2.049466], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 88 / 176], [train main loss -2.047153], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 89 / 176], [train main loss -2.072141], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 90 / 176], [train main loss -2.047639], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 91 / 176], [train main loss -2.054430], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 92 / 176], [train main loss -2.047069], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 93 / 176], [train main loss -2.065154], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 94 / 176], [train main loss -2.059325], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 95 / 176], [train main loss -2.073455], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 96 / 176], [train main loss -2.101454], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 97 / 176], [train main loss -2.094425], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 98 / 176], [train main loss -2.086109], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 99 / 176], [train main loss -2.095730], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 100 / 176], [train main loss -2.083648], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 101 / 176], [train main loss -2.072441], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 102 / 176], [train main loss -2.069783], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 103 / 176], [train main loss -2.063899], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 104 / 176], [train main loss -2.063614], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 105 / 176], [train main loss -2.056234], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 106 / 176], [train main loss -2.064912], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 107 / 176], [train main loss -2.051705], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 108 / 176], [train main loss -2.042195], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 109 / 176], [train main loss -2.021930], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 110 / 176], [train main loss -2.017029], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 111 / 176], [train main loss -2.004631], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 112 / 176], [train main loss -2.031125], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 113 / 176], [train main loss -2.015686], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 114 / 176], [train main loss -1.997027], [lr 0.000343] [batchtime 0.415]
[epoch 169], [iter 115 / 176], [train main loss -2.016024], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 116 / 176], [train main loss -2.002753], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 117 / 176], [train main loss -1.988458], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 118 / 176], [train main loss -1.989006], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 119 / 176], [train main loss -1.985895], [lr 0.000343] [batchtime 0.414]
[epoch 169], [iter 120 / 176], [train main loss -1.991715], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 121 / 176], [train main loss -2.013220], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 122 / 176], [train main loss -1.996370], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 123 / 176], [train main loss -1.993194], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 124 / 176], [train main loss -2.006883], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 125 / 176], [train main loss -1.999848], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 126 / 176], [train main loss -1.986676], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 127 / 176], [train main loss -1.997985], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 128 / 176], [train main loss -2.003242], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 129 / 176], [train main loss -2.009328], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 130 / 176], [train main loss -2.006060], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 131 / 176], [train main loss -2.022679], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 132 / 176], [train main loss -2.024355], [lr 0.000343] [batchtime 0.412]
[epoch 169], [iter 133 / 176], [train main loss -2.022839], [lr 0.000343] [batchtime 0.413]
[epoch 169], [iter 134 / 176], [train main loss -2.031437], [lr 0.000343] [batchtime 0.423]
[epoch 169], [iter 135 / 176], [train main loss -2.018208], [lr 0.000343] [batchtime 0.423]
[epoch 169], [iter 136 / 176], [train main loss -2.024127], [lr 0.000343] [batchtime 0.423]
[epoch 169], [iter 137 / 176], [train main loss -2.022712], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 138 / 176], [train main loss -2.017239], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 139 / 176], [train main loss -2.006860], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 140 / 176], [train main loss -2.029222], [lr 0.000343] [batchtime 0.422]
[epoch 169], [iter 141 / 176], [train main loss -2.049709], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 142 / 176], [train main loss -2.064672], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 143 / 176], [train main loss -2.074995], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 144 / 176], [train main loss -2.087310], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 145 / 176], [train main loss -2.086456], [lr 0.000343] [batchtime 0.421]
[epoch 169], [iter 146 / 176], [train main loss -2.091130], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 147 / 176], [train main loss -2.098313], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 148 / 176], [train main loss -2.116684], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 149 / 176], [train main loss -2.121236], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 150 / 176], [train main loss -2.133095], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 151 / 176], [train main loss -2.149149], [lr 0.000343] [batchtime 0.42]
[epoch 169], [iter 152 / 176], [train main loss -2.151655], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 153 / 176], [train main loss -2.148455], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 154 / 176], [train main loss -2.150374], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 155 / 176], [train main loss -2.140935], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 156 / 176], [train main loss -2.140986], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 157 / 176], [train main loss -2.138916], [lr 0.000343] [batchtime 0.419]
[epoch 169], [iter 158 / 176], [train main loss -2.125045], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 159 / 176], [train main loss -2.124028], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 160 / 176], [train main loss -2.137824], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 161 / 176], [train main loss -2.136949], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 162 / 176], [train main loss -2.142323], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 163 / 176], [train main loss -2.140671], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 164 / 176], [train main loss -2.151426], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 165 / 176], [train main loss -2.155273], [lr 0.000343] [batchtime 0.418]
[epoch 169], [iter 166 / 176], [train main loss -2.171853], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 167 / 176], [train main loss -2.167051], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 168 / 176], [train main loss -2.179116], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 169 / 176], [train main loss -2.172296], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 170 / 176], [train main loss -2.170427], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 171 / 176], [train main loss -2.157203], [lr 0.000343] [batchtime 0.417]
[epoch 169], [iter 172 / 176], [train main loss -2.159258], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 173 / 176], [train main loss -2.169090], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 174 / 176], [train main loss -2.183313], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 175 / 176], [train main loss -2.193196], [lr 0.000343] [batchtime 0.416]
[epoch 169], [iter 176 / 176], [train main loss -2.184316], [lr 0.000343] [batchtime 0.415]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.15  35.55   0.02  0.03         0.98      0.97
   1  sidewalk          71.68   5.49   0.20  0.20         0.83      0.84
   2  building          87.11  25.02   0.06  0.09         0.94      0.92
   3  wall              19.81   0.16   2.64  1.41         0.27      0.41
   4  fence             27.33   0.42   2.03  0.63         0.33      0.61
   5  pole              41.13   0.60   0.90  0.53         0.53      0.65
   6  traffic light     21.15   0.04   3.21  0.52         0.24      0.66
   7  traffic sign      30.07   0.18   2.08  0.24         0.32      0.80
   8  vegetation        84.48  11.70   0.06  0.13         0.95      0.89
   9  terrain           42.05   0.38   0.92  0.46         0.52      0.68
  10  sky               93.90   3.77   0.03  0.04         0.97      0.96
  11  person            56.03   1.06   0.45  0.34         0.69      0.75
  12  rider             15.27   0.02   4.54  1.00         0.18      0.50
  13  car               86.71   6.73   0.05  0.10         0.95      0.91
  14  truck              1.94   0.01  50.15  0.40         0.02      0.71
  15  bus               17.23   0.05   0.91  3.89         0.52      0.20
  16  train             35.36   0.08   1.26  0.57         0.44      0.64
  17  motorcycle         5.99   0.01  15.04  0.66         0.06      0.60
  18  bicycle           39.83   0.28   0.38  1.13         0.73      0.47
Mean: 45.91
-----------------------------------------------------------------------------------------------------------
this : [epoch 169], [val loss 0.28618], [acc 0.91519], [acc_cls 0.55152], [mean_iu 0.45905], [fwavacc 0.85250]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 170], [iter 1 / 176], [train main loss 0.799962], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 2 / 176], [train main loss -0.629997], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 3 / 176], [train main loss -0.826303], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 4 / 176], [train main loss -1.039529], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 5 / 176], [train main loss -0.934891], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 6 / 176], [train main loss -0.999293], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 7 / 176], [train main loss -1.460702], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 8 / 176], [train main loss -1.372781], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 9 / 176], [train main loss -1.597481], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 10 / 176], [train main loss -1.527904], [lr 0.000286] [batchtime 0]
[epoch 170], [iter 11 / 176], [train main loss -1.531362], [lr 0.000286] [batchtime 0.366]
[epoch 170], [iter 12 / 176], [train main loss -1.653409], [lr 0.000286] [batchtime 0.383]
[epoch 170], [iter 13 / 176], [train main loss -1.740862], [lr 0.000286] [batchtime 0.391]
[epoch 170], [iter 14 / 176], [train main loss -1.822827], [lr 0.000286] [batchtime 0.39]
[epoch 170], [iter 15 / 176], [train main loss -1.984933], [lr 0.000286] [batchtime 0.392]
[epoch 170], [iter 16 / 176], [train main loss -1.904908], [lr 0.000286] [batchtime 0.394]
[epoch 170], [iter 17 / 176], [train main loss -2.001809], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 18 / 176], [train main loss -2.016961], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 19 / 176], [train main loss -2.043526], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 20 / 176], [train main loss -2.214656], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 21 / 176], [train main loss -2.233609], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 22 / 176], [train main loss -2.320834], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 23 / 176], [train main loss -2.263671], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 24 / 176], [train main loss -2.200968], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 25 / 176], [train main loss -2.231881], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 26 / 176], [train main loss -2.174320], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 27 / 176], [train main loss -2.151928], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 28 / 176], [train main loss -2.161944], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 29 / 176], [train main loss -2.137755], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 30 / 176], [train main loss -2.225978], [lr 0.000286] [batchtime 0.395]
[epoch 170], [iter 31 / 176], [train main loss -2.203653], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 32 / 176], [train main loss -2.188553], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 33 / 176], [train main loss -2.237972], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 34 / 176], [train main loss -2.208502], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 35 / 176], [train main loss -2.184431], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 36 / 176], [train main loss -2.190597], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 37 / 176], [train main loss -2.139809], [lr 0.000286] [batchtime 0.397]
[epoch 170], [iter 38 / 176], [train main loss -2.141367], [lr 0.000286] [batchtime 0.396]
[epoch 170], [iter 39 / 176], [train main loss -2.219088], [lr 0.000286] [batchtime 0.445]
[epoch 170], [iter 40 / 176], [train main loss -2.237967], [lr 0.000286] [batchtime 0.449]
[epoch 170], [iter 41 / 176], [train main loss -2.230659], [lr 0.000286] [batchtime 0.447]
[epoch 170], [iter 42 / 176], [train main loss -2.251138], [lr 0.000286] [batchtime 0.445]
[epoch 170], [iter 43 / 176], [train main loss -2.263993], [lr 0.000286] [batchtime 0.444]
[epoch 170], [iter 44 / 176], [train main loss -2.268262], [lr 0.000286] [batchtime 0.442]
[epoch 170], [iter 45 / 176], [train main loss -2.270497], [lr 0.000286] [batchtime 0.441]
[epoch 170], [iter 46 / 176], [train main loss -2.253758], [lr 0.000286] [batchtime 0.44]
[epoch 170], [iter 47 / 176], [train main loss -2.190002], [lr 0.000286] [batchtime 0.439]
[epoch 170], [iter 48 / 176], [train main loss -2.192086], [lr 0.000286] [batchtime 0.438]
[epoch 170], [iter 49 / 176], [train main loss -2.152620], [lr 0.000286] [batchtime 0.437]
[epoch 170], [iter 50 / 176], [train main loss -2.123403], [lr 0.000286] [batchtime 0.436]
[epoch 170], [iter 51 / 176], [train main loss -2.210666], [lr 0.000286] [batchtime 0.435]
[epoch 170], [iter 52 / 176], [train main loss -2.208352], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 53 / 176], [train main loss -2.198701], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 54 / 176], [train main loss -2.235565], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 55 / 176], [train main loss -2.259271], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 56 / 176], [train main loss -2.269846], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 57 / 176], [train main loss -2.270186], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 58 / 176], [train main loss -2.253516], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 59 / 176], [train main loss -2.234257], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 60 / 176], [train main loss -2.217623], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 61 / 176], [train main loss -2.179776], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 62 / 176], [train main loss -2.215631], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 63 / 176], [train main loss -2.173372], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 64 / 176], [train main loss -2.182268], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 65 / 176], [train main loss -2.191922], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 66 / 176], [train main loss -2.238261], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 67 / 176], [train main loss -2.238247], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 68 / 176], [train main loss -2.284840], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 69 / 176], [train main loss -2.270198], [lr 0.000286] [batchtime 0.423]
[epoch 170], [iter 70 / 176], [train main loss -2.272649], [lr 0.000286] [batchtime 0.423]
[epoch 170], [iter 71 / 176], [train main loss -2.259845], [lr 0.000286] [batchtime 0.422]
[epoch 170], [iter 72 / 176], [train main loss -2.262094], [lr 0.000286] [batchtime 0.422]
[epoch 170], [iter 73 / 176], [train main loss -2.280410], [lr 0.000286] [batchtime 0.422]
[epoch 170], [iter 74 / 176], [train main loss -2.265812], [lr 0.000286] [batchtime 0.421]
[epoch 170], [iter 75 / 176], [train main loss -2.245834], [lr 0.000286] [batchtime 0.421]
[epoch 170], [iter 76 / 176], [train main loss -2.222731], [lr 0.000286] [batchtime 0.421]
[epoch 170], [iter 77 / 176], [train main loss -2.192058], [lr 0.000286] [batchtime 0.42]
[epoch 170], [iter 78 / 176], [train main loss -2.231262], [lr 0.000286] [batchtime 0.42]
[epoch 170], [iter 79 / 176], [train main loss -2.215786], [lr 0.000286] [batchtime 0.42]
[epoch 170], [iter 80 / 176], [train main loss -2.214067], [lr 0.000286] [batchtime 0.419]
[epoch 170], [iter 81 / 176], [train main loss -2.229365], [lr 0.000286] [batchtime 0.419]
[epoch 170], [iter 82 / 176], [train main loss -2.227778], [lr 0.000286] [batchtime 0.419]
[epoch 170], [iter 83 / 176], [train main loss -2.215076], [lr 0.000286] [batchtime 0.418]
[epoch 170], [iter 84 / 176], [train main loss -2.191517], [lr 0.000286] [batchtime 0.418]
[epoch 170], [iter 85 / 176], [train main loss -2.165438], [lr 0.000286] [batchtime 0.42]
[epoch 170], [iter 86 / 176], [train main loss -2.190139], [lr 0.000286] [batchtime 0.437]
[epoch 170], [iter 87 / 176], [train main loss -2.183046], [lr 0.000286] [batchtime 0.437]
[epoch 170], [iter 88 / 176], [train main loss -2.192603], [lr 0.000286] [batchtime 0.436]
[epoch 170], [iter 89 / 176], [train main loss -2.207649], [lr 0.000286] [batchtime 0.435]
[epoch 170], [iter 90 / 176], [train main loss -2.204836], [lr 0.000286] [batchtime 0.435]
[epoch 170], [iter 91 / 176], [train main loss -2.212376], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 92 / 176], [train main loss -2.216383], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 93 / 176], [train main loss -2.244192], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 94 / 176], [train main loss -2.250784], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 95 / 176], [train main loss -2.230358], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 96 / 176], [train main loss -2.232233], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 97 / 176], [train main loss -2.235288], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 98 / 176], [train main loss -2.218429], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 99 / 176], [train main loss -2.207191], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 100 / 176], [train main loss -2.208683], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 101 / 176], [train main loss -2.221416], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 102 / 176], [train main loss -2.243481], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 103 / 176], [train main loss -2.215138], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 104 / 176], [train main loss -2.209073], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 105 / 176], [train main loss -2.243189], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 106 / 176], [train main loss -2.259295], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 107 / 176], [train main loss -2.251933], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 108 / 176], [train main loss -2.268639], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 109 / 176], [train main loss -2.263069], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 110 / 176], [train main loss -2.255659], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 111 / 176], [train main loss -2.256685], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 112 / 176], [train main loss -2.249271], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 113 / 176], [train main loss -2.252912], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 114 / 176], [train main loss -2.241671], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 115 / 176], [train main loss -2.266133], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 116 / 176], [train main loss -2.286294], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 117 / 176], [train main loss -2.305678], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 118 / 176], [train main loss -2.296450], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 119 / 176], [train main loss -2.306414], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 120 / 176], [train main loss -2.294374], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 121 / 176], [train main loss -2.293427], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 122 / 176], [train main loss -2.300505], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 123 / 176], [train main loss -2.285850], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 124 / 176], [train main loss -2.284025], [lr 0.000286] [batchtime 0.423]
[epoch 170], [iter 125 / 176], [train main loss -2.301957], [lr 0.000286] [batchtime 0.423]
[epoch 170], [iter 126 / 176], [train main loss -2.308839], [lr 0.000286] [batchtime 0.423]
[epoch 170], [iter 127 / 176], [train main loss -2.297173], [lr 0.000286] [batchtime 0.423]
[epoch 170], [iter 128 / 176], [train main loss -2.310738], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 129 / 176], [train main loss -2.299054], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 130 / 176], [train main loss -2.323550], [lr 0.000286] [batchtime 0.424]
[epoch 170], [iter 131 / 176], [train main loss -2.315028], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 132 / 176], [train main loss -2.317377], [lr 0.000286] [batchtime 0.437]
[epoch 170], [iter 133 / 176], [train main loss -2.314286], [lr 0.000286] [batchtime 0.437]
[epoch 170], [iter 134 / 176], [train main loss -2.327796], [lr 0.000286] [batchtime 0.436]
[epoch 170], [iter 135 / 176], [train main loss -2.330780], [lr 0.000286] [batchtime 0.436]
[epoch 170], [iter 136 / 176], [train main loss -2.346710], [lr 0.000286] [batchtime 0.435]
[epoch 170], [iter 137 / 176], [train main loss -2.350314], [lr 0.000286] [batchtime 0.435]
[epoch 170], [iter 138 / 176], [train main loss -2.357750], [lr 0.000286] [batchtime 0.435]
[epoch 170], [iter 139 / 176], [train main loss -2.355160], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 140 / 176], [train main loss -2.329922], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 141 / 176], [train main loss -2.324017], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 142 / 176], [train main loss -2.317304], [lr 0.000286] [batchtime 0.434]
[epoch 170], [iter 143 / 176], [train main loss -2.322918], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 144 / 176], [train main loss -2.319348], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 145 / 176], [train main loss -2.332876], [lr 0.000286] [batchtime 0.433]
[epoch 170], [iter 146 / 176], [train main loss -2.327040], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 147 / 176], [train main loss -2.326763], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 148 / 176], [train main loss -2.332647], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 149 / 176], [train main loss -2.340006], [lr 0.000286] [batchtime 0.432]
[epoch 170], [iter 150 / 176], [train main loss -2.326252], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 151 / 176], [train main loss -2.339126], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 152 / 176], [train main loss -2.368968], [lr 0.000286] [batchtime 0.431]
[epoch 170], [iter 153 / 176], [train main loss -2.373995], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 154 / 176], [train main loss -2.372286], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 155 / 176], [train main loss -2.357922], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 156 / 176], [train main loss -2.365309], [lr 0.000286] [batchtime 0.43]
[epoch 170], [iter 157 / 176], [train main loss -2.367204], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 158 / 176], [train main loss -2.369096], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 159 / 176], [train main loss -2.370340], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 160 / 176], [train main loss -2.363055], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 161 / 176], [train main loss -2.360198], [lr 0.000286] [batchtime 0.429]
[epoch 170], [iter 162 / 176], [train main loss -2.355171], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 163 / 176], [train main loss -2.360819], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 164 / 176], [train main loss -2.364485], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 165 / 176], [train main loss -2.365143], [lr 0.000286] [batchtime 0.428]
[epoch 170], [iter 166 / 176], [train main loss -2.352717], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 167 / 176], [train main loss -2.352141], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 168 / 176], [train main loss -2.359427], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 169 / 176], [train main loss -2.351149], [lr 0.000286] [batchtime 0.427]
[epoch 170], [iter 170 / 176], [train main loss -2.353237], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 171 / 176], [train main loss -2.357518], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 172 / 176], [train main loss -2.363684], [lr 0.000286] [batchtime 0.426]
[epoch 170], [iter 173 / 176], [train main loss -2.354546], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 174 / 176], [train main loss -2.367017], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 175 / 176], [train main loss -2.371054], [lr 0.000286] [batchtime 0.425]
[epoch 170], [iter 176 / 176], [train main loss -2.369954], [lr 0.000286] [batchtime 0.425]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.04  35.58   0.02  0.03         0.98      0.97
   1  sidewalk          71.24   5.42   0.22  0.19         0.82      0.84
   2  building          87.17  25.01   0.06  0.08         0.94      0.92
   3  wall              19.81   0.16   2.75  1.30         0.27      0.43
   4  fence             27.08   0.41   2.07  0.63         0.33      0.62
   5  pole              41.07   0.60   0.90  0.54         0.53      0.65
   6  traffic light     19.33   0.03   3.73  0.44         0.21      0.69
   7  traffic sign      30.55   0.19   2.01  0.26         0.33      0.79
   8  vegetation        84.32  11.70   0.06  0.13         0.95      0.89
   9  terrain           41.47   0.39   0.90  0.52         0.53      0.66
  10  sky               93.96   3.75   0.03  0.03         0.97      0.97
  11  person            56.66   1.09   0.41  0.35         0.71      0.74
  12  rider             15.53   0.02   4.44  1.00         0.18      0.50
  13  car               87.01   6.73   0.05  0.10         0.95      0.91
  14  truck              1.87   0.01  52.03  0.53         0.02      0.65
  15  bus               16.87   0.05   0.85  4.07         0.54      0.20
  16  train             35.65   0.08   1.15  0.65         0.46      0.61
  17  motorcycle         6.02   0.01  14.95  0.65         0.06      0.61
  18  bicycle           41.02   0.28   0.40  1.04         0.72      0.49
Mean: 45.88
-----------------------------------------------------------------------------------------------------------
this : [epoch 170], [val loss 0.28187], [acc 0.91501], [acc_cls 0.55231], [mean_iu 0.45878], [fwavacc 0.85207]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 171], [iter 1 / 176], [train main loss -2.745666], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 2 / 176], [train main loss -2.358559], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 3 / 176], [train main loss -1.957820], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 4 / 176], [train main loss -1.367311], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 5 / 176], [train main loss -1.640680], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 6 / 176], [train main loss -1.880009], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 7 / 176], [train main loss -2.012949], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 8 / 176], [train main loss -1.768239], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 9 / 176], [train main loss -1.611227], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 10 / 176], [train main loss -1.743670], [lr 0.000229] [batchtime 0]
[epoch 171], [iter 11 / 176], [train main loss -1.694970], [lr 0.000229] [batchtime 0.392]
[epoch 171], [iter 12 / 176], [train main loss -1.547633], [lr 0.000229] [batchtime 0.395]
[epoch 171], [iter 13 / 176], [train main loss -1.771640], [lr 0.000229] [batchtime 0.393]
[epoch 171], [iter 14 / 176], [train main loss -1.966994], [lr 0.000229] [batchtime 0.394]
[epoch 171], [iter 15 / 176], [train main loss -2.148576], [lr 0.000229] [batchtime 0.398]
[epoch 171], [iter 16 / 176], [train main loss -1.969124], [lr 0.000229] [batchtime 0.398]
[epoch 171], [iter 17 / 176], [train main loss -1.913082], [lr 0.000229] [batchtime 0.398]
[epoch 171], [iter 18 / 176], [train main loss -1.918425], [lr 0.000229] [batchtime 0.398]
[epoch 171], [iter 19 / 176], [train main loss -1.870925], [lr 0.000229] [batchtime 0.396]
[epoch 171], [iter 20 / 176], [train main loss -2.021840], [lr 0.000229] [batchtime 0.396]
[epoch 171], [iter 21 / 176], [train main loss -2.095692], [lr 0.000229] [batchtime 0.397]
[epoch 171], [iter 22 / 176], [train main loss -2.043181], [lr 0.000229] [batchtime 0.398]
[epoch 171], [iter 23 / 176], [train main loss -1.978641], [lr 0.000229] [batchtime 0.398]
[epoch 171], [iter 24 / 176], [train main loss -2.001161], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 25 / 176], [train main loss -2.048052], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 26 / 176], [train main loss -2.005731], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 27 / 176], [train main loss -2.052553], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 28 / 176], [train main loss -2.050519], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 29 / 176], [train main loss -2.015307], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 30 / 176], [train main loss -2.049703], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 31 / 176], [train main loss -2.015882], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 32 / 176], [train main loss -1.951733], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 33 / 176], [train main loss -1.965804], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 34 / 176], [train main loss -1.943415], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 35 / 176], [train main loss -1.968576], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 36 / 176], [train main loss -1.997554], [lr 0.000229] [batchtime 0.399]
[epoch 171], [iter 37 / 176], [train main loss -2.001091], [lr 0.000229] [batchtime 0.405]
[epoch 171], [iter 38 / 176], [train main loss -2.024547], [lr 0.000229] [batchtime 0.452]
[epoch 171], [iter 39 / 176], [train main loss -2.027942], [lr 0.000229] [batchtime 0.45]
[epoch 171], [iter 40 / 176], [train main loss -2.093342], [lr 0.000229] [batchtime 0.448]
[epoch 171], [iter 41 / 176], [train main loss -2.048735], [lr 0.000229] [batchtime 0.446]
[epoch 171], [iter 42 / 176], [train main loss -2.044289], [lr 0.000229] [batchtime 0.444]
[epoch 171], [iter 43 / 176], [train main loss -2.052622], [lr 0.000229] [batchtime 0.443]
[epoch 171], [iter 44 / 176], [train main loss -2.037147], [lr 0.000229] [batchtime 0.442]
[epoch 171], [iter 45 / 176], [train main loss -2.036045], [lr 0.000229] [batchtime 0.44]
[epoch 171], [iter 46 / 176], [train main loss -1.994017], [lr 0.000229] [batchtime 0.439]
[epoch 171], [iter 47 / 176], [train main loss -2.039138], [lr 0.000229] [batchtime 0.438]
[epoch 171], [iter 48 / 176], [train main loss -2.025270], [lr 0.000229] [batchtime 0.437]
[epoch 171], [iter 49 / 176], [train main loss -2.066313], [lr 0.000229] [batchtime 0.436]
[epoch 171], [iter 50 / 176], [train main loss -2.037735], [lr 0.000229] [batchtime 0.435]
[epoch 171], [iter 51 / 176], [train main loss -2.066708], [lr 0.000229] [batchtime 0.434]
[epoch 171], [iter 52 / 176], [train main loss -2.062088], [lr 0.000229] [batchtime 0.433]
[epoch 171], [iter 53 / 176], [train main loss -2.071451], [lr 0.000229] [batchtime 0.433]
[epoch 171], [iter 54 / 176], [train main loss -2.047380], [lr 0.000229] [batchtime 0.432]
[epoch 171], [iter 55 / 176], [train main loss -1.994097], [lr 0.000229] [batchtime 0.431]
[epoch 171], [iter 56 / 176], [train main loss -2.034310], [lr 0.000229] [batchtime 0.431]
[epoch 171], [iter 57 / 176], [train main loss -2.044765], [lr 0.000229] [batchtime 0.43]
[epoch 171], [iter 58 / 176], [train main loss -2.039059], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 59 / 176], [train main loss -2.075027], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 60 / 176], [train main loss -2.078144], [lr 0.000229] [batchtime 0.428]
[epoch 171], [iter 61 / 176], [train main loss -2.138886], [lr 0.000229] [batchtime 0.427]
[epoch 171], [iter 62 / 176], [train main loss -2.129821], [lr 0.000229] [batchtime 0.427]
[epoch 171], [iter 63 / 176], [train main loss -2.168797], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 64 / 176], [train main loss -2.129049], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 65 / 176], [train main loss -2.116125], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 66 / 176], [train main loss -2.123886], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 67 / 176], [train main loss -2.116474], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 68 / 176], [train main loss -2.133832], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 69 / 176], [train main loss -2.130699], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 70 / 176], [train main loss -2.154814], [lr 0.000229] [batchtime 0.422]
[epoch 171], [iter 71 / 176], [train main loss -2.135441], [lr 0.000229] [batchtime 0.422]
[epoch 171], [iter 72 / 176], [train main loss -2.146170], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 73 / 176], [train main loss -2.136069], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 74 / 176], [train main loss -2.131926], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 75 / 176], [train main loss -2.137953], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 76 / 176], [train main loss -2.135315], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 77 / 176], [train main loss -2.130415], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 78 / 176], [train main loss -2.113159], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 79 / 176], [train main loss -2.155753], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 80 / 176], [train main loss -2.162609], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 81 / 176], [train main loss -2.129191], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 82 / 176], [train main loss -2.129769], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 83 / 176], [train main loss -2.124577], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 84 / 176], [train main loss -2.142678], [lr 0.000229] [batchtime 0.439]
[epoch 171], [iter 85 / 176], [train main loss -2.140871], [lr 0.000229] [batchtime 0.438]
[epoch 171], [iter 86 / 176], [train main loss -2.130918], [lr 0.000229] [batchtime 0.437]
[epoch 171], [iter 87 / 176], [train main loss -2.113998], [lr 0.000229] [batchtime 0.437]
[epoch 171], [iter 88 / 176], [train main loss -2.092166], [lr 0.000229] [batchtime 0.436]
[epoch 171], [iter 89 / 176], [train main loss -2.057313], [lr 0.000229] [batchtime 0.436]
[epoch 171], [iter 90 / 176], [train main loss -2.031789], [lr 0.000229] [batchtime 0.435]
[epoch 171], [iter 91 / 176], [train main loss -2.011982], [lr 0.000229] [batchtime 0.435]
[epoch 171], [iter 92 / 176], [train main loss -2.021364], [lr 0.000229] [batchtime 0.434]
[epoch 171], [iter 93 / 176], [train main loss -2.032035], [lr 0.000229] [batchtime 0.434]
[epoch 171], [iter 94 / 176], [train main loss -2.030873], [lr 0.000229] [batchtime 0.433]
[epoch 171], [iter 95 / 176], [train main loss -2.042507], [lr 0.000229] [batchtime 0.433]
[epoch 171], [iter 96 / 176], [train main loss -2.040409], [lr 0.000229] [batchtime 0.433]
[epoch 171], [iter 97 / 176], [train main loss -2.078574], [lr 0.000229] [batchtime 0.432]
[epoch 171], [iter 98 / 176], [train main loss -2.057744], [lr 0.000229] [batchtime 0.432]
[epoch 171], [iter 99 / 176], [train main loss -2.038053], [lr 0.000229] [batchtime 0.431]
[epoch 171], [iter 100 / 176], [train main loss -2.044421], [lr 0.000229] [batchtime 0.431]
[epoch 171], [iter 101 / 176], [train main loss -2.045846], [lr 0.000229] [batchtime 0.431]
[epoch 171], [iter 102 / 176], [train main loss -2.058793], [lr 0.000229] [batchtime 0.43]
[epoch 171], [iter 103 / 176], [train main loss -2.058985], [lr 0.000229] [batchtime 0.43]
[epoch 171], [iter 104 / 176], [train main loss -2.058238], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 105 / 176], [train main loss -2.051241], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 106 / 176], [train main loss -2.030299], [lr 0.000229] [batchtime 0.43]
[epoch 171], [iter 107 / 176], [train main loss -2.031181], [lr 0.000229] [batchtime 0.43]
[epoch 171], [iter 108 / 176], [train main loss -2.024708], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 109 / 176], [train main loss -2.039240], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 110 / 176], [train main loss -2.028898], [lr 0.000229] [batchtime 0.429]
[epoch 171], [iter 111 / 176], [train main loss -2.034597], [lr 0.000229] [batchtime 0.428]
[epoch 171], [iter 112 / 176], [train main loss -2.020609], [lr 0.000229] [batchtime 0.428]
[epoch 171], [iter 113 / 176], [train main loss -2.017903], [lr 0.000229] [batchtime 0.427]
[epoch 171], [iter 114 / 176], [train main loss -2.016877], [lr 0.000229] [batchtime 0.427]
[epoch 171], [iter 115 / 176], [train main loss -2.011339], [lr 0.000229] [batchtime 0.427]
[epoch 171], [iter 116 / 176], [train main loss -2.043658], [lr 0.000229] [batchtime 0.427]
[epoch 171], [iter 117 / 176], [train main loss -2.048236], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 118 / 176], [train main loss -2.067316], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 119 / 176], [train main loss -2.073343], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 120 / 176], [train main loss -2.066409], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 121 / 176], [train main loss -2.062681], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 122 / 176], [train main loss -2.061276], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 123 / 176], [train main loss -2.045041], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 124 / 176], [train main loss -2.049693], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 125 / 176], [train main loss -2.052696], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 126 / 176], [train main loss -2.048882], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 127 / 176], [train main loss -2.052063], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 128 / 176], [train main loss -2.038406], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 129 / 176], [train main loss -2.025274], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 130 / 176], [train main loss -2.028256], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 131 / 176], [train main loss -2.038904], [lr 0.000229] [batchtime 0.426]
[epoch 171], [iter 132 / 176], [train main loss -2.033151], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 133 / 176], [train main loss -2.049214], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 134 / 176], [train main loss -2.068314], [lr 0.000229] [batchtime 0.425]
[epoch 171], [iter 135 / 176], [train main loss -2.088242], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 136 / 176], [train main loss -2.087887], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 137 / 176], [train main loss -2.081589], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 138 / 176], [train main loss -2.074538], [lr 0.000229] [batchtime 0.424]
[epoch 171], [iter 139 / 176], [train main loss -2.080672], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 140 / 176], [train main loss -2.087874], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 141 / 176], [train main loss -2.078733], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 142 / 176], [train main loss -2.060710], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 143 / 176], [train main loss -2.056441], [lr 0.000229] [batchtime 0.423]
[epoch 171], [iter 144 / 176], [train main loss -2.068189], [lr 0.000229] [batchtime 0.422]
[epoch 171], [iter 145 / 176], [train main loss -2.062246], [lr 0.000229] [batchtime 0.422]
[epoch 171], [iter 146 / 176], [train main loss -2.077282], [lr 0.000229] [batchtime 0.422]
[epoch 171], [iter 147 / 176], [train main loss -2.064668], [lr 0.000229] [batchtime 0.422]
[epoch 171], [iter 148 / 176], [train main loss -2.072827], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 149 / 176], [train main loss -2.068344], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 150 / 176], [train main loss -2.074040], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 151 / 176], [train main loss -2.070070], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 152 / 176], [train main loss -2.057238], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 153 / 176], [train main loss -2.064986], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 154 / 176], [train main loss -2.077449], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 155 / 176], [train main loss -2.074020], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 156 / 176], [train main loss -2.063375], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 157 / 176], [train main loss -2.067850], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 158 / 176], [train main loss -2.077984], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 159 / 176], [train main loss -2.078833], [lr 0.000229] [batchtime 0.421]
[epoch 171], [iter 160 / 176], [train main loss -2.078205], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 161 / 176], [train main loss -2.086673], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 162 / 176], [train main loss -2.069971], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 163 / 176], [train main loss -2.072865], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 164 / 176], [train main loss -2.079138], [lr 0.000229] [batchtime 0.42]
[epoch 171], [iter 165 / 176], [train main loss -2.072865], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 166 / 176], [train main loss -2.071245], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 167 / 176], [train main loss -2.065641], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 168 / 176], [train main loss -2.054182], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 169 / 176], [train main loss -2.044538], [lr 0.000229] [batchtime 0.419]
[epoch 171], [iter 170 / 176], [train main loss -2.048919], [lr 0.000229] [batchtime 0.418]
[epoch 171], [iter 171 / 176], [train main loss -2.034574], [lr 0.000229] [batchtime 0.418]
[epoch 171], [iter 172 / 176], [train main loss -2.037259], [lr 0.000229] [batchtime 0.418]
[epoch 171], [iter 173 / 176], [train main loss -2.041671], [lr 0.000229] [batchtime 0.418]
[epoch 171], [iter 174 / 176], [train main loss -2.055480], [lr 0.000229] [batchtime 0.417]
[epoch 171], [iter 175 / 176], [train main loss -2.050963], [lr 0.000229] [batchtime 0.417]
[epoch 171], [iter 176 / 176], [train main loss -2.061914], [lr 0.000229] [batchtime 0.417]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.10  35.63   0.02  0.03         0.98      0.97
   1  sidewalk          71.15   5.41   0.22  0.19         0.82      0.84
   2  building          87.22  25.07   0.06  0.09         0.94      0.92
   3  wall              18.59   0.15   3.00  1.38         0.25      0.42
   4  fence             26.52   0.40   2.17  0.60         0.32      0.63
   5  pole              40.93   0.59   0.92  0.52         0.52      0.66
   6  traffic light     20.41   0.03   3.46  0.44         0.22      0.69
   7  traffic sign      29.75   0.18   2.12  0.24         0.32      0.81
   8  vegetation        84.53  11.71   0.06  0.13         0.95      0.89
   9  terrain           40.92   0.37   0.97  0.48         0.51      0.68
  10  sky               93.96   3.76   0.03  0.03         0.97      0.97
  11  person            56.47   1.08   0.42  0.35         0.71      0.74
  12  rider             14.78   0.02   4.81  0.96         0.17      0.51
  13  car               86.93   6.72   0.05  0.10         0.95      0.91
  14  truck              2.27   0.01  42.62  0.44         0.02      0.69
  15  bus               16.49   0.04   0.96  4.10         0.51      0.20
  16  train             37.34   0.09   1.02  0.65         0.49      0.60
  17  motorcycle         6.05   0.01  14.94  0.59         0.06      0.63
  18  bicycle           41.20   0.28   0.41  1.02         0.71      0.50
Mean: 45.82
-----------------------------------------------------------------------------------------------------------
this : [epoch 171], [val loss 0.28636], [acc 0.91538], [acc_cls 0.54866], [mean_iu 0.45820], [fwavacc 0.85233]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 172], [iter 1 / 176], [train main loss -3.226736], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 2 / 176], [train main loss -2.109382], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 3 / 176], [train main loss -1.854161], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 4 / 176], [train main loss -1.530042], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 5 / 176], [train main loss -1.549140], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 6 / 176], [train main loss -1.742282], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 7 / 176], [train main loss -1.882401], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 8 / 176], [train main loss -1.923697], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 9 / 176], [train main loss -2.152497], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 10 / 176], [train main loss -2.150641], [lr 0.000171] [batchtime 0]
[epoch 172], [iter 11 / 176], [train main loss -2.154480], [lr 0.000171] [batchtime 0.367]
[epoch 172], [iter 12 / 176], [train main loss -2.192328], [lr 0.000171] [batchtime 0.379]
[epoch 172], [iter 13 / 176], [train main loss -2.057705], [lr 0.000171] [batchtime 0.384]
[epoch 172], [iter 14 / 176], [train main loss -2.101688], [lr 0.000171] [batchtime 0.386]
[epoch 172], [iter 15 / 176], [train main loss -1.986233], [lr 0.000171] [batchtime 0.389]
[epoch 172], [iter 16 / 176], [train main loss -1.894863], [lr 0.000171] [batchtime 0.391]
[epoch 172], [iter 17 / 176], [train main loss -2.139975], [lr 0.000171] [batchtime 0.392]
[epoch 172], [iter 18 / 176], [train main loss -2.127108], [lr 0.000171] [batchtime 0.395]
[epoch 172], [iter 19 / 176], [train main loss -2.087014], [lr 0.000171] [batchtime 0.477]
[epoch 172], [iter 20 / 176], [train main loss -2.119177], [lr 0.000171] [batchtime 0.468]
[epoch 172], [iter 21 / 176], [train main loss -2.061492], [lr 0.000171] [batchtime 0.461]
[epoch 172], [iter 22 / 176], [train main loss -2.140972], [lr 0.000171] [batchtime 0.455]
[epoch 172], [iter 23 / 176], [train main loss -2.148410], [lr 0.000171] [batchtime 0.45]
[epoch 172], [iter 24 / 176], [train main loss -2.235330], [lr 0.000171] [batchtime 0.446]
[epoch 172], [iter 25 / 176], [train main loss -2.243322], [lr 0.000171] [batchtime 0.442]
[epoch 172], [iter 26 / 176], [train main loss -2.234453], [lr 0.000171] [batchtime 0.439]
[epoch 172], [iter 27 / 176], [train main loss -2.256411], [lr 0.000171] [batchtime 0.437]
[epoch 172], [iter 28 / 176], [train main loss -2.218588], [lr 0.000171] [batchtime 0.435]
[epoch 172], [iter 29 / 176], [train main loss -2.240686], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 30 / 176], [train main loss -2.329722], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 31 / 176], [train main loss -2.365175], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 32 / 176], [train main loss -2.351055], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 33 / 176], [train main loss -2.340912], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 34 / 176], [train main loss -2.375879], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 35 / 176], [train main loss -2.427410], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 36 / 176], [train main loss -2.372083], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 37 / 176], [train main loss -2.339422], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 38 / 176], [train main loss -2.338598], [lr 0.000171] [batchtime 0.48]
[epoch 172], [iter 39 / 176], [train main loss -2.319862], [lr 0.000171] [batchtime 0.476]
[epoch 172], [iter 40 / 176], [train main loss -2.346619], [lr 0.000171] [batchtime 0.473]
[epoch 172], [iter 41 / 176], [train main loss -2.322971], [lr 0.000171] [batchtime 0.47]
[epoch 172], [iter 42 / 176], [train main loss -2.336788], [lr 0.000171] [batchtime 0.467]
[epoch 172], [iter 43 / 176], [train main loss -2.348991], [lr 0.000171] [batchtime 0.465]
[epoch 172], [iter 44 / 176], [train main loss -2.410968], [lr 0.000171] [batchtime 0.463]
[epoch 172], [iter 45 / 176], [train main loss -2.392327], [lr 0.000171] [batchtime 0.461]
[epoch 172], [iter 46 / 176], [train main loss -2.364893], [lr 0.000171] [batchtime 0.459]
[epoch 172], [iter 47 / 176], [train main loss -2.426763], [lr 0.000171] [batchtime 0.457]
[epoch 172], [iter 48 / 176], [train main loss -2.424604], [lr 0.000171] [batchtime 0.456]
[epoch 172], [iter 49 / 176], [train main loss -2.387469], [lr 0.000171] [batchtime 0.454]
[epoch 172], [iter 50 / 176], [train main loss -2.391436], [lr 0.000171] [batchtime 0.452]
[epoch 172], [iter 51 / 176], [train main loss -2.375218], [lr 0.000171] [batchtime 0.451]
[epoch 172], [iter 52 / 176], [train main loss -2.361769], [lr 0.000171] [batchtime 0.45]
[epoch 172], [iter 53 / 176], [train main loss -2.421795], [lr 0.000171] [batchtime 0.448]
[epoch 172], [iter 54 / 176], [train main loss -2.373795], [lr 0.000171] [batchtime 0.447]
[epoch 172], [iter 55 / 176], [train main loss -2.384381], [lr 0.000171] [batchtime 0.446]
[epoch 172], [iter 56 / 176], [train main loss -2.401357], [lr 0.000171] [batchtime 0.445]
[epoch 172], [iter 57 / 176], [train main loss -2.380465], [lr 0.000171] [batchtime 0.444]
[epoch 172], [iter 58 / 176], [train main loss -2.384928], [lr 0.000171] [batchtime 0.443]
[epoch 172], [iter 59 / 176], [train main loss -2.360880], [lr 0.000171] [batchtime 0.442]
[epoch 172], [iter 60 / 176], [train main loss -2.371448], [lr 0.000171] [batchtime 0.443]
[epoch 172], [iter 61 / 176], [train main loss -2.371396], [lr 0.000171] [batchtime 0.442]
[epoch 172], [iter 62 / 176], [train main loss -2.353041], [lr 0.000171] [batchtime 0.441]
[epoch 172], [iter 63 / 176], [train main loss -2.359531], [lr 0.000171] [batchtime 0.441]
[epoch 172], [iter 64 / 176], [train main loss -2.412877], [lr 0.000171] [batchtime 0.44]
[epoch 172], [iter 65 / 176], [train main loss -2.432687], [lr 0.000171] [batchtime 0.439]
[epoch 172], [iter 66 / 176], [train main loss -2.412348], [lr 0.000171] [batchtime 0.438]
[epoch 172], [iter 67 / 176], [train main loss -2.411905], [lr 0.000171] [batchtime 0.437]
[epoch 172], [iter 68 / 176], [train main loss -2.404279], [lr 0.000171] [batchtime 0.437]
[epoch 172], [iter 69 / 176], [train main loss -2.374057], [lr 0.000171] [batchtime 0.436]
[epoch 172], [iter 70 / 176], [train main loss -2.327664], [lr 0.000171] [batchtime 0.435]
[epoch 172], [iter 71 / 176], [train main loss -2.320851], [lr 0.000171] [batchtime 0.435]
[epoch 172], [iter 72 / 176], [train main loss -2.353365], [lr 0.000171] [batchtime 0.434]
[epoch 172], [iter 73 / 176], [train main loss -2.341828], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 74 / 176], [train main loss -2.341072], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 75 / 176], [train main loss -2.361176], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 76 / 176], [train main loss -2.310498], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 77 / 176], [train main loss -2.312588], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 78 / 176], [train main loss -2.286240], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 79 / 176], [train main loss -2.290862], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 80 / 176], [train main loss -2.300739], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 81 / 176], [train main loss -2.271993], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 82 / 176], [train main loss -2.273905], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 83 / 176], [train main loss -2.263744], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 84 / 176], [train main loss -2.259572], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 85 / 176], [train main loss -2.259474], [lr 0.000171] [batchtime 0.447]
[epoch 172], [iter 86 / 176], [train main loss -2.245777], [lr 0.000171] [batchtime 0.446]
[epoch 172], [iter 87 / 176], [train main loss -2.268523], [lr 0.000171] [batchtime 0.445]
[epoch 172], [iter 88 / 176], [train main loss -2.291734], [lr 0.000171] [batchtime 0.445]
[epoch 172], [iter 89 / 176], [train main loss -2.314621], [lr 0.000171] [batchtime 0.444]
[epoch 172], [iter 90 / 176], [train main loss -2.315337], [lr 0.000171] [batchtime 0.444]
[epoch 172], [iter 91 / 176], [train main loss -2.325113], [lr 0.000171] [batchtime 0.443]
[epoch 172], [iter 92 / 176], [train main loss -2.310115], [lr 0.000171] [batchtime 0.442]
[epoch 172], [iter 93 / 176], [train main loss -2.322580], [lr 0.000171] [batchtime 0.442]
[epoch 172], [iter 94 / 176], [train main loss -2.324105], [lr 0.000171] [batchtime 0.441]
[epoch 172], [iter 95 / 176], [train main loss -2.312269], [lr 0.000171] [batchtime 0.441]
[epoch 172], [iter 96 / 176], [train main loss -2.324544], [lr 0.000171] [batchtime 0.44]
[epoch 172], [iter 97 / 176], [train main loss -2.331089], [lr 0.000171] [batchtime 0.44]
[epoch 172], [iter 98 / 176], [train main loss -2.309841], [lr 0.000171] [batchtime 0.44]
[epoch 172], [iter 99 / 176], [train main loss -2.295270], [lr 0.000171] [batchtime 0.439]
[epoch 172], [iter 100 / 176], [train main loss -2.296258], [lr 0.000171] [batchtime 0.438]
[epoch 172], [iter 101 / 176], [train main loss -2.307314], [lr 0.000171] [batchtime 0.438]
[epoch 172], [iter 102 / 176], [train main loss -2.285635], [lr 0.000171] [batchtime 0.438]
[epoch 172], [iter 103 / 176], [train main loss -2.291924], [lr 0.000171] [batchtime 0.437]
[epoch 172], [iter 104 / 176], [train main loss -2.283818], [lr 0.000171] [batchtime 0.437]
[epoch 172], [iter 105 / 176], [train main loss -2.271429], [lr 0.000171] [batchtime 0.436]
[epoch 172], [iter 106 / 176], [train main loss -2.280518], [lr 0.000171] [batchtime 0.436]
[epoch 172], [iter 107 / 176], [train main loss -2.294726], [lr 0.000171] [batchtime 0.437]
[epoch 172], [iter 108 / 176], [train main loss -2.287982], [lr 0.000171] [batchtime 0.436]
[epoch 172], [iter 109 / 176], [train main loss -2.271657], [lr 0.000171] [batchtime 0.436]
[epoch 172], [iter 110 / 176], [train main loss -2.244244], [lr 0.000171] [batchtime 0.436]
[epoch 172], [iter 111 / 176], [train main loss -2.240453], [lr 0.000171] [batchtime 0.435]
[epoch 172], [iter 112 / 176], [train main loss -2.230633], [lr 0.000171] [batchtime 0.435]
[epoch 172], [iter 113 / 176], [train main loss -2.241291], [lr 0.000171] [batchtime 0.434]
[epoch 172], [iter 114 / 176], [train main loss -2.233471], [lr 0.000171] [batchtime 0.434]
[epoch 172], [iter 115 / 176], [train main loss -2.247966], [lr 0.000171] [batchtime 0.434]
[epoch 172], [iter 116 / 176], [train main loss -2.254397], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 117 / 176], [train main loss -2.286967], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 118 / 176], [train main loss -2.281265], [lr 0.000171] [batchtime 0.433]
[epoch 172], [iter 119 / 176], [train main loss -2.261900], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 120 / 176], [train main loss -2.263343], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 121 / 176], [train main loss -2.268240], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 122 / 176], [train main loss -2.255209], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 123 / 176], [train main loss -2.261441], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 124 / 176], [train main loss -2.259702], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 125 / 176], [train main loss -2.241134], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 126 / 176], [train main loss -2.238939], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 127 / 176], [train main loss -2.239657], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 128 / 176], [train main loss -2.235721], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 129 / 176], [train main loss -2.228043], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 130 / 176], [train main loss -2.223781], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 131 / 176], [train main loss -2.224662], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 132 / 176], [train main loss -2.243689], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 133 / 176], [train main loss -2.229255], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 134 / 176], [train main loss -2.236553], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 135 / 176], [train main loss -2.214174], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 136 / 176], [train main loss -2.228268], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 137 / 176], [train main loss -2.224814], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 138 / 176], [train main loss -2.215187], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 139 / 176], [train main loss -2.208930], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 140 / 176], [train main loss -2.209611], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 141 / 176], [train main loss -2.230087], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 142 / 176], [train main loss -2.218229], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 143 / 176], [train main loss -2.196436], [lr 0.000171] [batchtime 0.432]
[epoch 172], [iter 144 / 176], [train main loss -2.203348], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 145 / 176], [train main loss -2.193997], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 146 / 176], [train main loss -2.179678], [lr 0.000171] [batchtime 0.431]
[epoch 172], [iter 147 / 176], [train main loss -2.182876], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 148 / 176], [train main loss -2.201345], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 149 / 176], [train main loss -2.175220], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 150 / 176], [train main loss -2.172568], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 151 / 176], [train main loss -2.189207], [lr 0.000171] [batchtime 0.43]
[epoch 172], [iter 152 / 176], [train main loss -2.191131], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 153 / 176], [train main loss -2.193899], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 154 / 176], [train main loss -2.188170], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 155 / 176], [train main loss -2.201712], [lr 0.000171] [batchtime 0.429]
[epoch 172], [iter 156 / 176], [train main loss -2.175381], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 157 / 176], [train main loss -2.188644], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 158 / 176], [train main loss -2.188987], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 159 / 176], [train main loss -2.191952], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 160 / 176], [train main loss -2.181090], [lr 0.000171] [batchtime 0.428]
[epoch 172], [iter 161 / 176], [train main loss -2.170359], [lr 0.000171] [batchtime 0.427]
[epoch 172], [iter 162 / 176], [train main loss -2.185457], [lr 0.000171] [batchtime 0.427]
[epoch 172], [iter 163 / 176], [train main loss -2.183101], [lr 0.000171] [batchtime 0.427]
[epoch 172], [iter 164 / 176], [train main loss -2.175630], [lr 0.000171] [batchtime 0.427]
[epoch 172], [iter 165 / 176], [train main loss -2.192629], [lr 0.000171] [batchtime 0.427]
[epoch 172], [iter 166 / 176], [train main loss -2.180638], [lr 0.000171] [batchtime 0.426]
[epoch 172], [iter 167 / 176], [train main loss -2.173138], [lr 0.000171] [batchtime 0.426]
[epoch 172], [iter 168 / 176], [train main loss -2.173084], [lr 0.000171] [batchtime 0.426]
[epoch 172], [iter 169 / 176], [train main loss -2.190223], [lr 0.000171] [batchtime 0.426]
[epoch 172], [iter 170 / 176], [train main loss -2.179240], [lr 0.000171] [batchtime 0.425]
[epoch 172], [iter 171 / 176], [train main loss -2.180040], [lr 0.000171] [batchtime 0.425]
[epoch 172], [iter 172 / 176], [train main loss -2.177676], [lr 0.000171] [batchtime 0.425]
[epoch 172], [iter 173 / 176], [train main loss -2.188766], [lr 0.000171] [batchtime 0.425]
[epoch 172], [iter 174 / 176], [train main loss -2.186328], [lr 0.000171] [batchtime 0.424]
[epoch 172], [iter 175 / 176], [train main loss -2.194133], [lr 0.000171] [batchtime 0.424]
[epoch 172], [iter 176 / 176], [train main loss -2.185237], [lr 0.000171] [batchtime 0.424]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.10  35.61   0.02  0.03         0.98      0.97
   1  sidewalk          71.33   5.41   0.22  0.18         0.82      0.84
   2  building          87.18  25.03   0.06  0.09         0.94      0.92
   3  wall              19.08   0.15   2.87  1.37         0.26      0.42
   4  fence             27.16   0.41   2.07  0.61         0.33      0.62
   5  pole              40.79   0.58   0.95  0.50         0.51      0.67
   6  traffic light     19.55   0.03   3.70  0.42         0.21      0.70
   7  traffic sign      29.92   0.18   2.10  0.24         0.32      0.81
   8  vegetation        84.29  11.72   0.05  0.13         0.95      0.88
   9  terrain           41.65   0.39   0.90  0.50         0.53      0.67
  10  sky               94.00   3.75   0.03  0.03         0.97      0.97
  11  person            56.52   1.08   0.42  0.35         0.71      0.74
  12  rider             15.30   0.02   4.57  0.96         0.18      0.51
  13  car               86.98   6.73   0.05  0.10         0.95      0.91
  14  truck              2.10   0.01  45.98  0.55         0.02      0.64
  15  bus               16.53   0.05   0.86  4.19         0.54      0.19
  16  train             36.86   0.08   1.11  0.60         0.47      0.62
  17  motorcycle         6.02   0.01  14.98  0.63         0.06      0.61
  18  bicycle           40.71   0.28   0.40  1.05         0.71      0.49
Mean: 45.85
-----------------------------------------------------------------------------------------------------------
this : [epoch 172], [val loss 0.28885], [acc 0.91520], [acc_cls 0.55062], [mean_iu 0.45845], [fwavacc 0.85224]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 173], [iter 1 / 176], [train main loss -1.634011], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 2 / 176], [train main loss -2.034483], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 3 / 176], [train main loss -3.234231], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 4 / 176], [train main loss -3.111460], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 5 / 176], [train main loss -3.489376], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 6 / 176], [train main loss -3.269039], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 7 / 176], [train main loss -2.819701], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 8 / 176], [train main loss -2.953738], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 9 / 176], [train main loss -2.908030], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 10 / 176], [train main loss -2.973289], [lr 0.000114] [batchtime 0]
[epoch 173], [iter 11 / 176], [train main loss -2.879730], [lr 0.000114] [batchtime 0.384]
[epoch 173], [iter 12 / 176], [train main loss -2.762573], [lr 0.000114] [batchtime 0.39]
[epoch 173], [iter 13 / 176], [train main loss -2.572838], [lr 0.000114] [batchtime 0.393]
[epoch 173], [iter 14 / 176], [train main loss -2.582710], [lr 0.000114] [batchtime 0.398]
[epoch 173], [iter 15 / 176], [train main loss -2.628338], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 16 / 176], [train main loss -2.667177], [lr 0.000114] [batchtime 0.4]
[epoch 173], [iter 17 / 176], [train main loss -2.600868], [lr 0.000114] [batchtime 0.4]
[epoch 173], [iter 18 / 176], [train main loss -2.604532], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 19 / 176], [train main loss -2.513439], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 20 / 176], [train main loss -2.504730], [lr 0.000114] [batchtime 0.4]
[epoch 173], [iter 21 / 176], [train main loss -2.486302], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 22 / 176], [train main loss -2.514752], [lr 0.000114] [batchtime 0.398]
[epoch 173], [iter 23 / 176], [train main loss -2.553104], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 24 / 176], [train main loss -2.510731], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 25 / 176], [train main loss -2.495843], [lr 0.000114] [batchtime 0.4]
[epoch 173], [iter 26 / 176], [train main loss -2.386445], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 27 / 176], [train main loss -2.372655], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 28 / 176], [train main loss -2.345790], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 29 / 176], [train main loss -2.307664], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 30 / 176], [train main loss -2.263533], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 31 / 176], [train main loss -2.221636], [lr 0.000114] [batchtime 0.399]
[epoch 173], [iter 32 / 176], [train main loss -2.271642], [lr 0.000114] [batchtime 0.4]
[epoch 173], [iter 33 / 176], [train main loss -2.230077], [lr 0.000114] [batchtime 0.4]
[epoch 173], [iter 34 / 176], [train main loss -2.247233], [lr 0.000114] [batchtime 0.406]
[epoch 173], [iter 35 / 176], [train main loss -2.320600], [lr 0.000114] [batchtime 0.462]
[epoch 173], [iter 36 / 176], [train main loss -2.338036], [lr 0.000114] [batchtime 0.459]
[epoch 173], [iter 37 / 176], [train main loss -2.320345], [lr 0.000114] [batchtime 0.456]
[epoch 173], [iter 38 / 176], [train main loss -2.306681], [lr 0.000114] [batchtime 0.454]
[epoch 173], [iter 39 / 176], [train main loss -2.318989], [lr 0.000114] [batchtime 0.451]
[epoch 173], [iter 40 / 176], [train main loss -2.301725], [lr 0.000114] [batchtime 0.45]
[epoch 173], [iter 41 / 176], [train main loss -2.336725], [lr 0.000114] [batchtime 0.448]
[epoch 173], [iter 42 / 176], [train main loss -2.327477], [lr 0.000114] [batchtime 0.446]
[epoch 173], [iter 43 / 176], [train main loss -2.358219], [lr 0.000114] [batchtime 0.445]
[epoch 173], [iter 44 / 176], [train main loss -2.308488], [lr 0.000114] [batchtime 0.443]
[epoch 173], [iter 45 / 176], [train main loss -2.252623], [lr 0.000114] [batchtime 0.442]
[epoch 173], [iter 46 / 176], [train main loss -2.207801], [lr 0.000114] [batchtime 0.441]
[epoch 173], [iter 47 / 176], [train main loss -2.187827], [lr 0.000114] [batchtime 0.439]
[epoch 173], [iter 48 / 176], [train main loss -2.148169], [lr 0.000114] [batchtime 0.438]
[epoch 173], [iter 49 / 176], [train main loss -2.166006], [lr 0.000114] [batchtime 0.437]
[epoch 173], [iter 50 / 176], [train main loss -2.102949], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 51 / 176], [train main loss -2.121841], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 52 / 176], [train main loss -2.118727], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 53 / 176], [train main loss -2.108106], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 54 / 176], [train main loss -2.090538], [lr 0.000114] [batchtime 0.432]
[epoch 173], [iter 55 / 176], [train main loss -2.050159], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 56 / 176], [train main loss -2.063509], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 57 / 176], [train main loss -2.047274], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 58 / 176], [train main loss -2.038820], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 59 / 176], [train main loss -2.004874], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 60 / 176], [train main loss -2.008059], [lr 0.000114] [batchtime 0.428]
[epoch 173], [iter 61 / 176], [train main loss -1.995327], [lr 0.000114] [batchtime 0.427]
[epoch 173], [iter 62 / 176], [train main loss -2.015725], [lr 0.000114] [batchtime 0.427]
[epoch 173], [iter 63 / 176], [train main loss -2.007699], [lr 0.000114] [batchtime 0.426]
[epoch 173], [iter 64 / 176], [train main loss -1.980932], [lr 0.000114] [batchtime 0.426]
[epoch 173], [iter 65 / 176], [train main loss -2.005922], [lr 0.000114] [batchtime 0.425]
[epoch 173], [iter 66 / 176], [train main loss -1.945523], [lr 0.000114] [batchtime 0.425]
[epoch 173], [iter 67 / 176], [train main loss -1.953807], [lr 0.000114] [batchtime 0.424]
[epoch 173], [iter 68 / 176], [train main loss -1.928114], [lr 0.000114] [batchtime 0.424]
[epoch 173], [iter 69 / 176], [train main loss -1.906620], [lr 0.000114] [batchtime 0.423]
[epoch 173], [iter 70 / 176], [train main loss -1.924046], [lr 0.000114] [batchtime 0.423]
[epoch 173], [iter 71 / 176], [train main loss -1.906711], [lr 0.000114] [batchtime 0.422]
[epoch 173], [iter 72 / 176], [train main loss -1.892050], [lr 0.000114] [batchtime 0.422]
[epoch 173], [iter 73 / 176], [train main loss -1.877771], [lr 0.000114] [batchtime 0.421]
[epoch 173], [iter 74 / 176], [train main loss -1.858755], [lr 0.000114] [batchtime 0.421]
[epoch 173], [iter 75 / 176], [train main loss -1.921563], [lr 0.000114] [batchtime 0.421]
[epoch 173], [iter 76 / 176], [train main loss -1.953643], [lr 0.000114] [batchtime 0.42]
[epoch 173], [iter 77 / 176], [train main loss -1.971777], [lr 0.000114] [batchtime 0.42]
[epoch 173], [iter 78 / 176], [train main loss -1.946168], [lr 0.000114] [batchtime 0.419]
[epoch 173], [iter 79 / 176], [train main loss -1.952456], [lr 0.000114] [batchtime 0.419]
[epoch 173], [iter 80 / 176], [train main loss -1.965451], [lr 0.000114] [batchtime 0.418]
[epoch 173], [iter 81 / 176], [train main loss -1.945311], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 82 / 176], [train main loss -1.929020], [lr 0.000114] [batchtime 0.441]
[epoch 173], [iter 83 / 176], [train main loss -1.932706], [lr 0.000114] [batchtime 0.44]
[epoch 173], [iter 84 / 176], [train main loss -1.906505], [lr 0.000114] [batchtime 0.44]
[epoch 173], [iter 85 / 176], [train main loss -1.904406], [lr 0.000114] [batchtime 0.439]
[epoch 173], [iter 86 / 176], [train main loss -1.897358], [lr 0.000114] [batchtime 0.439]
[epoch 173], [iter 87 / 176], [train main loss -1.877764], [lr 0.000114] [batchtime 0.438]
[epoch 173], [iter 88 / 176], [train main loss -1.872826], [lr 0.000114] [batchtime 0.437]
[epoch 173], [iter 89 / 176], [train main loss -1.840843], [lr 0.000114] [batchtime 0.437]
[epoch 173], [iter 90 / 176], [train main loss -1.836970], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 91 / 176], [train main loss -1.852695], [lr 0.000114] [batchtime 0.442]
[epoch 173], [iter 92 / 176], [train main loss -1.824958], [lr 0.000114] [batchtime 0.442]
[epoch 173], [iter 93 / 176], [train main loss -1.831921], [lr 0.000114] [batchtime 0.441]
[epoch 173], [iter 94 / 176], [train main loss -1.822180], [lr 0.000114] [batchtime 0.44]
[epoch 173], [iter 95 / 176], [train main loss -1.839059], [lr 0.000114] [batchtime 0.44]
[epoch 173], [iter 96 / 176], [train main loss -1.823538], [lr 0.000114] [batchtime 0.439]
[epoch 173], [iter 97 / 176], [train main loss -1.865770], [lr 0.000114] [batchtime 0.439]
[epoch 173], [iter 98 / 176], [train main loss -1.840697], [lr 0.000114] [batchtime 0.438]
[epoch 173], [iter 99 / 176], [train main loss -1.836480], [lr 0.000114] [batchtime 0.438]
[epoch 173], [iter 100 / 176], [train main loss -1.859539], [lr 0.000114] [batchtime 0.437]
[epoch 173], [iter 101 / 176], [train main loss -1.864097], [lr 0.000114] [batchtime 0.437]
[epoch 173], [iter 102 / 176], [train main loss -1.829012], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 103 / 176], [train main loss -1.859256], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 104 / 176], [train main loss -1.846188], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 105 / 176], [train main loss -1.825902], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 106 / 176], [train main loss -1.831259], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 107 / 176], [train main loss -1.826041], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 108 / 176], [train main loss -1.821178], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 109 / 176], [train main loss -1.848497], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 110 / 176], [train main loss -1.848781], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 111 / 176], [train main loss -1.862024], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 112 / 176], [train main loss -1.859588], [lr 0.000114] [batchtime 0.432]
[epoch 173], [iter 113 / 176], [train main loss -1.870444], [lr 0.000114] [batchtime 0.432]
[epoch 173], [iter 114 / 176], [train main loss -1.878726], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 115 / 176], [train main loss -1.867021], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 116 / 176], [train main loss -1.884054], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 117 / 176], [train main loss -1.886960], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 118 / 176], [train main loss -1.882054], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 119 / 176], [train main loss -1.904499], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 120 / 176], [train main loss -1.906391], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 121 / 176], [train main loss -1.934802], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 122 / 176], [train main loss -1.949454], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 123 / 176], [train main loss -1.959895], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 124 / 176], [train main loss -1.960655], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 125 / 176], [train main loss -1.960510], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 126 / 176], [train main loss -1.963094], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 127 / 176], [train main loss -1.982772], [lr 0.000114] [batchtime 0.437]
[epoch 173], [iter 128 / 176], [train main loss -1.978157], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 129 / 176], [train main loss -1.997155], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 130 / 176], [train main loss -2.005725], [lr 0.000114] [batchtime 0.436]
[epoch 173], [iter 131 / 176], [train main loss -2.029641], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 132 / 176], [train main loss -2.031720], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 133 / 176], [train main loss -2.037220], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 134 / 176], [train main loss -2.036790], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 135 / 176], [train main loss -2.039596], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 136 / 176], [train main loss -2.046598], [lr 0.000114] [batchtime 0.434]
[epoch 173], [iter 137 / 176], [train main loss -2.052601], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 138 / 176], [train main loss -2.043432], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 139 / 176], [train main loss -2.038211], [lr 0.000114] [batchtime 0.433]
[epoch 173], [iter 140 / 176], [train main loss -2.032116], [lr 0.000114] [batchtime 0.432]
[epoch 173], [iter 141 / 176], [train main loss -2.029239], [lr 0.000114] [batchtime 0.432]
[epoch 173], [iter 142 / 176], [train main loss -2.037763], [lr 0.000114] [batchtime 0.432]
[epoch 173], [iter 143 / 176], [train main loss -2.046346], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 144 / 176], [train main loss -2.038463], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 145 / 176], [train main loss -2.044921], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 146 / 176], [train main loss -2.052459], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 147 / 176], [train main loss -2.050839], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 148 / 176], [train main loss -2.054549], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 149 / 176], [train main loss -2.065343], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 150 / 176], [train main loss -2.072626], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 151 / 176], [train main loss -2.058951], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 152 / 176], [train main loss -2.047917], [lr 0.000114] [batchtime 0.431]
[epoch 173], [iter 153 / 176], [train main loss -2.050466], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 154 / 176], [train main loss -2.058240], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 155 / 176], [train main loss -2.060566], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 156 / 176], [train main loss -2.065650], [lr 0.000114] [batchtime 0.43]
[epoch 173], [iter 157 / 176], [train main loss -2.066588], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 158 / 176], [train main loss -2.052087], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 159 / 176], [train main loss -2.054587], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 160 / 176], [train main loss -2.056411], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 161 / 176], [train main loss -2.073638], [lr 0.000114] [batchtime 0.429]
[epoch 173], [iter 162 / 176], [train main loss -2.058563], [lr 0.000114] [batchtime 0.428]
[epoch 173], [iter 163 / 176], [train main loss -2.057821], [lr 0.000114] [batchtime 0.428]
[epoch 173], [iter 164 / 176], [train main loss -2.043117], [lr 0.000114] [batchtime 0.428]
[epoch 173], [iter 165 / 176], [train main loss -2.052460], [lr 0.000114] [batchtime 0.428]
[epoch 173], [iter 166 / 176], [train main loss -2.043060], [lr 0.000114] [batchtime 0.428]
[epoch 173], [iter 167 / 176], [train main loss -2.038707], [lr 0.000114] [batchtime 0.427]
[epoch 173], [iter 168 / 176], [train main loss -2.036620], [lr 0.000114] [batchtime 0.427]
[epoch 173], [iter 169 / 176], [train main loss -2.037883], [lr 0.000114] [batchtime 0.427]
[epoch 173], [iter 170 / 176], [train main loss -2.037751], [lr 0.000114] [batchtime 0.426]
[epoch 173], [iter 171 / 176], [train main loss -2.042896], [lr 0.000114] [batchtime 0.426]
[epoch 173], [iter 172 / 176], [train main loss -2.035658], [lr 0.000114] [batchtime 0.426]
[epoch 173], [iter 173 / 176], [train main loss -2.030340], [lr 0.000114] [batchtime 0.425]
[epoch 173], [iter 174 / 176], [train main loss -2.024637], [lr 0.000114] [batchtime 0.426]
[epoch 173], [iter 175 / 176], [train main loss -2.017768], [lr 0.000114] [batchtime 0.435]
[epoch 173], [iter 176 / 176], [train main loss -2.008629], [lr 0.000114] [batchtime 0.435]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.06  35.62   0.02  0.03         0.98      0.97
   1  sidewalk          71.18   5.42   0.22  0.19         0.82      0.84
   2  building          87.13  25.06   0.06  0.09         0.94      0.92
   3  wall              19.58   0.16   2.74  1.37         0.27      0.42
   4  fence             26.60   0.40   2.18  0.58         0.31      0.63
   5  pole              40.73   0.58   0.95  0.51         0.51      0.66
   6  traffic light     18.92   0.03   3.88  0.40         0.20      0.71
   7  traffic sign      28.50   0.17   2.28  0.23         0.30      0.82
   8  vegetation        84.42  11.71   0.06  0.13         0.95      0.89
   9  terrain           41.23   0.38   0.93  0.50         0.52      0.67
  10  sky               94.00   3.75   0.03  0.03         0.97      0.97
  11  person            56.45   1.07   0.43  0.34         0.70      0.74
  12  rider             13.55   0.01   5.59  0.79         0.15      0.56
  13  car               86.95   6.73   0.05  0.10         0.95      0.91
  14  truck              2.50   0.01  38.43  0.49         0.03      0.67
  15  bus               17.06   0.05   0.92  3.94         0.52      0.20
  16  train             36.97   0.08   1.12  0.59         0.47      0.63
  17  motorcycle         5.68   0.01  16.02  0.58         0.06      0.63
  18  bicycle           40.84   0.27   0.42  1.03         0.71      0.49
Mean: 45.65
-----------------------------------------------------------------------------------------------------------
this : [epoch 173], [val loss 0.28892], [acc 0.91516], [acc_cls 0.54579], [mean_iu 0.45651], [fwavacc 0.85183]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2820
cls 0 len 5541
cls 1 len 4897
cls 2 len 5357
cls 3 len 1268
cls 4 len 1537
cls 5 len 5398
cls 6 len 2703
cls 7 len 4610
cls 8 len 5185
cls 9 len 2407
cls 10 len 4436
cls 11 len 3530
cls 12 len 1329
cls 13 len 4864
cls 14 len 415
cls 15 len 398
cls 16 len 183
cls 17 len 551
cls 18 len 2272
[epoch 174], [iter 1 / 176], [train main loss -0.931614], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 2 / 176], [train main loss -0.876208], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 3 / 176], [train main loss -0.606080], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 4 / 176], [train main loss -1.634262], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 5 / 176], [train main loss -1.544705], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 6 / 176], [train main loss -1.695801], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 7 / 176], [train main loss -1.359037], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 8 / 176], [train main loss -1.302289], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 9 / 176], [train main loss -1.428554], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 10 / 176], [train main loss -1.650006], [lr 0.000057] [batchtime 0]
[epoch 174], [iter 11 / 176], [train main loss -1.652952], [lr 0.000057] [batchtime 0.361]
[epoch 174], [iter 12 / 176], [train main loss -1.663142], [lr 0.000057] [batchtime 0.378]
[epoch 174], [iter 13 / 176], [train main loss -1.745678], [lr 0.000057] [batchtime 0.383]
[epoch 174], [iter 14 / 176], [train main loss -1.793340], [lr 0.000057] [batchtime 0.385]
[epoch 174], [iter 15 / 176], [train main loss -1.656395], [lr 0.000057] [batchtime 0.386]
[epoch 174], [iter 16 / 176], [train main loss -1.691889], [lr 0.000057] [batchtime 0.389]
[epoch 174], [iter 17 / 176], [train main loss -1.746077], [lr 0.000057] [batchtime 0.393]
[epoch 174], [iter 18 / 176], [train main loss -1.863464], [lr 0.000057] [batchtime 0.394]
[epoch 174], [iter 19 / 176], [train main loss -1.992490], [lr 0.000057] [batchtime 0.393]
[epoch 174], [iter 20 / 176], [train main loss -2.001112], [lr 0.000057] [batchtime 0.395]
[epoch 174], [iter 21 / 176], [train main loss -2.014538], [lr 0.000057] [batchtime 0.396]
[epoch 174], [iter 22 / 176], [train main loss -2.021117], [lr 0.000057] [batchtime 0.396]
[epoch 174], [iter 23 / 176], [train main loss -1.967471], [lr 0.000057] [batchtime 0.396]
[epoch 174], [iter 24 / 176], [train main loss -1.960717], [lr 0.000057] [batchtime 0.395]
[epoch 174], [iter 25 / 176], [train main loss -1.940282], [lr 0.000057] [batchtime 0.395]
[epoch 174], [iter 26 / 176], [train main loss -1.913443], [lr 0.000057] [batchtime 0.394]
[epoch 174], [iter 27 / 176], [train main loss -1.892497], [lr 0.000057] [batchtime 0.394]
[epoch 174], [iter 28 / 176], [train main loss -1.921824], [lr 0.000057] [batchtime 0.394]
[epoch 174], [iter 29 / 176], [train main loss -1.964068], [lr 0.000057] [batchtime 0.394]
[epoch 174], [iter 30 / 176], [train main loss -1.993210], [lr 0.000057] [batchtime 0.402]
[epoch 174], [iter 31 / 176], [train main loss -2.005089], [lr 0.000057] [batchtime 0.468]
[epoch 174], [iter 32 / 176], [train main loss -1.999918], [lr 0.000057] [batchtime 0.465]
[epoch 174], [iter 33 / 176], [train main loss -1.938211], [lr 0.000057] [batchtime 0.461]
[epoch 174], [iter 34 / 176], [train main loss -1.923456], [lr 0.000057] [batchtime 0.458]
[epoch 174], [iter 35 / 176], [train main loss -1.997454], [lr 0.000057] [batchtime 0.456]
[epoch 174], [iter 36 / 176], [train main loss -2.016999], [lr 0.000057] [batchtime 0.454]
[epoch 174], [iter 37 / 176], [train main loss -1.945594], [lr 0.000057] [batchtime 0.452]
[epoch 174], [iter 38 / 176], [train main loss -1.983216], [lr 0.000057] [batchtime 0.45]
[epoch 174], [iter 39 / 176], [train main loss -2.031308], [lr 0.000057] [batchtime 0.448]
[epoch 174], [iter 40 / 176], [train main loss -2.061873], [lr 0.000057] [batchtime 0.446]
[epoch 174], [iter 41 / 176], [train main loss -2.050451], [lr 0.000057] [batchtime 0.445]
[epoch 174], [iter 42 / 176], [train main loss -2.037053], [lr 0.000057] [batchtime 0.443]
[epoch 174], [iter 43 / 176], [train main loss -2.012992], [lr 0.000057] [batchtime 0.442]
[epoch 174], [iter 44 / 176], [train main loss -2.051291], [lr 0.000057] [batchtime 0.441]
[epoch 174], [iter 45 / 176], [train main loss -2.053690], [lr 0.000057] [batchtime 0.441]
[epoch 174], [iter 46 / 176], [train main loss -2.113029], [lr 0.000057] [batchtime 0.44]
[epoch 174], [iter 47 / 176], [train main loss -2.104138], [lr 0.000057] [batchtime 0.439]
[epoch 174], [iter 48 / 176], [train main loss -2.178302], [lr 0.000057] [batchtime 0.438]
[epoch 174], [iter 49 / 176], [train main loss -2.218059], [lr 0.000057] [batchtime 0.437]
[epoch 174], [iter 50 / 176], [train main loss -2.170602], [lr 0.000057] [batchtime 0.436]
[epoch 174], [iter 51 / 176], [train main loss -2.201235], [lr 0.000057] [batchtime 0.436]
[epoch 174], [iter 52 / 176], [train main loss -2.226137], [lr 0.000057] [batchtime 0.438]
[epoch 174], [iter 53 / 176], [train main loss -2.191424], [lr 0.000057] [batchtime 0.437]
[epoch 174], [iter 54 / 176], [train main loss -2.217004], [lr 0.000057] [batchtime 0.436]
[epoch 174], [iter 55 / 176], [train main loss -2.210106], [lr 0.000057] [batchtime 0.435]
[epoch 174], [iter 56 / 176], [train main loss -2.196423], [lr 0.000057] [batchtime 0.434]
[epoch 174], [iter 57 / 176], [train main loss -2.200718], [lr 0.000057] [batchtime 0.433]
[epoch 174], [iter 58 / 176], [train main loss -2.179363], [lr 0.000057] [batchtime 0.432]
[epoch 174], [iter 59 / 176], [train main loss -2.165607], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 60 / 176], [train main loss -2.133760], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 61 / 176], [train main loss -2.153456], [lr 0.000057] [batchtime 0.43]
[epoch 174], [iter 62 / 176], [train main loss -2.149830], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 63 / 176], [train main loss -2.170448], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 64 / 176], [train main loss -2.159967], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 65 / 176], [train main loss -2.144129], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 66 / 176], [train main loss -2.185016], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 67 / 176], [train main loss -2.169248], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 68 / 176], [train main loss -2.180584], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 69 / 176], [train main loss -2.225430], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 70 / 176], [train main loss -2.181124], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 71 / 176], [train main loss -2.192628], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 72 / 176], [train main loss -2.204573], [lr 0.000057] [batchtime 0.424]
[epoch 174], [iter 73 / 176], [train main loss -2.207564], [lr 0.000057] [batchtime 0.424]
[epoch 174], [iter 74 / 176], [train main loss -2.201629], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 75 / 176], [train main loss -2.191683], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 76 / 176], [train main loss -2.201288], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 77 / 176], [train main loss -2.188985], [lr 0.000057] [batchtime 0.445]
[epoch 174], [iter 78 / 176], [train main loss -2.194276], [lr 0.000057] [batchtime 0.444]
[epoch 174], [iter 79 / 176], [train main loss -2.180571], [lr 0.000057] [batchtime 0.443]
[epoch 174], [iter 80 / 176], [train main loss -2.192746], [lr 0.000057] [batchtime 0.442]
[epoch 174], [iter 81 / 176], [train main loss -2.168194], [lr 0.000057] [batchtime 0.442]
[epoch 174], [iter 82 / 176], [train main loss -2.147550], [lr 0.000057] [batchtime 0.441]
[epoch 174], [iter 83 / 176], [train main loss -2.138976], [lr 0.000057] [batchtime 0.441]
[epoch 174], [iter 84 / 176], [train main loss -2.142996], [lr 0.000057] [batchtime 0.44]
[epoch 174], [iter 85 / 176], [train main loss -2.139759], [lr 0.000057] [batchtime 0.439]
[epoch 174], [iter 86 / 176], [train main loss -2.151376], [lr 0.000057] [batchtime 0.439]
[epoch 174], [iter 87 / 176], [train main loss -2.148119], [lr 0.000057] [batchtime 0.438]
[epoch 174], [iter 88 / 176], [train main loss -2.125493], [lr 0.000057] [batchtime 0.438]
[epoch 174], [iter 89 / 176], [train main loss -2.128903], [lr 0.000057] [batchtime 0.437]
[epoch 174], [iter 90 / 176], [train main loss -2.152536], [lr 0.000057] [batchtime 0.437]
[epoch 174], [iter 91 / 176], [train main loss -2.181821], [lr 0.000057] [batchtime 0.436]
[epoch 174], [iter 92 / 176], [train main loss -2.181837], [lr 0.000057] [batchtime 0.436]
[epoch 174], [iter 93 / 176], [train main loss -2.177773], [lr 0.000057] [batchtime 0.435]
[epoch 174], [iter 94 / 176], [train main loss -2.157805], [lr 0.000057] [batchtime 0.435]
[epoch 174], [iter 95 / 176], [train main loss -2.157118], [lr 0.000057] [batchtime 0.435]
[epoch 174], [iter 96 / 176], [train main loss -2.177840], [lr 0.000057] [batchtime 0.434]
[epoch 174], [iter 97 / 176], [train main loss -2.182584], [lr 0.000057] [batchtime 0.434]
[epoch 174], [iter 98 / 176], [train main loss -2.209269], [lr 0.000057] [batchtime 0.434]
[epoch 174], [iter 99 / 176], [train main loss -2.198234], [lr 0.000057] [batchtime 0.435]
[epoch 174], [iter 100 / 176], [train main loss -2.189520], [lr 0.000057] [batchtime 0.434]
[epoch 174], [iter 101 / 176], [train main loss -2.187457], [lr 0.000057] [batchtime 0.434]
[epoch 174], [iter 102 / 176], [train main loss -2.211550], [lr 0.000057] [batchtime 0.433]
[epoch 174], [iter 103 / 176], [train main loss -2.223073], [lr 0.000057] [batchtime 0.433]
[epoch 174], [iter 104 / 176], [train main loss -2.231476], [lr 0.000057] [batchtime 0.433]
[epoch 174], [iter 105 / 176], [train main loss -2.230830], [lr 0.000057] [batchtime 0.432]
[epoch 174], [iter 106 / 176], [train main loss -2.217432], [lr 0.000057] [batchtime 0.432]
[epoch 174], [iter 107 / 176], [train main loss -2.245669], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 108 / 176], [train main loss -2.265372], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 109 / 176], [train main loss -2.274269], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 110 / 176], [train main loss -2.246729], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 111 / 176], [train main loss -2.257737], [lr 0.000057] [batchtime 0.43]
[epoch 174], [iter 112 / 176], [train main loss -2.261557], [lr 0.000057] [batchtime 0.43]
[epoch 174], [iter 113 / 176], [train main loss -2.241742], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 114 / 176], [train main loss -2.236634], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 115 / 176], [train main loss -2.236985], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 116 / 176], [train main loss -2.227138], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 117 / 176], [train main loss -2.246403], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 118 / 176], [train main loss -2.264322], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 119 / 176], [train main loss -2.266437], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 120 / 176], [train main loss -2.268328], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 121 / 176], [train main loss -2.270679], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 122 / 176], [train main loss -2.263340], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 123 / 176], [train main loss -2.238523], [lr 0.000057] [batchtime 0.432]
[epoch 174], [iter 124 / 176], [train main loss -2.247553], [lr 0.000057] [batchtime 0.432]
[epoch 174], [iter 125 / 176], [train main loss -2.239267], [lr 0.000057] [batchtime 0.432]
[epoch 174], [iter 126 / 176], [train main loss -2.259650], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 127 / 176], [train main loss -2.266763], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 128 / 176], [train main loss -2.285758], [lr 0.000057] [batchtime 0.431]
[epoch 174], [iter 129 / 176], [train main loss -2.274142], [lr 0.000057] [batchtime 0.43]
[epoch 174], [iter 130 / 176], [train main loss -2.278269], [lr 0.000057] [batchtime 0.43]
[epoch 174], [iter 131 / 176], [train main loss -2.279185], [lr 0.000057] [batchtime 0.43]
[epoch 174], [iter 132 / 176], [train main loss -2.276756], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 133 / 176], [train main loss -2.275523], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 134 / 176], [train main loss -2.283776], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 135 / 176], [train main loss -2.274647], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 136 / 176], [train main loss -2.262011], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 137 / 176], [train main loss -2.252225], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 138 / 176], [train main loss -2.249019], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 139 / 176], [train main loss -2.250968], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 140 / 176], [train main loss -2.260546], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 141 / 176], [train main loss -2.262244], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 142 / 176], [train main loss -2.257534], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 143 / 176], [train main loss -2.256253], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 144 / 176], [train main loss -2.235961], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 145 / 176], [train main loss -2.241767], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 146 / 176], [train main loss -2.262572], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 147 / 176], [train main loss -2.257680], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 148 / 176], [train main loss -2.266529], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 149 / 176], [train main loss -2.270750], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 150 / 176], [train main loss -2.279975], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 151 / 176], [train main loss -2.290262], [lr 0.000057] [batchtime 0.426]
[epoch 174], [iter 152 / 176], [train main loss -2.276844], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 153 / 176], [train main loss -2.276471], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 154 / 176], [train main loss -2.299602], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 155 / 176], [train main loss -2.305603], [lr 0.000057] [batchtime 0.425]
[epoch 174], [iter 156 / 176], [train main loss -2.322139], [lr 0.000057] [batchtime 0.424]
[epoch 174], [iter 157 / 176], [train main loss -2.329269], [lr 0.000057] [batchtime 0.424]
[epoch 174], [iter 158 / 176], [train main loss -2.311776], [lr 0.000057] [batchtime 0.424]
[epoch 174], [iter 159 / 176], [train main loss -2.295135], [lr 0.000057] [batchtime 0.424]
[epoch 174], [iter 160 / 176], [train main loss -2.291343], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 161 / 176], [train main loss -2.278249], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 162 / 176], [train main loss -2.259432], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 163 / 176], [train main loss -2.259697], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 164 / 176], [train main loss -2.239744], [lr 0.000057] [batchtime 0.423]
[epoch 174], [iter 165 / 176], [train main loss -2.242640], [lr 0.000057] [batchtime 0.422]
[epoch 174], [iter 166 / 176], [train main loss -2.254254], [lr 0.000057] [batchtime 0.422]
[epoch 174], [iter 167 / 176], [train main loss -2.259112], [lr 0.000057] [batchtime 0.422]
[epoch 174], [iter 168 / 176], [train main loss -2.251689], [lr 0.000057] [batchtime 0.422]
[epoch 174], [iter 169 / 176], [train main loss -2.263808], [lr 0.000057] [batchtime 0.422]
[epoch 174], [iter 170 / 176], [train main loss -2.270238], [lr 0.000057] [batchtime 0.421]
[epoch 174], [iter 171 / 176], [train main loss -2.282560], [lr 0.000057] [batchtime 0.421]
[epoch 174], [iter 172 / 176], [train main loss -2.278000], [lr 0.000057] [batchtime 0.427]
[epoch 174], [iter 173 / 176], [train main loss -2.278790], [lr 0.000057] [batchtime 0.429]
[epoch 174], [iter 174 / 176], [train main loss -2.256792], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 175 / 176], [train main loss -2.260215], [lr 0.000057] [batchtime 0.428]
[epoch 174], [iter 176 / 176], [train main loss -2.246408], [lr 0.000057] [batchtime 0.428]
validating[Iter: 1 / 81]
validating[Iter: 21 / 81]
validating[Iter: 41 / 81]
validating[Iter: 61 / 81]
validating[Iter: 81 / 81]
IoU:
  Id  label            iU_1.0     TP     FP    FN    Precision    Recall
----  -------------  --------  -----  -----  ----  -----------  --------
   0  road              95.06  35.61   0.02  0.03         0.98      0.97
   1  sidewalk          71.20   5.39   0.22  0.18         0.82      0.85
   2  building          87.19  25.07   0.06  0.09         0.94      0.92
   3  wall              18.95   0.15   2.89  1.38         0.26      0.42
   4  fence             26.68   0.41   2.13  0.62         0.32      0.62
   5  pole              40.86   0.58   0.95  0.50         0.51      0.67
   6  traffic light     20.07   0.03   3.55  0.44         0.22      0.70
   7  traffic sign      30.91   0.19   1.97  0.27         0.34      0.79
   8  vegetation        84.55  11.69   0.06  0.12         0.95      0.89
   9  terrain           41.48   0.39   0.87  0.54         0.54      0.65
  10  sky               94.02   3.76   0.03  0.03         0.97      0.97
  11  person            56.74   1.08   0.42  0.34         0.70      0.74
  12  rider             15.52   0.02   4.51  0.94         0.18      0.52
  13  car               86.72   6.73   0.05  0.10         0.95      0.91
  14  truck              2.07   0.01  46.72  0.52         0.02      0.66
  15  bus               16.73   0.04   0.94  4.04         0.51      0.20
  16  train             40.15   0.09   0.92  0.57         0.52      0.64
  17  motorcycle         5.93   0.01  15.22  0.66         0.06      0.60
  18  bicycle           40.95   0.27   0.43  1.01         0.70      0.50
Mean: 46.09
-----------------------------------------------------------------------------------------------------------
this : [epoch 174], [val loss 0.28579], [acc 0.91531], [acc_cls 0.55227], [mean_iu 0.46093], [fwavacc 0.85226]
best : [epoch 168], [val loss 0.28885], [acc 0.91553], [acc_cls 0.55072], [mean_iu 0.46198], [fwavacc 0.85223]
-----------------------------------------------------------------------------------------------------------
